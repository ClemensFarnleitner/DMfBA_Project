,answer_id,vote_count,answer_content,creation_date,user_name,user_profile_link,reputation_score,post_id
79049681,79049681,0,"What is the use case for this scenario? Is it the classification or regression problem? It always depends on the training data. From training data, the model learns how to predict. If you have the same output value for X1 and X3, the model will also expect the same predicted value for these features for test data.


I don't know any reason to constrain model output for concrete values. If you want the output to be the same for x1 and x3, you can pick the predicted value for x1 and replace it with the predicted value for x3.",2024-10-03T08:20:49,Maurever,https://stackoverflow.com/users/5036600/maurever,157,79045928
79038349,79038349,0,"I think there might be two issues:




installing correct version of java,


telling H2O where the java is.




I'm not sure what's the best way to do the (1) but I think I might help with the (2).


Once you install java and if it doesn't work, it's likely due to different than usual file paths. To mitigate this issue you can set 
JAVA_HOME
 or 
H2O_JAVA_HOME
 environment variables to point to your java installation or you can even 
start the h2o backend manually
 and then call 
h2o.connect()
 instead of 
h2o.init()
.",2024-09-30T07:34:12,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,79033110
78997017,78997017,1,"I couldn't reproduce the issue but I think it might be caused by having different types - if the training frame has factors/enums and test frame integer values then it could cause the first frame to encode so the names could end up something like X1.1 instead of X1.


Could you try 
attributes(x_df_new)[[""types""]]
 and 
attributes(x_df)[[""types""]]
 and then verify that the types are the same?


You can also use 
nn_model_training@model$names
 to find out what names the model used.


Also I would suggest you make sure that the 
y
 is still a factor after the conversion to h2o frame.


You can convert columns to factors in h2o using:

x_df$y <- h2o.asfactor(x_df$y)",2024-09-18T07:30:14,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,78995266
78995415,78995415,1,"Please check and make sure the test data frame 
x_df_new
 has the same predictor column names as your 
x_df
.


You can find the names of a h2o frame by calling 
names(x_df)",2024-09-17T18:47:25,jpsmith,https://stackoverflow.com/users/12109788/jpsmith,16.3k,78995266
78988439,78988439,0,"Looks like the ""JAVA not found"" error from 
agua::h2o_start()
 is coming from a call to 
Sys.which(""java"")
. What output do you see in that case? Do you see different output in a terminal with 
which java
? I might focus on making sure the system knows where to find java using 
which
 as my first debugging route.


Also, some diagnostic messages read:


h2o::h2o.init()
#> Note:  In case of errors look at the following log files:
#>     C:\Users\siava\AppData\Local\Temp\Rtmp08HkaV\filec5072151a2b/h2o_siava_started_from_r.out
#>     C:\Users\siava\AppData\Local\Temp\Rtmp08HkaV\filec50cc92881/h2o_siava_started_from_r.err



Could you re-run 
h2o::h2o.init()
, note the log files shown in the output, attempt to run your tuning code, and then paste the log file contents here?


(For future readers, further discussion of this issue at 
https://github.com/tidymodels/agua/issues/57
).",2024-09-15T22:07:28,Simon Couch,https://stackoverflow.com/users/14038605/simon-couch,531,78986631
78998793,78998793,0,"Turns out
 this user had 
cluster <- parallel::makeCluster(...)
 in their 
.Rprofile
, setting up tidymodels parallelism support.


agua_backend_options(parallelism = 5)
 tells agua to use H2O's within-model parallelism, distributing computations for a single model across 5 cores. 
cluster <- parallel::makeCluster(...)
 tells tidymodels to use its across-model parallelism, fitting 
n_models
/
n_cores
 models per core across 
n_cores
 cores. Setting both of these is an example of ""nested parallelism,"" and is unsupported by agua, as connections to H2O can't be serialized and shipped off to cluster workers. So, either 
agua_backend_options(parallelism = 5)
 or 
cluster <- parallel::makeCluster(...)
 will work, but not both at the same time.",2024-09-18T14:37:11,Simon Couch,https://stackoverflow.com/users/14038605/simon-couch,531,78986631
79004093,79004093,0,"Solved. It doesn't have anything to do with R/H2O version, Java, or Linux/Windows. It was right there but strangely I didn't see the obvious: You need to have a cluster object and every node needs to be initialized. The future package doesn't have a function to return the cluster object nor the ability to initialize nodes properly with complex code, but the parallel package does.


To use the model parallelism for tidymodels and data parallelism for h2o and agua, you need to mix-up parallel, future, and doFuture packages. The parallel packages is used to detect cores, make a cluster, and then load-up and initialize every node. The future and doFuture packages are used to plan a future and register the for.each backend, which is required to enable model-parallelism in tidymodels. Tidymodels specifically uses the future package while agua can work with future, parallel, etc (please correct if wrong).


# H2O for machine learning
library(h2o)

# Initialize local H2O server and start
local_h2o <- h2o::h2o.init(startH2O = TRUE)
local_h2o |> print()

# The agua package provides tidymodels interface to the H2O platform and the
# H2O R package
library(agua)

# Adaptive Parallelism - Decided by H2O
h2o_thread_spec <- agua::agua_backend_options(parallelism = 0)

# To be used when using grid search, racing, or any of the iterative search
# methods in tidymodels.
grid_ctrl <- tune::control_grid(
  allow_par = TRUE,
  save_pred = TRUE,
  save_workflow = TRUE,
  event_level = ""second"",
  # chooses between ""resamples"" and ""everything"" automatically
  parallel_over = NULL,
  backend_options = h2o_thread_spec
)

# Parallel computation libraries
library(future)
library(doFuture)

# Speed up computation with parrallel processing (optional)
n_cores <- parallel::detectCores(logical = TRUE) 
cluster <- parallel::makeCluster(spec = n_cores)
doFuture::registerDoFuture()
strategy <- future::plan(strategy = future::cluster, workers = cluster)

# load, initialize, and check status of h2o on a cluster node
node_h2o_init <- function() {
  library(h2o)
  library(agua)

  # doesn't start a new server if you've already started one
  cluster_init <- h2o.init(startH2O = FALSE)

  c(cluster_init = cluster_init, cluster_status = h2o.clusterIsUp())
}

# initialize and check each node
cluster |>
  parallel::clusterCall(cl = _, fun = node_h2o_init) |>
  purr::list_c()",2024-09-19T19:08:18,,,,78986631
78854135,78854135,0,"I think more appropriate is to do a weighted average since categorical variable has always only one value at a time and I would weigh it by the relative frequency of each level - imagine you have a very rare level that influences the target variable a lot. If you’d use average, this rare level would influence the relative importance more than it should.


Another possibility is to use SHAP via 
predict_contributions
 and set 
output_format = “compact”
. This will give you coefficients multiplied by average value from each variable from the 
background_set
. These contributions then sum up to the prediction (might be in link space so unless you’re using Gaussian regression, you might want to se 
output_space=TRUE
). You can take the mean absolute value to get some 
feature importance
.",2024-08-09T18:08:56,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,78853756
78862361,78862361,0,"Another reason that only standardized coefficients are used in the calculation of variable importance is due to the scaling of the different predictors.  A predictor A that is in the range of 0 to 1 and another predictor B is in the range of 10000-200000. I know that both predictors contribute equally to the final model output.


For example, A = 0.5, B = 20000, y = 40000.  Then, in this case, we will have 40000
A+1
B = 40000.  Hence, the variable importance without standardization will give you the impression that predictor A is much more important than predictor B which is incorrect.  They participated equally in generating the model output and the two should have the same variable importance.",2024-08-12T15:02:37,Wendy,https://stackoverflow.com/users/20736722/wendy,301,78853756
78721140,78721140,0,"H2O is capable of using 
curl
 package instead of 
RCurl
 if installed. I would first try to use the 
curl
 package (
install.packages(""curl"")
) and if that doesn't help, I would like to ask you to provide more information such as H2O version, OS version, processor architecture (x86_64 or M1), total available memory (RAM) on the laptop and free memory, dataset size, dataset metadata (type and cardinality (if applicable) of each column, number of rows, number of columns).


Also feel free to submit a 
bug report
 to H2O-3 if installing 
curl
 doesn't help. The bug report template should guide you to fill the most important things that we need to find out what went wrong.",2024-07-08T13:33:34,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,78716974
78449461,78449461,1,"The warning says your column 'bush_name' was detected as bad or constant and is not used during training. So, the result predictions are not based on this column.


If the column is not bad or constant (the bush_name data looks good in your example), it is used to train a model, and the result predictions are based on its values (levels).


If you put some unknown level in your test data, the model will create the prediction, but the prediction could not be as good as if the value were in the training dataset. That is the reason why we are raising the warning. However, the model will create some predictions for data with unknown levels.",2024-05-08T14:59:36,Maurever,https://stackoverflow.com/users/5036600/maurever,157,78444040
78453131,78453131,1,"The problem might be with 
bush_name
 being a character vector and not a factor vector. Since 
R 4.0
, 
stringsAsFactors
 is set to FALSE so the character vector is not automatically converted to factors and H2O does not consider string vector as a valid input for most of its supervised algorithms.


You can use 
str()
 to inspect the structure of a data structure in R, this can be very useful for 
data.frame
s to find out what data types individual columns have. For example, when adding 
stringsAsFactors=TRUE
 the types of 
date
 and 
bush_name
 change types from 
character
 to 
factor
:


> train_data <- data.frame(date = c(""2022-01-01"", ""2022-01-07"", ""2022-02-09"", ""2022-05-01"", ""2022-11-01"", ""2022-11-02""),
                   bush_name = c(""bush001"", ""bush001"", ""bush001"", ""bush043"", ""bush043"", ""bush043""),
                   bugs = c(2, 0, 1, 0, 3, 1),
                   has_rotten_berry = c(1, 0, 0, 1, 1, 0),
                   berry_count = c(12, 1, 7, 100, 14, 4),
                   weather = c(1, 0, 2, 0, 1, 1))
> str(train_data)
'data.frame':   6 obs. of  6 variables:
 $ date            : chr  ""2022-01-01"" ""2022-01-07"" ""2022-02-09"" ""2022-05-01"" ...
 $ bush_name       : chr  ""bush001"" ""bush001"" ""bush001"" ""bush043"" ...
 $ bugs            : num  2 0 1 0 3 1
 $ has_rotten_berry: num  1 0 0 1 1 0
 $ berry_count     : num  12 1 7 100 14 4
 $ weather         : num  1 0 2 0 1 1
>
> # Now let's add stringsAsFactors=TRUE to the data.frame function
> train_data <- data.frame(date = c(""2022-01-01"", ""2022-01-07"", ""2022-02-09"", ""2022-05-01"", ""2022-11-01"", ""2022-11-02""),
                   bush_name = c(""bush001"", ""bush001"", ""bush001"", ""bush043"", ""bush043"", ""bush043""),
                   bugs = c(2, 0, 1, 0, 3, 1),
                   has_rotten_berry = c(1, 0, 0, 1, 1, 0),
                   berry_count = c(12, 1, 7, 100, 14, 4),
                   weather = c(1, 0, 2, 0, 1, 1), stringsAsFactors=TRUE)
> str(train_data)
'data.frame':   6 obs. of  6 variables:
 $ date            : Factor w/ 6 levels ""2022-01-01"",""2022-01-07"",..: 1 2 3 4 5 6
 $ bush_name       : Factor w/ 2 levels ""bush001"",""bush043"": 1 1 1 2 2 2
 $ bugs            : num  2 0 1 0 3 1
 $ has_rotten_berry: num  1 0 0 1 1 0
 $ berry_count     : num  12 1 7 100 14 4
 $ weather         : num  1 0 2 0 1 1



However, I'd recommend to use the default and change the type afterwards (so the 
date
 is not converted to a factor vector) by using:


> train_data$bush_name <- factor(train_data$bush_name, levels=c(""bush001"", ""bush043""))



Note the explicit enumeration of levels - you should use the same argument for 
test_data
 so that you ensure the same encoding of the factors.


You'll probably also want to encode the date column. H2O doesn't do any clever date preprocessing - at best it will represent date as a number of seconds since 1st January 1970 which is not ideal for rotten berry prediction as seasonality will likely have a bigger effect than number of seconds since some date. You can use 
step_date
 for date preprocessing.",2024-05-09T08:15:01,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,78444040
78492388,78492388,0,"Hi:  It looks like you are just trying to predict the rotten blueberries on a bush based on the predictors bugs, has_rotten_berry, berry_count and weather.  I will simply build a model with bugs, has_rotten_berry, berry_count and weather and ignore all the other columns.


The name of the berry bush should not matter to rotten blueberries.  The date is not important because this should be reflected by the weather column.",2024-05-16T20:42:45,Wendy,https://stackoverflow.com/users/20736722/wendy,301,78444040
78252702,78252702,2,"h2o.predict
 returns an ""H2OFrame"". That is not expected as almost all predict methods return a data.frame. You transform the input data to a H2OFrame, but you also need to transform the output to a data.frame:


dnn_pred <- function(model, data, ...) {
   predict(model, newdata=as.h2o(data), ...) |> as.data.frame()
}

p <- predict(logo, model=dl_model, fun=dnn_pred)
plot(p, nr=1, mar=c(1,2,1,4))",2024-03-31T20:12:28,,,,78250475
78248479,78248479,1,"I guess this is getting close votes because it will be the data that is causing the problem, but the data is not given. But maybe your data cannot be given, or there is too much of it.


So I'd suggest try just using the first/half second half of data, and if only one or the other trigger it then keep repeating, to see if you can narrow it down to just one row.


And the same for columns, e.g. try 10-15 columns at a time, to see if it is just one column, or maybe certain types of column, triggering it.


Of course, once you have that, you also have the solution: exclude the troublesome column/row.
But you will also have enough to give a bug report to H2O (looks like this can be done at 
https://github.com/h2oai/h2o-3/issues
)",2024-03-30T15:28:57,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,78245999
78201658,78201658,1,"Without more logs, I cannot see what the problem is.  However, I do frequently encounter the following problem:


I started a H2O-3 cluster and start doing my work.  Then, I started another H2O-3 cluster.  My first cluster ended up shutting down because the two clusters try to form a H2O-3 cloud (they have the same default names) and my H2O-3 versions are not quite the same or the hash or something is not matching.


The way to get around this problem is to start each of your h2o-3 cluster with a different name like this:


java -jar h2o.jar -name ""cluster007""


I hope this will resolve your issue.  If not, please give me more logs or codes to reproduce the error.",2024-03-21T16:56:54,Wendy,https://stackoverflow.com/users/20736722/wendy,301,78183646
78181801,78181801,2,"Currently PCA does not support any rotation.  All it does is to decompose your datasets into factors and its corresponding coefficients in those factor directions.


Given a dataset A of m rows by n predictors (or coordinates), PCA will do the following


A = X*D where X is m by k, D is k by n and k < n.


I assume when you say you want to specify a rotation, you really wanted


A = Y*E where Y is m by k, E is k by n and E is given.


I believe you can solve the problem by doing the following: :




you can use H2O PCA to find: A = X*D.


given E, use any conventional software (Matlab, R, Octave or Python packages), you can find D = R * E (R = D * inverse(E)).


Substitue into A=X * D in terms of R and E: A = X * R * E = (X*R)*E


Set Y = X * R and you will get your desired answer A = Y*E.




Hope this helps.",2024-03-18T16:55:16,Wendy,https://stackoverflow.com/users/20736722/wendy,301,78180809
77993564,77993564,0,"Could you also share the printed output, please?


My first idea is you are using the same grid_id = ""gbm_grid""; please try to change the second one to be different.


Also, in your grid settings, the only difference is setting the response column (the first grid y=61, the second grid y=2). I don't see an offset column setting.


I will also try this suggestion with my generic data to see if this is the issue.


Thanks!


Edit:
I tried your code with different data and got models with different RMSEs. So please check that your data makes sense.",2024-02-14T10:25:49,,,,77976819
77911914,77911914,1,"I see there 2 issues:




H2O-3 requires its internal keys to start with a letter. The internal key is derived from the file name. When shiny uploads the file it renames it and in this case the file was named 
0.csv
. To workaround this you can specify 
destination_frame
, e.g.:




data <- h2o.uploadFile(path = path, destination_frame = paste0(""file_"", digest::digest(path)))





The other issue is reading the csv. You use 
read.csv(data)
 where 
data
 is an H2OFrame, this will not work. You should use 
as.data.frame(data)
 or 
read.csv(path, ...)
.",2024-01-31T08:44:31,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,77908088
77875297,77875297,0,"Check this page: 
https://www.tensorflow.org/decision_forests/tutorials/model_composition_colab


It combines CNN and decision forest just like what you are trying to do.


If they do not have gridsearch, you will just have to run the chained models multiple times.  Each time you will use a different hyperparameter settings.",2024-01-24T18:02:09,Wendy,https://stackoverflow.com/users/20736722/wendy,301,77874825
77841614,77841614,0,"Please add


import h2o


before you call anything from h2o toolboxes.",2024-01-18T18:16:22,Wendy,https://stackoverflow.com/users/20736722/wendy,301,77838561
77680312,77680312,1,"Let me first say what you have done is very innovative!  We do not provide binary model support across the different H2O-3 versions but you found a way to do this by using Mojo and generic model.


Here is the code I used to check out your issues.  However, I used the same version of H2O-3 3.44.0.3.  I was able to execute the code and get a prediction frame at the end of it.  If this does not help, please open an issue here (
https://github.com/h2oai/h2o-3/issues
) with versions of old H2O-3 and new H2O-3 that you use to create your old model and the version you try to load it with.


import h2o
import tempfile
from h2o.estimators import H2ORandomForestEstimator, H2OGenericEstimator

    airlines= h2o.import_file(path=pyunit_utils.locate(""smalldata/testng/airlines_train.csv""))
drf = H2ORandomForestEstimator(ntrees=1)
drf.train(x=x, y=y, training_frame=airlines)

original_model_filename = tempfile.mkdtemp()
original_dir = original_model_filename
original_model_filename = drf.download_mojo(original_model_filename)
  
model = H2OGenericEstimator.from_file(original_model_filename)
modelBinary = model.download_model(original_dir)
model2 = h2o.load_model(modelBinary)
pred2 = model2.predict(airlines)",2023-12-18T16:03:49,Wendy,https://stackoverflow.com/users/20736722/wendy,301,77679172
77559928,77559928,0,"Actually, we have a toolbox just for this using GLM.  You are looking for the best K predictors to use to build your model.  The best model is chosen for the one with the highest R2.  ModelSelection will build a GLM model selecting the best 1 predictor model, best 2 predictors model, ...., the best K predictor models.  Please checkout our modelselection toolbox:  
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/model_selection.html?highlight=modelselection


A sample code will look like this:


import sys
import h2o
from h2o.estimators.model_selection import H2OModelSelectionEstimator

train = h2o.import_file(""import your dataset"")
response=""response"" # set your response column
predictors = train.names
predictors.remove(response)

maxrsweep_model = H2OModelSelectionEstimator(mode=""maxrsweep"", max_predictor_number=100)
maxrsweep_model.train(x=predictors, y=response, training_frame=train)

# to get the best predictor subset
best_100_predictors = maxrsweep_model.coef(predictor_size=100)
print(best_100_predictors) # print predictor names and GLM coefficients



I hope this helps.",2023-11-27T21:01:59,Wendy,https://stackoverflow.com/users/20736722/wendy,301,77549868
77488166,77488166,0,"Thanks for the question.


Every leaf node contains 
predValue
 = information regarding the final prediction made on that node.


See tree structure info here:




Python: 
https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/tree.html


R: 
https://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/H2OTree-class.html




To get information if the result prediction is 0 or 1, you must get the threshold (
default_threshold
) used for these decisions. You can find the 
default_threshold
 in the model info.


You can get the decision path for the concrete node see 
decision_paths
 or decision paths for the whole tree, see 
tree_decision_path
.


If you are interested in leaf node assignment, see 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html?#predicting-leaf-node-assignment
.


Let me know if you have another question.",2023-11-15T13:39:15,Maurever,https://stackoverflow.com/users/5036600/maurever,157,77475890
77209082,77209082,1,"Yes, Luis Felipe is correct.  Please make sure




you set distribution=""multinomial""


change your dat_h20 to H2O frame as data_h2o <- as.h2o(dat_h20)


Make sure the response column is a factor: data_h2o[,4] <- as.factor(data_h2o[,4] assuming that the fourth column is the response column.




Normally if you have 2 and 3, H2O deeplearning will be able to figure out that it is a multiclass classification automatically.",2023-10-01T02:59:24,Wendy,https://stackoverflow.com/users/20736722/wendy,301,77208586
77208591,77208591,0,"Ensure Multi-Class Setting: In H2O's deep learning function, the default behavior for classification is to expect binary labels. For multi-class classification, the system should automatically handle it when provided with a categorical response column with more than two levels. If you've encoded your response variable as numeric, this might be the root of the problem. It's preferable to leave it as a factor",2023-09-30T22:01:31,Luis Felipe,https://stackoverflow.com/users/22597384/luis-felipe,1,77208586
77220900,77220900,3,"I had exactly the same problem and I fixed it by setting 
safe_serialization=True
 when using the 
save_pretrained()
 method. Hope this works for you. However, I do want to know what was going on when loading a model with a vanilla .bin format.",2023-10-03T08:58:22,Luxin.Z,https://stackoverflow.com/users/7483499/luxin-z,39,77064065
78046835,78046835,-1,"You can try this method:

model = AutoModelForCausalLM.from_pretrained(model_path, device_map=""auto"",  trust_remote_code=True).eval()


It may work.",2024-02-23T10:49:45,Joyanta J. Mondal,https://stackoverflow.com/users/9848043/joyanta-j-mondal,"1,037",77064065
77052978,77052978,0,"Thanks for your questions. I try to answer:




How are the scores from these trees combined into the final score vector?

You are right. For each class, a ""one-vs-rest"" tree is trained. The final prediction vector is calculated as a prediction of each tree and then normalized to sum up to one.




Why this approach was chosen?

Good question. But I don't know. It is one of the oldest algorithms we implemented in H2O-3. My guess is it was easier to implement. :) You can open an issue and ask to implement another approach. We are open to improving our algorithm base.




Should be multiclass classifier and one-vs-rest multiclass classifier similar in performance?

Well, I am not sure. I think it depends on the data, too. Do you have any performance comparisons you can share? Which type of data you are using?",2023-09-06T14:39:48,Maurever,https://stackoverflow.com/users/5036600/maurever,157,77016904
76952165,76952165,0,"Thank you for your interest in h2o-3!
I'm having troubles reproducing that on the same Ubuntu and Java version, can you please share which git branch are you using? If you're not using git I would suggest cloning the project and using 
rel-3.42.0
 branch, which is the latest release branch.


I also strongly suggest skipping the tests at first:

./gradlew build -x test",2023-08-22T10:00:35,krasinski,https://stackoverflow.com/users/2922413/krasinski,69,76950243
76957170,76957170,0,"can you please try enabling 
convertUnknownCategoricalLevelsToNa
?


Here is the related documentation:

https://s3.amazonaws.com/h2o-release/sparkling-water/spark-3.1/3.42.0.2-1-3.1/doc/deployment/load_mojo.html#customizing-the-mojo-settings",2023-08-22T22:25:05,krasinski,https://stackoverflow.com/users/2922413/krasinski,69,76931856
76874347,76874347,0,"Solved. If I omit the ""start column"" it works. I don't know why, cause thought that this columns represents the beginning time of the observations, which means it could have zero values, but it can't.",2023-08-10T09:23:45,ilpadrino,https://stackoverflow.com/users/1974542/ilpadrino,13,76850663
76871083,76871083,0,"Here is a suggestion:


pseudotensor commented 3 days ago •
Looks like you have a package ""utils"" installed and it's looking there instead of the local code.


Maybe try:


setenv PYTHONPATH=.:src:$PYTHONPATH


python generate.py ...


Here is the link to the same issue:  
https://github.com/h2oai/h2ogpt/issues/622#issuecomment-1666898436",2023-08-09T20:31:49,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76844317
76790924,76790924,1,"To get around the error that you are getting, please try this:


gbm_autoML = h2o.get_model(aml.leader)
gbm_continued = H2OGradientBoostingEstimator(
  model_id = 'gbm_continued', 
  max_depth = gbm_autoML.actual_params['max_depth'], 
  ntrees = gbm_autoML.actual_params['ntrees']+2, 
  checkpoint = aml.leader)



To continue to train a GBM model meaning that you are adding more trees into the model.  That is why I have added 2 to the ntrees parameter.  Feel free to change the 2 to anything else that you want as long as it >= 1.


Hope this helps and good luck.",2023-07-28T20:42:20,Aemyl,https://stackoverflow.com/users/6074182/aemyl,"2,182",76790068
76775726,76775726,1,"Currently h2o generic estimator loaded from mojo files can perform scoring but will not be able to be trained again.


If you are interesting in training a previously build model, please consider using checkpoint.  Here is the documentation on it: 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/checkpoint.html#:~:text=The%20checkpoint%20option%20allows%20you,continuing%20building%20a%20previous%20model
.",2023-07-26T23:53:24,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76774699
76723361,76723361,1,"The complete java command call is


java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i ""path/to/model.zip"" -o model.gv -f 20 -d 3


where the -f is for fontsize, -d is for number of decimal points and they are optional.  To convert this into a subprocess call in Python, the gv_call is probably this:


gv_call="" "".join([""java"", ""-cp"", h2o_jar_path, ""hex.genmodel.tools.PrintMojo"", ""--tree"", str(tree_number), ""-i"", mojo_path, ""-o"", gv_file_path, ""-f"", str(20), ""-d"", str(3)])",2023-07-19T16:20:37,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76722818
76664005,76664005,0,"have a look at H2O's 
partial_plot
. With 
plot=False
 you can get just the data that you want for each feature (and target in case of multinomial classification) separately. The features in 
explain
 method are sorted using variable importance that you can retrieve for most models by using the 
varimp
 method.",2023-07-11T16:25:08,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,76659512
76663826,76663826,0,"Using initial weights can be tricky because you need to make sure to get the dimension right.  Here is a code snippet on how to figure out the correct weight dimension and then use it in when calling the model:


df <- as.h2o(iris)
dl1 <- h2o.deeplearning(x=1:4,y=5,training_frame=df,hidden=c(10,10),export_weights_and_biases = TRUE, seed=1234, reproducible=TRUE)

## get weights and biases.  This will give you the correct dimension.
w1 <- h2o.weights(dl1,1)
w2 <- h2o.weights(dl1,2)
w3 <- h2o.weights(dl1,3)
b1 <- h2o.biases(dl1,1)
b2 <- h2o.biases(dl1,2)
b3 <- h2o.biases(dl1,3)

## make a model from given weights/biases
dl2 <- h2o.deeplearning(x=1:4,y=5,training_frame=df,hidden=c(10,10),initial_weights=c(w1,w2,w3),initial_biases=c(b1,b2,b3), epochs=0)",2023-07-11T16:01:23,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76659362
76524767,76524767,0,"Let's call your original frame train_log2.


If you want to pick out part of an H2OFrame which has certain characteristics like ID == 10, you can do the following:


train_log2_ID10 <- train_log2[train_log2$ID==10,]


Now, you can call and build your model with train_log2_ID10 as before just using dataset rows when the ID is 10.  You can do any kind of logical combinations like train_log2$ID==10 || train_log2$ID==20 or whatever you like.",2023-06-21T15:08:57,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76523487
76507433,76507433,0,"H2O deeplearning does not utilize GPU.  However, there is the parameter fast_mode you can use to speed up your training.",2023-06-19T14:09:47,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76503651
76490770,76490770,1,"Check the 
reproducible
 parameter of the autoencoder in 
the h2o-3 documentation
:




reproducible: Specify whether to force reproducibility on small data.
If this option is enabled, the model takes more time to generate
because it uses only one thread. This option defaults to False
(disabled).




Also set the 
seed
 parameter to a fixed integer value.",2023-06-16T13:40:01,Community,https://stackoverflow.com/users/-1/community,1,76488419
76435209,76435209,1,"The problem here is the number of columns.  While the number of rows control the overall training time, the number of columns control the training time per row.  Having 2232 is quite a lot.  If you can do some data munging and reduce the number of predictors you use, it will definitely speed up training.


You can also try the following:




set stopping_tolerance to a higher number: 0.1 or higher.  This will enable early stopping to stop training if the average improvement in some metrics does not improve by 0.1 compared to the last one;


set max_runtime_secs=120 if you want to stop the model building after 120 seconds


reduce score_training_samples from default of 10000 to say 5000.  This will perform scoring on a smaller number of samples and hence can reduce training time.




Note that stopping the model early as in 1, 2 may reduce the model training time but will get you a model that may not be a good fit for your data.",2023-06-08T19:40:35,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76428833
76420161,76420161,0,"The PMML converter can only use information that was made available by the original ML framework. If partial predictions are not available for intermediate tree levels, then this is so because the original ML framework did not store this information in model dump file (the in-memory representation and the dumped representation are sometime different).


Now, the information about intermediate tree levels is typically omitted, because this is useless for most application scenarios - when making predictions, then the prediction is computed exclusively based on terminal nodes.


With probability distribution-type trees and their ensembles there are two sub-types. Some models present this information in 
absolute
 terms (class data record counts), whereas other model types present it in 
relative
 terms (class probabilities).


If you are working with any model that has record counts available for terminal nodes, then you can re-construct record counts for all higher levels by aggregating them. Continue with the aggregation up until the root tree level - the sum of calculated record counts will equal to the size of the training dataset there.",2023-06-07T05:39:43,user1808924,https://stackoverflow.com/users/1808924/user1808924,"4,926",76412118
76394821,76394821,0,"Could you specify the version of h2o you use and how you use it (are you using  IPython/bpython/Jupyter or some IDE like Spyder/PyCharm)?


Since you have 
pandas
 installed you can use 
print(hf.head().as_data_frame())
 to convert the ""head"" of the hf to 
pandas
 and render it using 
pandas
.


For the model object you can try 
gbm_default.show()
 or

gbm_default.get_summary()
 (or 
gbm_default.summary()
 if you have older versions).",2023-06-03T06:30:18,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,76391929
76317334,76317334,2,"You could also try setting multiple repositories, e.g.


options(repos = c(
 h2o = ""http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R"",
 CRAN = ""https://cloud.r-project.org""
))

install.packages(""h2o"", type=""source"")



This way, R can find the 
h2o
 package on its own repository, and install any dependencies from the regular CRAN repository.",2023-05-23T17:33:55,Kevin Ushey,https://stackoverflow.com/users/1342082/kevin-ushey,21.2k,76316226
76316527,76316527,1,It looks like you need to install the R package jsonlite.,2023-05-23T15:43:50,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76316226
76316002,76316002,1,"it looks like some kind of a firewall is blocking the ports, I would suggest to investigate that",2023-05-23T14:43:40,krasinski,https://stackoverflow.com/users/2922413/krasinski,69,76310451
76275385,76275385,0,"H2O is built to deal with large amounts of data.  Hence, your problem is perfect for h2O-3.  I would suggest you do the following: save your smaller datasets as .csv files into a folder say big_data_folder.  Say you have data1.csv, data2.csv, data3.csv, .... in your /Users/abcde/big_data_folder.  Then, in your R code, you call this:


dataset <- h2o.importFile(""/Users/abcde/big_data_folder"")


Then, you can call deeplearning algo with the proper parameters.


To save a h2o frame data1, you can do h2o.downloadCSV(data1, ""/Users/abcde/big_data_folder/data1.csv"") in R.


The reason that the merging does not work is because it is not implemented efficiently and can take up a lot of memory.  Please try my suggestion and let me know if you encounter problems.


Thanks and good luck,
Wendy",2023-05-17T18:56:28,,,,76274774
76204054,76204054,2,"You would be better off using a MOJO wrapped in a web service.
Using a full H2O-3 instance for real-time scoring is not recommended.


Here is a link to a really old, but really simple, example:


https://github.com/h2oai/app-consumer-loan/blob/master/src/main/java/org/gradle/PredictServlet.java


The link you provided above to the eScorer tutorial assumes you have an H2O AI Cloud instance with the model already hosted.


Whereas the simple OSS example directly instantiates a java servlet container and has the model inside.


You can try to dockerize this simple example if you want, but that's probably overkill.  If you dockerize it, I suggest running 
docker run
 directly and not using 
docker compose
 at all.",2023-05-08T20:11:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",76201233
76201004,76201004,0,"The loss related function parameters are not in the right format, so it gets confused (and gives you the error) for applying a ""improper"" loss function to a given data type.


Instead of passing 
loss = 
 or 
loss_by_col_idx = 
, pass just 
loss_by_col = 
. This is designed to take a loss function name per feature in your 
training_frame
 so it needs to be the same length as 
ncol(my_data)
.


losses2 = dplyr::case_when(
  my_data_types$var_type == 'binary' ~ 'Logistic',
  my_data_types$var_type == 'ordinal' ~ 'Ordinal',
  TRUE ~ 'Categorical')

losses2

# console:
# [1] ""Logistic""    ""Logistic""    ""Logistic""    ""Logistic""    ""Logistic""    ""Ordinal""    
# [7] ""Ordinal""     ""Ordinal""     ""Categorical"" ""Logistic"" 

# Run GLRM
my_glrm <- h2o::h2o.glrm(
  training_frame = my_data_h2o,
  k = 2,
  loss_by_col = losses2,
  regularization_x = ""None"",
  regularization_y = ""None"",
  transform = ""NONE"",
  max_iterations = 2000,
  seed = 12345
)



Now you're model is up and running, but dropping some no information features, just like we wanted.",2023-05-08T13:19:06,Nate,https://stackoverflow.com/users/5878751/nate,10.7k,76200605
76229101,76229101,0,"I have looked at your problem for GBM for Bernoulli distribution.  I used save_mojo and import_mojo and checkout the predicted result.  If you lookt at the predicted result, it contains one column only.  It is the probability of the class belonging to class 1.  Hence, if you want the probability of class 0, you can do a 1-predicted result.


Here is the code I used:


fr = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"")

model = H2OGradientBoostingEstimator(ntrees=10, seed=1234)
model.train(x=list(range(2, fr.ncol)), y=1, training_frame=fr)

# Default filename is model_id
mojo_path = model.save_mojo()
mojo_model = h2o.import_mojo(mojo_path)
predictFrame = mojo_model.predict(fr)
print(predictFrame[0,0])",2023-05-11T15:07:11,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76199437
76174460,76174460,0,"DeepLearning and StackedEnsemble models have a parameter 
score_training_samples
 that defaults to 10 000 which speeds up the training by calculating the training scores only on a sample - the rationale behind it is that users don't generally care much about the training performance metrics so the estimate on the sample is often sufficient while providing a speed up.


You can use 
best_model.confusion_matrix(training_frame)
 to get confusion matrix for the whole training frame. More details are in the 
documentation
.",2023-05-04T14:43:26,,,,76173043
76132980,76132980,2,"Regarding your question 1.  Correct.  For algorithms that do not have the standardize parameter, the predictors are not standardized.  For tree based algorithms, we are dealing with comparisons like val >= threshold to determine which side of the child nodes to go to.  If we implement standardization, we will have to perform (val-mean)/standard deviation >= threshold.  In choosing not to standardize will say us a lot of time during the tree traversal because we don't need to perform standardization of the predictors when we are trying to evaluate the expression val >= threshold.


Regarding question 2: When you set standardize=true, only the numerical features are standardized.  The response column is not standardized.",2023-04-28T20:11:42,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76131318
76133956,76133956,1,"If you are looking to get confidence intervals for your results, you are looking for getting confident intervals of the coefficients.  To do that, you need to call GLM with compute_p_values, remove_collinear_columns to true.  Once the model building process is done, you can model.coef_with_p_values() that will return your model coefficients, the p-values and the std_error and other fields.",2023-04-29T00:12:47,Wendy,https://stackoverflow.com/users/20736722/wendy,301,76123086
76033531,76033531,1,"If you want to use the whole dataset for training you should use just the 
training_frame
 and to be sure you use cross-validation you should specify 
nfolds
 to a number greater than 1 or specify 
fold_column
.


If the data is big enough (with respect to the computational cluster) the AutoML can decide to use ""blending mode"" instead of cross-validation - internally split the data to training/validation sets and use validation metrics for leaderboard sorting and training the Stacked Ensembles. This happens only when 
nfolds=0
.


To answer your last question: if you have that much data, I would try using July as leaderboard frame and once I would have the best model from AutoML selected on unseen data from July, I would use the parameters from that model to train a new model on the whole dataset including the July. But I that's just how I'd do it, not necessarily the best approach.",2023-04-17T09:16:55,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,76032896
75985998,75985998,1,"H2O-3 cluster requires a static environment. It can't recover from the scenario when one of the nodes is killed. After such an event, a state of in-memory storage gets corrupted. The newly created node won't join the cluster since the cluster  was locked after first usage. If the situation above happens, the whole cluster must be killed and new one started.


If you want to get a deterministic URL for flow UI, add 
-proxy
 parameter to your hadoop jar command:

hadoop jar h2odriver.jar -n 3 -mapperXmx 10g -proxy


It will start a simple HTTP proxy on Hadoop edge node that will forward all the traffic to one of the H2O nodes (leader) running on a Hadoop compute node.",2023-04-11T12:38:38,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,75873650
75822097,75822097,2,"Take a looks at the Sparkling Water project. You can build pipelines where the data preprocessing is performed by a logic written in Spark and ML performed by H2O-3 models.




https://docs.h2o.ai/sparkling-water/3.3/latest-stable/doc/about.html


https://docs.h2o.ai/sparkling-water/3.3/latest-stable/doc/deployment/load_mojo.html


https://github.com/h2oai/sparkling-water/tree/master/examples",2023-03-23T10:56:00,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,75816459
75754767,75754767,0,"The easiest way is to use pandas' 
groupby
 to create the H2OFrames.


df = pd.DataFrame(data, columns=['Dt','Co','Team','Val1','Val2','Type'])
frames = df.groupby([""Dt"", ""Team""]).apply(h2o.H2OFrame)
automls = dict()

for key, training_frame in frames.items():
    aml = H2OAutoML(max_runtime_secs = 10, seed = 42)
    aml.train(x = x, y = y, training_frame = training_frame, ...)
    automls[key] = aml



It's possible I misunderstood the question and you want to split the folds in cross-validation by 
Team
, if that's the case, you can use the 
fold_column
 parameter.",2023-03-16T10:13:25,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,75749800
75723237,75723237,4,"Probably the easiest way to modify this plot is to take the 
data
 from it and recreate the plot:


ggplot(plt$data, aes(.data$feature, .data$contribution, color = .data$normalized_value, text = .data$row)) +
        geom_hline(yintercept = 0, linetype = ""dashed"") +
        geom_point(position = h2o:::position_jitter_density(), alpha = 0.5, size = 4) +
        scale_color_gradient(low = ""#00AAEE"", high = ""#FF1166"") +
        coord_flip() +
        labs(y = ""SHAP Contribution"", x = ""Feature"") +
        theme_bw()",2023-03-13T14:30:29,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,75722820
75701595,75701595,1,"Answering my own question here, it appears that setting lambda = 0 in the glm function is required to make this work as expected.",2023-03-10T22:40:43,darkness,https://stackoverflow.com/users/3380142/darkness,85,75701517
75723220,75723220,2,"Yes, variable importance is calculated based on the training datasets alone.  For GLM, they are related to the coefficients of the model.  For GBM, they are calculated as we are building the various trees.  Hence, they cannot be calculated from validation or test datasets as those datasets are not used to generate the various model parameters.",2023-03-13T14:29:00,Wendy,https://stackoverflow.com/users/20736722/wendy,301,75700445
75689840,75689840,2,"h2o
 version 
3.40.0.2
 still doesn't solve the problem.


Luckily, I found this workaround; it works with no problem somehow.


train = h2o.splitFrame(data_h2o, ratios = c(0.7,0.15), seed =1)[[1]] 
valid = h2o.splitFrame(data_h2o, ratios = c(0.7,0.15), seed =1)[[2]] 
test = h2o.splitFrame(data_h2o, ratios = c(0.7,0.15), seed =1)[[3]] 



Edit: Another workaround


Supplying destination frame names does not generate above error.


parts = h2o.splitFrame(data_h2o, ratios = c(0.7,0.15), destination_frames = c('train','valid','test'), seed =1)



Edit::
@Erin


parts = h2o.splitFrame(data_h2o, ratios = c(0.7,0.15), seed =1)
Error in .Call(R_curl_fetch_memory, enc2utf8(url), handle, nonblocking) : 
  reached elapsed time limit
train = parts[[1]]

ERROR: Unexpected HTTP Status code: 404 Not Found (url = http://localhost:54321/3/Frames/RTMP_sid_b98f_20?row_count=10)

water.exceptions.H2OKeyNotFoundArgumentException
 [1] ""water.exceptions.H2OKeyNotFoundArgumentException: Object 'RTMP_sid_b98f_20' not found for argument: key""     
 [2] ""    water.api.FramesHandler.getFromDKV(FramesHandler.java:136)""                                              
 [3] ""    water.api.FramesHandler.doFetch(FramesHandler.java:226)""                                                 
 [4] ""    water.api.FramesHandler.doFetch(FramesHandler.java:221)""                                                 
 [5] ""    water.api.FramesHandler.fetch(FramesHandler.java:200)""                                                   
 [6] ""    jdk.internal.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)""                                    
 [7] ""    java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)""
 [8] ""    java.base/java.lang.reflect.Method.invoke(Method.java:566)""                                              
 [9] ""    water.api.Handler.handle(Handler.java:60)""                                                               
[10] ""    water.api.RequestServer.serve(RequestServer.java:472)""                                                   
[11] ""    water.api.RequestServer.doGeneric(RequestServer.java:303)""                                               
[12] ""    water.api.RequestServer.doGet(RequestServer.java:225)""                                                   
[13] ""    javax.servlet.http.HttpServlet.service(HttpServlet.java:687)""                                            
[14] ""    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)""                                            
[15] ""    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)""                                  
[16] ""    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)""                              
[17] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)""                       
[18] ""    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)""                      
[19] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)""                        
[20] ""    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)""                               
[21] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)""                        
[22] ""    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)""                       
[23] ""    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)""                           
[24] ""    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)""                   
[25] ""    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)""                         
[26] ""    water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)""            
[27] ""    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)""                   
[28] ""    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)""                         
[29] ""    org.eclipse.jetty.server.Server.handle(Server.java:531)""                                                 
[30] ""    org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)""                                       
[31] ""    org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)""                             
[32] ""    org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)""             
[33] ""    org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)""                                       
[34] ""    org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)""                                    
[35] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)""                  
[36] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)""                
[37] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)""               
[38] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)""                      
[39] ""    org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)""
[40] ""    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)""                        
[41] ""    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)""                         
[42] ""    java.base/java.lang.Thread.run(Thread.java:829)""                                                         

Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  : 
  

ERROR MESSAGE:

Object 'RTMP_sid_b98f_20' not found for argument: key

valid = parts[[2]]
test = parts[[3]]

print(train) # works

4 -1.756761e-02    0.83612315
5 -1.110098e-16   -0.30177617
6  9.999955e-01   12.29344288

[487719970 rows x 16 columns] 
print(valid) # works
print(test) # works",2023-03-09T20:42:21,,,,75689169
75689319,75689319,0,It looks like it failed to find the frame data_h2o and hence failed the frame splitting.  The error message provided to you is bad.,2023-03-09T19:43:34,Wendy,https://stackoverflow.com/users/20736722/wendy,301,75689169
75659358,75659358,2,"It's possible using the H2O's REST API. Have a look at 
model.download_mojo()
 for the reference which gets the model from the backend and then persists it using the 
_process_response()
 method. You can have a look at 
h2o.upload_mojo()
 for the uploading part.",2023-03-07T08:06:03,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,75653463
75547194,75547194,1,"Would 
grid_perf._grid_json
 work for your case?


Maybe 
_grid_json[""summary_table""]
?",2023-02-23T15:50:29,,,,75546765
75548216,75548216,0,"Thanks to Adam Valenta for the suggestion.
Using that, the solution is:


grid_perf=gs.get_grid(sort_by='auc', decreasing=True)
table = grid_perf._grid_json['summary_table'].as_data_frame()
table.to_csv('GridSearch1.csv',index=False)",2023-02-23T17:20:27,Adam,https://stackoverflow.com/users/12979649/adam,21,75546765
75523949,75523949,1,The function call h2o.splitFrame works only on h2o frame.  That is why you need to convert to an h2o object before calling the splitFrame function.  Thank you for figuring this one out.,2023-02-21T17:29:35,Wendy,https://stackoverflow.com/users/20736722/wendy,301,75511989
75512316,75512316,0,"I have finally resolved the issue. I had to convert the dataset again to an h2o object before calling the splitFrame function.


trans_hf <- as.h2o(atm_trans)
splits <- h2o.splitFrame(trans_hf, ratios = c(0.4, 0.4), seed = 42)



I don't know why I had to do that because the trans_hf was not empty nor null but it is ok now.",2023-02-20T17:13:34,Hakeem Ojulari,https://stackoverflow.com/users/7119300/hakeem-ojulari,51,75511989
75349489,75349489,2,"Yes, there's a way to do this in H2O AutoML and all the supervised H2O algorithms.


There's an argument called 
fold_column
 in which you specify the name of the column that defines the fold ID.  So if you have a 
""subject_id""
 column, just set 
fold_column = ""subject_id""
.


More info in the 
docs
.",2023-02-05T01:09:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",75346452
75324052,75324052,0,"I found an alternative way for downloading the latest package:




define where you want your ZIP file to be downloaded to (i created a Downloads folder in my working directory) and download from  
http://h2o-release.s3.amazonaws.com/h2o/latest_stable.html


run this in the terminal




cd ~/Downloads
unzip h2o-3.38.0.2.zip
cd h2o-3.38.0.2
java -jar h2o.jar





go through the dialoge in the terminal to install r (not python)


install via the console




install.packages(""~\Downloads\h2o-3.38.0.4\R\h2o_3.38.0.4.tar.gz"", repos = NULL, type = ""source"")





load the library




library(h2o)



Troubleshooting: make sure to have the fitting Java Version installed (e.g. Version 8)


Alternatively: here is also a code posted by H2O: 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html#install-in-r",2023-02-02T13:43:00,luise,https://stackoverflow.com/users/21124591/luise,3,75308849
75289520,75289520,0,"As mentioned in the comments, there are several problems with this approach overall, the main of which is that importances are a tricky matter even with standard analysis, and further complicating things is likely to produce misleading results. One-hot encoding is not too problematic with GLMs, but it could be with, say, RFs. With that out of the way...


Given a dataframe (which 
model.summary
 seemingly produces):


import pandas as pd

df = pd.DataFrame([
    ['abs.C5.', 1.508031, 1.000000, 0.257004],
    ['abs.C4.', 1.364653, 0.904924, 0.232569],
    ['abs.C3.', 1.158184, 0.768011, 0.197382],
    ['abs.C2.', 0.766653, 0.508380, 0.130656],
    ['abs.C1.', 0.471997, 0.312989, 0.080440],
    ['0.de', 0.275667, 0.182799, 0.046980],
    ['0.ne', 0.210085, 0.139311, 0.035803],
    ['0.ya', 0.078100, 0.051789, 0.013310],
    ['0.c', 0.034353, 0.022780, 0.005855],
], columns=['variable', 'relative_importance', 'scaled_importance', 'percentage'])

df
#   variable    relative_importance scaled_importance   percentage  orig
# 0 abs.C5. 1.508031    1.000000    0.257004    abs
# 1 abs.C4. 1.364653    0.904924    0.232569    abs
# 2 abs.C3. 1.158184    0.768011    0.197382    abs
# 3 abs.C2. 0.766653    0.508380    0.130656    abs
# 4 abs.C1. 0.471997    0.312989    0.080440    abs
# 5 0.de    0.275667    0.182799    0.046980    0
# 6 0.ne    0.210085    0.139311    0.035803    0
# 7 0.ya    0.078100    0.051789    0.013310    0
# 8 0.c 0.034353    0.022780    0.005855    0



You can add an artificial column for groupby and then aggregate (sum):


df['original_variable'] = df['variable'].apply(lambda x: x.split('.')[0])
df.groupby('original_variable')['percentage'].sum()

# orig
# 0      0.101948
# abs    0.898051
# Name: percentage, dtype: float64



Or do it in one line so not to alter the dataframe, to the same effect:


df.groupby(df['variable'].apply(lambda x: x.split('.')[0]))['percentage'].sum()",2023-01-30T19:59:58,Lodinn,https://stackoverflow.com/users/10672371/lodinn,472,75188789
75305502,75305502,0,"I think the section of the docs on deploying pipeline models might be relevant: 
https://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/deployment/pysparkling_pipeline.html


Pipelines may not be what you're looking for depending on the use case.


Something like the following might work for your use case.


drf = H2ODRF(featuresCols = predictors,
                labelCol = response,
                columnsToCategorical = [response])

pipeline = Pipeline(stages=[drf])

model = pipeline.fit(data)
model.save(""drf_model"")",2023-02-01T03:56:51,TheFon,https://stackoverflow.com/users/5225817/thefon,31,75169165
76123024,76123024,0,"model.save(""mySavePath"")



and then later when you need to load the model:


model = pysparkling.ml.H2OMOJOModel.load(""mySavePath"")",2023-04-27T17:06:33,,,,75169165
75152725,75152725,0,"If you have categorical columns, you don't need to encode it.  You just need to make sure that that column is read in as enum and not int.  For Deeplearning, if you want to use all factors of the categorical columns, you just need to set the parameter use_all_factor_levels=True/true/TRUE for Python, Java or R.",2023-01-17T22:10:25,Wendy,https://stackoverflow.com/users/20736722/wendy,301,75130927
75264658,75264658,0,"XGBoost in H2O actually runs outside the H2O Cluster (Java heap), so when you start up H2O with 
h2o.init()
 you need to make sure to save enough RAM to run both H2O and XGBoost.  I think that might be the issue you're having, but please let me know if this does not fix it.


We recommend leaving at least 1/3 of the RAM for XGBoost.  So if you have 30GB RAM, give 20GB for H2O (
h2o.init(max_mem_size=""30G""
), which leaves 10GB for XGBoost.",2023-01-28T00:51:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",74815510
74800319,74800319,7,"Some model objects in R require 
native serialization
 methods to be saved and reloaded from file—h2o objects (and thus the tidymodels objects that wrap them) are an example of one that does.


The tidymodels and vetiver teams at Posit recently collaborated on a package, 
bundle
, that provides a consistent interface to native serialization methods. The docs on h2o are 
here
.


library(bundle)



In short, you will want to 
bundle()
 the object you're preparing to save, save it with the usual 
saveRDS()
, and then, in your new session, 
loadRDS()
 and 
unbundle()
 the loaded-in object. The output of 
unbundle()
 is your ready-to-go model object. :)


# to save:
auto_fit <- fit(auto_wflow, data = concrete_train)
auto_fit_bundle <- bundle(auto_fit)
saveRDS(auto_fit_bundle, file = ""test.h2o.auto_fit.rds"") #save the object
h2o_end()



# to reload
h2o_start()
auto_fit_bundle <- readRDS(""test.h2o.auto_fit.rds"")
auto_fit <- unbundle(auto_fit_bundle)
predict(auto_fit, new_data = concrete_test)",2022-12-14T15:09:57,Simon Couch,https://stackoverflow.com/users/14038605/simon-couch,531,74795331
74560338,74560338,1,"The 
h2o.varimp(rautoml_winner@leader)
 makes no sense since the 
rautoml_winner
 is already the leader model (= the best model according to the sort metric from the automl). Removing the 
@leader
 would fix it for all models except for the Stacked Ensembles which do not have variable importance calculated during training.


You can still get variable importance for Stacked Ensembles using the permutation variable importance, e.g., 
h2o.permutation_importance(rautoml_winner, test_h2o)
. See the 
documentation
 for more information.",2022-11-24T11:52:01,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,74559844
74487467,74487467,1,"I would recommend specifying 
stopping_metric = ""AUCPR""
 to optimize for AUCPR and 
sort_metric = ""AUCPR""
 to let AutoML know that the leader model should be the one with the best AUCPR (otherwise it would use AUC by default).


If your data is small enough, you might be able to use libraries like 
imbalanced-learn
 in python or 
themis
 in R to do some preprocessing like SMOTE, removing Tomek links etc.",2022-11-18T09:27:45,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,74486548
76995212,76995212,2,"There's a bug in the manual R² computation - the first value of the R's numeric vector gets broadcasted with the operation across the H2O column.


To see what's happening I tried the following:


> Y_true <- Y[,1]
> Y_pred <- Y_pred[,1]
> (as.numeric(Y_true)-as.numeric(Y_pred))
       predict
1 -0.085572158
2 -0.090655887
3  0.090492763
4  0.127857837
5  0.005002167
6 -0.335313060

[150 rows x 1 column] 
> (as.numeric(Y_true)-as.numeric(Y_pred))+as.numeric(Y_pred) 
  predict
1     1.4
2     1.4
3     1.4
4     1.4
5     1.4
6     1.4

[150 rows x 1 column] 
> Y_true
  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.4
 [39] 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4
 [77] 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0
[115] 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1



You can either convert it to R by changing


MSE = mean((as.numeric(Y_true)-as.numeric(Y_pred))**2)



to


MSE = mean((as.numeric(as.vector(Y_true))-as.numeric(as.vector(Y_pred)))**2)



Or convert it to H2O by changing


MSE = mean((as.numeric(Y_true)-as.numeric(Y_pred))**2)



to


MSE = mean((as.numeric(as.h2o(Y_true))-as.numeric(as.h2o(Y_pred)))**2)



NOTE:
 Even with this you might notice that the manually calculated R² and H2O's R² differ. I believe that this is caused by train/test split that is used in AutoML when 
nfolds=0
 (e.g. for early stopping). (
difference between manual R^2 & H2O reported R^2:  0.0005075975
).


NOTE 2:
 The 
as.numeric
 is probably unnecessary but I kept it there just in case you need it for your data.",2023-08-28T18:21:43,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,74368804
74373233,74373233,1,"The 
docs
 don't describe the algorithm, but what might be useful to know is that 
h2o.r2()
 doesn't calculate it: it takes the value from metrics calculated when the model was being made:

https://github.com/h2oai/h2o-3/blob/6758ed00b5200c782cd2bbebf0094374757dc472/h2o-r/h2o-package/R/models.R#L2018


Anyway, is the difference the set of data? 
h2o.r2(model,train=T)
 will only be on evaluating on training data, whereas you are passing in the whole of 
X_df
.




for simple linear models it seems to work.




Well, you could make a case that R2 is only meaningful for simple linear models. In fact people will 
make the case
 it isn't even meaningful then.",2022-11-09T10:22:02,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,74368804
74747505,74747505,0,"The two datasets are almost the same except at one place:


In the first dataset, number of rows for VehBrand with B1 = 72
In the second dataset, number of rows for VehBrand with B14 = 721.


If you look and compare the two datasets, you can map the equivalent names to the number of rows in the two dataset as follows:


Freq B2 == Relevel B2 with 26500 rows


Freq B12 == Relevel B13 with 1883 rows


Freq B3 == Relevel B3 with 8260 rows


Freq B5 == Relevel B5 with 6053 rows


Freq B6 == Relevel B1 with 27240 rows


Freq B4 == Relevel B11 with 1774 rows


Freq B10 == Relevel B4 with 3968 rows


Freq B13 == Relevel B10 with 2268 rows


Freq B11 == Relevel B12 with 16619 rows


Freq B14 == Relevel B6 with 4714 rows.


Since you are training the two GLM models with different datasets, you will get different coefficients and different prediction results.",2022-12-09T19:27:08,Wendy,https://stackoverflow.com/users/20736722/wendy,301,74294256
78945472,78945472,0,"it supports for latest version and as of date.
go to (
https://www.oracle.com/java/technologies/downloads/#jdk21-mac
) and select ARM64 DMG Installer for M series MAC.


after installation, with h2o installed h2o.init(), should run.",2024-09-03T17:30:05,user27182947,https://stackoverflow.com/users/27182947/user27182947,1,74240019
74098240,74098240,1,"It seems to me that you are passing frame instead of list of column names.
Both 
x
 and 
y
 are supposed to be ""pointers"" to columns in the 
training_frame
.


If you want to use all columns as predictors (all except the target), you can specify just the 
y
 parameter.


Something like the following should do the trick:


train_data[""Survived""] = train_data[""Survived""].asfactor()
classifier  =  H2OGradientBoostingEstimator(nfolds =    5,
                                            ntrees =   15,
                                            seed   =    42,
                                            max_depth = 4)

classifier.train(x=[""pclass"", ""sex"", ""age"",  ...], y=""Survived"", training_frame = train_data)",2022-10-17T13:39:11,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,74097863
73905821,73905821,2,"There's no easy way to use 
.explain()
 on sklearn's pipeline.
You can extract the H2OAutoML's leader model (the best model trained in the AutoML) and on that you could call the 
.explain()
.


For 
.explain()
 to work you'll need an H2OFrame with the same features as was used to train the model and that's the problem for both interpretability and ease of use. You will need to create the dataset using the first 2 steps in the pipeline (in your example 
polyfeat
 and 
featselect
). This alone will make it very hard to interpret - the columns will get names like 
C1
, 
C2
, ...


You can do the things I described using the following code:


transformed_df = X_classes_test

num_of_steps = len(pipeline.steps)

# Transform the data using the pipeline
for i in range(num_of_steps - 1):
    transformed_df = pipeline.steps[i][1].transform(transformed_df)
    
# Create the H2OFrame
h2o_frame = h2o.H2OFrame(transformed_df)
h2o_frame.columns = [c for c in pipeline.steps[num_of_steps - 1][1].estimator.leader._model_json[""output""][""names""] 
                     if c != pipeline.steps[num_of_steps - 1][1].estimator.leader.actual_params[""response_column""]]    
# Add the response column
h2o_frame = h2o_frame.cbind(h2o.H2OFrame(y_classes_test.to_frame()))
h2o_frame.set_name(h2o_frame.shape[1]-1, pipeline.steps[num_of_steps - 1][1].estimator.leader.actual_params[""response_column""])

# Run the .explain()
pipeline.steps[num_of_steps - 1][1].estimator.leader.explain(h2o_frame)



However, I'd recommend another approach - if you need interpretability and do not need to cross-validate the whole pipeline. Use the first N-1 steps of the pipeline to create a data frame, add appropriate column names to the newly created data frame and then run h2o AutoML using the h2o api. This will make it easier to use 
.explain()
 and other interpretability related methods and you will have column names with actual meaning rather than just names based on column order.",2022-09-30T08:15:29,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,73903859
73838367,73838367,2,"You have a mistake in your rmse function. The return of 
length(y)
 is not returning what you think it does. You should use 
nrow
 to get the number of rows. You can check this with 
length(test['Sepal.Length'])
, which will return 1 and not 31 as you expect. Your function should be like this:


rmse = function(y, y_predict){
  N = nrow(y)
  RMSE = sqrt(sum((y-y_predict)^2,na.rm=T)/N)
  return(RMSE)
}

rmse(test['Sepal.Length'], test['predicted'])
[1] 0.3395448",2022-09-24T15:18:28,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,73831597
74120543,74120543,2,"Yes, H2O AutoML uses most of the hyperparameter defaults in GLM and Deep Learning, and both of those default to 
standardize = TRUE
.




In H2O, every transformation that happens in training will happen at predict time, so you don't need to worry.",2022-10-19T06:03:15,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",73804485
73552890,73552890,1,"I believe it could be caused by the small data. Try having at least 200 rows in your dataset. If that won't help, I'd recommend looking into h2o logs (e.g. 
h2o.download_all_logs(PATH_TO_A_DIRECTORY)
) and adding the whole stacktrace along with h2o version to this question.",2022-08-31T08:21:16,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,73548237
73546872,73546872,0,"Alpha and lambda have no acceptable range. Usually, it depends on the problem you're trying to solve and the other parameters you're using, like max depth. The value for both typically ranges from 0 to 5, but it is not limited to that range.


I recommend you to take a look at this link: 
https://medium.com/data-design/xgboost-hi-im-gamma-what-can-i-do-for-you-and-the-tuning-of-regularization-a42ea17e6ab6


The idea is very clearly explained.",2022-08-30T18:14:50,Mark,https://stackoverflow.com/users/19747149/mark,1,73532614
73422497,73422497,0,Training with such severely imbalanced data set is pointless. I would try a combination of up sampling and down sampling to get a more balanced data set that does not get too small.,2022-08-19T21:39:36,OliverHennhoefer,https://stackoverflow.com/users/16420204/oliverhennhoefer,939,73419125
73536902,73536902,0,"This may be the worst class imbalance I have ever seen in a problem.


If you can subset your majority class - not until the point that it is balanced - but until the balance is less sever while still being representative (i.e., 15/85% minority/majority), you'll have more luck with other conventional techniques, or a mixture (i.e., up sampling and
augmentation.) Can the data logically be subset to help with the imbalance? For example if data ranges back several years, you could use only the last year's worth of data. I'd also manually optimize the threshold against the minority class, like true positive rate.",2022-08-30T03:42:55,,,,73419125
73361306,73361306,0,"I tried 
conda install -c h2oai h2o
 in new environment and everything works fine for me.


It seems that you have installed only client version of the package which does not include h2o.jar. Can you provide your commands to reproduce it?",2022-08-15T12:53:18,Adam Valenta,https://stackoverflow.com/users/18505934/adam-valenta,36,73355181
73321499,73321499,0,"The fit method on 
H2OAutoML
 returns the leader model. Each model in SW has the method 
getFeatureImportances()
 returning Spark data frame with feature importances.


model=aml.fit(sparkDF)
model.getFeatureImportances().show()",2022-08-11T13:26:34,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,73316915
73294761,73294761,1,"Let's say you have an H2OAutoML object in a variable named 
aml
, you can then see the leaderboard by using 
aml.leaderboard
. The leaderboard is basically a table of all trained models sorted by some metric (AUC, RMSE, etc).


Stacked ensembles use the models that were trained before them - either all the models or the best model per model family (GBM, GLM, DRF, etc). To see the base models you can use the following:


print(aml.leaderboard) # to see what models were trained

# Let's assume you like the SE model with
# model_id ""StackedEnsemble_AllModels_1_AutoML_2_20220809_174830""

# You can retrieve the model by using h2o.get_model:
se = h2o.get_model(""StackedEnsemble_AllModels_1_AutoML_2_20220809_174830"")

# And then you can list model ids of the base models:
se.base_models",2022-08-09T15:55:56,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,73294368
73276790,73276790,0,"the automatic start of SW external backend is only support in Hadoop or K8s environments. In a standalone deployment, you need to deploy the external backend manually according to 
the tutorial in SW documentation
.",2022-08-08T10:57:51,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,73276305
73461505,73461505,0,"I'm not sure, but it seems to me they maybe just chose the lazy way out of a numerical difficulty.


mu=0
 (
ym
) is a degenerate case where 
p=0
 and so 
y=0
 always. It's not interesting, and not really part of any useful analysis. I'm not sure it can even come out with the linear-predictor. With using the natural parameter = linear predictor, you need the linear predictor to be equal to minus infinity...


However, 
y
 can be equal to 
0
 for other 
mu
's. And what you do in this case, is take the limit of the deviance as 
y->0
, which is completely defined for Negative-Binomial, and isn't equal to 0. They could have implemented it, but chose not too, so this is why I call it ""lazy"".",2022-08-23T15:37:57,Maverick Meerkat,https://stackoverflow.com/users/6296435/maverick-meerkat,"6,314",73215715
73167339,73167339,1,"The parameter 
--packages ai.h2o:sparkling-water-package_2.12:3.36.1.3-1-3.2
 downloads a jar artifact from Maven. This artifact could be used only for Scala/Java. I see there is a mistake in 
Sparkling Water documentation
.


If you want to use Python API, you need to:




Download SW zip archive from 
this location


Unzip the archive and go to the unzipped folder


Use the command 
spark-submit --master spark://local:7077 --py-files py/h2o_pysparkling_3.2-3.36.1.3-1-3.2.zip spark_h20/h2o.py
 for submitting the script to the cluster.",2022-07-29T13:13:25,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,73164701
73137883,73137883,1,"This is expected behavior, H2OAutoML is not reproducible by default.
To make H2OAutoML reproducible you need to set 
max_models
, 
seed
 and exclude DeepLearning (
exclude_algos=[""DeepLearning""]
) and make sure 
max_runtime_secs
 is not set.


To compare models you can use 
model explanations
 or you can just compare the 
model metrics
.",2022-07-27T12:24:06,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,73137419
72900660,72900660,1,"Yes, the 
h2o.explain
 uses the provided 
test_set
. The confusion matrix itself in your case is generated by 
h2o.confusionMatrix(object = model@leader, newdata = test_set)
.


Confusion matrix
 aggregates the data from 
h2o.predict
 thus providing some high level view on how does the model perform. 
h2o.predict
 gives you individual predictions without any aggregation.",2022-07-07T15:38:17,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72900276
72961595,72961595,1,"Created the Azure Python Timer Trigger Function in VS Code.


Installed the below dependencies in the VS Code Project terminal:




pip install requests
pip install tabulate
pip install future





If any existing or previous versions of H2o is available, uninstall it using the below command:



Next, run this command to install H2o module in the Project integrated terminal:




pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o





With the version of 
h2o==3.32.0.2
, I also got the same exceptions in VS Code output terminal.
So, I have tried with the below versions and working well.


requirements.txt file
:


azure-functions
h2o==3.36.1.2



Result
:




It also working with the version 
3.14.0.2
 H2o module in Python
.",2022-07-13T06:02:57,,,,72888069
72897315,72897315,1,"In H2O3, the 
model.explain()
 will return 
h2o.explanation._explain.H2OExplanation
 object. You can iterate through it to save your plots.


param 
render
, if 
True
, render the model explanations otherwise model explanations are just returned.


I was able to do it with the below function


tested with h2o version 
'3.36.1.2'


def save_explain_plots(model, data):
    obj = model.explain(data, render=False)
    for key in obj.keys():
        print(f""saving {key} plots"")
        if not obj.get(key).get(""plots""):
            continue
        plots = obj.get(key).get(""plots"").keys()

        os.makedirs(f""./images/{key}"", exist_ok=True)
        for plot in plots:
            fig = obj.get(key).get(""plots"").get(plot).figure()
            fig.savefig(f""./images/{key}/{plot}.png"")",2022-07-07T11:50:13,,,,72562340
72564512,72564512,0,"I think this is bug (off-by-one error) in the SVMLight parser, so I filed a bug 
here
.  For now, I'd recommend just naming the columns after you import the file.  Thank you for the reproducible example and bug report!",2022-06-09T17:41:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",72560442
72468521,72468521,0,"This is not an issue with H2O, it is a known vulnerability with much older versions of Java: 
https://nvd.nist.gov/vuln/detail/CVE-2012-0507",2022-06-01T22:02:04,TheFon,https://stackoverflow.com/users/5225817/thefon,31,72465078
72463879,72463879,1,"H2O.ai offers a bunch of ML solutions: h2o-3, driverless ai, hydrogen torch to name the main ones.


Driverless AI is AutoML driven, the user has, however, an option to provide a custom recipe (in Python) to customize it. Driverless AI has Snowflake integration.


H2O-3 is a framework that implements a collection of popular ML algorithms. H2O-3 also integrates an AutoML solution utilizing the built-in algos. There is no option to integrate a 3rd party solution into H2O-3 AutoML and to extend H2O-3 algos other than by coding in Java (small Python customizations can be made by providing eg. custom loss function in GBM).",2022-06-01T14:49:21,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72456723
72411068,72411068,3,"Removing the object from the R session using 
rm(h2o_df)
 will eventually trigger garbage collection in R and the delete will be propagated to H2O. I don't think this is ideal, however.


The recommended way is to use 
h2o.rm
 or for your particular use case, it seems like 
h2o.removeAll
 would be the best (takes care of everything, models, data..).",2022-05-27T21:04:54,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72400864
72377082,72377082,1,"I believe the issue is in the 
metalearner_algorithm
 specification - it should be one of 
""AUTO""
, 
""glm""
, 
""gbm""
, 
""drf""
, 
""deeplearning""
, or 
""xgboost""
. See the 
documentation
 for more details.",2022-05-25T11:49:26,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72376952
72352330,72352330,2,"This is happening because H2O considers value -Double.MAX_VALUE to be the lowest possible representable floating-point number. This value corresponds to -1.80e308. I agree this is confusing and I would consider this to be a bug. You can file an issue in our bug tracker: 
https://h2oai.atlassian.net/
 (PUBDEV project)",2022-05-23T17:06:19,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72253927
72255034,72255034,1,"Not sure how to achieve that with 
h2o.group_by()
 – I get the same weird value when running your code. If you are open for a somewhat hacky workaround, you might want to try the following (I included the part on H2O initialization for future reference):




convert your frame to long format, ie key-value representation


split by group and apply aggregate function using 
h2o.ddply()


convert your frame back to wide format




## initialize h2o
library(h2o)

h2o.init(
  nthreads = parallel::detectCores() * 0.5
)

df_h2o = as.h2o(
  df
)

## aggregate per group
df_h2o |> 
  
  # convert to long format
  h2o.melt(
    id_vars = ""Group""
    , skipna = TRUE # does not include `NA` in the result
  ) |> 
  
  # calculate `max()` per group
  h2o.ddply(
    .variables = c(""Group"", ""variable"")
    , FUN = function(df) {
      max(df[, 3])
    }
  ) |> 
  
  # convert back to wide format
  h2o.pivot(
    index = ""Group""
    , column = ""variable""
    , value = ""ddply_C1""
  )

# Group ID VarA VarB VarD
#     1  4    3  NaN   16
#     2  7   12   14   14
#     3 10   14   16   16
#     4 12   14   16   16
#     5 16   16   16   16
# 
# [5 rows x 5 columns] 

## shut down h2o instance
h2o.shutdown(
  prompt = FALSE
)",2022-05-16T06:41:50,,,,72253927
72099329,72099329,0,"Unfortunately, the 
explain
 method in H2O-3 is supported only for the supervised algorithms.


What you could do is to use a surrogate model and look at explanations on it.
Basically, you'd fit a GBM (or DRF as those 2 models support the 
TreeSHAP
) on the data + the prediction of the Extended Isolation Forest which would be the response.",2022-05-03T12:22:55,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72098968
72104750,72104750,0,"Here is another approach how to explain prediction of (E)IF: 
https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/isolation-forest/interpreting_isolation-forest.ipynb",2022-05-03T19:50:29,Adam Valenta,https://stackoverflow.com/users/18505934/adam-valenta,36,72098968
72062440,72062440,1,Right now we do not support categorical columns in generating splines.  It is on our roadmap though.,2022-04-29T18:42:43,Wendy Wong,https://stackoverflow.com/users/15170707/wendy-wong,11,72048657
74668911,74668911,0,"I could run successfully following the steps:




Downloaded sparkling water distribution zip: 
http://h2o-release.s3.amazonaws.com/sparkling-water/spark-3.1/3.36.1.1-1-3.1/index.html


Dependent JARs path: s3://bucket_name/sparkling-water-assembly-scoring_2.12-3.36.1.1-1-3.1-all.jar


--additional-python-modules, h2o-pysparkling-3.1==3.36.1.1-1-3.1",2022-12-03T17:15:33,,,,71928885
72014048,72014048,1,"I believe you are looking for the 
learning curve plot
. In h2o you can retrieve the ""scoring history"" data using 
model.scoring_history()
.


You can influence the frequency of scoring as well as amount of data used for the loss estimate using parameters prefixed with 
score_
, e.g., 
score_interval
, 
score_validation_samples
 etc.",2022-04-26T12:33:26,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,71777142
71741875,71741875,2,"You can use 
aml.leader
 to get the top model or you can use 
get_best_model
 to pick the model by some criterium. If you want to pick some specific model from the leaderboard you can use 
h2o.get_model(""model_id"")
 (the model_id is from the leaderboard).


To get parameters from all the base models you can use the following:


{base_model: h2o.get_model(base_model).actual_params
 for base_model in h2o.get_model(""model_id"").base_models}



You might also want to get parameters from the stacked ensemble and the metalearner:


metalearner_params = h2o.get_model(""SE_model_id"").metalearner().actual_params
se_params = h2o.get_model(""SE_model_id"").actual_params",2022-04-04T18:08:54,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,71741263
71699115,71699115,4,"There's a few things wrong with the code (we need to do a better job of documenting the 
random_columns
 parameter).  Currently the 
random_columns
 parameter only supports column indexes (not column names) and I created a 
JIRA
 to improve this.


The error is not actually saying that the column has to be numeric; in fact it needs to be a factor.  And lastly, you need to set 
HGLM = TRUE
.  To fix your code above, you can do:


df2$ID2 <- as.factor(df2$ID2)

test_glm2 <- h2o.glm(family = ""gaussian"",
                     x = ""x"",
                     y = ""y"",
                     training_frame = df2,
                     random_columns = c(4),
                     HGLM = TRUE,
                     lambda = 0,
                     compute_p_values = TRUE)



EDIT: This still causes a bug, so I filed a bug report 
here
.",2022-03-31T21:04:02,,,,71693880
71617486,71617486,1,"It seems that your environment still contains old H2O R library. 
cacert
 is an 
valid parameter
 and it was introduced in H2O 3.26.0.6.",2022-03-25T13:08:37,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,71616995
71616883,71616883,1,"See 
this tutorial
 please. The newer versions of Rsparkling use {H2OContext.getOrCreate(h2oConf)} instead of {h2o_context(sc)}.",2022-03-25T12:19:19,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,71609592
71530878,71530878,1,"I am sorry, the XGBoost is not supported on Apple M1 processor yet.


https://h2oai.atlassian.net/browse/PUBDEV-8482",2022-03-18T17:19:44,Adam Valenta,https://stackoverflow.com/users/18505934/adam-valenta,36,71529386
71238234,71238234,0,"userIdAttribute=""uid"" worked for me.
Now the authentication from LDAP is successful, however now it's failing with same exception mentioned at:

https://github.com/eclipse/jetty.project/issues/2648
, and the suggested fix is NOT included in h2o.jar, hence the failure.
#h2o team needs to update the h2o.jar with this fix.",2022-02-23T13:57:32,Pankaj Mahadik,https://stackoverflow.com/users/16570951/pankaj-mahadik,31,71172747
71150841,71150841,0,"This typically means one of the nodes crashed, it can be due to many different reasons - memory is the most common one.


I see your machine has about 64GB of physical memory and H2O is getting 48GB out of that. XGBoost runs in native memory, not in the JVM memory. For XGBoost we recommend splitting the physical memory 50-50 to H2O and XGBoost.


You are running a development version of H2O (3.33) - I suggest upgrading to the latest stable.",2022-02-17T00:02:39,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71146238
71150782,71150782,0,"Stacked Ensemble is a model that is based on outputs of other models. To re-train the SE model you will need to re-train the individual models.


Apart from that AutoML will not pre-process the data. It delegates the pre-processing to downstream models. There is one exception - target encoding.


Did you enable TE in AutoML?",2022-02-16T23:54:28,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71138526
71150875,71150875,1,Based on description in comments - this seems like a bug and fix will be needed.,2022-02-17T00:06:57,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71093974
71150717,71150717,0,"Can you post a list of all built models and their performances? The best one has  a depth 10, it would be useful to know what other hyperparameters were explored.


You max runtime is only 5 minutes, it is possible most of the hyperparameter space was not explored. Lets see what other models were build.",2022-02-16T23:46:43,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71081912
71069800,71069800,1,"With the glm your predictions are in log form. To compare them you need to use the exponential of the predictions.


Metrics::rmse(exp(pred), test$DriversKilled)
[1] 18.09796



If you make a prediction with h2o you will see that it has already taken care of the exponential operation.


Note that the models differ slightly in the rmse. 
h2o.glm
 has a lot more going on in the background.",2022-02-10T17:39:03,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,71068729
71150632,71150632,0,"This is because you cannot use an older model in a newer version of H2O. When you are working with binary models, the version has to be the same.",2022-02-16T23:34:54,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71063715
70804860,70804860,0,"Article 
https://www.h2o.ai/blog/hacking-algorithms-into-h2o-quantiles/
 is still relevant, some details changed by the main concept remained the same.


Everything you read about map-reduce and DKV is still relevant to this day. The foundation of the article didn't change.


We will refresh the article to make it up to date with the current code base.",2022-01-21T16:55:35,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70759860
71150866,71150866,0,"I already added an example of extending H2O: 
https://github.com/h2oai/h2o-3/pull/6070


It gives you a skeleton of the implementation of H2O algorithm.",2022-02-17T00:05:26,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70759860
70737274,70737274,1,"Try this instead:


from h2o.estimators.model_selection import H2OModelSelectionEstimator



If you can't import it, then you probably don't have the latest version of H2O, so you should 
download
 it.  
ModelSelection
 was just released in 3.36.0.1.",2022-01-17T06:22:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70721119
70682629,70682629,4,"Thank you for the question, Roshan,


Snowflake Partner Connect enables a 14-day trial of Driverless AI to be started directly from the Snowflake UI.


When Driverless AI is deployed independently or in the H2O.ai Managed cloud it can connect to Snowflake using the Snowflake connector or JDBC.


Partner Connect is only for trials and labs that demonstrate the capabilities of the products. Customers would then pick a deployment (on-prem, cloud, managed cloud etc.) that aligns with your deployment requirements.


Both Driverless AI and H2O-3 can connect to Snowflake to access data for training, using the Snowflake Connector (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/connectors/snowflake.html
) or JDBC (
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/getting-data-into-h2o.html#jdbc-databases
)


When inferencing (scoring) models can be used with Snowflake as either external functions or user defined functions (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/snowflake-integration.html
)


The functionality in Driverless AI can be used via an API, here is a link the describes how to use the client and notebooks (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/python_client.html
)


Please reach out if you have any questions.",2022-01-12T13:43:06,Eric Gudgion,https://stackoverflow.com/users/17915291/eric-gudgion,41,70637288
70678604,70678604,2,"Changing Java install to 
FROM openjdk:15.0.2-jdk-slim
 has solved the issue",2022-01-12T08:48:55,sandoronodi,https://stackoverflow.com/users/6126355/sandoronodi,315,70622044
70609024,70609024,1,"Unfortunately, H2O-3 doesn't currently support exporting GLM with interactions as MOJO. There's a bug that allows the GLM to be exported with interactions but the MOJO doesn't work correctly - the interactions are replaced by missing values. This should be fixed in the next release (3.36.0.2) - it will not allow to export that MOJO in the first place.


There's not much other than writing the stacked ensemble in R (base model predictions preprocessing (e.g., interaction creation) and then feeding it to the h2o.glm) that you can do. There is now an unmaintained package 
h2oEnsemble
 that might be helpful for that. You can also use another metalearner model that is more flexible, e.g., GBM.",2022-01-06T14:54:28,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,70597370
70883882,70883882,1,"This functionality is called ""row binding"", it is not exposed as an API method. It is, however, available as a Rapids expression (simple scheme-like language). You can follow this example to row-bind 2 H2O Frames: 
https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/test/java/water/rapids/ast/prims/mungers/AstRBindTest.java#L40
 In a nutshell, if you have 2 frames with keys A and B you would run water.rapids.Rapids.exec(""rbind A B"").getFrame()",2022-01-27T18:28:01,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70471661
70442318,70442318,1,"Did you try Notebook-scoped library concepts ?  Notebook-scoped libraries let you create, modify, save, reuse, and share custom Python environments that are specific to a notebook. When you install a notebook-scoped library, only the current notebook and any jobs associated with that notebook have access to that library. Other notebooks attached to the same cluster are not affected. You can ref : 
link


Limitations : Notebook-scoped libraries do not persist across sessions. You must reinstall notebook-scoped libraries at the beginning of each session, or whenever the notebook is detached from a cluster.",2021-12-21T22:39:00,Karthikeyan Rasipalay Durairaj,https://stackoverflow.com/users/9599091/karthikeyan-rasipalay-durairaj,"2,316",70440726
70467722,70467722,3,"H2O.ai has releases/patches upgraded to the latest log4j version 2.17 to address the various vulnerabilities found. Updates are at:


https://www.h2o.ai/security/bulletins/h2o-2021-001/",2021-12-23T21:49:01,Satish Maruvada,https://stackoverflow.com/users/17711973/satish-maruvada,46,70408222
70408223,70408223,1,"H2O.ai is closely tracking the vulnerabilities and publishing updates at 
https://www.h2o.ai/security/bulletins/h2o-2021-001/
.",2021-12-19T00:35:45,Michal,https://stackoverflow.com/users/5089773/michal,437,70408222
70366535,70366535,3,"A jar file is just a compressed folder with a different name. You can explore your packages looking for this information.


H2Os official statement, including affected versions and recommendations: 
https://www.h2o.ai/security/bulletins/h2o-2021-001/",2021-12-15T15:46:58,Luna,https://stackoverflow.com/users/16686308/luna,185,70366277
70366543,70366543,3,"As stated on 
https://logging.apache.org/log4j/2.x/security.html
 Log4J 1.x versions are not affected by this vulnerability. And it seems that 
h2o
 is using 
log4j-1.2.15.jar
 so you are okay.",2021-12-15T15:47:13,bradley101,https://stackoverflow.com/users/7373144/bradley101,721,70366277
71150938,71150938,0,"Uninstalling a simply a matter of deleting the H2O jar file in your case.


To my knowledge Windows will only open the port for the given piece of software. Once you remove H2O from your computer the firewall rule will no longer apply.


This is more of a Windows-firewall question rather than H2O question, so please take my answer with a grain of salt.",2022-02-17T00:15:38,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70311395
71150953,71150953,0,"One way to define the threshold would be to calculate a say 0.95 quantile of MSE on your training set and use that for a threshold.


Is part of your data labeled - that would open up possibilities for other ways of defining threshold.",2022-02-17T00:18:45,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70294943
70719459,70719459,0,"You cannot add new methods in your pipeline in Flow.  Flow is just a simple GUI which allows you to do things like create train/test splits, train models, test models and view some metrics.  You'd have to use the R or Python client to create a pipeline of any sort.",2022-01-15T06:56:57,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70279189
71150888,71150888,0,"Yes, this is expected. Once one of the nodes crashes, you will need to restart the whole cluster. You need to make sure that you configure your kubernets jobs so that the pods are not preempted.",2022-02-17T00:08:37,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70274744
70211830,70211830,2,"My guess is that the first approach will give better performance due to less context switching. I'm not too familiar with H2O but I guess they start a thread per core. So if you have 3 H2O instances, you get 3 threads per core which will lead to an increased number of context switches and hence reduced performance.


And I'm pretty sure that H2O can work with huge amounts of memory. They can pool the created arrays, so there should not be too much need for garbage collection for the actual data.",2021-12-03T09:08:53,pveentjer,https://stackoverflow.com/users/2245707/pveentjer,11.2k,70205550
70719466,70719466,0,Running H2O on a single node is always better (when possible) because there's communication overhead between the cluster nodes.  Models will train faster on a single node.,2022-01-15T06:58:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70205550
70186489,70186489,0,"The master node is also known as the ""driver"" so yes, you can set the driver memory: 
spark.driver.memory
  Here's a 
complete list of settings
 you can tweak.",2021-12-01T15:01:08,Matt Andruff,https://stackoverflow.com/users/13535120/matt-andruff,"5,100",70178457
69993553,69993553,1,"It looks like h2o bug, but you can work with H2OFrame.levels() directly.
h2o model(GLM at least) automatically takes first level from levels list as a base level.


So you can reorder them like in example below:


Considering hf['color'] as factor column, print out levels list


df_dict = {'a': [1,2,3,4,3,3,3], 'b': [5,6,7,8,4,4,4], 'c': [9,10,11,12,3,3,3], 
     'color': pd.Series(['red', 'blue', 'green', 'red', 'orange', 'blue', 'red'])}
df = pd.DataFrame(df_dict)

hf = h2o.H2OFrame(df)

hf['color'] = hf['color'].asfactor()
print(hf['color'].levels())




Wich gives the next result:


[['blue', 'green', 'orange', 'red']]




Then, transform levels list and set directly with set_levels()


future_base_level = 'green'

levels_list = hf['color'].levels()[0]
my_index = levels_list.index(future_base_level)
levels_list[my_index], levels_list[0] = levels_list[0], future_base_level

hf['color'] = hf['color'].set_levels(levels=levels_list)
print(hf['color'].levels())



Result:


[['green', 'blue', 'orange', 'red']]




Order changed, base level now on the 'green' value.",2021-11-16T17:23:51,DmitryKutsev,https://stackoverflow.com/users/17392851/dmitrykutsev,11,69939756
71153576,71153576,3,"In the 
iml package documentation
, it says that the 
class
 argument is ""The class column to be returned."". When you set 
class = ""classification""
, it's looking for a column called ""classification"" which is not found. At least on GitHub, it looks like the 
iml package
 has gone through a fair amount of development since that blog post, so I imagine some functionality may not be backwards compatible anymore.


After reading through the package documentation, I think you might want to try something like:


predictor.glm <- Predictor$new(
  model = glm, 
  data = features, 
  y = ""Attrition"",
  predict.function = pred,
  type = ""prob""
  )

# check ability to predict first
check <- predictor.glm$predict(features)
print(check)



Even better might be to leverage H2O's extensive functionality around machine learning interpretability.


h2o.varimp(glm)
 will give the user the variable importance for each feature


h2o.varimp_plot(glm, 10)
 will render a graphic showing the relative importance of each feature.


h2o.explain(glm, as.h2o(features))
 is a wrapper for the explainability interface and will by default provide the confusion matrix (in this case) as well as variable importance, and partial dependency plots for each feature.


For certain algorithms (e.g., tree-based methods), 
h2o.shap_explain_row_plot()
 and 
h2o.shap_summary_plot()
 will provide the shap contributions.


The 
h2o-3 docs
 might be useful here to explore more",2022-02-17T06:45:55,TheFon,https://stackoverflow.com/users/5225817/thefon,31,69930234
70011481,70011481,1,"This is Azim from H2O.ai.


To deploy the model you trained on your H2O DAI instance and start making predictions, you will need a license key. As a trial user, you could sign up here for a license key that is valid for 21 days: 
https://www.h2o.ai/try-driverless-ai/


This is listed as a prerequisite in the first section titled 
Use Case Overview
 on the Snowflake and H2O.ai quickstart guide. Thanks for your question, we will clarify this by adding a note on the 
Deployment
 section too.",2021-11-17T21:00:40,desertnaut,https://stackoverflow.com/users/4685471/desertnaut,60.1k,69910275
69709530,69709530,0,make sure there are only parquet files in your folder (no spline etc),2021-10-25T14:09:56,donSjon,https://stackoverflow.com/users/17242529/donsjon,1,69496937
70884445,70884445,2,"I think I also experienced this issue, although on macOS 12.1.
I tried to debug it and found out that sometimes I also get another error:


Unexpected CURL error: Failed to connect to 127.0.0.1 port 54321: Connection reset by peer



I found out that this issue appears only when I have 
RCurl
 compiled against 
curl
 7.68.0 and above.


Downgrading to 
curl
 7.67.0 resolved the issue for me but then I got some issues with RStudio (Segmentation Fault) so I looked into the issue little further.


And I found out that compiling a recent version of 
curl
 with 
--disable-socketpair
 solved it for me as well.


I was monitoring open files and sockets (
lsof
) and it seems to me that 
R
 process runs out of sockets it can create and 
RCurl
 then fails with one of those errors. Running 
gc()
 in R frequently helps (I called it after every single request) but still the minimum number of open sockets after 
gc()
 is slowly but monotonically increasing which leads me to believe there might be some leak. I reported this as a possible bug to the RCurl maintainers.


For anybody using macOS and homebrew this can be accomplished by running the following:


$ brew edit curl # add --disable-socketpair to args list
$ brew install --build-from-source curl # using reinstall might be needed instead of install

$ export RCURL_PATH=""usr/local/opt/
[email protected]
"" # can be found using `brew info curl`
$ export PATH=""$RCURL_PATH/bin:$PATH"" # for curl-config
$ export LDFLAGS=""-L$RCURL_PATH//lib""
$ export CPPFLAGS=""-I$RCURL_PATH/include""
$ export PKG_CONFIG_PATH=""$RCURL_PATH/lib/pkgconfig""

$ R -e ""chooseCRANmirror(graphics=FALSE, ind=1);install.packages('RCurl', type = 'source')""
$ R -e ""RCurl::curlVersion()$version"" # check if RCurl is using the proper version of curl




Looking at the 
curl
 version in ubuntu 20.04 which is 7.68.0 (according to 
https://packages.ubuntu.com/focal/curl
) I think you won't be able to use the following as the 
--disable-socketpair
 was added in 
curl
 7.73.0 but since you are using a virtual machine it might be easier to just use ubuntu 18.04 since it's 
still supported
 and is using old enough 
curl
 version (7.58.0).


I haven't used ubuntu for a while but at least I can provide some pseudo-code that should do the same:


$ sudo apt install devscripts
$ # make sure source repositories are enabled (uncommented in /etc/apt/s
$ apt-get source curl
$ sudo apt-get build-dep curl
$ cd curl
$ nano debian/rules # add the --disable-socketpair configure option
$ dch -i # bump the version
$ debuild -us -uc -b # build the package
$ dpkg -i ../curl-some_version.dpkg

$ export PATH=""$RCURL_PATH/bin:$PATH"" # for curl-config
$ export LDFLAGS=""-L$RCURL_PATH//lib""
$ export CPPFLAGS=""-I$RCURL_PATH/include""
$ export PKG_CONFIG_PATH=""$RCURL_PATH/lib/pkgconfig""

$ R -e ""chooseCRANmirror(graphics=FALSE, ind=1);install.packages('RCurl', type = 'source')""
$ R -e ""RCurl::curlVersion()$version"" # check if RCurl is using the proper version of curl",2022-01-27T19:14:55,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,69485936
70026679,70026679,0,This is a known bug (I assume you're on Windows) with 3.34.0.1.  Please upgrade to latest version of H2O and it should be fixed.  Sorry for the bug!,2021-11-18T21:00:40,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",69377034
71283499,71283499,0,"I'm not sure if it's the best approach but using the following should be more efficient than using 
as.vector
(one pass over all the rows to get the 
mpg_mean
 and one pass in 
h2o.ifelse
).


mpg_mean <-  h2o.mean(mtcars[mtcars[[""cyl""]] == 4, ""mpg""])
mtcars[[""mpg_rel""]] <- h2o.ifelse(mtcars[[""cyl""]] == 4, mtcars[[""mpg""]] / mpg_mean, mtcars[[""mpg""]])",2022-02-27T09:13:30,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,69366490
69354466,69354466,2,"Your Python session is ending, and thus your H2O cluster may be stopping.


You can start H2O 3 from 
Command Line
, for example:


java -jar h2o.jar



^you will need to be in the directory of your H2O 3 folder (like 
here
).


Alternatively, you can add 
sleep
 to your script:


import time
time.sleep(10)



^this will leave the program running for 10 seconds. If you want to extend it, just add more seconds to the max time you want the program to run.",2021-09-28T00:21:04,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,69351124
69265528,69265528,0,"Try setting 
fold_assignment=""Stratified""
. See 
fold_assignment
 documentation for more details.",2021-09-21T08:13:38,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,69263794
69410071,69410071,1,I can confirm that I got the same error on version 3.34.0.1 when attempting to run automl on a regression problem. Building a GBM didn't throw an error. I downgraded versions to 3.32.1.7 and when running the identical code did not get an error message. For now I would suggest reverting to the prior version until an update is released.,2021-10-01T17:46:35,Ben Fowler,https://stackoverflow.com/users/8720891/ben-fowler,21,69234002
69259130,69259130,1,"If you want to launch H2O via CLI with 3 independent nodes, then give them different names:


-name H2O_CLUSTER_NAME_1


-name H2O_CLUSTER_NAME_2


-name H2O_CLUSTER_NAME_3


If you try to give theme the same name, they will try to form a cluster. See 
here
.",2021-09-20T18:17:18,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,69195292
69114412,69114412,0,"Can't track the issue given limited information in your question. You can try the code below.


import pandas as pd
import h2o

# Pandas DataFrame
df = pd.DataFrame({'col1': [1,2,3], 'col2': ['A', 'B', 'C']})

# Conversion to h2o frame
hf = h2o.H2OFrame(df)",2021-09-09T08:01:08,Furqan Hashim,https://stackoverflow.com/users/7326981/furqan-hashim,"1,318",69113860
68897762,68897762,1,"The 
docker exec -it <CONTAINER_ID> pip list
 is not enough to check if package is installed in the image. Airflow image uses custom entrypoint which you need to use to enter the image to get into the same environment, airflow containers are running in. This is mainly to make it open-shift compatible and allows to run it via different users - not only airflow, but also root and any other users you want.


You can see details about the entrypoint here: 
https://airflow.apache.org/docs/docker-stack/entrypoint.html


I built the image using your dockerfile:


docker build . --tag my-image



And it worked just fine. When I enter the image using 
bash
 command (as described in the ""entrypoint"" documentation, I got h2o properly installed:


docker run -it my-image bash
airflow@d319ba82f3b4:/opt/airflow$ pip freeze | grep h2o
h2o==3.32.1.6



The way you can actually check if the image has the right dependencies installed, is to 
exec
 into the running container via 
/entrypoint
. I did it as well on a running container and it looks good:


exec -it d319ba82f3b4 /entrypoint bash
airflow@d319ba82f3b4:/opt/airflow$ pip freeze | grep h2o
h2o==3.32.1.6
airflow@d319ba82f3b4:/opt/airflow$ 



Also this works quite fine:


docker exec -it d319ba82f3b4 /entrypoint bash -c 'pip list | grep h2o'
h2o                                      3.32.1.6



Likely - for some reason, still old not rebuilt image is used. Did you run 
docker-compose up
 with 
--build
 flag? You can also run 
docker-compose build
 to make sure that your images are rebuilt when you use 
build
 directive in docker-compose.


There is one comment to your image though.


Your image is highly un-optimized. Because you've added 
build-essentials
 to the image, your image is about 200 MB (at least) bigger than it could be if you go ""customization"" route. Going that route is a bit more complex (requires Airflow sources) but it's well worth it. See 
https://airflow.apache.org/docs/docker-stack/build.html#customizing-the-image
  there are some examples where going 
customization
 route saves ~25% of image  size.",2021-08-23T19:00:03,,,,68888281
69051070,69051070,1,"There is an error message showing up in your output


Details: ERRR on field: _min_rows: The dataset size is too 
small to split for min_rows=10.0: must have at least 20.0 (weighted) rows, but have only 
0.7xxxx.



It seems like you need to increase your weight values and/or increase number of rows. Try multiplying your weight column by 10 or 100x and see if it helps. I suspect this wouldn't be an issue if you try setting weights columns to all ones.",2021-09-03T22:22:43,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,68874158
68979838,68979838,0,"This is an 
undocumented parameter
 (used internally for testing), so although I will post how to do it here, you should not count on this parameter as something that will always be available.  Use at your own risk!


The reason that you're getting this error is that this is only available when you start H2O with special Java flags.  In Python, you have to start H2O like this:


# Start H2O with custom algo_parameters option enabled
h2o.init(jvm_custom_args=[""-Dsys.ai.h2o.automl.algo_parameters.all.enabled=true""])



And then this will work:


aml = H2OAutoML(
    nfolds=5, 
    include_algos=['XGBoost'], 
    sort_metric='auc', 
    seed=1, 
    max_runtime_secs=10,
    algo_parameters=dict(XGBoost__booster = 'gbtree')
)



Note: you should pre-pend the algorithm name to the parameter name with two underscores, so it knows which algo to use it in, even if you only include XGBoost, it's good to be verbose.",2021-08-30T06:37:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",68695428
68680725,68680725,3,"I think the reason is that the parallel speed is composed of two main components:




computing time on every single core


communicating time to communicate and collecting results




If you have small data and a lot of cores, the algorithm could slow down due to huge communication. Try for example 4, 6, 10 cores instead of 96 to speed up.",2021-08-06T11:18:52,Maurever,https://stackoverflow.com/users/5036600/maurever,157,68672166
68850864,68850864,0,"In H2O, there is 
balance_classes
 which helps with resampling your positives/negatives. However, it doesn't seem to be supported for XGBoost yet. Applying a 
weights_column
 would be a good alternative.",2021-08-19T15:44:22,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,68669460
68610168,68610168,3,"TLDR: your problem would be massively simplified by changing the instances to detect anomalies to be cycles, not individual data samples from sensor. The differences between existing applied methods are probably due to differences in hyper-parameters, and the sensitivity to hyperparameters due to the less-than-ideal problem specification.


This is a time-series, and your anomalies seem to be stateful - that is an anomaly starts to occur, and then affects many time-steps, then recovers again. However, you appear to be trying to detect anomalies in individual time-steps / samples, which will not work well, because in the anomalous condition the highest values are still within the normal range of individual datapoints from a normal condition. Furthermore there are strong temporal patterns in your data for the normal condition, and these are not possible to model with such an approach. That different softwares give different not-so-good results is expected, as tradeoffs will have to be made, and different hyperparameters will influence this.


What you should do is to transform your original time-series to get instances that are more meaningful than individual point samples. The best for this kind of cyclic process with strong similarities between cycles, is to transform into a time-series for each cycle. This requires knowing (or reliably detecting) when a cycle starts.


If cycle start is not available, one can instead use a sliding window approach, where the window is long enough to cover one or more cycles.


Once you have such a set of windows, one can think about doing anomaly detection on it. Start with computing basic statistics that summaries the window (mean,std,min,max,max-min etc). The anomalies you have shown as an example will be trivially separable by the mean value of the cycle (or max or min). Don't need a isolation forest even, a Gaussian Mixture Model will do just fine, and allow for more interpretable results. This should work across a wide range of models and hyperparamters.


Once a basic solution that captures such large discrepancies are in place, one can consider going further. Adding a sequence model autoencoder would for example be able to pick up much smaller deviations, if one has enough data.",2021-08-01T11:54:49,,,,68461155
68461268,68461268,2,"Pycaret uses for anomaly detection the library PyOD. It is then PyOD vs H2O. Maybe there are different default parameters. In Pycaret (PyOD) could be modified the parameter fraction  - default = 0.05, the percentage / proportion of outliers in the dataset.


You should try to play with this parameter und perhaps you get the same results from both libraries.",2021-07-20T20:57:38,Essegn,https://stackoverflow.com/users/13218304/essegn,153,68461155
68584159,68584159,2,"First of all you'd need to provide particular versions of each library as implementation of isolation forest and thus results might differ between PyOD versions.


Other than that try to see first if results of running isolation forest alone in PyOD and in H2O are consistently the same - maybe it's more of a random number generator / state issue than implementation difference.


Apart from validating parameters I recommend you to take a look at code of these libraries - likely it's difference between default parameter values: 
https://pyod.readthedocs.io/en/latest/_modules/pyod/models/iforest.html",2021-07-30T00:32:39,Adrian Szymczak,https://stackoverflow.com/users/2148483/adrian-szymczak,79,68461155
68454174,68454174,1,"I believe the algorithms from Scikit-Learn do not accept H2O Frames. So, you can convert the H2O Frames, for example, into Pandas DataFrames, by doing:


pandas_frame = h2o_frame.as_data_frame()",2021-07-20T11:35:20,luis_ferreira223,https://stackoverflow.com/users/12857373/luis-ferreira223,84,68404982
68401329,68401329,1,"There's no concept of a ""target metric"" when generating predictions, since you're just predicting the response for a row of data (there's no scoring here).


Edit: Thanks for clarifying your question.  If you want to change how the threshold is generated, then what you're doing above is a good solution.  If you have a suggestion for a utility function that would make this more straight-forward, please file a 
JIRA
 with your idea (it could definitely be improved).",2021-07-15T22:14:08,,,,68401118
68313233,68313233,0,"Most likely a bug in 
h2o
. Yesterday, there was a new fix release so if you can, I'd suggest upgrading to the newest version. Note that not all versions end up on 
CRAN
 (
h2o
 releases more frequently than recommended on 
CRAN
) so you can install the new version from 
here
.


If that doesn't help, you can file a bug report as described 
here
.


There might also be a chance that you could mitigate the issue by changing the 
solver
 but in this case, it would still be nice if you'd file a bug report (so it gets fixed). Ideally with more details, e.g., stack trace from the Java backend (might be printed in the error message in 
RStudio
 and definitely is in the logs).",2021-07-09T08:00:10,David Lee,https://stackoverflow.com/users/9246764/david-lee,663,68310117
68370871,68370871,1,"It will be a bit tricky, since the packages are a bit different. Sklearn is based on Python/Cython/C and H2O uses Java. The underlying algorithms could also be different. However, you can try matching/translating your hyperparameters between the two since they will be similar.


Additionally, it would be a good idea to have an ecosystem that is library agnostic so that you can interchange different models.",2021-07-14T01:09:23,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,68295229
68099249,68099249,0,"The issue is related to number of descriptors setting in linux. The 
cron
 environment is different than the system environment when running the script in interactive mode.


As a solution I have used extra parameter in my 
cron
 :


0 18 21 6 * ulimit -nS 1048576 && Rscript <script_name>



Then the error disappeared and the script ran correctly.",2021-06-23T11:48:56,Tomas,https://stackoverflow.com/users/11533623/tomas,91,68095583
68075629,68075629,2,"Getting the right Flow URL can be tricky because of the changes in the base URL at DBC. There were 
some improvements in more recent releases of SW
 that give the proper URL within Databricks, so make sure you try the latest version.


You should get it from your print/output, when you create an H2OContext. The port would be 9009. If you want to change it, you can use 
spark.ext.h2o.client.web.port
.


You can also find the link in ""Spark UI"" -> ""Sparkling Water"" tab


The format would be something like: 
https://your-dbc-domain/driver-proxy/o/xxxxxxxx/yyyyyyy/9009/flow/index.html


From the 
docs
 for reference:




Flow is accessible via the URL printed out after H2OContext is
started. Internally we use open port 9009. If you have an environment
where a different port is open on your Azure Databricks cluster, you
can configure it via spark.ext.h2o.client.web.port or corresponding
setter on H2OConf.",2021-06-21T22:53:56,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,68026366
77682641,77682641,0,"Did you get the 
HTTP ERROR 500 java.lang.NoSuchMethodError: org.apache.spark.ui.UIUtils$.listingTable(Lscala/collection/Seq;Lscala/Function1;Lscala/collection/Iterable;ZLscala/Option;Lscala/collection/Seq;ZZLscala/collection/Seq;)Lscala/collection/Seq;
 ?
There's seems to be the breaking change since spark 3.2 and the issues is still open. 
https://github.com/h2oai/sparkling-water/issues/2870


You could add more details in the issues post with the AWS also.",2023-12-19T02:23:42,silencepill,https://stackoverflow.com/users/10412518/silencepill,23,68026366
78555298,78555298,0,"To expand on Neema's answer, I put together a script that builds the proper URL. For some context, I'm running Databricks on GCP using 
h2o_pysparkling_3.5
 with runtime 14.3 LTS ML


import pandas as pd

x = ""spark.databricks.clusterUsageTags.""
org = spark.conf.get(x + ""orgId"")
clst = spark.conf.get(x + ""clusterId"")

flow = ""https://"" + org + ""."" + org[-1] + "".gcp.databricks.com/driver-proxy/o/"" + org + ""/"" + clst + ""/54321/flow/index.html""

dic = [{""Cluster"" : spark.conf.get(x + ""clusterName""), ""URL"" : flow}]

df = pd.DataFrame(dic)

def make_clickable(val):
    return '<a target=""_blank"" href=""{}"">{}</a>'.format(val, val)
  
df.style.format({'URL': make_clickable})



Replace 
gcp.databricks.com
 with whatever cloud provider domain you're using.",2024-05-30T13:30:15,tomasu,https://stackoverflow.com/users/11167644/tomasu,"1,438",68026366
69110665,69110665,0,Seems h2o cluster version is updated on CRAN version now. Simply reinstalling from CRAN solved the issue.,2021-09-08T23:28:36,Matthew Son,https://stackoverflow.com/users/10484383/matthew-son,"1,385",67940893
67830165,67830165,2,"I think I was able to solve it. After some monitoring with the htop command I think the issue was actually a memory one. I restarted h2o limiting the memory to 1GB and 2 threads (maybe this is not strictly necessary) and I was able to run everything ok, as it seems.


h2o.init(max_mem_size=""1G"", nthreads=2)



Hope it helps to anyone who stumbles with the same problem.",2021-06-04T00:45:14,Lucas Bali,https://stackoverflow.com/users/9366998/lucas-bali,81,67823594
67817409,67817409,1,"nfolds
 is specified when you want to do cross-validation. If you are not doing cross-validation and instead you are doing a train/valid/test data split, then you can ignore it.


train_samples_per_iteration
 decides how often scoring is done. The default is to let H2O decide, which is normally a good idea. Only touch it if you feel like a significant portion of training time is being wasted on scoring the model too frequently, or at the other extreme, that it is not scoring often enough (and missing chances to do early stopping).




Also, is it necessary to scale the training and testing sets before training the model?




No, H2O will 
do this by default
.




Would it be important to transfer the response variable to a factor form?




Yes. If the response variable is one of a set of categories, make sure H2O has recognized it as a factor. If it recognizes it as a numerical type it will build a regression model instead.


(It normally does the right thing automatically, but it can miss your intention if your categories are numbers, e.g. ""0"" for no, ""1"" for yes.)",2021-06-03T07:44:51,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,67814769
67725424,67725424,2,"You're getting different results because you're evaluating the learner using different train and test data. If I use the same 3-fold CV, I get the same results:


set.seed(1234)
resample(learner, task, cv3, list(auc, acc))

Aggr perf: auc.test.mean=0.8526496,acc.test.mean=0.7466667



In general, every computed performance is only an 
estimate
 of the true generalization performance. This will vary depending on what method of resampling you choose and what data.",2021-05-27T15:33:05,Lars Kotthoff,https://stackoverflow.com/users/1172002/lars-kotthoff,109k,67725019
67644195,67644195,2,"Thanks for the bug report.  Here's a 
link
 to the Jira ticket, for reference.",2021-05-21T21:50:41,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",67638484
68839331,68839331,0,"I get the same error but I found a workaround. For me reloading (from a 
pandas.DataFrame
 in my case) the trainings 
H2OFrame
 works. Seems like in training it get somehow corrupted...


In your case, try:


df = h2o.H2OFrame(python_obj=df0)
y_pred = model.predict(df)",2021-08-18T21:07:35,Marcel Bischoff,https://stackoverflow.com/users/2681210/marcel-bischoff,116,67638484
67644634,67644634,3,"I was able to reproduce the error and indeed it's not working (neither 
nfolds
 nor 
fold_column
 seem to be working). We will fix this ASAP.  Here's the Jira ticket: 
https://h2oai.atlassian.net/browse/PUBDEV-8163",2021-05-21T22:58:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",67636662
67655317,67655317,0,"Changing your EC2 instance won't necessarily make it faster. You need to understand where is the bottleneck. Review the logs and see what takes time on GBM vs XGBoost. Is XGBoost creating deeper trees or more trees? It could be your settings are different between the two algorithms. Check that all the hyperparameters are similar (close as possible).


Also, XGBoost uses memory external to H2O's JVM. As mentioned in 
FAQ of H2O's XGBoost docs
, try adding 
-extramempercent 120
 and lowering your H2O memory.",2021-05-23T01:00:12,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,67633018
67607198,67607198,3,"I find it confusing. If calibration is a post-processing step




The reason why it is part of model training right now is to have it in MOJO (our deployment artifact).




and is model agnostic, shouldn't it be possible to calibrate any model trained using H2O, even after the training process is finished?




Calibrating a model ex-post makes a lot of sense, all the code is already in - it “just” needs to be exposed to users.  We created a ticket for this 
here
.",2021-05-19T16:27:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",67602679
67589199,67589199,2,"Ad 1


I would recommend handling the H2O cluster outside the pipeline in a separate script. That way, 
tar_visnetwork()
 would not start or stop the cluster, and you could more cleanly separate the software engineering from the data analysis.


# run_pipeline.R
start_h2o_cluster(port = ...)
on.exit(stop_h2o_cluster(port = ...))
targets::tar_make_clustermq(workers = 4)



Ad 2


It sounds like H2O objects are 
not exportable
. Currently, you would need to save those files manually, identify the paths, and write 
format = ""file""
 in 
tar_target()
. I am willing to consider H20-based formats. Are all objects in some way covered by 
h2o.exportFile()
, 
h2o.importFile()
, 
h2o::h2o.saveModel()
, and 
h2o::h2o.loadModel()
, or are there more kinds of objects with different serialization functions? And does 
h2o
 have utilities to perform this (un)serialization in memory like 
serialize_model()
/
unserialize_model()
 in 
keras
?",2021-05-18T15:18:24,landau,https://stackoverflow.com/users/3704549/landau,"5,821",67584018
67529082,67529082,0,"Your Python client may be hosted at a different location than your H2O server. When you connect with 
h2o.connect(url=""https://[external ip]:54321"", auth=(username, password))
, you are specifying an external IP address. So what you see with 
ls
 will be at a different location.


Your error message shows that the file is not found on the file system that Python is running at:


accessed path : file:/tmp/gcsModels/serverless/v1/cust_PCA_DEMO_v1 msg: File not found.



Try using 
gs://
 to specify that the file location will be on Google Storage
. I can't tell what your exact path is, but I would expect it something like:


h2o.load_model(""gs://<BUCKETNAME>/gcsModels/serverless/v1/cust_PCA_DEMO_v1"")",2021-05-14T04:32:47,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,67509897
67537725,67537725,0,"So... after a lot of poking around I found the answer. Windows Defender ughhh was blocking access to the h2o.jar. The solution was to open PowerShell on the h2o java folder and run the h2o.jar using 
java -jar h2o.jar
. Then you'll get the security prompt asking you to authorize the program (I've had to do it every time, so you might want to check your settings). Once you do that 
h2o.init()
 runs very smoothly in R.",2021-05-14T16:27:39,rrodriguezbarron,https://stackoverflow.com/users/11689518/rrodriguezbarron,29,67509322
67452497,67452497,3,"As usual in 
R
 you can create/modify columns of a 
data.frame
 with using the the assignment operator 
<-
.


data.hex$Z <- data.hex$X + data.hex$Y
data.hex

   X  Y  Z
1 10 30 40
2 20 40 60

[2 rows x 3 columns] 



Since a 
data.frame
 is nothing else then a 
list
, you can also use list indexing for this.


data.hex[[""Z""]] <- data.hex[[""X""]] + data.hex[[""Y""]]
data.hex

   X  Y  Z
1 10 30 40
2 20 40 60",2021-05-08T21:55:56,Ben373,https://stackoverflow.com/users/8015575/ben373,971,67452392
67405035,67405035,3,"XGBoost is not supported on Windows, see the 
limitations
 in the H2O documentation.


If you are not using Windows and you didn't find another reason in the documentation mentioned above, you can try to reinstall h2o, e.g.,


pip install --force-reinstall https://h2o-release.s3.amazonaws.com/h2o/rel-zipf/2/Python/h2o-3.32.1.2-py2.py3-none-any.whl",2021-05-05T16:16:11,desertnaut,https://stackoverflow.com/users/4685471/desertnaut,60.1k,67404805
67408612,67408612,1,"I think I found the answer to this warning. I am running a windows machine.


https://twitter.com/ledell/status/1148512129659625472?lang=en




If you're on Windows, XGBoost is not supported 😿 so the parts of the tutorial that use XGBoost can be replaced by 
h2o.gbm()
. The AutoML process will also exclude XGBoost models.",2021-05-05T20:53:15,Leo Barbosa,https://stackoverflow.com/users/15415131/leo-barbosa,31,67404805
67411486,67411486,0,"Make sure you have ""Enable Autoscaling"" unchecked. You need fixed number of nodes for Sparkling Water.


Try using a non-ML runtime.


Also, check if you have any other packages that could conflict with pysparkling.




You can follow the standard setup 
here
.",2021-05-06T03:34:51,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,67371448
67360203,67360203,0,"AFAIK, you can't directly save to a SQL table. But you can save the whole frame as a new Hive table. See 
here
.


iris_hex = h2o.import_file(""iris/iris_wheader.csv"")
iris_hex.save_to_hive(
         jdbc_url = ""jdbc:hive2://hive-server:10000/default"",
         table_name = ""airlines"",
         format = ""parquet"",
         table_path = ""/user/bob/tables/iris""
)



You can also convert it 
back to a pandas frame
 
h2oframe.as_data_frame()
 then use 
iterrows()
 (as mentioned in the error 
.iterrows()
 is not an attribute for H2O).",2021-05-02T19:07:21,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,67328267
67360444,67360444,1,"H2O can do it's own SHAP calculations for DRF, GBM and XGBoost models. Here is an example:


prostate <- h2o.importFile(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"")

# Set the predictors and response; set the factors:
prostate$CAPSULE <- as.factor(prostate$CAPSULE)
splits <- h2o.splitFrame(prostate,ratios=c(0.6,0.2),seed=1234)
train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]
predictors <- c(""ID"", ""AGE"", ""RACE"", ""DPROS"", ""DCAPS"", ""PSA"", ""VOL"", ""GLEASON"")
response <- ""CAPSULE""

# Build and train the model:
pros_gbm <- h2o.gbm(x = predictors,
                    y = response,
                    nfolds = 5,
                    seed = 1111,
                    keep_cross_validation_predictions = TRUE,
                    training_frame = train)


pred <- predict_contributions.H2OModel(pros_gbm, train)



^ 
pred
 will return the SHAP values for your dataset; which it sounds like that's what you are asking for.


Also, check out 
H2O's Model Explainability
. You can create a SHAP summary plot:


exp <- h2o.explain(pros_gbm, test)
exp$shap_summary",2021-05-02T19:37:46,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,67314618
67295510,67295510,2,"Do you have terminal access? 
sudo apt install default-jdk
 should work on Debian-based systems (such as Ubuntu); or if you need a specific version, e.g. JDK 14: 
sudo apt install openjdk-14-jdk


Alternatively, there is a guide to 
installing H2O on Azure
 in the manual; apparently H2O is available in the Marketplace.",2021-04-28T07:15:47,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,67277764
67347467,67347467,2,"Solution:


Install openjdk through conda but specify conda-forge as the channel to install the package from.


name: venv
channels:
  - defaults
  - conda-forge
dependencies:
  - conda-forge::openjdk=11.0.9.1",2021-05-01T14:44:33,AlvinH,https://stackoverflow.com/users/11612543/alvinh,"1,409",67277764
67220307,67220307,1,"In my case, I needed to install a ""
Library
"" to my Databricks workspace, cluster, or job. I could either upload it or just have Databricks fetch it from Maven coordinates.


In Databricks Workspace:




click Home icon


click ""Shared"" > ""Create"" > ""Library""


click ""Maven"" (as ""Library Source"")


click ""Search packages"" link next to ""Coordinates"" box


click dropdown box and choose ""Maven Central""


enter 
ai.h2o.sparkling-water-package
 into the ""Query"" box


choose recent ""Artifact Id"" with ""Release"" that matches your 
rsparkling
 version, for me 
ai.h2o:sparkling-water-package_2.12:3.32.0.5-1-3.0


click ""Select"" under ""Options""


click ""Create"" to create the Library



thankfully, this required no changes to my Databricks R Notebook when run as a Databricks job








# install specific R packages
install.packages(c(""httr"", ""xml2""))

# sparklyr and Spark
install.packages(c(""sparklyr""))

# h2o
# RSparkling 3.32.0.5-1-3.0 requires H2O of version 3.32.0.5.
install.packages(c(""statmod"", ""RCurl""))
install.packages(""h2o"", type = ""source"", repos = ""http://h2o-release.s3.amazonaws.com/h2o/rel-zermelo/5/R"")

# rsparkling
# RSparkling 3.32.0.5-1-3.0 is built for 3.0.
install.packages(""rsparkling"", type = ""source"", repos = ""http://h2o-release.s3.amazonaws.com/sparkling-water/spark-3.0/3.32.0.5-1-3.0/R"")
# connect to H2O cluster with Sparkling Water context

library(sparklyr)
sparklyr::spark_install(""3.0.1"", hadoop_version = ""3.2"")
Sys.setenv(SPARK_HOME = ""~/spark/spark-3.0.1-bin-hadoop3.2"")
sparklyr::spark_default_version()
library(rsparkling)
 
SparkR::sparkR.session()
sc <- sparklyr::spark_connect(method = ""databricks"", version = ""3.0.1"")
sparklyr::spark_version(sc)

# next command will not work without adding https://mvnrepository.com/artifact/ai.h2o/sparkling-water-package_2.12/3.32.0.5-1-3.0 file as ""Library"" to Databricks cluster
h2oConf <- H2OConf()
hc <- H2OContext.getOrCreate(h2oConf)",2021-04-22T20:27:21,josephD,https://stackoverflow.com/users/15723919/josephd,152,67201421
67111895,67111895,0,"I can offer a hacky solution that utilizes the fact that 
iml
 uses 
ggplot2
 to plot.


N <- 10 # number of features to show

# Capture the ggplot2 object
p <- plot(shapley, sort = TRUE)

# Modify it so it shows only top N features
print(p + scale_x_discrete(limits=rev(p$data$feature.value[order(-p$data$phi)][1:N])))",2021-04-15T15:57:53,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,67095498
66979694,66979694,0,"Below is the example found in the 
docs
. It is expected to get MSE as NaN. It may be better to exclude it from the output. Check to see if you get 
Sum of Squared Error (Numeric)
 or use the loss function (objective) as you defined as 
""quadratic""
.


import h2o
from h2o.estimators import H2OGeneralizedLowRankEstimator
h2o.init()

# Import the USArrests dataset into H2O:
arrestsH2O = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/pca_test/USArrests.csv"")

# Split the dataset into a train and valid set:
train, valid = arrestsH2O.split_frame(ratios=[.8], seed=1234)

# Build and train the model:
glrm_model = H2OGeneralizedLowRankEstimator(k=4,
                                            loss=""quadratic"",
                                            gamma_x=0.5,
                                            gamma_y=0.5,
                                            max_iterations=700,
                                            recover_svd=True,
                                            init=""SVD"",
                                            transform=""standardize"")
glrm_model.train(training_frame=train)



Returns MSE and RMSE and NaN:




Model Details
============= H2OGeneralizedLowRankEstimator :  Generalized Low Rank Modeling Model Key:  GLRM_model_python_1617769810268_1


Model Summary:
number_of_iterations  final_step_size final_objective_value
0     58.0    0.00005 8.250804e-31


ModelMetricsGLRM: glrm
** Reported on train data. **


MSE: NaN
RMSE: NaN

Sum of Squared Error (Numeric):
1.9833472629189004e-13

Misclassification Error (Categorical): 0.0",2021-04-07T04:45:53,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66973512
66912082,66912082,2,"This could be achieved like so.


First, inspecting the ggplot object we see that the fill color of the 
geom_col
 is set as an argument.


library(ggplot2)

gg <- shap_explain_row_plot

gg$layers[[1]]
#> geom_col: width = NULL, na.rm = FALSE, fill = #b3ddf2, flipped_aes = FALSE
#> stat_identity: na.rm = FALSE
#> position_stack



Therefore to map on the 
fill
 aesthetic we first have to remove the fill argument via


gg$layers[[1]]$aes_params$fill <- NULL



Second, from the 
mapping
 we see that the length of the bars corresponds to variable 
contribution
 which is mapped on the 
y
 aesthetic.


gg$mapping
#> Aesthetic mapping: 
#> * `x`    -> `.data$feature`
#> * `y`    -> `.data$contribution`
#> * `text` -> `.data$text`



Therefore, to get your desired result you could map 
contribution < 0
 on the fill aesthetic and set the desired color values via 
scale_fill_manual


gg + aes(fill = contribution < 0) + scale_fill_manual(values = c(""TRUE"" = ""blue"", ""FALSE"" = ""pink""))





Created on 2021-04-01 by the 
reprex package
 (v1.0.0)",2021-04-01T21:59:54,stefan,https://stackoverflow.com/users/12993861/stefan,121k,66911104
66966786,66966786,0,"Thank you for your question. We definitely should provide this information in the 
documentation
. We are working on improving the doc. To answer your question:


The loss function for multinomial classification is softmax for H2O GBM and XGBoost too. H2O GBM is implemented based on this 
paper
: Greedy function approximation: A gradient boosting machine, Jerome H. Friedman 2001. In chapter 4.6. the author nicely explains how it is calculated and why.




Based on loss function the 
negHalfGradient
 method is defined and every distribution implements it individually. For multinomial distribution (
here
) the implementation is:


@Override
public double negHalfGradient(double y, double f, int l) {
    return ((int) y == l ? 1f : 0f) - f;
}



Where:




y
 is an actual response


f
 is a predicted response in link space


l
 is a class label (converted lexicographically from original labels to 0-number of class - 1)




Let me know if you have other questions.",2021-04-06T10:19:30,Maurever,https://stackoverflow.com/users/5036600/maurever,157,66902471
66867972,66867972,0,"Please try to use absolute path to the 
sample_csv.csv
. R tells H2O to read the file but the current working directory of H2O process is different from R's and in H2O's current working directory is no file named 
sample_csv.csv
.


It might seem easy to make this work reliably even with relative paths but it is important to realize that H2O might be running on some different computer where the relative path would be correct but it wouldn't be on the R client's side.",2021-03-30T09:11:24,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,66865411
66859455,66859455,2,"For H2O's Driverless AI, you can use it out of the box for time-series modeling. See 
this section
. You need to provide the ""Time Column"" as your TimeStamp and add ID to your ""Time Groups Column"".


If your target column is 0s or 1s, then it should automatically identify it as binary. If you not, you can toggle it from regression to binary classification.",2021-03-29T18:14:58,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66850203
66859737,66859737,0,"H2O models/MOJOs run on Java and need a JVM. Python will still need to run the job in Java.


If you don't want to initialize an H2O server, then the best way is to use Java directly and score with the MOJO. See 
more here
.


Other option is using PySpark to score/predict without initializing an H2O server, but you need Spark set up in that case.",2021-03-29T18:36:09,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66832971
66806706,66806706,4,"Sorry about this.  We are working to improve this process.  Please see this 
ticket
 and feel free to provide your feedback here or on the ticket.




This prompted me to install the latest version of Java, which I did: version 16.




Can you explain where H2O prompted you to update your Java?  Are you sure it was not asking you to just update your version of H2O?


H2O does not yet support Java 16 and our next release (coming out very shortly) has official support for Java 15.  If you want to install Java 15, then you can use a 
nightly
 version of H2O until our next stable release comes out in the next few days.",2021-03-25T19:57:34,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",66806500
66821410,66821410,0,"For imbalanced target column, I would avoid AUC (since it will generally be high). Consider using AUC-PR or Logloss.


For multiclass/multinomial, you would have one-vs-all predictions. So each prediction is based on its class vs the rest. So P0 is probability of class_0 vs class_1 + class_2. So P(1,2) = 0.6 would make sense.


For comparing probabilities, yes, you can select the predicted class with the highest probability output 
P1 (0.35) > P2 (0.25) -> Class = 1
.",2021-03-26T17:10:08,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66805422
66654564,66654564,2,"I'd be careful using 
%%capture
, it doesn't capture html content (tables) in the 
stdout
.


The 
redirect_stdout
 works flawlessly when used from python CLI/script. IPython/Jupyter might cause issues with tables as they are 
display
ed not 
print
ed. Note that you should not use 
.readlines()
 to get the results from 
StringIO
 - use 
.getvalue()
.


You can use 
h2o_model.save_model_details(path)
 to persist information about the model to a json file (which might serve you better in a long run but it's not really human readable).


If you really want to have the output that looks like what would you get from a Jupyter notebook, you can use the following hack:




create a template jupyter notebook that contains:




import os
import h2o
h2o.connect(verbose=False)
h2o.get_model(os.environ[""H2O_MODEL""])





and in your original notebook add




!H2O_MODEL={h2o_model.key} jupyter nbconvert --to html --execute template.ipynb --output={h2o_model.key}_results.html



You can also create a template for the 
nbconvert
 to hide the code cells.",2021-03-16T11:41:56,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,66653093
66653300,66653300,1,"You should call 
h2o_model.accuracy()
 (note the parentheses). The reason the whole model gets printed is non-idiomatic implementation of 
__repl__
 in h2o models which prints rather then returning a string (there's a JIRA to fix that).


If you encounter some other situation where you would like to save printed output of some command, you can use 
redirect_stdout
[1] to capture it (assuming you have python 3.4+).


[1] 
https://docs.python.org/3.9/library/contextlib.html#contextlib.redirect_stdout",2021-03-16T10:26:14,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,66653093
66653685,66653685,0,"Ok, so only the 
h2o_model.accuracy
 output cannot be captured, while 
xgb_model.cross_validation_metrics_summary
 or even 
h2o_model
 alone can - e.g. like that:


%%capture captured_output

# print model validation 
# data to `captured_output`
xgb_model




In another notebook cell:


# print(captured_output.stdout.replace(""\n\n"",""\n""))

with open(filename, 'w') as f:
    f.write((captured_output.stdout.replace(""\n\n"",""\n"")))",2021-03-16T10:48:01,,,,66653093
66621323,66621323,2,"You call the 
weights_column
 from the 
.train()
 method. For example:


aml.train(x=x, y=y, training_frame=train, weights_column='weight')",2021-03-14T05:17:37,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66615090
66576837,66576837,2,"This is not currently supported, but we should support it, so I created a 
JIRA ticket
 (you can follow the ticket for progress/updates).",2021-03-11T05:11:30,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",66573496
67182581,67182581,1,"Just setting 
H2O_WAVE_APP_ADDRESS
 is enough.


$ H2O_WAVE_APP_ADDRESS=http://0.0.0.0:8000 uvicorn my_app:main",2021-04-20T16:13:18,,,,66569899
66499708,66499708,1,"H2O-3 is a Java application so it follows the usual Java way of adding to the classpath. In your example changing the environmental variable name 
JARPATH
 to 
CLASSPATH
 should work.




I am using below docker compose file but its not able to pick DRIVERLESS_AI_CONFIG_FILE environment variable.




H2O-3 does not accept Driverless AI configuration file.",2021-03-05T21:13:43,bilcus,https://stackoverflow.com/users/1898794/bilcus,43,66469322
66378133,66378133,2,"You can get the predicted probabilities (cumulative for each tree) using 
staged_predict_proba()
 and the lead node assignments from 
predict_leaf_node_assignment()
. Here is an example:


from h2o.estimators import H2OGradientBoostingEstimator

# Import the prostate dataset into H2O:
prostate = h2o.import_file(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"")

# Set the predictors and response; set the factors:
prostate[""CAPSULE""] = prostate[""CAPSULE""].asfactor()
predictors = [""ID"",""AGE"",""RACE"",""DPROS"",""DCAPS"",""PSA"",""VOL"",""GLEASON""]
response = ""CAPSULE""

# Build and train the model:
pros_gbm = H2OGradientBoostingEstimator(nfolds=5,
                                        seed=1111,
                                        keep_cross_validation_predictions = True)
pros_gbm.train(x=predictors, y=response, training_frame=prostate)

print(pros_gbm.predict_leaf_node_assignment(prostate[:1, :]))
print(pros_gbm.staged_predict_proba(prostate[:1, :]))




You can also check out the 
Tree Class
 if you want details (leaf/split info) for each tree.",2021-02-25T23:47:11,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66339379
69021464,69021464,1,"you can simply assign 
""accuracy""
 as a sorting metric while building h2o aml model like:


aml = H2OAutoML(max_runtime_secs = 30, sort_metric = ""accuracy"")



It will publish the model based on accuracy in ascending order from top to bottom.",2021-09-01T23:15:09,David Buck,https://stackoverflow.com/users/7508700/david-buck,"3,784",66324765
66325195,66325195,0,"It doesn't look like the leaderboard allows you to sort using accuracy as a metric. The following lines of code and text have been directly taken from the 
documentation
:


aml = H2OAutoML(max_runtime_secs = 30, sort_metric = ""logloss"")





For binomial classification choose between 
AUC
, 
""logloss""
, 
""mean_per_class_error""
, 
""RMSE""
, 
""MSE""
.",2021-02-23T00:00:37,desertnaut,https://stackoverflow.com/users/4685471/desertnaut,60.1k,66324765
66311564,66311564,0,"If you want to look at correlated features and manually remove them before building a model. Go to the Autoviz section and look at the 
Correlated Scatterplots
 then drop those columns from the experiment or dataset.


Removing collinear features is difficult for any modeling since you won't know which feature would be better than the other. What if having both ""max number of saving accounts in past 9 months"" and ""max number of saving accounts in past 3 months"" make your model perform much better than only having one? This is where domain knowledge becomes important, and the expert should decide.


One way to remove some collinearity is limiting the number of features your model has. You can use 
max_orig_cols_selected
 to limit the number. You can set it in expert settings or 
config.toml (see for more info)
. But as I said before, it's hard to determine whether some collinear features should be kepts over others.


Another option is to use algorithms/models that inherently do feature selection, like L1 (LASSO) regression.",2021-02-22T07:27:56,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66309697
66300609,66300609,2,"From the 
documentation
 of 
h2o.init()
 (emphasis mine):




This method first checks if H2O is connectible. If it cannot connect and 
startH2O = TRUE
 with IP of 
localhost
, it will attempt to start an instance of H2O with IP = 
localhost
, port = 54321. Otherwise, it stops immediately with an error. When initializing H2O locally, this method searches for 
h2o.jar
 in the R library resources [...], and if the file does not exist, it will automatically attempt to 
download
 the correct version from Amazon S3. 
The user must have Internet access for this process to be successful
. Once connected, the method checks to see if the local H2O R package version matches the version of H2O running on the server. If there is a mismatch and the user indicates she wishes to 
upgrade
, it will remove the local H2O R package and 
download/install
 the H2O R package from the server.




So, 
h2o.init()
 with the default setting 
ip = ""127.0.0.1""
, as here, connects the R session with the H2O instance (sometimes referred to as ""server"") in your 
local
 machine. If all the necessary package files are in place and up to date, no internet connection is necessary; the package will attempt to connect to the internet only to 
download
 stuff in case something is not present or up to date. No data is uploaded anywhere.",2021-02-21T08:52:45,,,,66299204
66288624,66288624,1,"You're training a regression model and that's why you're missing the binary classification metrics.  The way that H2O knows whether to train a regression vs classification model is by looking at the data type of the response column.


We explain it 
here
 in the H2O User Guide, but this is a frequent question we get since it's different than how scikit-learn works, which uses different methods for regression vs classification and doesn't require you to think about column types.


y_test.nunique()
failure    2
dtype: int64



On the response column in your training data, you can do something like this:


train[""response""] = train[""response""].asfactor()



Alternatively, when you read the file in from disk, you can parse the response column as ""enum"" type, so you don't have to convert it, after-the-fact.  There's some examples of how to do that in Python 
here
.  If the response is stored as integers, H2O just assumes it's a numeric column when it reads in the data from disk, but if the response is stored as strings, it will correctly parse it as a categorical (aka. ""enum"") column and you won't need to specify or convert it.",2021-02-20T06:18:04,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",66288297
67203844,67203844,0,"Training segments is for supervised models only. Deep learning is supported but only for supervised learning. Autoencoder is not supervised (does not need a target column, 
y
), so it won't work. You will need to loop through each segment individually to do training.",2021-04-21T21:41:45,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66242735
68444128,68444128,0,"As you mentioned, based on the documentation (
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/svm.html
) currently there is no way to train linear SVM on H2O. Within linear models, I think it only has GLM (
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html
).",2021-07-19T16:39:18,,,,66192230
66253696,66253696,0,"You can use 
h2o.as_date(x, format, ...)
. 
format
 will specify the date-time pattern.


For example:


hdf <- h2o.importFile(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"")
h2o.as_date(hdf$ds5, ""%d.%m.%y %H:%M"")",2021-02-18T04:36:30,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66188791
66167538,66167538,0,"GBM inherently creates interactions.  You can extract information about feature interactions using the 
.feature_interaction()
 extractor method (for an H2O Model).  More information is provided in the 
user guide
 and the Python 
docs
.


If you want to explicitly add a new column that is the interaction between two numerics, you could create that manually by multiplying the two (or more) columns together to get a new interaction column.


For categorical interactions, there's also the the 
h2o.interaction()
 method in Python 
here
 to create interaction columns in the data (prior to sending it to the GBM or any algorithm).",2021-02-12T06:58:29,,,,66167474
66097159,66097159,1,"64bit JDK is required. See the 
requirements
.",2021-02-08T07:02:07,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66053665
66023126,66023126,0,"I found work around to resolve this issue. Please find below the steps I followed:




Remove the package using: remove.packages(""h2o"")


Quit the current session and launch the new one.


Move out lock file for h2o from path where package was installed mostly under R with file name like - 00LOCK-h2o


Install new/latest version of package via RStudio console using install.packages()




It should now resolve this issue.",2021-02-03T07:39:46,Akshay Gane,https://stackoverflow.com/users/11888134/akshay-gane,13,66011434
66005425,66005425,0,"There are a few options to control number of features used


# Maximum number of columns selected out of original set of original columns, using feature selection
# The selection is based upon how well target encoding (or frequency encoding if not available) on categoricals and numerics treated as categoricals
# This is useful to reduce the final model complexity. First the best
# [max_orig_cols_selected] are found through feature selection methods and then
# these features are used in feature evolution (to derive other features) and in modelling.
#max_orig_cols_selected = 10000

# Maximum number of numeric columns selected, above which will do feature selection
# same as above (max_orig_cols_selected) but for numeric columns.
#max_orig_numeric_cols_selected = 10000

# Maximum number of non-numeric columns selected, above which will do feature selection on all features and avoid treating numerical as categorical
# same as above (max_orig_numeric_cols_selected) but for categorical columns.
#max_orig_nonnumeric_cols_selected = 300

# Like max_orig_cols_selected, but columns above which add special individual with original columns reduced.
# 
#fs_orig_cols_selected = 500



# Maximum features per model (and each model within the final model if ensemble) kept.
# Keeps top variable importance features, prunes rest away, after each scoring.
# Final ensemble will exclude any pruned-away features and only train on kept features,
# but may contain a few new features due to fitting on different data view (e.g. new clusters)
# Final scoring pipeline will exclude any pruned-away features,
# but may contain a few new features due to fitting on different data view (e.g. new clusters)
# -1 means no restrictions except internally-determined memory and interpretability restrictions.
# Notes:
# * If interpretability > remove_scored_0gain_genes_in_postprocessing_above_interpretability, then
# every GA iteration post-processes features down to this value just after scoring them.  Otherwise,
# only mutations of scored individuals will be pruned (until the final model where limits are strictly applied).
# * If ngenes_max is not also limited, then some individuals will have more genes and features until
# pruned by mutation or by preparation for final model.
# * E.g. to generally limit every iteration to exactly 1 features, one must set nfeatures_max=ngenes_max=1
# and remove_scored_0gain_genes_in_postprocessing_above_interpretability=0, but the genetic algorithm
# will have a harder time finding good features.
# 
#nfeatures_max = -1



See the 
config.toml file
 or look in expert settings.


Note that you can't control specific features of having transformers or not.",2021-02-02T07:38:41,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,66004255
65948328,65948328,0,"You have set 
max_runtime_secs = 360
 via 
search_criteria
 in the grid settings, so the longest it will potentially run is 6 minutes.


If the grid is stopping prior to that, it means that your early stopping settings are triggering the grid to stop early.  If you'd like it to run longer, then you can increase 
stopping_rounds
 for the grid and/or increase the 
stopping_tolerance
 and it should be less sensitive to stopping early and run longer (in the code above you have them set to 
5
 and 
1e-2
, respectively).  You might also want to set 
stopping_metric = ""RMSE""
, since the default value for regression is mean residual deviance (
""deviance""
).  See more information about  stopping metric in the 
user guide
.


I noticed that you have 
stopping_rounds = 2
 for the individual DNN models (you might want to try increasing that if your models are underfitting).",2021-01-29T03:17:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",65944291
65950029,65950029,1,"That's definitely an oversight and we will need to add the ability to turn on/off and/or specify the GPU.  I opened a 
ticket
 for this.  I wonder if there's a way to temporarily disable the GPU at the system level (outside of H2O/Python) in the meantime?  Thanks for the report!",2021-01-29T06:53:26,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",65897690
65872975,65872975,0,"If anyone has encountered the same issue, I found the solution.
For whatever reason the predict method fails if the data is not shaped in the way the algorithm has been trained on, and this also includes the outcome column.
In order to make the method not to break I just added a fake outcome column with all zeros as a placeholder. Now everything works fine.
Thank you",2021-01-24T16:17:31,Marco De Virgilis,https://stackoverflow.com/users/4332914/marco-de-virgilis,"1,067",65871708
65850617,65850617,1,"I was not able to reproduce the error.  Are you sure that's the exact code that produced the error?  It looks like it's picking up an extra 
(
 somehow (maybe you had a typo and then you fixed it?).


Here's the same code, as a reproducible example (which is working):


library(h2o)

h2o.init()

hf <- as.h2o(iris)
split_h2o <- h2o.splitFrame(hf, c(0.7, 0.15), seed = 12345)",2021-01-22T18:17:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",65850262
65836827,65836827,3,"You don't get to choose your port on Heroku. Instead, 
Heroku assigns you a port via the 
PORT
 environment variable
.


Change your 
Procfile
 from


web: uvicorn foo:main --host 0.0.0.0 --port 10101



to


web: uvicorn foo:main --host 0.0.0.0 --port $PORT",2021-01-21T22:39:38,Chris,https://stackoverflow.com/users/354577/chris,136k,65836484
72794158,72794158,0,"See 
this blog post
 for the exact guide.


More explanation for why the other answer is generally correct but does not apply to H2O Wave:


If you look at 
architecture
, you may notice there are actually 2 servers included. The first is a python (uvicorn) one that is used for your Wave app - this is not exposed to the outside directly but uses a kind of a proxy server - the second server. This second (Golang) server communicates directly with a browser (outside) and thus should be started on the 
$PORT
 Heroku assigned to you, e.g. via the 
H2O_WAVE_LISTEN
 env variable - see 
other config options
.",2022-06-28T23:18:45,MartinT,https://stackoverflow.com/users/6108459/martint,614,65836484
65890202,65890202,0,"To get the dispersion parameter for H2O's GLM model in 
Python
 it would be 
your_glm_model._model_json['output']['dispersion']

And in 
R
 it would be 
attr(your_glm_model, 'model')$dispersion
 or 
your_glm_model@model$dispersion",2021-01-25T18:14:39,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,65766697
65742754,65742754,0,"Full example in R:


library(h2o)
h2o.init()
gbm <- h2o.gbm(y = ""Species"", training_frame = as.h2o(iris), seed = 1)
gbm@model$training_metrics@metrics$nobs
# [1] 150",2021-01-15T19:55:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",65736436
65675799,65675799,1,"The 
h2o.weights()
 function returns the first layer weights by default, as an H2OFrame.  You can get an arbitrary layer by changing the 
matrix_id
 argument.


Some examples:


> h2o.weights(model)
           x
1  0.3520632
2  0.5535296
3 -0.4793063
4  0.3828013
5 -0.3253765
6  0.7234487

[200 rows x 1 column]


> h2o.weights(model, matrix_id = 5)
          C1        C2         C3         C4         C5         C6          C7          C8         C9         C10
1  0.7233770 0.7793967 -1.4486042 -0.8187707  0.8667952  1.0290394  0.26213858  0.02487412  0.3342296  0.39383927
2  0.4528885 0.2434976  0.5963052  0.9640941 -0.4480562 -0.1976745 -0.63002998  0.17428128 -0.9241131  0.13199258
3 -0.5477357 0.4918589 -0.7991062 -0.6445754  0.3618000  0.1324274  0.60856968 -0.35876906 -0.0655041  0.21673690
4 -0.3147219 0.2541574 -0.5886489 -0.9993418  0.3042635  0.4107490 -0.08639368 -1.11863077  0.8755589 -0.06117416
5 -0.7028044 0.4625969 -0.3838535 -0.6484048 -0.6975272  0.2663548 -0.17953268  0.14127040 -0.6482394 -0.04426440



> hidden <- c(200,100,50,10,5)
> for (i in 1:(length(hidden) + 1)) {
+   print(dim(h2o.weights(model, matrix_id = i)))
+ }
[1] 200   1
[1] 100 200
[1]  50 100
[1] 10 50
[1]  5 10
[1] 1 5",2021-01-11T23:05:34,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",65674849
65897238,65897238,1,"If you open the binary model file with a text editor, you will see that the first line would display the H2O version it was saved in.


For example, using unix based command 
head -n 1 your_model_file
 returns


?   3.32.0.3 ...",2021-01-26T07:19:18,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,65672022
65559976,65559976,1,"Yes, you can remove objects with 
h2o.rm()
. You can use the variable name or key.


h2o.rm(your_object)
h2o.rm(‘your_key’)



You can use 
h2o.ls()
 to check what objects are in memory. Also, you can add the argument 
cascade = TRUE
 to the 
rm
 method to remove sub-models.


See more 
here",2021-01-04T08:56:58,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,65512435
65522183,65522183,1,"It appears you are using PyCharm to run your code.  If you prefer an interactive session, I would recommend that you utilize the ""Python Console"" to input your commands.  This will maintain the session open so that you can access the Flow GUI from your browser, while maintaining your ability to inject your Python dataframes into the java server.


As an aside, I found difficulty importing csv files using Flow, but Python dataframes could be used to pipe the data into the process without error.",2020-12-31T14:34:31,,,,65419605
65409107,65409107,3,"You can check if xgboost is available on the h2o cluster and can be used with:


h2o.xgboost.available()


But if you are on Windows xgboost within h2o is not available. See 
the limitations
 on help pages of h2o for xgboost.",2020-12-22T12:53:44,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,65408098
65391232,65391232,1,"H2O may not understand that this path is on the DBFS.  You may try to specify path 
/dbfs/FileStore/tables/iris.csv
 - in this case it will be read as ""local file"", or try to specify the full path with schema, like 
dbfs:/FileStore/tables/iris.csv
 - but this may require DBFS-specific jars for H2O.",2020-12-21T10:37:39,Alex Ott,https://stackoverflow.com/users/18627/alex-ott,86.8k,65384846
65242857,65242857,0,"You can call the model metrics by calling their respective methods. E.g. 
model1.mse()
, 
model1.auc()
, 
model1.gini()
.


For your second question, it's not clear what you are trying to extract. You can make it into a list 
perf.confusion_matrix().to_list()",2020-12-10T21:54:40,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,65239478
65050822,65050822,0,"Not an expert but I took some time and also looked a bit into it and as far as I can tell, there is no way to retrieve an in-bag score. It wouldn't really make sense to calculate it for a random forest. I also didn't find anything related to the out-of-bag or in-bag  samples, so I would assume they also don't get stored. However, if you'd manage to find them somewhere you could probably use 
h2o.getModelTree()
 to produce some kind of score.


You could also go and look into the 
source code
 and see if you get any deeper insights.


I also found this 
Question
 which might help you. However, it does not use 
h2o
 but the 
randomForest
 R library, if that is an option for you. There you can retrieve the OOB samples, thus you know what the in-bag samples are and you can then score them yourself, but I have not done this myself.",2020-11-28T14:46:51,R.Pickman,https://stackoverflow.com/users/14698636/r-pickman,13,65010226
64994315,64994315,0,"Stacked Ensemble requires the CV predictions from the base learners, which are not currently being saved when you save the models to disk via 
h2o.saveModel()
.  They need to be saved and then reloaded into the model when using 
h2o.loadModel()
, so that they're available for the metalearning step of the Stacked Ensemble algorithm.


Update:
  This 
feature
 has been added, and is available in H2O 3.32.0.3.  Link to download latest stable version of H2O is 
here
.",2020-11-24T20:26:58,,,,64985991
65095671,65095671,0,"In H2O the mean squared error is calculated from the node residuals. The goal there is to have an unbiased estimator, so the SE to be minimized is calculated as:


SE = MSE * N = Var * N
= w
y
y - (w * y)^2/N


where y means node residuals not response, w means weights and N means the number of observations. You can read more about H2O GBM tree learning in this booklet: 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/GBMBooklet.pdf
 in chapter Theory and Framework.",2020-12-01T17:43:20,Maurever,https://stackoverflow.com/users/5036600/maurever,157,64879426
64809800,64809800,1,"I'll reframe the answer I wrote for 
Python
, for R.  It's the same process:


The 
Changes.md
 file is the easiest place to look for links to where you can download every version.  Just search for the version you want (e.g. ""3.30.0.1"") and you 
will see
 the URL there.


Click on the link and it will bring you to the 
download page for that version (e.g. 3.30.0.1)
 and you can click on the ""Install in R"" tab which will show some code like this that you can copy/paste into your terminal:


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload = TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type = ""source"", repos = ""http://h2o-release.s3.amazonaws.com/h2o/rel-zahradnik/1/R"")



The URLs are ""predictable"" but you have to know the name of the release as well as the version number to correctly guess the URL.",2020-11-12T18:35:30,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",64801593
64802583,64802583,0,"The simplest method is to use the provided 
install_version()
 function of the devtools package to install the version you need. For instance:


require(devtools)
install_version(""h2o"", version = ""3.30.0.1"", repos = ""http://cran.us.r-project.org"")",2020-11-12T10:56:09,Klaus,https://stackoverflow.com/users/10842883/klaus,484,64801593
64791818,64791818,1,"I found the answer.


nfolds_index = h2o.import_file('myfile_index.csv')
nfolds_index.set_names([""fold_numbers""])
data = data.cbind(nfolds_index)
model2 = H2OGradientBoostingEstimator( seed=1234)
model2.train(x=predictors,y=response,training_frame=data, fold_column=""fold_numbers"")
print('rmse: ',model2.rmse(xval=True))
print('R2: ',model2.r2(xval=True))",2020-11-11T18:07:17,cnp,https://stackoverflow.com/users/13576600/cnp,339,64790872
64754816,64754816,0,"This is an actual issue with parallelism in grid search, previously noticed but not reported correctly.
Thanks for raising this, we'll try to fix it soon: see 
https://h2oai.atlassian.net/browse/PUBDEV-7886
 if you want to track progress.


Until proper fix, you must avoid using both CV and parallelism in your grids.


Regarding the following error:




Some models were not built due to a failure, for more details run `summary(grid_object, show_stack_traces = TRUE)




if the error is reproducible, you should be getting more details by running the grid with 
verbose=True
.
Adding the entire error message to the ticket above might also help.",2020-11-09T15:48:12,,,,64745423
66073479,66073479,0,"This is because you set max_models = 5, your grid will only make 5 models then stop.


There are three ways to set up early stopping criteria:




""max_models"": max number of models created


""max_runtime_secs"": max running time in seconds


metric-based early stopping by setting up for ""stopping_rounds"",  ""stopping_metric"", and ""stopping_tolerance""",2021-02-06T04:08:26,Tranle,https://stackoverflow.com/users/12684181/tranle,101,64745423
64704448,64704448,2,"There's two ways:




You can create and specify the folds manually.


You can ask H2O to save the fold indexes (for each row, which fold ID does it belong to?) and return them as a single-column of data, by setting 
keep_cross_validation_fold_assignment=True
.




Here are some code examples:


import h2o
from h2o.estimators import *

h2o.init()

# Import cars dataset
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")
cars[""economy_20mpg""] = cars[""economy_20mpg""].asfactor()
x = [""displacement"",""power"",""weight"",""acceleration"",""year""]
y = ""economy_20mpg""
nfolds = 5



First way:


# Create a k-fold column and append to the cars dataset
# Or you can use an existing fold id column
cars[""fold_id""] = cars.kfold_column(n_folds=nfolds, seed=1)

# Train a GBM
cars_gbm = H2OGradientBoostingEstimator(seed=1, fold_column = ""fold_id"",
              keep_cross_validation_fold_assignment=True)
cars_gbm.train(x=x, y=y, training_frame=cars)

# View the fold ids (identical to cars[""fold_id""])
print(cars_gbm.cross_validation_fold_assignment())



Second way:


# Train a GBM & save fold IDs
cars_gbm = H2OGradientBoostingEstimator(seed=1, nfolds=nfolds,
              keep_cross_validation_fold_assignment=True)
cars_gbm.train(x=x, y=y, training_frame=cars)

# View the fold ids
print(cars_gbm.cross_validation_fold_assignment())",2020-11-05T19:56:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",64694979
64657414,64657414,0,"Check out the 
leftward
 attribute - it's the so-called ""majority way"", which means that all data records that can't be explicitly evaluated (eg. a data record with a missing value) will be sent there.


In the current case, 
""leftward"": false
 should cause missing values to be sent to the right child node (node number 10).",2020-11-03T05:48:36,user1808924,https://stackoverflow.com/users/1808924/user1808924,"4,926",64653397
64597507,64597507,1,"Precision, Recall and F-Score are only available for binary classification.  You have a multi-class case, which is why you don't see them.  More information is available in the User Guide: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html",2020-10-29T18:54:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",64587004
64509104,64509104,1,"Question 1


You shouldn't need to decrease the number of inputted features into the model. I can't say I know what would happen during training, but collinear/associated features could be eliminated in the hidden layers as you said. You could consider adjusting your hidden nodes and see how it behaves. 
hidden = c(25,25,25)
 -> 
hidden = c(25,10,25)
 or 
hidden = c(15,15)
 or even 
hidden = c(7, 5, 7)
 for your few features.


Question 2


What is the purpose of your model? Are you trying to determine which ""Sender/Receiver combinations"" are anomalies or are you trying to determine which ""Sender/Receiver + specific Action combo"" are anomalies? If it's the former (""Sender/Receiver combinations"") I would guess Example B is better.


If you want to know ""Sender/Receiver combinations"" and use Example A, then how would you aggregate all the actions for one Sender-Receiver combo? Will you average their error?


But it sounds like Example A has more of a response for anomalies in ascended order list (where only a few rows have high error). I would sample different rows and see if the errors make sense (as a domain expert). See if higher errors tend to seem to be anomaly-like rows.",2020-10-24T01:23:55,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64490264
64471725,64471725,1,"How do I amend the rule so that https://k8s-master:30439/h2otest goes directly to https://k8s-master:30439/h2otest/flow/index.html




That is not an nginx-ingress question. Like most of the other ingresses nginx-ingress is there to do name based virtual hosting and SNI (or SSL Name based virtual hosting) with SSL offloading. Out of the box it's limited in any more.


While nginx-ingress can do some basic re-writing, it's limited to rewriting 
/path/(.*)
 to 
/(.*)
 and passing it to the next container to handle the traffic from there. If you're wanting it to do more you're into writing config maps for nginx-ingress.
Yes you'll want to set annotations for client body size etc, but the app itself (not the ingress) needs to be handling the 
/h2otest
 -> 
/h2otest/flow/index.html
 rewriting (or 
/
 -> 
/flow/index.html
).


From what you're describing your layout looks like

(nginx)ingress
 -> 
app


You may need to change the layout to 
(nginx)ingress
 -> 
nginx
 ->
app
 with the middle nginx doing the 
/
 -> 
/flow/index.html
 rewrite


A word of advice. If you have any chance use name based virtual hosting rather than path virtual hosting (unless you have a good reason eg cors) for path based. Alot of apps these days just assume they are on 
/
 an the config gets ""interesting"" if you're elsewhere",2020-10-21T21:03:25,ceharep,https://stackoverflow.com/users/12246875/ceharep,439,64352366
64459302,64459302,0,"Nginx reverse proxy rewrite 
/h2otest
 to 
/
 but h2o redirect 
/
 to 
/flow/index.html
. At this point, nginx does not have a rule to handle 
/flow
 so result to 404.


Try remove the path and use root 
/
 instead.


apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress
  namespace: ns-test
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
        - path: /
          pathType: Prefix
          backend:
            serviceName: test-h2o-svc
            servicePort: 54321",2020-10-21T08:08:42,,,,64352366
64313473,64313473,0,"Currently, only target encoding is done, but more work is being done to add for preprocessing. See the 
docs
 for more info.",2020-10-12T07:36:42,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64286080
64312891,64312891,1,"This feature is being added in upcoming release. See this 
Jira
 for the status.",2020-10-12T06:44:39,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64247245
64312872,64312872,0,"Each user/account is separate so the dynamic graphs won't be shared. However, you could create a notebook and share that usugin the Python client to build the visualizations. Check out this 
example
 which uses Autoviz and Python client.",2020-10-12T06:42:55,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64237745
64312775,64312775,1,"Yes, you can use a data recipe for processing datasets (including joining them). See the 
docs
 for more about data recipes. You can create a recipe that joins datasets.


# Let's join a `employee.csv` (X) to `dept.csv` (Y1) and `country.csv` (Y2)
# Define and read locations of datasets for Y1/Y2
Y_file_name1 = ""./tmp/user/location_of_dept.csv.bin""
Y_file_name2 = ""./tmp/user/location_of_country.csv.bin""
Y1 = dt.fread(Y_file_name1)
Y2 = dt.fread(Y_file_name2)

# Set key and join Y1
key1 = [""dept_id""]
Y1.key = key1
X = X[:, :, dt.join(Y1)]

# Set key and join Y2
key2 = [""country_code""]
Y2.key = key2
X = X[:, :, dt.join(Y2)]

return X



See 
this recipe
 as an example for joining one dataset to another.",2020-10-12T06:33:41,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64220636
64165996,64165996,1,"I just need to convert the boolean into an int.


X,y = make_classification(n_samples=5000, n_features=15,n_informative=15, n_redundant=0, n_repeated=0, n_classes=4
                          ,n_clusters_per_class=2,class_sep=3,flip_y=0.1,weights=[0.4,0.20,0.10,0.05], shuffle=True,random_state=1234)

dataset_x = pd.DataFrame({'var1': X[:, 0], 'var2': X[:, 1],'var3': X[:, 2]})

dataset_x['var2'] = dataset_x['var3'].round(0)

dataset_x['var3'] = dataset_x['var3']*(-1)

dataset_x['var4'] =np.where(dataset_x['var1']<=0, 0, 1)

conditions = [(dataset_x['var2'] <= 0) & (dataset_x['var4'] == 0)
              ,(dataset_x['var2'] <=0) & (dataset_x['var4'] == 1)
              ,(dataset_x['var2'] >=0) & (dataset_x['var4'] == 0)
              ,(dataset_x['var2'] >=0) & (dataset_x['var4'] == 1)]

choices = [0, 1, 2, 3]

dataset_x['var5'] = np.select(conditions, choices, default=0)

dataset_x['var6'] = dataset_x['var3'].abs().round(0)

mean_var1 = dataset_x['var3'].mean()
len_var1 = len(dataset_x['var3'])

dataset_x['var7'] =(mean_var1*(2.718)**((mean_var1)*(dataset_x['var1'].round(0))*-1))

dataset_x['var8'] =dataset_x['var1'].round(0)

dataset_x['var8'] =abs(dataset_x['var1'].round(0))*2

dataset_y = pd.DataFrame({'target': y})

simulated_irregular_dataset = pd.concat([dataset_x,dataset_y], axis=1)

def boolean_slicer(size,num_feat):
    array_slicer = []
    for i in range(size):
        slicer = np.ones(num_feat,dtype=np.bool)
        slicer[:int(0.3*num_feat)]=False
        np.random.shuffle(slicer)
        array_slicer.append(slicer)
    return array_slicer

list_of_Boolean = boolean_slicer(20,8)
for i in popo:
    print(i.tolist())

h2o.init(min_mem_size_GB=8)    
#Transform data into a H2O Frame
H20_df = h2o.H2OFrame(X_train)
print(H20_df)

for i in list_of_Boolean:
    print (i)
    i = 1*i
    i = i.astype(int)
    print(H20_df[:,i.tolist()])",2020-10-02T03:57:41,Gerard,https://stackoverflow.com/users/5760497/gerard,518,64165952
64202851,64202851,1,"You don't want to have cross-validation (CV) if you are dealing with times-series (non-IID) data, since you won't want folds from the future to the predict the past.


I would explicitly add 
nfolds=0
 so that CV is disabled in AutoML:


aml = H2OAutoML(max_runtime_secs=3600, seed=1, nfolds=0)
aml.train(x=x,y=y, training_frame=k-1_years, validation_frame=k_year)



To have an ensemble, add a 
blending_frame
 which also applies to time-series. See more info 
here
.


Additionally, since you are dealing with time-series data. I would recommend adding time-series transformations (e.g. lags), so that your model gets info from previous years and their aggregates (e.g. weighted moving average).",2020-10-05T05:22:36,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64154312
64201034,64201034,2,"here is another way. However, I'm not sure it's faster. I'm using the h2o.as_list() function to convert a column to a list and then I use the np.array() function to convert the list to an array.


import h2o
import numpy as np

h2o.init()

# Using sample dataset from H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")


## Creating np array from h2o frame column  
np.array(h2o.as_list(train['x1']))",2020-10-05T00:09:10,BP34500,https://stackoverflow.com/users/11616033/bp34500,178,64047807
64057390,64057390,3,"Here's how it's done:


import h2o
from h2o.automl import H2OAutoML

h2o.init()

# import prostate dataset
prostate = h2o.import_file(""https://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv"")
# convert columns to factors
prostate['CAPSULE'] = prostate['CAPSULE'].asfactor()
prostate['RACE'] = prostate['RACE'].asfactor()
prostate['DCAPS'] = prostate['DCAPS'].asfactor()
prostate['DPROS'] = prostate['DPROS'].asfactor()

# set the predictor and response columns
predictors = [""AGE"", ""RACE"", ""VOL"", ""GLEASON""]
response_col = ""CAPSULE""

# split into train and testing sets
train, test = prostate.split_frame(ratios = [0.8], seed = 1234)

# run AutoML for 100 seconds
aml = H2OAutoML(seed=1, max_runtime_secs=100, exclude_algos=[""DeepLearning"", ""GLM""],
                    nfolds=5, keep_cross_validation_predictions=True)
aml.train(x=predictors, y=response_col, training_frame=prostate)

# Get the leader model
leader = aml.leader



There is a caveat to mention here about cross-validated AUC -- H2O currently stores two computations of CV AUC.  One is an aggregated version (take the AUC of aggregated CV predictions), and the other is the ""true"" definition of cross-validated AUC (an average of the k AUCs from k-fold cross-validation).  The latter is stored in an object which also contains the individual fold AUCs, as well as the standard deviation across the folds.


If you're wondering why we do this, there's some historical & technical reasons why we have two versions, as well as a 
ticket
 open to only every report the latter.


The first one is what you get when you do this (and also what appears on the AutoML Leaderboard).


# print CV AUC for leader model
print(leader.model_performance(xval=True).auc())



If you want the fold-wise AUCs so you can compute or view their mean and variability (standard deviation), you can do that by looking here:


# print CV metrics summary
leader.cross_validation_metrics_summary()



Output:


Cross-Validation Metrics Summary:
             mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------  ----------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy     0.71842104  0.06419111   0.7631579     0.6447368     0.7368421     0.7894737     0.65789473
auc          0.7767409   0.053587236  0.8206676     0.70905924    0.7982079     0.82538515    0.7303846
aucpr        0.6907578   0.0834025    0.78737605    0.7141305     0.7147677     0.67790955    0.55960524
err          0.28157896  0.06419111   0.23684211    0.35526314    0.2631579     0.21052632    0.34210527
err_count    21.4        4.8785243    18.0          27.0          20.0          16.0          26.0
---          ---         ---          ---           ---           ---           ---           ---
precision    0.61751753  0.08747421   0.675         0.5714286     0.61702126    0.7241379     0.5
r2           0.20118153  0.10781976   0.3014902     0.09386432    0.25050205    0.28393403    0.07611712
recall       0.84506994  0.08513061   0.84375       0.9142857     0.9354839     0.7241379     0.8076923
rmse         0.435928    0.028099842  0.41264254    0.47447023    0.42546       0.41106534    0.4560018
specificity  0.62579334  0.15424488   0.70454544    0.41463414    0.6           0.82978725    0.58

See the whole table with table.as_data_frame()



Here's what the leaderboard looks like (storing aggregated CV AUCs).  In this case, because the data is so small (300 rows), there's a noticeable difference between the two reported between the two reported CV AUC values, however for larger datasets, they should be much closer estimates.


# print the whole Leaderboard (all CV metrics for all models)
lb = aml.leaderboard
print(lb)



That will print the top of the leaderboard:


model_id                                                  auc    logloss     aucpr    mean_per_class_error      rmse       mse
---------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------
XGBoost_grid__1_AutoML_20200924_200634_model_2       0.769716   0.565326  0.668827                0.290806  0.436652  0.190665
GBM_grid__1_AutoML_20200924_200634_model_4           0.762993   0.56685   0.666984                0.279145  0.437634  0.191524
XGBoost_grid__1_AutoML_20200924_200634_model_9       0.762417   0.570041  0.645664                0.300121  0.440255  0.193824
GBM_grid__1_AutoML_20200924_200634_model_6           0.759912   0.572651  0.636713                0.30097   0.440755  0.194265
StackedEnsemble_BestOfFamily_AutoML_20200924_200634  0.756486   0.574461  0.646087                0.294002  0.441413  0.194845
GBM_grid__1_AutoML_20200924_200634_model_7           0.754153   0.576821  0.641462                0.286041  0.442533  0.195836
XGBoost_1_AutoML_20200924_200634                     0.75411    0.584216  0.626074                0.289237  0.443911  0.197057
XGBoost_grid__1_AutoML_20200924_200634_model_3       0.753347   0.57999   0.629876                0.312056  0.4428    0.196072
GBM_grid__1_AutoML_20200924_200634_model_1           0.751706   0.577175  0.628564                0.273603  0.442751  0.196029
XGBoost_grid__1_AutoML_20200924_200634_model_8       0.749446   0.576686  0.610544                0.27844   0.442314  0.195642

[28 rows x 7 columns]",2020-09-25T03:30:07,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",64032018
75302587,75302587,0,"I submitted the following task

https://h2oai.atlassian.net/browse/PUBDEV-8984


This is when you want to order your grid search for a specific metric.


def sort_grid(grid,metric):
#input: grid and metric to order
if metric == 'accuracy':
    id = 0
elif metric == 'auc':
    id = 1
elif metric=='err':
    id = 2
elif metric == 'err_count':
    id=3
elif metric=='f0point5':
    id=4
elif metric=='f1':
    id=5
elif metric =='f2':
    id=6
elif metric =='lift_top_group':
    id=7
elif metric == 'logloss':
    id=8
elif metric == 'max_per_class_error':
    id=9
elif metric == 'mcc':
    metric=9
elif metric =='mena_per_class_accuracy':
    id=10
elif metric == 'mean_per_class_error':
    id=11
elif metric == 'mse':
    id =12
elif metric == 'pr_auc':
    id=13
elif metric == 'precision':
    id=14
elif metric == 'r2':
    id=15
elif metric =='recall':
    id=16
elif metric == 'rmse':
    id = 17
elif metric == 'specificity':
    id = 18
else: 
    return 0

model_ids = []
cross_val_values = []
number_of_models = len(grid.model_ids) 
number_of_models
for i in range(number_of_models):
    modelo_grid = grid[i]
    mean = np.array(modelo_grid.cross_validation_metrics_summary()[[1]])
    cross_val= mean[0][id]
    model_id = grid.model_ids[i]
    model_ids.append(model_id)
    cross_val_values.append(cross_val)

df = pd.DataFrame(
    {'Model_IDs': model_ids, metric: cross_val_values}
)
df = df.sort_values([metric], ascending=False)
best_model = h2o.get_model(df.iloc[0,0])
return df, best_model
#outputs: ordered grid in pandas dataframe and best model



I used this for a binary classification model",2023-01-31T20:06:55,,,,64032018
64085419,64085419,1,"H2O should recognize the datatypes of parquet files and set them beforehand. You may have the numeric columns set as strings/categorical when saving the parquet files. What do you have the parquet file saving the column datatypes as?


I verified on on H2O 3.30.0.1 that data types will be recognized by what the parquet files defines them as. See below.


Create numeric column (
sepal_len
) with a missing value from iris dataset


#Read a dataset
iris = h2o.import_file(""http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"")
#Convert one value to None
iris[0, 0] = None
#Make it as pandas df and save as parquet as 
df = iris.as_data_frame()
df.to_parquet('iris.parquet')
df.dtypes



Returns:


sepal_len    float64
sepal_wid    float64
petal_len    float64
petal_wid    float64
class         object
dtype: object



^columns are floats


#Read in h2o
iris2 = h2o.import_file('iris.parquet')
iris2.head(2)



Returns:


sepal_len   sepal_wid   petal_len   petal_wid   class
nan         3.5         1.4         0.2         Iris-setosa
4.9         3           1.4         0.2.        Iris-setosa



Check datatypes remain same from definition from parquet (made in pandas)


iris2.types



Returns:


{'sepal_len': 'real',
 'sepal_wid': 'real',
 'petal_len': 'real',
 'petal_wid': 'real',
 'class': 'enum'}



^H2O frame data types are real (not enum)


Change pandas dataframe to 
str
 column and save as a new parquet file:


#Save the parquet as a string column
df.astype({'sepal_len':'str'}).to_parquet('irisB.parquet')
#Read file again
irisB = h2o.import_file('irisB.parquet')
irisB.types



Returns:


{'sepal_len': 'enum',
 'sepal_wid': 'real',
 'petal_len': 'real',
 'petal_wid': 'real',
 'class': 'enum'}",2020-09-27T06:15:37,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,64004836
64001885,64001885,0,"What you're currently doing is starting the H2O cluster on a single machine and then connecting to it from the other machine (this is the scenario when you want two users to have access to the same H2O cluster to share data/models).


What you're trying to do is start a multi-node H2O cluster.  It's not clear whether this will speed up your training or not because there's communication overhead when you use a multi-node cluster, so it's always good to check.  If you are adding a larger number of cores, e.g. 40 + 40 for a total of 80 cores, I would expect that to speed things up in most cases, but adding 4 to 6 might not help that much (I just want to emphasize that it's good to test training speed on the 6 core single machine cluster vs 10 core multi-core cluster).  There are instructions for that in the H2O user guide 
here
.  There is also an FAQ about H2O clusters 
here
.  If the docs are not clear enough, please let me know (I am noticing it's a bit sparse on examples/information).


Lastly, if you specifically want to use Amazon EC2 for clustering, there's more info on that 
here
.",2020-09-22T01:29:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",64001253
63944534,63944534,0,"It sounds like you might have an access issue with the directory you trying to read from. I just tested on H2O 3.30.0.1 following the 
w2v example from docs
 and it ran fine:


job_titles = h2o.import_file((""https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv""),
                              col_names = [""category"", ""jobtitle""],
                              col_types = [""string"", ""string""],
                              header = 1)
STOP_WORDS = [""ax"",""i"",""you"",""edu"",""s"",""t"",""m"",""subject"",""can"",
              ""lines"",""re"",""what"",""there"",""all"",""we"",""one"",""the"",
              ""a"",""an"",""of"",""or"",""in"",""for"",""by"",""on"",""but"",""is"",
              ""in"",""a"",""not"",""with"",""as"",""was"",""if"",""they"",""are"",
              ""this"",""and"",""it"",""have"",""from"",""at"",""my"",""be"",""by"",
              ""not"",""that"",""to"",""from"",""com"",""org"",""like"",""likes"",
              ""so""]

# Make the 'tokenize' function:
def tokenize(sentences, stop_word = STOP_WORDS):
    tokenized = sentences.tokenize(""\\W+"")
    tokenized_lower = tokenized.tolower()
    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]
    tokenized_words = tokenized_filtered[tokenized_filtered.grep(""[0-9]"",invert=True,output_logical=True),:]
    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]
    return tokenized_words

# Break job titles into a sequence of words:
words = tokenize(job_titles[""jobtitle""])

# Build word2vec model:
w2v_model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10)

w2v_model.train(training_frame=words)

#Save model
wv_path = 'models/'
model_path = h2o.save_model(model = w2v_model, path= wv_path ,force=True)

#Load Model
w2v_model2 = h2o.load_model(model_path)",2020-09-17T18:52:44,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63928863
75390168,75390168,0,"It wasn't possible at that moment. After talking to some representatives of H2O and reviewing my options, I ended up doing the data preparation in Android code and then just feeding the prepared data into the model.",2023-02-08T18:23:44,nicolezk,https://stackoverflow.com/users/4534835/nicolezk,106,63836412
63800139,63800139,1,"The H2O 
tmp
 directory is set by your R env. See the output for 
tempdir()
. You can modify it before launching h2o, by installing unixtools and running


install.packages(""unixtools"",,""http://rforge.net/"",type=""source"")
unixtools::set.tempdir(""/your/new/path"")",2020-09-08T19:06:26,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63746299
63662507,63662507,3,"It sounds like you're not setting a seed, so you should start there.  In order for the algorithms with inherent randomness (e.g. XGBoost, GBM, Random Forest) to produce the same answer each time, a random seed must be set (at minimum).  In H2O AutoML, there's a single 
seed
 argument (which gets piped down to all the individual algorithms) and if you set it to the same value each time, 
most
 of the models will be the same on repeated runs.  By default, AutoML will also do cross-validation with random folds, so this also guarantees the same folds are used each time.


There are a few caveats -- H2O Deep Learning is not reproducible (by default) even if you set a seed, so those models will always change.  Since the ""All Models"" Stacked Ensemble uses Deep Learning models in addition to a bunch of other models, the final ensemble will also be non-reproducible.


Lastly, you should use the 
max_models
 instead of 
max_runtime_secs
 to control how long AutoML should run for -- otherwise you may get a different number of models on the leaderboard (and in the All Models Stacked Ensemble) on subsequent runs.",2020-08-30T21:55:02,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",63628501
63799372,63799372,1,"For XGBoost, if it becomes unresponsive, you may need to allocate additional memory for it, since it uses memory independent of H2O (algortihms)




Why does my H2O cluster on Hadoop became unresponsive when running XGBoost even when I supplied 4 times the datasize memory?






This is why the extramempercent option exists, and we recommend setting this to a high value, such as 120. What happens internally is that when you specify -node_memory 10G and -extramempercent 120, the h2o driver will ask Hadoop for 10𝐺∗(1+1.2)=22𝐺 of memory. At the same time, the h2o driver will limit the memory used by the container JVM (the h2o node) to 10G, leaving the 10𝐺∗120 memory “unused.” This memory can be then safely used by XGBoost outside of the JVM. Keep in mind that H2O algorithms will only have access to the JVM memory (10GB), while XGBoost will use the native memory for model training. For example:

hadoop jar h2odriver.jar -nodes 1 -mapperXmx 20g -extramempercent 120




Source",2020-09-08T18:05:05,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63615325
63799517,63799517,0,"H2O is expecting a native Python 
int
, but you are passing a 
numpy int64
. More is explained 
here
 about the differences.


Try converting the numpy array into a list 
max_depth=np.arange(10,11,1).tolist()[0]",2020-09-08T18:16:10,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63615228
63610605,63610605,5,"It's written on the error line :




Error Output: Only Java 8, 9, 10, 11, 12 and 13 are supported, system
version is 14.0.1 Error in h2o.init() : H2O failed to start, stopping
execution.




Only Java 8 up to 13 are supported in your version of H2O, while yours is 14.0.1, which causes it failed to execute.  Java 14 support was 
officially added in H2O 3.30.1.1
.  You can either downgrade your version of Java, or upgrade your version of H2O.  H2O 3.30.1.1 was recently 
released
 and not yet on CRAN, but you can install it using the following code in R:


if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-zeno/1/R"")",2020-08-27T06:50:45,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",63610554
63613581,63613581,0,"Tried uninstalling the h2o , then stopped the current R session, then restarted the R session and followed the installation process mentioned in h2o website.
This is working now.",2020-08-27T09:59:37,Ransingh Satyajit Ray,https://stackoverflow.com/users/10089181/ransingh-satyajit-ray,385,63610554
63445788,63445788,1,"It is safe to convert them to categorical 
.asfactor()
. It will treat the new transformed data the same as it will if it saw the levels earlier (it would be consistent).


If new levels are being transformed and predicted then it will be treated as unseen data and will follow 
the majority direction
.",2020-08-17T06:42:38,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63430711
63430696,63430696,0,"If I run your code and check the warnings:


warnings()
Warning messages:
1: model fit failed for Fold1.Rep1: max_depth=1, ntrees= 50, learn_rate=0.1, min_rows=10, col_sample_rate=1 Error in h2o.getConnection() : 
  No active connection to an H2O cluster. Did you run `h2o.init()` ?



So you need to do 
h2o.init()
 (check the 
webpage
 for more details):


library(caret)
library(h2o)

h2o.init()
ds = mosaicData::HELPrct

fitControl= trainControl(method=""repeatedcv"", number = 5)
ds$sub = as.factor(ds$substance)
h2oFit1 <- train(homeless ~ female + i1 + sub + sexrisk + mcs + pcs, 
               trControl=fitControl, 
               method = ""gbm_h2o"", 
               data=ds[complete.cases(ds),])

h2oFit1
Gradient Boosting Machines 

117 samples
  6 predictor
  2 classes: 'homeless', 'housed' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 1 times) 
Summary of sample sizes: 93, 94, 93, 94, 94 
Resampling results across tuning parameters:

  max_depth  ntrees  Accuracy   Kappa    
  1           50     0.5826087  0.0669072
  1          100     0.6253623  0.1895957
  1          150     0.6420290  0.2188447
  2           50     0.6159420  0.1708235
  2          100     0.6072464  0.1513658
  2          150     0.6329710  0.2035319
  3           50     0.6253623  0.1878658
  3          100     0.6159420  0.1701928
  3          150     0.6420290  0.1761487",2020-08-15T20:50:26,StupidWolf,https://stackoverflow.com/users/12258459/stupidwolf,46.7k,63342853
63446076,63446076,2,"Make sure you split the dataset the same for all ML algos (same seed). Having the same seed for each model won't necessarily have the same cross validation assignments. To ensure they are apples-to-apples comparisons, create a fold column (
.kfold_column()
 or 
.stratified_kfold_column()
) and specify it during training so they all use the same fold assignment.",2020-08-17T07:03:19,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63310789
63195299,63195299,0,It looks like the MOJO was trained with a newer version of sparkling water and you're trying to load it into an older version which is incompatible. Loading MOJOs is version dependant. Double check what version of H2O you used to train the MOJO.,2020-07-31T16:02:49,Thomas Ott,https://stackoverflow.com/users/3508160/thomas-ott,36,63177610
63164270,63164270,3,"I don't think this error has anything to do with using the optim package.  That is an error from the H2O package which just that 
""Test/Validation dataset has no columns in common with the training set""
.


So you should check the column names of your test set (or whatever dataset you're passing to the 
h2o.predict()
 function) to make sure it looks like your training set (all training columns should be present in test set).  If you can post a reproducible example, I can probably be more helpful.",2020-07-30T00:06:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",63160845
63158010,63158010,0,"Can you try with the following H2O function : 
h2o.randomForest()
 (
link with an example
)


Regarding your parameters, for min_bucket, I would try 
min_rows = 1
 even though, min_rows is applied to all leafs and not only the terminal leaf.",2020-07-29T16:16:38,BP34500,https://stackoverflow.com/users/11616033/bp34500,178,63144417
68475466,68475466,1,"There is no reason to expect that the AUC for any one of the folds should correspond to the AUC when trained on a single fold/the entire training data.


The AUC when trained on a single fold/the entire training data should correspond, approximately if not exactly, to the average of the AUCs for each of the folds.",2021-07-21T19:30:48,NathanG,https://stackoverflow.com/users/14223802/nathang,11,63135959
63211548,63211548,0,"once your gbm model is trained, you can access the variable importance using the following line :


import pandas as pd
varImp = pd.DataFrame(gbm_model.varimp(True))



From there you have a pandas dataframe and it is easy to access the columns names or even slice the dataframe anyway you like.


Cheers !",2020-08-02T01:29:22,Dharman,https://stackoverflow.com/users/1839439/dharman,33k,63114129
63077206,63077206,1,"If you're using Python or R client to run H2OAutoML, you can see the progression — e.g. which model is being built or completed — using the 
verbosity='info'
 parameter.
For example:


aml = H2OAutoML(project_name=""my_aml"",
                ...,
                verbosity='info')
aml.train(...)



If you're using the Flow web UI, this progress is shown automatically when you click on the running job.


You can then obtain the model ids from those console logs, and retrieve the models as usual in a separate client:


m = h2o.get_model('the_model_id')



or you can even access the current state of the leaderboard with the model metrics:


h2o.automl.get_automl('my_aml').leaderboard



The same logic applies to R client.


An alternative, maybe simpler if the goal is just to monitor progress, is to use Flow ( usually availble at http://localhost:54321 ) > 'Admin' > 'Jobs' > search for the AutoML job..",2020-07-24T15:58:52,,,,63068076
63124541,63124541,1,"The first layer in an DNN is the input layer -- that is the number of variables (or encoded variables) you have in your training set.


To summarize the comments above, your training frame is being expanded (by default, one-hot encoded) for any categorical columns that you have.  Given the screenshot of your dataset, you seem to have mostly all categorical columns (and they must have a total number of categories of ~798).  So what you're seeing is reasonable.  Since it's an autoencoder, the output layer is the same size as the input layer, which is why the last layer is 798 units as well.",2020-07-27T22:30:20,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",63061965
63077862,63077862,2,"H2OAutoML uses GLM as a default metalearner algo, and we're not currently trying multiple metalearners to find the best one (this may change in future releases).


For now, you can train a different ensemble using the autoML models as base models:


aml = H2OAutoML(project_name=""my_aml"",
                ...,
                keep_cross_validation_predictions=True) # important if you want to stack the models later

aml.train(...)

# train another ensemble using GBM as algo metalearner
lb = aml.leaderboard
base_models = [m for m in [lb[i,0] for i in range(lb.nrows)] 
                 if 'StackedEnsemble' not in m]

se = h2o.estimators.H2OStackedEnsembleEstimator(
    base_models=base_models,
    metalearner_algorithm='gbm',
    ...
)",2020-07-24T16:39:32,seb.,https://stackoverflow.com/users/9892991/seb,141,63059262
63092176,63092176,0,"You can install it on Windows 10 Pro / Enterprise / Education. You can follow 
this doc
.


h2oai_client
 is the Python client. You would need to host Driverless AI on a server with the instructions above, then you can install the 
client
. Then you can connect to it using the Python client.",2020-07-25T18:42:57,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,63034065
62973353,62973353,2,"You must have accidentally trained a regression model using the Stacked Ensemble (regression predictions are just a single column).  For H2O to do classification, you need to ensure that your response column is a ""factor"" (aka ""enum"") type, otherwise H2O will do regression.",2020-07-18T20:14:12,,,,62973260
62973351,62973351,1,"[cutting and pasting my response to the h2ostream mailing list here too...]


i suspect the large number of categorical levels is causing the memory to blow up.


try removing that variable and seeing if it at least completes.


if it does, try re-binning into a smaller number of levels somehow.",2020-07-18T20:14:09,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",62968836
62945264,62945264,1,"The seed value will change the results slightly. See below demonstrating that 
MSE
 changes when using the example from the docs.


# Import the prostate dataset into H2O:
train_h2o = h2o.import_file(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"")

# Set the predictors and response; set the factors:
train_h2o[""CAPSULE""] = train_h2o[""CAPSULE""].asfactor()
x_col_names = [""ID"",""AGE"",""RACE"",""DPROS"",""DCAPS"",""PSA"",""VOL"",""GLEASON""]
y = ""CAPSULE""

# Build and train first model:
pros_gbm1 = H2OGradientBoostingEstimator(
    nfolds = 5, ntrees = 1000, max_depth = 5, learn_rate = 0.1, 
    stopping_rounds = 5, score_tree_interval = 10, seed = 1)

pros_gbm1.train(x = x_col_names, y = y, 
                training_frame = train_h2o)

# Build and train the second model with only seed number changed:
pros_gbm2 = H2OGradientBoostingEstimator(
    nfolds = 5, ntrees = 1000, max_depth = 5, learn_rate = 0.1, 
    stopping_rounds = 5, score_tree_interval = 10, seed = 123456789)

pros_gbm2.train(x = x_col_names, y = y, 
                training_frame = train_h2o)

print('Model 1 MSE:', pros_gbm1.mse())
print('Model 2 MSE:', pros_gbm2.mse())



Output


Model 1 MSE: 0.020725291770552916
Model 2 MSE: 0.02189654172905499



If your dataset is giving reproducible results with different seeds and hardware settings, it may be that the it is not large or complex enough for the models to behave stochastically. You can also try changing the folds in the 
fold_column
 to see if that has an affect.",2020-07-17T00:10:06,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62934509
62959141,62959141,1,"The null pointer exception was caused by a bug, which has now been fixed on master.  So if you want that fix immediately, you can install the nightly build from 
here
, or you can wait for the next 
stable release
 (in the next week or two).  If that doesn't fix your issue, please post back here.


We had some additional checks on the training frames of the base learners that were too strict and we are going to further relax those restrictions (they were originally put in to prevent the user from accidentially mixing base models that are not compatible for stacking), but we are going to further loosen the restrictions.  You can follow the progress in this 
JIRA
.",2020-07-17T17:37:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",62922255
62854835,62854835,0,"You need to provide one more argument: 
class_sampling_factors
.
Assuming there are 2 classes and You want to undersample the first class then use:


cov_gbm = H2OGradientBoostingEstimator(balance_classes = True, class_sampling_factors = [0.8, 1])



class_sampling_factors
 must be a list of floats. Each element of list determines factor of sampling per class.",2020-07-11T21:33:00,ipj,https://stackoverflow.com/users/2805083/ipj,"3,598",62852544
63056849,63056849,1,"It seems it is working now. R client version 
3.30.0.1
 with server version 
3.30.0.1
. Also tried with Python version 
3.30.0.7
 and server version 
3.30.0.7
 and it started working. Marvelous. The problem was caused by a version mismatch between the client and the server, as the python client was updated to 
3.30.0.7
 while the latest server for docker was 
3.30.0.6
.",2020-07-23T14:38:26,,,,62835901
62869853,62869853,0,"Yes, H2O's AutoML does also hyperparameter optimization. It mainly does random grid search. From the 
docs
:




AutoML performs a hyperparameter search over a variety of H2O
algorithms in order to deliver the best model. In the table below, we
list the hyperparameters, along with all potential values that can be
randomly chosen in the search. If these models also have a non-default
value set for a hyperparameter, we identify it in the list as well.
Random Forest and Extremely Randomized Trees are not grid searched (in
the current version of AutoML), so they are not included in the list
below.


Note: AutoML does not run a grid search for GLM. Instead AutoML builds
a single model with lambda_search enabled and passes a list of alpha
values. It returns only the model with the best alpha-lambda
combination rather than one model for each alpha.",2020-07-13T05:43:46,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62817956
62776105,62776105,2,"MOJO models are H2O's primary way of taking models into production. These self-contained zip files are primarily meant to be run via 
genmodel
 and not inspected. MOJO model does not equal binary model, which is tied to a certain H2O version. The reason for that is simple - algorithm parameters and the algorithm itself may change between versions.


Anyway, H2O provides a way to import MOJOs back into H2O and 
primarily
 use them for scoring. Some attributes of MOJOs are still extracted from the MOJO and provided to the user. But, as the 
documentation
 says, it is not guaranteed which model parameters are exposed and some might be missing. MOJO model import is implemented as a part of H2O's 
Generic model
 functionality - the ability of H2O to ""embrace"" any model, even the ones trained outside H2O, provided the ""Generic model driver"" is available.


With that said, there is definitely a way to provide variable importances to MOJO import functionality users. This is a known problem already and is tracked in 
H2O JIRA
.


More resources on MOJO model on 
my blog
.",2020-07-07T13:12:57,Pavel Pscheidl,https://stackoverflow.com/users/12533815/pavel-pscheidl,181,62774361
62775816,62775816,1,"Word2Vec is not currently in the list of 
allowed algos
 to import back into H2O.


The documentation is a little bit confusing and needs improvement. MOJO is a way to take H2O models into production. Those are usable outside of H2O using H2O's 
genmodel
. Some of those MOJOs are importable back into H2O and inspected. But not all of them. The first two algorithms listed are supported. Unfortunately, Word2Vec is not.


I've created a 
JIRA
 to track this issue. We should be able to enable at least scoring.",2020-07-07T12:56:38,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",62769892
62881029,62881029,1,"It looks like you are following older documentation. H2O has its own random grid search method. See below.


#GBM hyperparameters
gbm_params = {'ntrees': [10, 20], 'max_depth': [1, 2, 3], 'learn_rate': [0.1, 0.2]}

# Search criteria
search_criteria = {'strategy': 'RandomDiscrete', 'max_models': 5, 'seed': 42}

# Train and validate a random grid of GBMs
gbm_grid = H2OGridSearch(model=H2OGradientBoostingEstimator(distribution=""gaussian""), grid_id='gbm_grid', hyper_params=gbm_params, search_criteria=search_criteria)
gbm_grid.train(x=predictor_columns, y=response_column, training_frame=iris_df)



See 
the docs
 for more info.",2020-07-13T17:23:13,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62706595
62653410,62653410,2,"the function 
h2o.import_file
 can handle import from multiple files on it's own. This works both in Python and R.


Python:


    data = h2o.import_file([""/home/some/path/to/airliens/airline1.csv"",
                                ""/home/some/path/to/airliens/airline2.csv""])



R:


data = h2o.importFile(c(""/home/some/path/to/airliens/airline1.csv"",
                                ""/home/some/path/to/airliens/airline2.csv""))",2020-06-30T08:35:07,Pavel Pscheidl,https://stackoverflow.com/users/12533815/pavel-pscheidl,181,62644117
62583246,62583246,1,"That is the correct link: 
https://www.oracle.com/java/technologies/javase-downloads.html
  Are the double quotes at the end of the link part of the error message?  Or did that get added when you formatted your question here?  If you remove the quotes at the end, the link works.


Please download Java 11 because Java 14 (the latest) was just released and we don't officially support it yet.  H2O system requirements (Java 8-13) are listed 
here
.",2020-06-25T19:49:25,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",62571907
68057865,68057865,0,"Although the argument 
balance_classes
 is available in H2O GLM, the algorithm itself does not require special handling for imbalanced data. Not sure if it applies in general, but it seems it applies in H2O. You may refer to the FAQ section, 
How does the algorithm handle highly imbalanced data in a response column?
, to verify it.",2021-06-20T16:24:47,Anastasiya-Romanova 秀,https://stackoverflow.com/users/3397819/anastasiya-romanova-%e7%a7%80,"3,358",62571240
62593441,62593441,1,"The recommended way to clean only your work is to use 
h2o.remove(aml)
.
This will delete the automl instance on the backend and cascade to all the submodels and attached objects like metrics.
It won't delete the frames that you provided though (e.g. 
training_frame
).",2020-06-26T11:07:36,seb.,https://stackoverflow.com/users/9892991/seb,141,62506409
62507391,62507391,1,"You can use 
h2o.ls()
 to list the H2O objects. Then you can use 
h2o.remove('YOUR_key')
 to remove ones you don't want to keep.


For example:


#Create frame of objects
h_objects = h2o.ls()
#Filter for keys of one AutoML session
filtered_objects = h_objects[h_objects['key'].str.contains('AutoML_YYYYMMDD_xxxxxx')]
for key in filtered_objects['key']:
    h2o.remove(key)



Alternatively, you can remove all AutoML objects using the filter below instead.


filtered_objects = h_objects[h_objects['key'].str.lower().str.contains('automl')]",2020-06-22T04:20:59,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62506409
62450652,62450652,4,"What you got is most likely 
log-odds
 and not a probability itself.
In order to get a probability, you need to transform each log-odds to the probability space, i.e.


p=e^x/(1 + e^x)



when you use 
SHAP
 directly you can achieve this by specifying 
model_output
 parameter:


shap.TreeExplainer(model, data, model_output='probability')",2020-06-18T13:04:52,Tomasz Bartkowiak,https://stackoverflow.com/users/8741356/tomasz-bartkowiak,14.6k,62450138
62481514,62481514,1,"It will not work due to not having a target column with the current design. Isolation forest with grid search support is currently in development and targeted to be released with 3.30.1.1 according to 
this Jira
.",2020-06-20T04:05:33,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62437404
62465381,62465381,0,"If your question is why the predicted value is greater than 1 for some rows in the test set, then this is due to the test values having shorter mean_lengths. I.e. fewer than average splits are needed to isolate them compared to training data. Remember that isolation forest uses an ensemble of trees (not just one). So if you have records more unique than training (anomalies), then your predicted value can be greater than 1 (or mean_length is shorter than normal).


You can see this by looking at the rows in your test data that have 
predict
 larger than 1: 


scores[scores[,1] > 1, ]


   predict mean_length
1 1.232558        3.82
2 1.023256        4.36
3 1.069767        4.24
4 1.286822        3.68



Also, you can see that your training data had an mean_length averaged for all rows was 4.42 (which is larger than ones from your test data, mean_lengths above)


scores_train <- h2o.predict(model,train)
mean(scores_train[,'mean_length'])


4.42



Check out 
this post
 to learn more about interpreting isolation forests.",2020-06-19T07:31:54,,,,62436821
62546917,62546917,0,"Neema pointed out that h2o is using min/max path length to normalize which makes scores great than 1 possible.


[https://support.h2o.ai/support/tickets/97280]",2020-06-24T03:01:12,Memphizz,https://stackoverflow.com/users/13764727/memphizz,11,62436821
62414837,62414837,1,"This problem has been resolved.


The problem is that there are a lot more columns for data set B after one-hot-encoding during the model run. Please see below.


Data set A:


There are 4 categorical features. The number of unique values for these categorical features is 12, 14, 25, and 10, respectively.


Data set B:


There are 7 categorical features and 1 numerical feature. The number of unique values for the categorical features is 17, 49, 52, 85, 5032 (!), 18445 (!!) and 392124 (!!!), respectively. This explains why it's so slow.",2020-06-16T18:00:22,Fanwei Zeng,https://stackoverflow.com/users/13756465/fanwei-zeng,55,62410289
62607835,62607835,0,"you're using Java version 14, which is not yet supported officially in H2O.


There's a JIRA to track Java 14 integration: 
https://0xdata.atlassian.net/browse/PUBDEV-7647
 .


In H2O, there's a property to override this default setting, which will let you use H2O with Java 14 at your own risk. This can be done by settings the 
sys.ai.h2o.debug.allowJavaVersions
 property when starting H2O.




If started manually, use 
java -Dsys.ai.h2o.debug.allowJavaVersions=14 -jar h2o.jar


From Python, use: 
h2o.init(jvm_custom_args=[""sys.ai.h2o.debug.allowJavaVersions"", ""14""])


From R, use: 
h2o.init(jvm_custom_args=c(""sys.ai.h2o.debug.allowJavaVersions"", ""14""))",2020-06-27T08:50:21,Pavel Pscheidl,https://stackoverflow.com/users/12533815/pavel-pscheidl,181,62377746
63862306,63862306,0,"I was able to get H2O working with Java 14 by following the install instructions for the 
latest stable release
 (currently 
rel-zeno/2
):


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

# Next, we download packages that H2O depends on.
pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-zeno/2/R"")

# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()



You'll need to update the repos URL in the last 
install.packages
 line if you want a more 
recent release
.


When I tried the answer from @pavel-pscheidl (prior to trying the above) I got the following error:


> h2o.init(jvm_custom_args=c(""sys.ai.h2o.debug.allowJavaVersions"", ""14""))

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /var/folders/nx/pn7rnnx96f184jt2sdtm52_00000gp/T//RtmpTz7jEz/file88837ecffee3/h2o_username_started_from_r.out
    /var/folders/nx/pn7rnnx96f184jt2sdtm52_00000gp/T//RtmpTz7jEz/file88839672a20/h2o_username_started_from_r.err

openjdk version ""14.0.2"" 2020-07-14
OpenJDK Runtime Environment (build 14.0.2+12-46)
OpenJDK 64-Bit Server VM (build 14.0.2+12-46, mixed mode, sharing)

Starting H2O JVM and connecting: ............................................................Diagnostic HTTP Request:
   HTTP Status Code: -1
HTTP Error Message: Failed to connect to localhost port 54321: Connection refused
 
Error Output:
   Error: Could not find or load main class sys.ai.h2o.debug.allowJavaVersions
   Caused by: java.lang.ClassNotFoundException: sys.ai.h2o.debug.allowJavaVersions 
Error in h2o.init(jvm_custom_args = c(""sys.ai.h2o.debug.allowJavaVersions"",  : 
  H2O failed to start, stopping execution.",2020-09-12T16:09:18,dnlbrky,https://stackoverflow.com/users/1344789/dnlbrky,"9,785",62377746
70011697,70011697,0,"This is Related and has been answered here: 
https://stackoverflow.com/a/68370871/17441922




Sklearn is based on Python/Cython/C and H2O uses Java. The underlying algorithms could also be different. However, you can try matching/translating your hyperparameters between the two since they will be similar",2021-11-17T21:21:28,Jeremy Caney,https://stackoverflow.com/users/3025856/jeremy-caney,"7,520",62345352
62416990,62416990,0,The goal was to use H2O has the primary model profiling tool as well as to provide a richer interface for comparing metrics etc. As discovered H2O is not compatible with other proprietary models and does not include wrappers to convert them.,2020-06-16T20:24:27,user2284452,https://stackoverflow.com/users/2284452/user2284452,125,62308496
62268862,62268862,0,"One thing you could try is cheating by bypassing the containerization for networking by using:


network_mode: ""host""



Here is a different stackoverflow article with a discussion about that:




Docker compose, running containers in net:host




and a link to the compose documentation:




https://docs.docker.com/compose/compose-file/#network_mode




So, try this:


backend:
    image: xxxxx/xxx-backend
    build: backend/xxx/.
    network_mode: ""host""
    environment:
      - ""KEY: value""
    command: python manage.py runserver 0.0.0.0:8000
    depends_on:
      - db
    networks:
      - xxx",2020-06-08T18:28:53,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",62262881
62266833,62266833,0,"H2O does not support importing data directly from Elasticsearch. You can write it to CSV and then import it to H2O. The file formats that are supported are: CSV (delimited) files, ORC, SVMLight, ARFF, XLS/XLSX, Avro, Parquet. Data sources that could be used are: Local or Remotes Files, S3, HDFS, JDBC, Hive. You can refer to the documentation on 
Getting Data Into H2O
.",2020-06-08T16:30:39,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62259924
62277592,62277592,1,"AUC of the ROC curve is not accuracy, and the value is threshold independent. It is a measure of how well separated two classes are. The 71% value tells you the probability of you randomly sampling positive class having a higher predicted probability than a randomly sampled negative class. See 
this
 explanation.


Selecting the threshold should depend on your cost matrix (how much the penalty is for False Positives or False Negatives). You would want to select the threshold that maximize your desired metric (max. F1, precision, accuracy). H2O gives 
multiple options
. In H2O, if you call the model performance (Python ex: 
your_model.model_performance()
), you will get the threshold for 
max accuracy
 and other optimized metrics listed.",2020-06-09T07:50:46,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,62143598
62075440,62075440,0,"You likely have 32-bit version of Java installed as well as your new 64-bit version. 


H2O may find Java differently than what your terminal finds from 
Java -version
. The order H2O finds Java is:




Searches in 
PATH


If not found, then checks 
JAVA_HOME




You have a few options to resolve your issue:




Uninstall your old 32-bit version of Java as @TomKraljevic mentioned


Add the new 64-bit Java to the beginning of your Windows 
PATH
 system variable 
under Windows settings


Add the new 64-bit Java to the beginning of 
PATH
 in your R environment. For example: 




old_path <- Sys.getenv(""PATH"")
ys.setenv(PATH = paste(""path/to/new_java"", old_path, sep = "":""))",2020-05-28T22:15:59,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61980077
61958803,61958803,0,"The documentation you are following is for version 2.6 (the copyright at the bottom is 2013!), but you are running version 3.31.


I normally start H2O-related searches here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html


To set up a multinode cluster, I've used the 
flatfile approach
, and then start each of them from the commandline. Make sure all your nodes have started up and found each other (you can see this by watching the logs), before you try to connect to any node in the cluster, otherwise you will see the message you get.",2020-05-22T15:45:45,,,,61950298
61945596,61945596,0,"It is possible that an H2O cluster goes down due to out-of-memory and your client loses communication with it. You would need to review the H2O logs to determine the error/cause.


A general rule of thumb is to have about 4x memory of your dataset. See the 
docs
. In your case, you should have about 80GB needed to handle data manipulation and modeling.",2020-05-21T23:44:58,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61817203
61810353,61810353,1,"If you would like to call out the specific values from 
cross_validation_metrics_summary
, you can use the following:


current_model.cross_validation_metrics_summary().as_data_frame()[['', 'sd']]



The last part 
[['', 'sd']]
 will call the two columns of interest. 
''
 is the name of each score (e.g. accuracy, auc) and 
'sd'
 would give their corresponding standard deviations.


Outputs a table:


+-------+----------+--------------+
| index |    ''    |      sd      |
+-------+----------+--------------+
| 0     | accuracy | 0.0048520584 |
| 1     | auc      | 0.011593064  |
| 2     | aucpr    | 0.011920754  |
| ...   | ...      | ...          |
+-------+----------+--------------+",2020-05-15T01:47:01,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61779581
61961011,61961011,0,"You will need to set 
training_frame
 and 
validation_frame
 to 
None
 in 
new_params
. Try using the code below and see if that help.


gbm = h2o.get_model(sorted_final_grid.sorted_metric_table()['model_ids'][0])

params = gbm.params
new_params = {""nfolds"":5, ""model_id"":None, ""training_frame"":None, ""validation_frame"":None, 
              ""response_column"":None, ""ignored_columns"":None}
for key in new_params.keys():
    params[key]['actual'] = new_params[key] 
gbm_best = H2OGradientBoostingEstimator()
for key in params.keys():
    if key in dir(gbm_best) and getattr(gbm_best,key) != params[key]['actual']:
        setattr(gbm_best,key,params[key]['actual']) 



I will get the tutorial you referred to updated.",2020-05-22T17:53:48,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61769186
61752419,61752419,0,"In python you can use the One-Class Support Vector Machine implementation in scikit-learn: 


https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html",2020-05-12T13:01:35,maz,https://stackoverflow.com/users/5554921/maz,123,61752303
61766740,61766740,1,"Your dataset is called ""digiq_wine_multiclass_training(1)_scrubbed.csv"" so I assume you were have a multiclass classification problem?  If so, then the reason you're hitting an error is because partial dependence plots are only implemented for regression or binary classification problems.",2020-05-13T04:57:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",61722372
61714655,61714655,1,"H2O-3 has an in-memory architecture.


It does not write anything to disk unless you ask it to, and the location it persists to (when saving a model, for example) is the location you manually give it.


I suggest you try this without docker first, to get the hang of what to expect when H2O-3 restarts.",2020-05-10T15:44:52,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",61713239
61810627,61810627,1,"In H2O, you can get the variable importance using the 
varimp()
 method. You can use 
predictor.varimp()
.",2020-05-15T02:17:31,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61692023
61598814,61598814,1,"It's currently unimplemented, but you can follow the progress here: 
https://0xdata.atlassian.net/browse/PUBDEV-5137",2020-05-04T18:09:51,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",61593799
61598874,61598874,3,"Yes, you're correct.  The percentage of the data used for training is determined by the number of folds.",2020-05-04T18:14:17,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",61590772
61645457,61645457,0,"As mentioned in the 
docs
, during H2O's AutoML




all appropriate H2O algorithms will be used if the search stopping criteria allows and if the 
include_algos
 option is not specified




If you would like to specify certain algos, you can specify a list or vector in the 
include_algos
 argument (see 
here
).",2020-05-06T21:09:09,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61585373
61764153,61764153,0,"You would need to have 
nfolds
 disabled. As the 
docs
 say ""Cross-validation is not currently supported for checkpointing.""


If you are using new data, it may not make much sense to start from an old model for DRF. The old/original trees (1-49) won't benefit from the additional observations from the new data. The new trees after the checkpoint (50-99) will have the additional observations. So half your trees will be lacking some predictive info which can create some bias in your scoring.",2020-05-13T00:09:56,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61541709
61648444,61648444,0,"The answers to your questions:


1 - The response vector will need to be part of the 
H2OFrame
.


2 and 3 - 
h2o.import_file
 is the efficient way to create H2O Frames. It is best to use SVMLight file as that it what is 
supported for sparse datasets
.",2020-05-07T01:43:58,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61536248
61492475,61492475,0,"fold_column
 option works, some brief examples are there in the docs:

http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2o.grid.H2OGridSearch",2020-04-29T00:57:08,Manjit P.,https://stackoverflow.com/users/5906999/manjit-p,85,61474033
61462687,61462687,1,"With purrr you can embed it into the tibble, but let's say if you want to do prediction, you might need to use 
map2
, abit more complicated than should be i think :


library(dplyr)
library(h2o)
library(purrr)

iris%>%
dplyr::mutate(dataset=dplyr::if_else(sample(1:nrow(iris))<100,""train"",""val""))%>%
dplyr::group_by(Species,dataset)%>%
tidyr::nest()%>%
tidyr::pivot_wider(names_from = dataset,values_from = data) %>%
mutate(model=map(train,~h2o.randomForest(y=""Sepal.Width"",
x=c(""Sepal.Length"",""Petal.Width"",""Petal.Length""),training_frame=as.h2o(.x))))",2020-04-27T15:42:42,StupidWolf,https://stackoverflow.com/users/12258459/stupidwolf,46.7k,61460911
61437914,61437914,2,"First, as Tom says in the comments, you're gonna need a bigger boat. H2O holds all data in memory, and generally you need 3 to 4x the data size to be able to do anything useful with it. A dataset of 500GB means you need the total memory of your cluster to be 1.5-2TB.


(H2O stores the data compressed, and I don't think sqlite does, in which case you might get away with only needing 1TB.)


Second, 
as.h2o()
 is an inefficient way to load big datasets. What will happen is your dataset is loaded into R's memory space, then it is saved to a csv file, then that csv file is streamed over TCP/IP to the H2O process.


So, the better way is to export directly from sqlite to a csv file. And then use 
h2o.importFile()
 to load that csv file into H2O.


h2o.cbind()
 is also going to involve a lot of copying. If you can find a tool or script to column-bind the csv files in advance of import, it might be more efficient. A quick search found 
csvkit
, but I'm not sure if it needs to load the files into memory, or can do work with the files completely on disk.",2020-04-26T08:35:16,,,,61435532
61442498,61442498,1,"Since memory is a premium and all R runs in RAM, avoid storing large helper 
data.table
 and
h20
 objects in your global environment. Consider setting up a function to build a list for compilation that temporary objects are removed when function is out of scope. Ideally, you build your 
h2o
 objects directly from file source:


# BUILD LIST OF H20 OBJECTS WITHOUT HELPER COPIES
h2o_list <- lapply(list_of_files, function(f) as.h2o(data.table::fread(f))[-1])
# h2o_list <- lapply(list_of_files, function(f) h2o.importFile(f)[-1])

# CBIND ALL H20 OBJECTS
test.h2o <- do.call(h2o.cbind, h2o_list)



Or even combine both lines with named function as opposed to anonymous function. Then, only final object remains after processing. 


build_h2o <- function(f) as.h2o(data.table::fread(f))[-1])
# build_h2o <- function(f) h2o.importFile(f)[-1]

test.h2o <- do.call(h2o.cbind, lapply(list_of_files, build_h2o))



Extend function with 
if
 for some datasets that need to retain first column or not.


build_h2o <- function(f) {
   if (grepl(""lai|lu1000|lu250|msl"", f)) { tmp <- fread(f)[-1] }
   else { tmp <- fread(f) }

   return(as.h2o(tmp))
}



Finally, if possible, leverage 
data.table
 methods like 
cbindlist
:


final_dt <- cbindlist(lapply(list_of_files, function(f) fread(f)[-1]))

test.h2o <- as.h2o(final_dt)

rm(final_dt)
gc()",2020-04-26T14:31:06,Parfait,https://stackoverflow.com/users/1422451/parfait,107k,61435532
61647483,61647483,1,"To predict the future dates, you can upload a dataset that has the dates of interest (specify dates in the future) and provide anything additional that may be known (group ids or features known in the future). Then run/score your predictions on this new dataset.


Here is an example dataset to upload for a model that was trained up to 2020-05-31.


+------------+----------+-----------------+-----------------+
|    Date    | Group_ID | Known_Feature_1 | Known_Feature_2 |
+------------+----------+-----------------+-----------------+
| 2020-06-01 | A        |               3 |                1|
| 2020-06-02 | A        |               2 |                2|
| 2020-06-03 | A        |               4 |                1|
| 2020-06-01 | B        |               3 |                0|
| 2020-06-02 | B        |               2 |                1|
| 2020-06-03 | B        |               4 |                0|
+------------+----------+-----------------+-----------------+",2020-05-06T23:54:54,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,61420508
61308425,61308425,1,"Garbage collection only deletes objects that have no references to them, and deep copy makes a full copy of the object and hangs on to the reference.


If you want the object to be released, you need to remove it.


This updated program achieves the effect you were originally looking for.


import h2o 

h2o.init(max_mem_size='2G')

df = h2o.create_frame(frame_id='start_frame', rows=1000000, cols=10)
print(df.head())

def copy_and_remove_frame(i, df):
    df_copy = h2o.deep_copy(df, 'copy_'+str(i))
    h2o.remove(df_copy)
    return

for i in range(50):
    copy_and_remove_frame(i, df)
    print(h2o.ls())



The output from this updated program's ""ls"" is not growing each iteration, since each iteration is cleaning up after itself:


[['key'], ['start_frame']]
[['key'], ['start_frame']]
[['key'], ['py_188_sid_bc5e'], ['start_frame']]
[['key'], ['py_190_sid_bc5e'], ['start_frame']]
[['key'], ['py_192_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['py_197_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['py_198_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['py_200_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['py_202_sid_bc5e'], ['start_frame']]
[['key'], ['py_194_sid_bc5e'], ['py_204_sid_bc5e'], ['start_frame']]
[['key'], ['start_frame']]
[['key'], ['py_208_sid_bc5e'], ['start_frame']]
[['key'], ['start_frame']]
[['key'], ['py_212_sid_bc5e'], ['start_frame']]
[['key'], ['py_214_sid_bc5e'], ['start_frame']]
[['key'], ['py_216_sid_bc5e'], ['start_frame']]
[['key'], ['py_218_sid_bc5e'], ['start_frame']]
[['key'], ['py_220_sid_bc5e'], ['start_frame']]
[['key'], ['py_220_sid_bc5e'], ['start_frame']]
[['key'], ['py_220_sid_bc5e'], ['start_frame']]
[['key'], ['py_220_sid_bc5e'], ['py_226_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_240_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_242_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_244_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_250_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_254_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_256_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_258_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_260_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_262_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_264_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_270_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_272_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_274_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_276_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_278_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_280_sid_bc5e'], ['start_frame']]
[['key'], ['py_228_sid_bc5e'], ['py_246_sid_bc5e'], ['py_280_sid_bc5e'], ['start_frame']]



[ Now... you 
might
 have expected the 
python
 garbage collector to invisibly do a refcnt decrement on the df_copy object, since it's not returned from the function, causing an implicit h2o.remove() on the H2OFrame stored in Java memory on the back-end once the python refcnt reaches 0.  And once the high-level H2OFrame object is deleted from the back-end in-memory H2O-3 DKV, then the java garbage collector will scoop up the now-freed underlying byte array objects that actually hold the data.  But as you can see, the python layer didn't do that.  I think that's because it's too hard for data scientists bouncing betweeen cells in Jupyter notebooks to remember the exact liveness of different data frames in this very computer-science-y way, which is more suited to programs than to people.  And if you ask for a deep copy, you really meant to do that and want to keep it around.  So you have to explicitly delete it.  Having these expensively constructed big-data frames just disappearing on you unexpectedly is worse (which is to say, results in support calls from data scientists wondering what happened to their data :-). ]








Output from the original post's run, which shows the number of copied frames increasing (shown by ""ls"") each iteration.  This does, of course, end up in a failure, since memory is not infinite:


Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.
Attempting to start a local H2O server...
  Java Version: java version ""1.8.0_231""; Java(TM) SE Runtime Environment (build 1.8.0_231-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)
  Starting server from /Users/tomk/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /var/folders/vv/pkzvhy8x5hsfbsjg75_6q4ch0000gn/T/tmpagdl10y4
  JVM stdout: /var/folders/vv/pkzvhy8x5hsfbsjg75_6q4ch0000gn/T/tmpagdl10y4/h2o_tomk_started_from_python.out
  JVM stderr: /var/folders/vv/pkzvhy8x5hsfbsjg75_6q4ch0000gn/T/tmpagdl10y4/h2o_tomk_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
H2O_cluster_uptime: 02 secs
H2O_cluster_timezone:   America/Los_Angeles
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:    3.30.0.1
H2O_cluster_version_age:    15 days
H2O_cluster_name:   H2O_from_python_tomk_fv2qrn
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    1.778 Gb
H2O_cluster_total_cores:    16
H2O_cluster_allowed_cores:  16
H2O_cluster_status: accepting new members, healthy
H2O_connection_url: http://127.0.0.1:54321
H2O_connection_proxy:   {""http"": null, ""https"": null}
H2O_internal_security:  False
H2O_API_Extensions: Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4
Python_version: 3.6.10 final
Create Frame progress: |██████████████████████████████████████████████████| 100%
C1  C2  C3  C4  C5  C6  C7  C8  C9  C10
61.201  -76.343 -10.6917    98  c4.l71  c5.l21  -48.2047    0   nan -53.9755
-65.8869    34.639  -24.3842    61  c4.l63  c5.l73  -50.8215    0   52  -45.5802
73.5673 -65.7778    -93.1551    65  c4.l16  c5.l22  55.5902 0   97  -48.3528
12.5487 -17.0889    -38.5781    -61 c4.l39  c5.l85  -9.83111    0   77  50.9879
-54.0852    67.8506 -17.0522    81  c4.l40  c5.l9   41.9873 0   -8  -80.1168
-18.1366    -49.2238    -5.92224    24  c4.l95  c5.l11  -20.7617    0   29  92.2341
-14.861 11.7016 -51.1821    -60 c4.l32  c5.l17  -35.5073    0   -14 79.5753
-37.3768    -23.8756    15.1105 -65 c4.l20  c5.l32  29.6603 0   -11 -41.3118
-71.0224    9.29381 -74.2127    50  c4.l49  c5.l22  -90.8299    0   -50 8.42312
31.9923 0.228002    5.50001 -8  c4.l56  c5.l80  -92.0688    0   -75 -65.3436

[['key'], ['copy_0'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_31'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_31'], ['copy_32'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_31'], ['copy_32'], ['copy_33'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_31'], ['copy_32'], ['copy_33'], ['copy_34'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
[['key'], ['copy_0'], ['copy_1'], ['copy_10'], ['copy_11'], ['copy_12'], ['copy_13'], ['copy_14'], ['copy_15'], ['copy_16'], ['copy_17'], ['copy_18'], ['copy_19'], ['copy_2'], ['copy_20'], ['copy_21'], ['copy_22'], ['copy_23'], ['copy_24'], ['copy_25'], ['copy_26'], ['copy_27'], ['copy_28'], ['copy_29'], ['copy_3'], ['copy_30'], ['copy_31'], ['copy_32'], ['copy_33'], ['copy_34'], ['copy_35'], ['copy_4'], ['copy_5'], ['copy_6'], ['copy_7'], ['copy_8'], ['copy_9'], ['start_frame']]
---------------------------------------------------------------------------
H2OServerError                            Traceback (most recent call last)
<ipython-input-2-6dd1ee76f72f> in <module>
     11 
     12 for i in range(50):
---> 13     create_frame(i, df)
     14     print(h2o.ls())

<ipython-input-2-6dd1ee76f72f> in create_frame(i, df)
      7 
      8 def create_frame(i, df):
----> 9     df_copy = h2o.deep_copy(df, 'copy_'+str(i))
     10     return
     11 

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/h2o.py in deep_copy(data, xid)
    951     check_frame_id(xid)
    952     duplicate = data.apply(lambda x: x)
--> 953     duplicate._ex = ExprNode(""assign"", xid, duplicate)._eval_driver(False)
    954     duplicate._ex._cache._id = xid
    955     duplicate._ex._children = None

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/expr.py in _eval_driver(self, top)
    108     def _eval_driver(self, top):
    109         exec_str = self._get_ast_str(top)
--> 110         res = ExprNode.rapids(exec_str)
    111         if 'scalar' in res:
    112             if isinstance(res['scalar'], list):

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/expr.py in rapids(expr)
    247         :returns: The JSON response (as a python dictionary) of the Rapids execution
    248         """"""
--> 249         return h2o.api(""POST /99/Rapids"", data={""ast"": expr, ""session_id"": h2o.connection().session_id})
    250 
    251 

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/h2o.py in api(endpoint, data, json, filename, save_to)
    107     # type checks are performed in H2OConnection class
    108     _check_connection()
--> 109     return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)
    110 
    111 

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/backend/connection.py in request(self, endpoint, data, json, filename, save_to)
    476                 save_to = save_to(resp)
    477             self._log_end_transaction(start_time, resp)
--> 478             return self._process_response(resp, save_to)
    479 
    480         except (requests.exceptions.ConnectionError, requests.exceptions.HTTPError) as e:

~/anaconda/envs/h2o3/lib/python3.6/site-packages/h2o/backend/connection.py in _process_response(response, save_to)
    827         # Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server
    828         # did not provide the correct status code.
--> 829         raise H2OServerError(""HTTP %d %s:\n%r"" % (status_code, response.reason, data))
    830 
    831 

H2OServerError: HTTP 500 java.lang.OutOfMemoryError: GC overhead limit exceeded:
'<html>\n<head>\n<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>\n<title>Error 500 java.lang.OutOfMemoryError: GC overhead limit exceeded\n</title>\n</head>\n<body>\n<h2>HTTP ERROR: 500</h2>\n<p>Problem accessing /99/Rapids. Reason:\n<pre>    java.lang.OutOfMemoryError: GC overhead limit exceeded\n</pre></p>\n\n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n                                                \n</body>\n</html>\n'",2020-04-19T17:12:10,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",61305294
61293373,61293373,0,"The first choice (better, but more lines of code have to change) is not to load the data into R, and have H2O 
load
 it, and also have H2O 
split
 it instead. The H2O loader will recognize the first row is a header row and treat it as column names, and not as data.


The second approach is to strip out the header row in the R code.


However, that is already the default behaviour of 
read.csv()
 (the 
header
 argument defaults to 
TRUE
). So your data must have ""BUY"" somewhere other than the first row. In which case either fix the data manually, or seek and destroy that bad row after loading it into R.


(If you disagree, can you post a sample data file that demonstrates the problem, using the code you have given.)",2020-04-18T17:28:19,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,61277101
64080058,64080058,0,"Here is the official guide for installing 
H2O
 on Anaconda.


Jump to the 
Install on Anaconda Cloud
 part, make sure your Python's version is compatible with h2o module (2.7,3.5 and 3.6), follow the steps and you will be able to import h2o module through py36 channel.

Hope this answer helps you.",2020-09-26T16:29:17,Newcomer,https://stackoverflow.com/users/13949223/newcomer,73,61230237
61173397,61173397,1,"The approach you describe is different from what I would recommend.


For simplicity's sake (ignoring multiple servers and load balancing) I am going to draw your setup's architecture diagram like this:


[Client HTTP program] -> [python flask app] -> [java scoring backend]



This high-level architecture is fine, but you've gone about implementing the java scoring layer part in what I will say is the most difficult way possible instead of the intended way.


The intended way is to use only the MOJO and the lightweight MOJO runtime.  One straightforward way to do that is to wrap the MOJO in a very simple minimal web service.


Here are links to the javadoc for the MOJO:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#whatisamojo




and a github repo demonstrating how to use a MOJO in a simple Java servlet container:




https://github.com/h2oai/app-mojo-servlet




Also, here is an older github repo you might find useful that uses the POJO instead of the MOJO.  The MOJO is better.  Use the MOJO and not the POJO, but you may find reading the documentation in this repo helpful:




https://github.com/h2oai/app-consumer-loan




Note if you do things this way you can still scale/load balance the [python flask app] and [java scoring backend] services separately if you want, although my expectation would be the java will be substantially faster than the python, so it might be easier just to scale the python and java together in groups of two, and have the python make requests to a local java.




OK, now that I've talked about the best practice way, let me point out some issues I can spot in what you are doing now (the difficult way).




You didn't mention whether you are scoring one row at a time or doing batch scoring.  Using the full H2O-3 server itself for scoring is much better suited for batch scoring and horrendously inefficient for scoring one row at a time.  The parsing process is heavyweight and the scoring process is heavyweight for one row at a time.  This will impact latency.


While you can read in the MOJO object itself to a full H2O-3 server process and use it for batch scoring, doing this in a real-time HTTP workflow was never the intent.  (Interestingly, support for doing this wasn't even possible for about the first 5 years of H2O-3's existence.)


There are definitely memory leaks if you don't clean up after yourself.


Running the H2O-3 server process as a long-running service for scoring is not recommended.  But if you really want to do it, take these steps:




The in-memory objects need to be cleaned out.  You can find them with the h2o.ls() and remove them with the h2o.rm() calls in the R/python client APIs.  Both the datasets and the scores would need to be cleaned up.  You probably don't want to remove the model itself, though.


I don't expect you need to manually trigger garbage collections in the Java process, but you can if you want to.  Personally, I only do that when I have turned on Java flags like -XX:+PrintGCDetails -XX:+PrintGCTimeStamps so I can see the effect of the compaction on how much free heap memory remains after a Full GC.  I do this so I can see whether objects are really being retained, so I can confirm they are getting cleared out.  I like to give those logs to 
http://gceasy.io
 and visualize them.


Do monitor the logs to see the free heap remaining after a Full GC.


Even if you are doing the right stuff in terms of cleaning up memory, give the H2O-3 server process lots of memory.  I wouldn't even run it on my laptop with a smaller -Xmx than 5G.  As such, I would characterize the original poster's Java heap as severely under-provisioned (
H2O cluster free memory: 1.656 Gb
).


If you see the free heap remaining after Full GC creeping up, restart the Java process, since this is not the standard use case and not something that gets thoroughly tested.  The H2O-3 clusters are thought of by the development team as more as short-to-medium lifetime services (hours/days) than long-running services (months+, e.g. nginx/apache).








Hope that helps!",2020-04-12T14:56:55,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",61172226
61127401,61127401,1,"The problem is that you're storing the knot locations as strings (sorry, that was a bug the demo code on the 
GAM User Guide page
 -- we will fix that).  If you change the first lines of your code (remove the quotes around the numbers), it will work:


# create frame knots
knots1 <- c(-1.99905699, -0.98143075, 0.02599159, 1.00770987, 1.99942290)
frameKnots1 <- as.h2o(knots1)
knots2 <- c(-1.999821861, -1.005257990, -0.006716042, 1.002197392, 1.999073589)
frameKnots2 <- as.h2o(knots2)
knots3 <- c(-1.999675688, -0.979893796, 0.007573327, 1.011437347, 1.999611676)
frameKnots3 <- as.h2o(knots3)",2020-04-09T18:03:04,,,,61125642
61072583,61072583,2,"As silly as it sounds, there seems to be a bug in h2o which occurs when have a working directory set which has empty spaces in its name. e.g. 
""c:\test folder\model\""
, if you change this to 
""c:\test_folder\model\
"" or 
""c:\testfolder\model\""
, then we don't get the above error. H2o has difficult writing the files to those directories with address where there are empty spaces in between.",2020-04-07T03:56:19,Learner_seeker,https://stackoverflow.com/users/7609862/learner-seeker,544,61071343
72618756,72618756,0,"According to your code, change params to parameters; the argument passed earlier.


gs_clf = GridSearchCV(clf_pipe, param_grid=params)



Then becomes:


gs_clf = GridSearchCV(clf_pipe, param_grid=parameters)",2022-06-14T14:28:50,Edward Ji,https://stackoverflow.com/users/11658924/edward-ji,791,60918535
60797568,60797568,0,"Thank you, It is running now, I don't know how but I run after restart my PC.",2020-03-22T09:11:07,Subhadip Datta,https://stackoverflow.com/users/11991386/subhadip-datta,29,60797040
60709546,60709546,0,"You're probably running different 
python
 and 
pip
 environments, such as 
python2
 and 
pip3
. Try running 
python3 2_Forecasting_monthly.py >> pyforecast.log
 for instance.",2020-03-16T16:18:06,Jonas Byström,https://stackoverflow.com/users/87973/jonas-bystr%c3%b6m,26.1k,60709464
60699132,60699132,0,"H2O-3 does not have any specific file size limit.


Since the data is stored in-memory, the practical limit is directly correlated to the amount of memory you have.  You can add more nodes, or more memory to the existing nodes you have, to work with larger datasets.


For example, a billion rows with terabyte of total data is fine if you have the hardware to handle it.",2020-03-16T00:48:52,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",60696897
60672395,60672395,3,"I guess that's what you're looking for: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html#h2o.save_model


Please also note that you can access clients documentation from 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/api-reference.html
 (agree that it's a bit hidden...).


Like for any other Python function, you could also use 
help(h2o.save_model)
 from the Python repl, or 
h2o.save_model??
 from IPython/Jupyter.",2020-03-13T14:37:40,,,,60667920
60595045,60595045,1,"It appears that the problem has nothing to do with datatable. Look at the traceback:


Traceback (most recent call last):
  File ""/git/corona/python/pointr/experiments/python/datatable.py"", line 18, in <module>
    import datatable as dt
  File ""/git/corona/python/pointr/experiments/python/datatable.py"", line 19, in <module>
    print(f'datatable version={dt.__version__}')
AttributeError: module 'datatable' has no attribute '__version__'



Doesn't it strike you as suspicious that you have line 18 ""calling"" line 19? I mean, how could it be? Here's how:


When you name your script 
datatable.py
 and then do 
import datatable
, then instead of importing the actual module from site-packages, it imports the ""module"" datatable.py instead. Basically, the file imports itself. And the way python manages imports, is that it creates a ""stub"" module in the 
sys.modules
 first (in order to prevent infinite recursions during imports). In your case, the module tries to import itself, so the stub module is fetched instead -- and then when you try to print its 
__version__
 variable, turns out it doesn't exist.


You can verify this by printing 
dt.__file__
 instead, which should show the location of the file that is being imported.


Needless to say, all this is not specific to datatable in any way; for example if you created a file 
numpy.py
 and then tried to 
import numpy
, you'd run into same problems.",2020-03-09T05:15:07,Pasha,https://stackoverflow.com/users/958624/pasha,"6,540",60593198
62305338,62305338,2,"The exception is raised 
here
; in particular, in your case, the object 
py_7_sid_b8c3
 is valued with 
null
. That's a (Java, not Python despite the name) H2O object, which should encode the H2O frame passed for the training. Objects live within each node, I faced a similar issue and I discover in my case that one node was crashing for memory issues. Of course, it could be anything else which does not allow the cluster to get the H2O frame. In anycase, I suggest to inspect the stdout and the stderr logged by the JVMs which run the H2O cluster. They are generally stored in 
/tmp
, their paths are shown at the moment you init the H2O cluster. Generally in the Java stacktrace more info is logged.


UPDATE
: I was able to trigger again this issue in another case




import of a CSV file into an H2O frame


drop of a column, like 
df = df.drop('col')


run then the train of an estimator: 
estimator.train(x=predictors, y=response, training_frame=df)
 (with 
predictors
 valued with a list of columns which refer to the feature of the model, and 
response
 valued with the label needed for the training)




I think the error was due because H2O frames as Python objects refer to a Java object in the H2O backend: probably here after the 
drop
 there was a pending reference to a null vector, which triggered the exception. Maybe there was some race condition because not all the time the exception was raised.


I finally solved simply passing the proper list of usable features in the 
predictors
 variable. But as said in my previous comment, the main insight arrived looking at JVMs logs.",2020-06-10T13:53:03,,,,60563604
66141282,66141282,1,"The question is not about 
R
, but I've been consistently having the same error in 
R
. If any other 
R
 user stumbled on this thread looking for a solution:


I restarted h2o


h2o.shutdown()
h2o.init(enable_assertions = FALSE)



and immediately recreated my h2o training data


train.hex <- as.h2o(train_set)
tune.hex <- as.h2o(tune_set)
test.hex <- as.h2o(test_set)

trainh2o <- h2o.assign(train.hex, key = ""train"")
tuneh2o <- h2o.assign(tune.hex, key = ""tune"")
testh2o <- h2o.assign(test.hex, key = ""test"")

#Set up variable names 
xnames = setdiff(names(trainh2o, y = trainh2o$outcome)
yname = ""outcome""",2021-02-10T16:51:15,sahinakkaya,https://stackoverflow.com/users/9608759/sahinakkaya,"6,036",60563604
67011652,67011652,0,"Ran into this same issue.  Seems there may be something wrong in the docs as it mentions you can pass a H2OFrame.

https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html


However i think if you passed 
train=True
 it would work


print(gbm.confusion_matrix(train=True).as_data_frame())",2021-04-08T20:47:49,David Buck,https://stackoverflow.com/users/7508700/david-buck,"3,784",60509766
64906135,64906135,0,"Split the data into Train/Test/Validation with Train having 70% and test and validation 15% each


train,test,valid = prostate_df.split_frame(ratios=(.7, .15))",2020-11-19T05:56:33,Donald Duck,https://stackoverflow.com/users/4284627/donald-duck,"8,822",60496404
60490781,60490781,0,"mcc
 is specifically for 
binary
 classifiers; your factor has more than 2 levels.


You can tell you have successfully done a multinomial classification, rather than a regression, because the error message says ""No absolute_mcc for H2O
Multinomial
Metrics"".


h2o.accuracy()
 and 
h2o.logloss()
 are available for multinomial models.


UPDATE:
 ...well, 
the docs
 say 
h2o.accuracy()
 is available, but a quick check on the iris dataset gives me the same error you see; must be related to that warning in the docs (which I didn't understand).


Anyway, more useful is likely to be 
h2o.confusionMatrix(rf1)
; the overall error shown in the bottom right is 
1 - accuracy
. Also 
h2o.confusionMatrix(rf1,valid=T)
 and 
h2o.confusionMatrix(rf1, test)",2020-03-02T14:20:02,,,,60475543
60439949,60439949,0,"It's been a while, but if I recall, the way to do this is via by setting the -ice_root path.  This is what the h2o-on-hadoop launch path does.  Not much goes there, just some small log files.  No big data.  So even if you have a small /tmp, it's probably fine to just leave it.",2020-02-27T18:53:06,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",60438883
61966139,61966139,1,"Most likely this error occurs because you're trying to build 
datatable
 using an old version of 
pip
. In order to build 
datatable
 from source, 
pip
 version 20.0 or higher is required. 


Unfortunately, 
there is no way
 for a project to specify that it needs a specific minimum version of pip. And I presume if such setting would eventually be added, only the newest versions of pip would know about it anyways, defeating the purpose.",2020-05-23T01:03:43,Pasha,https://stackoverflow.com/users/958624/pasha,"6,540",60387031
60383896,60383896,0,"After looking through the EC2 instance system log I discovered an error was being logged indicating an invalid value being given for a categorical column.


Upon further investigation I discovered the columns in my 
row
 query parameter were NOT being interpreted in the same order as they appeared when I trained my model.


After opening my MOJO model's ZIP file and looking at the 
model.ini
 file within, I was able to determine the order of the columns as the model was expecting.


Supplying columns in the expected order yields valid prediction results.",2020-02-24T21:05:05,brice,https://stackoverflow.com/users/6472849/brice,"1,881",60370607
60310709,60310709,0,"Just try to use the below example, its working fine for me, the error can be due to 
h2o cluster version
, I have included mine and also the results for the 
h2o.hit_ratio_table


import h2o
h2o.init(
  nthreads=-1,            ## -1: use all available threads
  max_mem_size = ""8G"")  

from h2o.estimators import H2ORandomForestEstimator
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# set the factor:
cars[""cylinders""] = cars[""cylinders""].asfactor()

# split the training and validation sets:
r = cars[0].runif()
train = cars[r > .2]
valid = cars[r <= .2]

# set the predictors columns, repsonse column, and distribution type:
predictors = [""displacement"",""power"",""weight"",""acceleration"",""year""]
response_col = ""cylinders""
distribution = ""multinomial""

# build and train the model:
drf = H2ORandomForestEstimator(nfolds = 3, distribution = distribution)
drf.train(x=predictors, y=response_col, training_frame=train, validation_frame=valid)

# build the hit ratio table:
drf_hit = drf.hit_ratio_table(valid=True)
drf_hit.show()



Output:


H2O cluster uptime: 02 secs
H2O cluster timezone:   Etc/UTC
H2O data parsing timezone:  UTC
H2O cluster version:    3.26.0.10
H2O cluster version age:    3 months and 12 days !!!
H2O cluster name:   H2O_from_python_unknownUser_wggipn
H2O cluster total nodes:    1
H2O cluster free memory:    7.111 Gb
H2O cluster total cores:    4
H2O cluster allowed cores:  4
H2O cluster status: accepting new members, healthy
H2O connection url: http://127.0.0.1:54321
H2O connection proxy:   {'http': None, 'https': None}
H2O internal security:  False
H2O API Extensions: Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4
Python version: 3.6.6 final




k   hit_ratio
0   1   0.988235
1   2   0.988235
2   3   1.000000
3   4   1.000000
4   5   1.000000",2020-02-19T23:15:43,ashwin agrawal,https://stackoverflow.com/users/7702120/ashwin-agrawal,"1,611",60275392
60274187,60274187,0,"From error it clearly saying ""
Your java is not supported:
 java version ""1.7.0_80""""


Install new version of java from oracle 
site
 ex: java 8


then set that jre path from 
PATH and CLASSPATH
 




Windows 7:

   1. From the desktop, right click the Computer icon.

   2. Choose Properties from the context menu.

   3. Click the Advanced system settings link.

   4. Click Environment Variables. In the section System Variables, find the PATH environment variable and select it. Click Edit. If the PATH environment variable does not exist, click New.

   5. In the Edit System Variable (or New System Variable) window, specify the value of the PATH environment variable. Click OK. Close all remaining windows by clicking OK.",2020-02-18T05:17:55,Sumit Singh,https://stackoverflow.com/users/942391/sumit-singh,15.9k,60274066
60296492,60296492,0,"Connect to the Flow interface, running at 127.0.0.1:54321.


There is a section there where you can view the remaining memory. You can also see what models and data frames are being created. You have 
max_runtime_secs_per_model
 set to 600, and say 10 models takes an hour, so if you check in every 5-10 minutes, you can get an idea of how much memory each model is taking up.


Your h2o.init() response looks fine. The guideline was to have 3-4 times the dataset size free. If your data is only 2.7MB, then this should not be a concern. Though if you have a lot of categorical columns, especially with a lot of choices, then they can take up more memory than you expect.


The memory used by a model can vary quite a lot, depending on the parameters chosen. Again, it is best to look on Flow, to see what parameters AutoML is choosing for you.


If it is simply the case that 10 models will fit in memory, and 20 models won't, and you don't want to take manual control of the parameters, then you could do batches of 10 models, and save after each hour. (Choose a different 
seed
 for each run.)",2020-02-19T09:05:22,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,60269995
60237223,60237223,1,"I think you need something like Partial Dependency Plots.
Here is an example in H2O: 
https://rdrr.io/cran/h2o/man/h2o.partialPlot.html


PDP will show how the probability of target depends on the value of a certain variable.",2020-02-15T08:51:47,Andrey Lukyanenko,https://stackoverflow.com/users/6797250/andrey-lukyanenko,"3,841",60235198
60273239,60273239,0,"The problem described corresponds to a multi-variate time series problem that uses only lags 0 and 1. Of course, it can't and won't use use lag 0 on target, but it can will use lag 0 on other time series and features. 


To setup the problem in Driverless AI properly with walmart dataset set:




target column
: 
Weekly_Sales


time column
: 
Date


time group columns
 (TGC): 
Store
, 
Dept


Forecast horizon
: 1 week


Gap
: 0 week


Expert Settings -> Time Series
:




Time Series Lag Override
: 1


(optional but recommended) 
Probability to create non-target lag features
: 0.5 or higher


(optional but worth trying) 
Always Group by All Time Groups Columns for Creating Lag Features
: Disabled






With lag override set to 1 no lags greater than 1 can be used to predict target, plus current (lag 0) features (everything but target). So, effectively, it still a forecast problem but it complies with all restrictions you placed in your question.",2020-02-18T03:12:33,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,60176991
60168307,60168307,1,"People don't really automate Flows since there are scripting APIs for R and python.
But, there are some ancient tricks you can try to revive if you really want to.  You won't find any support for them, though.


Take a look at this ancient commit from 2015 which has the run-flow.coffee and run-flow.js scripts:


https://github.com/h2oai/h2o-3/tree/cd026d6dd71085c6f1fa91d5a27216b9ab86b39a/scripts


Note it requires a client-side phantomjs to work, which might defeat the point for you.


Sometime in the past these files were actually deleted from the top-of-tree repo, but you can still fish them out from history and try to revive the concept if you think it's useful for you.",2020-02-11T11:58:39,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",60164981
60254336,60254336,0,"Please run 
from pysparkling import *
 at the beggining of the code. This call ensures that we add Sparkling Water dependencies to the Spark app.",2020-02-16T23:49:26,,,,60112299
60116687,60116687,1,"Actually it worked by using a Gradle dependency instead of loading jar file.


implementation 'ai.h2o:h2o-genmodel:3.28.0.3'



Thank you @hfarhanahmed and @TomKraljevic for your help.",2020-02-07T15:41:52,DraXus,https://stackoverflow.com/users/2022620/draxus,81,60111812
60239233,60239233,0,"Why not use a workaround and utilize H2O UI to create the grid? There's a checkbox to make your chosen parameter griddable, and you can supply the parameter values as a comma-separated list via the web form where you would normally put a single value.",2020-02-15T13:34:58,mirekphd,https://stackoverflow.com/users/9962007/mirekphd,"6,488",60094702
60282267,60282267,0,"There's a workaround 
here
 I did not notice (probably I should have posted it as a bug in github in the first place).


gbm_grid = H2OGridSearch(algo=H2OGBM().setMaxDepth(30),
                         hyperParameters={'_learn_rate':[0.01, 0.1], '_ntrees': [100, 200]},
                         withDetailedPredictionCol=True,
                         labelCol='class',
                         stoppingMetric=""AUC"")
model_pipeline = Pipeline().setStages([gbm_grid])
model = model_pipeline.fit(iris_df)
model.stages[0].transform(iris_df).head()",2020-02-18T13:42:59,lrnzcig,https://stackoverflow.com/users/3519000/lrnzcig,"3,947",60094702
60054083,60054083,2,"I think there are several problems here, the most important one is mixing tidy and standard evaluation. In 
cor_function(Sepal.Length, Sepal.Width)
, the arguments are passed as expressions, whereas the elements in 
params_to_run
 are strings (or factors, actually).


Since I don't see that tidy evaluation is really necessary here, and 
map
ping over strings feels more natural, I propose a solution without tidy evaluation.


library(""h2o"")

library(""purrr"")
library(""dplyr"")

h2o.init()

data_h2o <- as.h2o(iris)

params_to_run <- expand.grid(var1 = ""Sepal.Length"", var2 = c(""Sepal.Width"", ""Petal.Width""))
params_to_run
#>           var1        var2
#> 1 Sepal.Length Sepal.Width
#> 2 Sepal.Length Petal.Width

cor_fun <- function(data, x, y, FUN, ...) {
    # as.character() because expand.grid() produces factors
    r <- FUN(x = data[, as.character(x)], y = data[, as.character(y)], ...)
    return(r)
}

cor_fun(iris,     ""Sepal.Length"", ""Sepal.Width"", cor)
#> [1] -0.1175698
cor_fun(data_h2o, ""Sepal.Length"", ""Sepal.Width"", h2o.cor)
#> [1] -0.1175698
mutate(params_to_run, res = map2(var1, var2, ~cor_fun(data_h2o, .x, .y, h2o.cor)))
#>           var1        var2        res
#> 1 Sepal.Length Sepal.Width -0.1175698
#> 2 Sepal.Length Petal.Width  0.8179411



👆 Note also that 
params_to_run
 is a data frame and you want to loop across rows. 
map()
 would loop across columns (like 
lapply()
), so I use 
mutate()
 to apply 
map()
 to every row. Note further that 
cor_fun()
 needs two arguments, so 
map2()
 is used.


In the end, one may even do it without the custom function 
cor_fun()
:


mutate(params_to_run, 
       res = map2(var1, var2, ~h2o.cor(x = data_h2o[, as.character(.x)],
                                       y = data_h2o[, as.character(.y)])))
#>           var1        var2        res
#> 1 Sepal.Length Sepal.Width -0.1175698
#> 2 Sepal.Length Petal.Width  0.8179411



Below, you find a soluation with tidy eval. However, this won't work with 
params_to_run
, which contains strings (or factors, actually).


cor_fun2 <- function(data, x, y, FUN, ...) {
    x <- rlang::enquo(x)
    y <- rlang::enquo(y)
    r <- FUN(x = data[, quo_name(x)], y = data[, quo_name(y)], ...)
    return(r)
}
cor_fun2(data_h2o, Sepal.Length, Sepal.Width, h2o::h2o.cor)
#> [1] -0.1175698



Created on 2020-02-04 by the 
reprex package
 (v0.3.0)",2020-02-04T09:16:38,,,,60046449
60028598,60028598,1,"Most likely the cause of the hang is running out of memory.  You either need to use less memory, or run your job on a system with more memory.


There are a number of factors at work here, and it's not necessarily obvious how to debug them unless you are aware of the underlying resource usage.


Below are three sections with suggestions about how to monitor memory usage, how to reduce memory usage, and how get a system with more memory.




Here are some memory monitoring suggestions:




Monitor your physical memory usage.  Do this with using a program like 
top
 on the Mac or on Linux.  An important number to look at is RSS (resident set size), which represents the actual amount of physical memory being used on the host.


Monitor any swapping.  Make sure your system is not swapping to disk.  Swapping occurs when you are trying to use more virtual memory (at one time) than you have physical memory on your host.  On linux, the 
vmstat
 command is good for showing swapping.


Turn on java GC logging with -XX:+PrintGCDetails -XX:+PrintGCTimeStamps you will get more log output which will show you if java itself is just bogging down from running out of memory. This is very likely.  Here is an example of how to do that by passing the 
jvm_custom_args
 flag when starting H2O-3 from inside of R:




h2o.init(jvm_custom_args = c(""-XX:+PrintGCDetails"", ""-XX:+PrintGCTimeStamps""))



You will see a message showing:


H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /var/folders/vv/pkzvhy8x5hsfbsjg75_6q4ch0000gn/T//RtmpUsdTRQ/h2o_tomk_started_from_r.out
    /var/folders/vv/pkzvhy8x5hsfbsjg75_6q4ch0000gn/T//RtmpUsdTRQ/h2o_tomk_started_from_r.err



The .out file above will now contain GC log output, as you can see below:


...
02-02 08:30:29.785 127.0.0.1:54321       21814  main      INFO: Open H2O Flow in your web browser: http://127.0.0.1:54321
02-02 08:30:29.785 127.0.0.1:54321       21814  main      INFO:
02-02 08:30:29.886 127.0.0.1:54321       21814  #84503-22 INFO: GET /, parms: {}
02-02 08:30:29.946 127.0.0.1:54321       21814  #84503-20 INFO: GET /, parms: {}
02-02 08:30:29.959 127.0.0.1:54321       21814  #84503-21 INFO: GET /, parms: {}
02-02 08:30:29.980 127.0.0.1:54321       21814  #84503-22 INFO: GET /3/Capabilities/API, parms: {}
02-02 08:30:29.981 127.0.0.1:54321       21814  #84503-22 INFO: Locking cloud to new members, because water.api.schemas3.CapabilitiesV3
02-02 08:30:30.005 127.0.0.1:54321       21814  #84503-25 INFO: GET /3/InitID, parms: {}
14.334: [GC (Allocation Failure) [PSYoungGen: 94891K->3020K(153088K)] 109101K->56300K(299008K), 0.0193290 secs] [Times: user=0.22 sys=0.01, real=0.02 secs]
14.371: [GC (Allocation Failure) [PSYoungGen: 120914K->3084K(153088K)] 174194K->173560K(338432K), 0.0256458 secs] [Times: user=0.29 sys=0.04, real=0.03 secs]
14.396: [Full GC (Ergonomics) [PSYoungGen: 3084K->0K(153088K)] [ParOldGen: 170475K->163650K(435200K)] 173560K->163650K(588288K), [Metaspace: 22282K->22282K(1069056K)], 0.0484233 secs] [Times: user=0.47 sys=0.00, real=0.05 secs]
14.452: [GC (Allocation Failure) [PSYoungGen: 118503K->160K(281088K)] 282153K->280997K(716288K), 0.0273738 secs] [Times: user=0.30 sys=0.05, real=0.02 secs]
14.479: [Full GC (Ergonomics) [PSYoungGen: 160K->0K(281088K)] [ParOldGen: 280837K->280838K(609792K)] 280997K->280838K(890880K), [Metaspace: 22282K->22282K(1069056K)], 0.0160751 secs] [Times: user=0.09 sys=0.00, real=0.02 secs]
14.516: [GC (Allocation Failure) [PSYoungGen: 235456K->160K(281088K)] 516294K->515373K(890880K), 0.0320757 secs] [Times: user=0.30 sys=0.10, real=0.03 secs]
14.548: [Full GC (Ergonomics) [PSYoungGen: 160K->0K(281088K)] [ParOldGen: 515213K->515213K(969216K)] 515373K->515213K(1250304K), [Metaspace: 22282K->22282K(1069056K)], 0.0171208 secs] [Times: user=0.09 sys=0.00, real=0.02 secs]



The ""Allocation Failure"" messages look scary, but are actually totally normal.  The time to worry is when you see back-to-back Full GC cycles that take a large number of ""real secs"".




Here are some suggestions for using less memory:




Split the data once and save it to disk, and then read it back in a new fresh H2O-3 cluster in two separate as.h2o or h2o.importFile steps.


In your example, you are doing a splitFrame.  This makes a duplicate copy of your data in memory.


Prefer h2o.importFile to as.h2o.


I don't know how much of a difference this really makes in your case, but h2o.importFile was designed and tested for big data, and as.h2o was not.


Use less data.


You have not said anything about the shape of your data, but if the automl or grid search works with GBM but not DRF, that is definitely pointing to running out of memory.  Those two algorithms do almost exactly the same thing computation-wise, but DRF models tend to be larger since DRF has a higher tree depth, which means it needs more memory to store the models.


Use the nthreads option to reduce the number of concurrent worker threads.


The more active concurrent threads you have running, the more memory you need, because each thread needs some working memory.  You can try setting nthreads to half of the number of CPU cores you have, for example.


Don't use xgboost.


Xgboost is special in the way that it uses memory because it makes a second copy of the data outside of the java heap.  This means when you are using xgboost, you don't want to give the java max_mem_size (or Xmx) your entire host's memory or you can run into problems (especially swapping).


Don't use DRF.


DRF trees are deeper, and hence the produced models are larger.  Alternately, build (and retain in memory) fewer DRF models, more shallow DRF models, or models with fewer trees.






The best quick suggestion for getting more memory is to run in the cloud.  You don't necessarily need a multi-node setup.  A single large node is easier to work with if that will adequately solve the problem.  In your case it likely will.  Given what you have said above (which is that you have 16 GB now and it finishes if you don't use DRF), I would start by using, an 
m5.4xlarge
 instance in EC2 which has 64 GB of RAM and costs under $1 / hr and give it a max_mem_size of 48G.",2020-02-02T17:15:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",60024798
59996908,59996908,1,"Based on the error, there is no object 
grid_perf
 to call. It should be defined before that line runs. 


From the document you are following, in section 19.2.2, it defines 
ae_grid
:


ae_grid <- h2o.grid(
  algorithm = 'deeplearning',
  x = seq_along(features),
  training_frame = features,
  grid_id = 'autoencoder_grid',
  autoencoder = TRUE,
  activation = 'Tanh',
  hyper_params = hyper_grid,
  sparse = TRUE,
  ignore_const_cols = FALSE,
  seed = 123
)



Did you try defining 
grid_perf
?


Then it calls it in section 19.2.3 
best_model_id <- ae_grid@model_ids[[1]]
 which is what it looks like you are trying to replicate.",2020-01-31T01:44:24,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,59991017
59893670,59893670,0,"You can track progress of introducing Scala 2.12 support in Sparkling Water with the JIRA ticket 
SW-1846
.",2020-01-24T09:31:35,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,59887618
59835713,59835713,2,"If you are definitively working on h2o, then the suitable option to not leave the R interface with h2o would be to use the options 
keep_cross_validation_models = TRUE, keep_cross_validation_predictions = TRUE,
. from  this you could build the misclassification error, of each category, on each model fitted with a specific sequence of values for lambda.  Alternatively, you could loop or lapply through a sequence of lambdas. for example 
for (i in lambda_vector){ models[[i]]= h2o.glm(...,lambda= i )}
. Each one of the objects has a confusion matrix hence you could pontentially compute the classification error for each category. And you could make your own selection criterion.   The custom metric does work only in python.


if you can use just R: 


to fit a multinomial model with an elastic penalty I would recommend , if there is not a particular reason to be tied to h2o,  to use the package 
glmnet
 that provides the command  cv.glmnet() with the options family=""multinomial"" and type.measure=""class"". This would yield a multinomial model chosen by cross validation on the clasification error.",2020-01-21T07:01:42,Diegolog,https://stackoverflow.com/users/9170214/diegolog,338,59833263
59936315,59936315,1,"I wrote 
h2o.glm_custom
 as a ""replacement"" for 
h2o.glm
 that keeps the cross validation models, so that a custom selection criterion can be used afterwords, as suggested by @Diegolog. My approach uses 
h2o.grid
. I attempted to include all of the parameters for 
h2o.glm
 but simplified some defaults to avoid extra work. 


h2o.glm_custom <- function(x,
                           y,
                           training_frame,
                           model_id = NULL,
                           validation_frame = NULL,
                           nfolds = 0,
                           seed = -1,
                           keep_cross_validation_models = TRUE,
                           keep_cross_validation_predictions = FALSE,
                           keep_cross_validation_fold_assignment = FALSE,
                           fold_assignment = ""AUTO"",
                           fold_column = NULL,
                           random_columns = NULL,
                           ignore_const_cols = TRUE,
                           score_each_iteration = FALSE,
                           offset_column = NULL,
                           weights_column = NULL,
                           family = ""binomial"",
                           rand_family = c(""[gaussian]""),
                           tweedie_variance_power = 0,
                           tweedie_link_power = 1,
                           theta = 1e-10,
                           solver = ""AUTO"",
                           alpha = 0,
                           early_stopping = TRUE,
                           nlambdas = 100,
                           standardize = TRUE,
                           missing_values_handling = ""MeanImputation"",
                           plug_values = NULL,
                           compute_p_values = FALSE,
                           remove_collinear_columns = FALSE,
                           intercept = TRUE,
                           non_negative = FALSE,
                           max_iterations = -1,
                           objective_epsilon = -1,
                           beta_epsilon = 1e-04,
                           gradient_epsilon = -1,
                           link = ""family_default"",
                           rand_link = ""[identity]"",
                           startval = NULL,
                           calc_like = FALSE,
                           HGLM = FALSE,
                           prior = -1,
                           lambda_min_ratio = 0.01,
                           beta_constraints = NULL,
                           max_active_predictors = -1,
                           obj_reg = -1,
                           export_checkpoints_dir = NULL,
                           balance_classes = FALSE,
                           class_sampling_factors = NULL,
                           max_after_balance_size = 5,
                           max_hit_ratio_k = 0,
                           max_runtime_secs = 0,
                           custom_metric_func = NULL) {

  # Find lambda_max
  model <- h2o.glm(x,
                   y,
                   training_frame,
                   model_id,
                   validation_frame,
                   nfolds,
                   seed,
                   keep_cross_validation_models,
                   keep_cross_validation_predictions,
                   keep_cross_validation_fold_assignment,
                   fold_assignment,
                   fold_column,
                   random_columns,
                   ignore_const_cols,
                   score_each_iteration,
                   offset_column,
                   weights_column,
                   family,
                   rand_family,
                   tweedie_variance_power,
                   tweedie_link_power,
                   theta,
                   solver,
                   alpha,
                   NULL, # lambda
                   TRUE, # lambda_search
                   early_stopping,
                   1, # nlambdas
                   standardize,
                   missing_values_handling,
                   plug_values,
                   compute_p_values,
                   remove_collinear_columns,
                   intercept,
                   non_negative,
                   max_iterations,
                   objective_epsilon,
                   beta_epsilon,
                   gradient_epsilon,
                   link,
                   rand_link,
                   startval,
                   calc_like,
                   HGLM,
                   prior,
                   lambda_min_ratio,
                   beta_constraints,
                   max_active_predictors,
                   obj_reg = obj_reg,
                   export_checkpoints_dir = export_checkpoints_dir,
                   balance_classes = balance_classes,
                   class_sampling_factor = class_sampling_factors,
                   max_after_balance_size = max_after_balance_size,
                   max_hit_ratio_k = max_hit_ratio_k,
                   max_runtime_secs = max_runtime_secs,
                   custom_metric_func = custom_metric_func)

  lambda_max <- model@model$lambda_best

  # Perform grid search on lambda, with logarithmic scale
  lambda_min <- lambda_max * lambda_min_ratio
  grid <- exp(seq(log(lambda_max), log(lambda_min), length.out = nlambdas))
  grid_list <- lapply(sapply(grid, list), list)
  hyper_parameters <- list(lambda = grid_list)

  result <- h2o.grid('glm',
                     x = x,
                     y = y,
                     training_frame = training_frame,
                     nfolds = nfolds,
                     family = family,
                     alpha = alpha,
                     ignore_const_cols = ignore_const_cols,
                     hyper_params = hyper_parameters,
                     seed = seed)
}



Then the following function could be used to select lambda based on misclassification error:


get_cv_means <- function(grid_results) {
  mean_errors <- lapply(grid_results@model_ids, function(id) {
    model <- h2o.getModel(id)
    lambda <- model@parameters$lambda
    err <- as.numeric(model@model$cross_validation_metrics_summary['err', 'mean'])
    data.frame(lambda = lambda, error = err)
  })
  dt <- data.table::rbindlist(mean_errors)
  data.table::setkey(dt, lambda)
  dt
}



Here is a complete example using these function to select lambda using cross validation based on misclassification error:


h2o.init()
path <- system.file(""extdata"", ""prostate.csv"", package= ""h2o"")
h2o_df <- h2o.importFile(path)
h2o_df$CAPSULE <- as.factor(h2o_df$CAPSULE)
lambda_min_ratio <- 0.000001
nlambdas <- 100
nfolds <- 20

result <- h2o.glm_custom(x = c(""AGE"", ""RACE"", ""PSA"", ""GLEASON""),
                         y = ""CAPSULE"",
                         training_frame = h2o_df,
                         family = ""binomial"",
                         alpha = 1,
                         nfolds = nfolds,
                         lambda_min_ratio = lambda_min_ratio,
                         nlambdas = nlambdas,
                         early_stopping = TRUE)

tbl <- get_cv_means(result)  



Gives:


> head(tbl)
lambda     error
1: 2.222376e-07 0.2264758
2: 2.555193e-07 0.2394541
3: 2.937851e-07 0.2380508
4: 3.377814e-07 0.2595451
5: 3.883666e-07 0.2478443
6: 4.465272e-07 0.2595603    



Which can be plotted, etc...


  ggplot() + geom_line(data = tbl[lambda < 0.00001], aes(x = lambda, y = error))",2020-01-27T17:45:01,James Hirschorn,https://stackoverflow.com/users/1349673/james-hirschorn,"7,886",59833263
59813317,59813317,4,"According to H2O documentation there is no 
as_dataframe
 method: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/_modules/h2o/model/confusion_matrix.html


I assume the easiest way is to call 
to_list()
.",2020-01-19T18:53:44,Razmik Melikbekyan,https://stackoverflow.com/users/8199034/razmik-melikbekyan,748,59812521
70572006,70572006,1,"The 
.table
 attribute gives the object with 
as_data_frame
 method.


model.confusion_matrix(valid=valid_set).table.as_data_frame()



If you need to access the table header, you can do


model.confusion_matrix(valid=valid_set).table._table_header



Hint: You can use 
dir()
 to check the valid attributes of a python object.",2022-01-03T22:10:37,Py2Pi,https://stackoverflow.com/users/8082999/py2pi,11,59812521
59690717,59690717,0,"Found the problem, can't find the docs / other-post-detailing-this right now, but basically, when running the 
hadoop jar h2odriver.jar ...
 command, there is an optional 
param called 
-output
 where you would normally put some 
hdfs location
 that h2o will write stuff (from what I can recall, this is some legacy directory that is not super important) to
. 


I had forgotten that this is an HDFS location and put some 
local
 temp folder's absolute path. The error was because h2o was trying to create that folder by creating the entire path in hdfs that lead to it, thus requiring being able to write from the hdfs root dir. The correct value would be something like 
/user/<username>
.",2020-01-11T00:44:13,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",59690508
59640385,59640385,0,"I've never works with H2O, but asumming it has no integration with mongo:


To me it looks like you should write the script that will:




Connect to mongo


Run the query and get the cursor


Iterate through the results, convert the object into the form that H2O understands and


Put into H2O (better in batches if H2O supports batch inserts)",2020-01-08T06:21:15,Mark Bramnik,https://stackoverflow.com/users/605153/mark-bramnik,42.2k,59640204
59797450,59797450,0,"One possible solution is load the data in spark cluster using spark-mongodb connector and the comverting DataFrame to H2OFrame.
For detail please check 
http://docs.h2o.ai/sparkling-water/2.2/latest-stable/doc/tutorials/spark_h2o_conversions.html#converting-a-dataframe-into-an-h2oframe


After that use Sparkling Water to analyze the data.",2020-01-18T04:05:53,arkaprova,https://stackoverflow.com/users/12672700/arkaprova,1,59640204
59552450,59552450,2,"Setting up individual h2o cluster per R session is ideal.


While initiating a h2o cluster with 
h2o::h2o.init()
, Make sure you specify these differently for each R session (each script running its own R session): 




ip
/
port
 (port under localhost which is already not taken)


name
 (to check its progress/usage on terminal via top/htop)




Change other options as required. Each R session knows the h2o cluster it is running and 
h2o::h2o.shutdown()
 will only shutdown the specific h2o cluster.",2020-01-01T12:19:40,talegari,https://stackoverflow.com/users/5638196/talegari,343,59552280
59563158,59563158,1,"Set up a single cluster, and have all scripts use it is the recommended approach, because it is more efficient. There is memory overhead for each cluster, so your 20 separate clusters would be wasteful (even more so if there are any static data tables all your scripts need to use). You'd also have to guess the correct amount to give to each one.


On the other hand, if your 20 scripts are each going to be referring to a specific table, e.g. loading it with their own data, and generally assuming they are the only script running, you will have a problem: you either need to modify the scripts to be well-behaved or run each on its own ip/port.




I am not sure how to automate initialization and shutting down of the H2O cluster for so many batches. The first batch has to create the cluster (H2O.init() and the last batch has to shut it down)




Start H2O from the commandline
 before running the first script, and manually kill it after all scripts have completed. By doing it this way, each script will discover it is already running when they do their 
h2o.init()
 call.


If you have to be fully automatic, make sure the launch command will run first, but you'll need some kind of watcher script to notice when all the other processes have completed.  (I tend to run a combination of 
ps
 and 
grep
 on cron jobs; there are more sophisticated ways, of course.)",2020-01-02T12:11:53,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,59552280
59555108,59555108,0,"Variants of this question have been asked and answered several times.


The best way to really know what is going on is to debug the code in a java debugger and single-step it.  I recommend IntelliJ IDEA.


I recommend copying one of the snippets in the following document:


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html


and then single-stepping through the predict method call in the Easy Wrapper and then the score0 low-level method call.


The code is all open source so you can cross-reference what you see in the debugger with github source code and comments.",2020-01-01T18:36:21,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",59536276
59516672,59516672,0,"H2O gets its path to 
java
 runtime from 
JAVA_HOME
 environment variable
, so make sure to 
set it properly for/from R
 if you have to use 
h2o.init()
 rather than system shell/bash (e.g. with 
java -Xmx1g -jar ./h2o.jar
).


More info


After several years of experience with H2O in Ubuntu/Centos/RHEL I now start H2O only from bash (issuing richly parameterized commands at H2O docker container startup), rather than with R or python API functions (it led to all sorts of problems, such as using all server CPU cores that yielded huge performance degradation for the inexperienced users or exposing passwordless REST API with root file access over standard H2O port to the entire corporate network...).


As a side note, Java 13 is supported by latest H2O versions, but I would still recommend using LTS versions, currently 11, for security reasons. The same of course applies to Ubuntu itself.",2019-12-29T03:36:30,Community,https://stackoverflow.com/users/-1/community,1,59514439
59573572,59573572,2,"Here is a snippet from the documentation:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/binomial_double_trees.html


When building classification models, this option specifies to build twice as many internal trees as the number of trees (one per class). Enabling this option can lead to higher accuracy but lower speed times, while disabling this can result in faster model building. This option is disabled by default.




When building a classification tree model, what happens under the hood is when the user asks for 10 trees, for example, the algorithm builds 10 trees 
for each class
 of the response column.  This is why tree algorithms are computationally expensive for heavily multinomial problems.  The number of trees that actually get calculated is numTrees * numClasses.


The binomial classification case is special where the 0 and 1 classes can be treated as mirror images of each other.  So only the 0 case is calculated and then the 1 case is just ""1 - p"".


The 
binomial_double_trees
 flag tells the algorithm to not use the mirror image shortcut, and to instead actually fully calculate out a second set of trees for the 1 class.  In practice, this will increase the training time, scoring time, and model size.


(Also note that the 
binomial_double_trees
 flag is unrelated to grid search, or finding the optimal number of trees.)",2020-01-03T05:23:47,,,,59510832
59508429,59508429,0,"if you carefully read 
h2o docs
 for 
h2o.stackedEnsemble
 then you realize that h2o metalearner won't need offset parameter anymore as it will use cross-validated predicted values from base models to train:


my_gbm <- h2o.gbm(x = x, y = y, training_frame = train, 
              fold_column = ""fold_id"",
              keep_cross_validation_predictions = TRUE,
              offset_column = ""offset"",
              seed = 1) 

my_glm <- h2o.glm(x = x, y = y, training_frame = train, 
              fold_column = ""fold_id"",
              keep_cross_validation_predictions = TRUE,
              offset_column = ""offset"",
              seed = 1,family = ""binomial"")

stack_model <- h2o.stackedEnsemble(x = x,
                               y = y,
                               training_frame = train,
                               base_models = list(my_gbm, my_glm))

h2o.performance(my_gbm, newdata = test)
h2o.performance(my_glm, newdata = test)
h2o.performance(stack_model, newdata = test)",2019-12-28T05:37:16,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,59471469
59436943,59436943,2,"You need to add port 54321+1 (so 54322) to the security group, as well.


The internal communication goes through 54322.


(I would also specify /16 for -network because it’s easier for other people to understand.  For example, even if you are sure /20 is technically correct for your network setup, I can’t easily be sure.  :-)


Depending on the actual network setup, you probably don’t need -network flag at all.  Your instances probably only have one interface.",2019-12-21T14:20:35,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",59434658
59398056,59398056,1,"There is an 
h2o.H2OFrame()
 function that takes several types of input (list, tuple, dictionary, Pandas DataFrame, Scipy sparse matrix).  More info on the 
H2OFrame
 constructor 
here
, and general info about data manipulation in H2O 
here
.


Example:


import h2o
hf = h2o.H2OFrame([[2,3],[4,5]])",2019-12-18T18:23:03,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",59397951
59366468,59366468,25,"There is an H2OFrame method called 
as_data_frame()
 but 
h2o.as_list()
 also works.


data_as_df = data.as_data_frame()",2019-12-17T01:39:16,,,,59366199
59366205,59366205,10,"Convert h2o frame to List


data_as_list = h2o.as_list(data, use_pandas=False)



Convert h2o frame to pandas DataFrame. (Default 
use_pandas=True
)


data_as_df = h2o.as_list(data)",2019-12-17T00:53:20,nautograph,https://stackoverflow.com/users/12413647/nautograph,264,59366199
59384246,59384246,1,"With just 88 instances of data, there is risk of overfitting. To ensure you are not overfitting, you should take a sample of your data as 
holdout/test
 (the model/training won't see) then use the rest for training and cross-validation. You can then use the holdout data to see if it performs similarly to what you found from validation and see if LOO is much better.




For your question: Why are the two confusion matrices different? Should not they find the same F1-optimal threshold?




Both confusion matrices use the max F1 threshold. The difference may be what 
dataset
 is used for calculating F1. You can see the threshold on the first row of the table ""Maximum Metrics: Maximum metrics at their respective thresholds."" 


aml@leader@model[[""cross_validation_metrics""]]
 looks to be using validation data, and 
h2o.confusionMatrix(aml@leader)
 is using training data. You can try 
aml@leader@model[[""training_metrics""]]
 to see if it matches 
h2o.confusionMatrix(aml@leader)
.",2019-12-18T01:15:44,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",59359438
59384660,59384660,1,"There is a lot going on here (I agree with Neema's comment about overfitting).  As he also mentioned, the main issue that you are seeing is that you are comparing cross-validation metrics with training metrics.  The 
h2o.confusionMatrix()
 function (and all metrics utility functions) return training error by default.


However, I think there is a bug with the 
h2o.confusionMatrix()
 function, as it is not allowing the 
xval = TRUE
 argument (which would typically return the CV metrics in any H2O metrics function).  I filed a bug report 
here
.",2019-12-18T02:29:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",59359438
59366423,59366423,2,"H2O is using max F1 threshold for both h2o.performance() and h2o.predict(). The difference is 
what dataset
 it will use to estimate the max F1 threshold.




h2o.predict()
 will use the threshold it selected during training. It uses different max F1 thresholds depending on how the model was trained. Basically: 




If you only have training data - the max F1 threshold comes from the train data model.


If there is validation data during training - the max F1 threshold comes from the validation data model.




This is explained in the 
documentation
 and also on 
stackoverflow
. Depending on if you had validation data during training, you will see the max F1 threshold to be determined by your 
training or validation
 dataset.


h2o.performance()
 will take the model and newdata and calculate what threshold will give the highest F1 for the 
new data
. In your case, 
test
 is being used to calculate max F1 threshold.",2019-12-17T01:29:09,Neema Mashayekhi,https://stackoverflow.com/users/12441750/neema-mashayekhi,930,59286816
61399362,61399362,0,"h2o.mojo_predict_d
f converts the data frame into a csv and then essentially runs 
h2o.mojo_predict_csv
. Hence in this process of writing and parsing the variables - certain variables may have formats which are incorrectly written in the csv and hence leads to difference in results. one example is scientific notation in R , if your numbers are displayed as 
e+10
. When these are written into the csv , the formats get mixed up. Use 
options(scipen=999)
 to correct for this and then run the mojo functions. The results should be the same.",2020-04-24T00:59:00,Learner_seeker,https://stackoverflow.com/users/7609862/learner-seeker,544,59281114
59291958,59291958,0,"I checked the source code and it doesn't look like it would be due to too few observations.


Can you please run just a single GBM model with balance classes enabled and provide the H2O log? 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/logs.html#logging-in-python


I am not quite sure if the current log will give us enough info to figure it out but I will make a change that will add more info in the next release.",2019-12-11T18:28:41,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,59273268
59446041,59446041,0,"For the non cross-validation case, try splitting your data up front into training and validation frames.


I expect you will get a worse AUC for the validation case.


Although for highly imbalanced cases, sometimes you just need to go by the error rate for each class.


Since there are so many true negatives, that can dominate the AUC (vast majority of predictions are correctly predicting “not interesting”).  Some people will upsample the minority class in this situation using row weights to make the model more sensitive to them.",2019-12-22T16:30:03,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",59219818
75620491,75620491,1,"h2o
 added support for exporting parquet files as of 
version 3.38.0.1
.


You need to set the 
format
 argument to be 
""parquet""
. Note that 
h2o.exportFile
 will ignore the 
parts
 argument if you specify 
""parquet""
. Instead, it chooses the number of parts based on the number of chunks of your data.


https://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.exportFile.html


h2o.exportFile(
  data = <your h2oFrame>,
  path = ""/path/to/exported/parquet/dir"",
  format = ""parquet""
)",2023-03-02T20:27:24,Hutch3232,https://stackoverflow.com/users/9244371/hutch3232,428,59186548
59160445,59160445,0,"No, there is no flag to totally disable Flow.


You can either firewall the port or protect it with authentication using one of the various supported approaches.  Hardcoded file username/password  authentication is the easiest (this is called hash authentication in the docs).",2019-12-03T15:31:10,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",59155659
59878408,59878408,0,"This is happening whenever using apply. Use the example from H2O documentation:


I was able to solve the problem by downgrading to Python 3.6.x


http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html#h2oframe


python_lists = [[1,2,3,4], [1,2,3,4]]
h2oframe = h2o.H2OFrame(python_obj=python_lists,
                        na_strings=['NA'])
colMean = h2oframe.apply(lambda x: x.mean(), axis=0)



---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-43-8da6b76c71bd> in <module>
      2 h2oframe = h2o.H2OFrame(python_obj=python_lists,
      3                         na_strings=['NA'])
----> 4 colMean = h2oframe.apply(lambda x: x.mean(), axis=0)

~/anaconda3/envs/h2o1/lib/python3.7/site-packages/h2o/frame.py in apply(self, fun, axis)
   4910         assert_is_type(fun, FunctionType)
   4911         assert_satisfies(fun, fun.__name__ == ""<lambda>"")
-> 4912         res = lambda_to_expr(fun)
   4913         return H2OFrame._expr(expr=ExprNode(""apply"", self, 1 + (axis == 0), *res))
   4914 

~/anaconda3/envs/h2o1/lib/python3.7/site-packages/h2o/astfun.py in lambda_to_expr(fun)
    133     code = fun.__code__
    134     lambda_dis = _disassemble_lambda(code)
--> 135     return _lambda_bytecode_to_ast(code, lambda_dis)
    136 
    137 def _lambda_bytecode_to_ast(co, ops):

~/anaconda3/envs/h2o1/lib/python3.7/site-packages/h2o/astfun.py in _lambda_bytecode_to_ast(co, ops)
    147         body, s = _opcode_read_arg(s, ops, keys)
    148     else:
--> 149         raise ValueError(""unimpl bytecode instr: "" + instr)
    150     if s > 0:
    151         print(""Dumping disassembled code: "")

ValueError: unimpl bytecode instr: CALL_METHOD",2020-01-23T12:18:17,,,,59146506
59146192,59146192,2,"The cluster information printed shows that it's connecting to an H2O cluster (version 3.24.0.5) that was started 30 minutes ago (running at the default location, localhost:54321).  You will need to shut that one down first (kill the java process from the command line or simply, 
h2o.shutdown()
.  


You don't need to remove or uninstall anything, you just need to kill the active (old) cluster.  After that, start from R using 
h2o.init()
 and it will use the updated version.",2019-12-02T20:27:19,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",59146086
59261670,59261670,1,"h2o provides slicing rows on dataframe for both R and Python so you can use 
isin
 method to filter rows based on a column.    


mask = df[""column name""].isin(pickTheseValues)
cols = df[mask,:]



You can reach the details by 
this
 link.",2019-12-10T06:48:43,dogankadriye,https://stackoverflow.com/users/599915/dogankadriye,538,59138734
59078562,59078562,1,"It all depends on the cardinality of the stop column and the stratification column. I would try just a single node with say 32-64GB of memory.


Please share details about the dataset.",2019-11-27T21:17:16,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,59077793
59141697,59141697,1,"I would try to isolate the different phases of the workload, even to the point of doing any data prep in one spark job, and then doing the H2O-3 model training in a new JVM without spark at all.  Then, whichever phase is causing the OOM, make sure you turn on java level GC logging.


-XX:PrintGCDetails
-XX:PrintGCTimeStamps



Take the GC logging output and feed it to 
http://gceasy.io
 and see what the curve looks like.


That will tell you if the memory growth is growing gradually or suddenly bursting up.",2019-12-02T15:09:07,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",59077793
66547890,66547890,0,"Personally, I rather keep the binary features untouched and apply MinMaxScalar between 0 and 1 to the numeric features instead of the normalization. This puts the numeric features on a similar standard deviation scale as those of binaries.",2021-03-09T13:33:12,hadi rahmani,https://stackoverflow.com/users/11723229/hadi-rahmani,1,59002720
59289777,59289777,0,"When I run this in my computer I get different predictions than when I use the same MOJO file to predict in a production environment.




Is the production environment running the exact same R script?",2019-12-11T16:05:06,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,59000235
59308601,59308601,0,"In the end I found out there was an error in the script for the production environment. After it was fixed, the predictions became pretty close.",2019-12-12T16:06:35,jessicalfr,https://stackoverflow.com/users/7111951/jessicalfr,79,59000235
59047739,59047739,1,"You don't need to apply stratified sampling before model training since h2o.ai provides different types of 
fold_assigment
 parameter including ""Stratified"". It applies ""Stratified"" sampling during training so you only need to set 
fold_assingment
 and 
fold_column
 parameters. 
You can find the details in the link below.

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/fold_assignment.html?highlight=stratified#example",2019-11-26T09:32:20,dogankadriye,https://stackoverflow.com/users/599915/dogankadriye,538,58997372
64221009,64221009,1,"Doing experiment with sample data as disney_data.csv, 
some errors come out
 below.




experiment log: <experiment_id>.stack
Exception: URL fetch failure on 
https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
: None -- [Errno -2] Name or service not known




<experiment_id>.stack
AssertionError: No best ensemble, so no models to use.




Expert setting : pipeline building recipe = image_model






Urgently, Want to know when comes out this kinds of error and how I can solve problems.",2020-10-06T07:16:02,yurial,https://stackoverflow.com/users/13178204/yurial,11,58966949
60144243,60144243,0,"Yes, the upcoming version 1.9.0 will support both classification and regression using image data. Meanwhile, a workaround for 1.8.x LTS using BYOR (custom recipes) found 
here
 is possible, please contact H2O.ai customer support if necessary.


The dataset can be prepared similarly to this example: 
https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/images/demo_disney_data.zip
 
First, copy the data to the VM (using 
scp
 or similar command) and then 
ssh
 to VM to unzip the file in the ~/data/ directory. Under the ~/data/disney_data/ find 
disney_data.csv
 file with the paths to the images and labels: 
path
, 
label
. Finally, load dataset from file using 
File System
 option by navigating to 
disney_data.csv
.",2020-02-10T04:48:56,,,,58966949
58917361,58917361,1,"[Revised based on comments and software updates from @MichalKurka below.]


Parquet files include metadata about the column type.  H2O-3 honors the metadata.


In csv files, the column type is guessed.


In H2O-3 versions 3.28.0.1 and higher, columns in a parquet dataset with a boolean type are treated as an enum value (aka categorical).   Prior versions of H2O-3 treated a parquet boolean column as a numeric value.",2019-11-18T14:58:04,,,,58916070
58913630,58913630,2,"When you start an h2o-3 instance on port N, it implicitly uses port N + 1 as well for internal communication.


So to say you started an h2o-3 on port 54321 and another one on port 54322 is actually impossible.


The second instance either failed to start (if you used the -port flag for the java process) or discovered a different port (if you used the -baseport flag for the java process).


Shutting down the instance on port 54321 will also free port 54322.",2019-11-18T11:31:16,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",58912175
58906510,58906510,1,"H2O Documentation says that:


h2o.h2o.download_csv(data, filename)


data : H2OFrame
 An H2OFrame object to be downloaded.


filename : str
 A string indicating the name that the CSV file should be should be saved to.


Additionally, as you have written in your question 
/mnt/azmnt/code/Users/SA/data_pred.csv'
 should be the path.",2019-11-18T00:20:23,mrconcerned,https://stackoverflow.com/users/10489887/mrconcerned,"1,879",58906453
58817766,58817766,0,"Turns out, in the dataset one column was including names that have non-UTF-8 characters like 'Ö', 'Ş' etc. So after deleting this column, it started working again. Which in my opinion should be fixed by the H2O in later releases.",2019-11-12T11:28:02,Ege,https://stackoverflow.com/users/1043686/ege,941,58813442
58913968,58913968,1,"Since the picture is a GBM plot, it’s not as straightforward as you might like, since the inference calculation does some math on the value extracted from the leaf of the tree.


The actual code is here:


https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/gbm/GbmMojoModel.java


Look at the score0 function.


My advice would be to build a 1-tree DRF instead, and then write a short java program and try to single-step it in a java debugger.


The java snippet to start from is how to compile and run a MOJO in this document:


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html


If you do this, you will be able to step through the exact steps that produce the answer (for GBM as well if you prefer), and nothing will be unknown at that point.",2019-11-18T11:51:40,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",58736225
58736635,58736635,1,"This is a special case for Deep Learning models and is not the case for any other models produced by the AutoML process.  For efficiency reasons (and since H2O is designed for very large datasets), the training metrics in Deep Learning models are calculated on a subset of the original training frame.  


There is a parameter in the 
H2O Deep Learning algorithm
 called 
score_training_samples
 that defaults to 10,000 rows (and since we do approximate sampling, also for efficiency reasons, it makes sense that the actual subset size is 9,993).


This should be a good approximation for training error.  The only way to change this in Flow would be to train a Deep Learning model manually (outside the AutoML process).",2019-11-06T18:42:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",58712625
58725997,58725997,0,"If your REQ_TIME field was 
always
 6 digits, i.e. was always zero-padded left and right, this becomes much easier. E.g. you could use 
gsub
 to just take the first two characters.


Or if it was always zero-padded on the right (i.e. ""00"" seconds appended when missing) and it was imported as a numeric field, you could divide by 10000, and use 
floor
.


(See 
http://h2o-release.s3.amazonaws.com/h2o/rel-turchin/5/docs-website/h2o-py/docs/frame.html
 for the operations available on H2OFrames, from python API.)


But in your case, I'd download that column, do the complex manipulation in python, then import a 
new
 H2O Frame containing just that column. Give it a column name of 
""hours""
. Then use 
cbind
 to join your new column to your existing h2o frame.


(Another way to view this problem is that the first line of your question is inaccurate, as it is not ""hhmmss"" format, but is in fact a mix of ""hmm"", ""hhmm"", ""hmmss"" and ""hhmmss"" all mixed together in one column. Once you describe it like that, you see you have a data problem. Personally I'd look into the effort to get that fixed at the point of data collection. Then, going forward, if you ever see a timestamp that is not exactly 6 digits, you immediately know you have bad data.)",2019-11-06T08:37:07,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,58691256
58675987,58675987,0,"You are not required to specify the ""Class sampling factors"" parameter when using ""Balance classes"".  


I just verified on H2O 3.26.0.9 that you can successfully run AutoML with ""Balance classes"" checked and leaving the ""Class sampling factors"" blank by using the 
HIGGS dataset
 (10k subset).  I also entered 1.0,0.5 for ""Class sampling factors"" and that worked as well.  I don't see any bugs reported on older versions of H2O (not sure which version you are using), so maybe the error is caused by something else?


Here's the Flow output generated by both options:",2019-11-02T22:55:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",58675365
58666823,58666823,1,"H2O comes with a similar function, 
h2o.getModelTree
, which can be used for both GBM and Random Forest models (see the 
docs
); in your case, for selecting, say, tree #3, it should be:


tree <- h2o.getModelTree(model=rf_md, tree_number=3)",2019-11-01T23:04:39,desertnaut,https://stackoverflow.com/users/4685471/desertnaut,60.1k,58665502
58915422,58915422,1,"In your example above, rf_md 
is
 the H2O-3 DRF (Distributed Random Forest) object.  (Or, more specifically, a pointer to it.  The real object lives in memory in the H2O-3 java process from the h2o.init())


H2O-3 model objects are different from the native R package objects.  There is no way to convert an H2O-3 DRF model into an R randomForest model.",2019-11-18T13:13:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",58665502
58661954,58661954,2,"The R environment doesn't actually contain H2O-3 models.


R is just a front-end for H2O.  The H2O-3 back-end is a java process, and it stores data and model in-memory.


See the picture here for how the R front-end and H2O-3 java back-end interact:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html#how-r-scripts-tell-h2o-to-ingest-data




As such, you need to save and restore them to/from disk with h2o.saveModel and h2o.loadModel methods:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html#saving-and-loading-a-model




Without doing this, a second invocation of h2o.init() (assuming the java process is not already running) will just have a ""blank"" H2O-3 java process with nothing yet residing in-memory.",2019-11-01T15:37:01,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",58653362
58631479,58631479,1,"see documentation 
here


Prediction Threshold


For classification problems, when running h2o.predict() or .predict(), the prediction threshold is selected as follows:


If you train a model with only training data, the Max F1 threshold from the train data model metrics is used.
If you train a model with train and validation data, the Max F1 threshold from the validation data model metrics is used.
If you train a model with train data and set the nfold parameter, the Max F1 threshold from the training data model metrics is used.
If you train a model with the train data and validation data and also set the nfold parameter, the Max F1 threshold from the validation data model metrics is used.",2019-10-30T18:15:58,Schilker,https://stackoverflow.com/users/11903913/schilker,505,58631145
58652055,58652055,0,"This implementation is a good use case to leverage docker volumes.


Create an external volume and mount/bind it to the location where the model is being saved. 


https://docs.docker.com/storage/volumes/",2019-10-31T22:45:07,Avinash Reddy,https://stackoverflow.com/users/1845818/avinash-reddy,"1,175",58630426
58660068,58660068,0,"For anyone that might run into this problem in the future, I used the R ssh library (
https://www.rdocumentation.org/packages/ssh/versions/0.6
) to solve the problem. 


After saving all my models I run a docker cp command to copy the files from the docker container to the host running the docker. 


Then I used the scp_download function from the ssh library to download the files to my computer.


Finally, I ran 2 ssh_exec_wait functions to delete the folders created on the the docker host as well as in the docker container itself.",2019-11-01T13:30:38,V1cst3r,https://stackoverflow.com/users/10382081/v1cst3r,57,58630426
58615548,58615548,5,"The 
diamonds
 dataset (at least the one from 
ggplot2
) includes variables of the 
ordered
 class:


> str(diamonds)
Classes ‘tbl_df’, ‘tbl’ and 'data.frame':   53940 obs. of  10 variables:
 $ carat  : num  0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ...
 $ cut    : Ord.factor w/ 5 levels ""Fair""<""Good""<..: 5 4 2 4 2 3 3 3 1 3 ...
 $ color  : Ord.factor w/ 7 levels ""D""<""E""<""F""<""G""<..: 2 2 2 6 7 7 6 5 2 5 ...
 $ clarity: Ord.factor w/ 8 levels ""I1""<""SI2""<""SI1""<..: 2 3 5 4 2 6 7 3 4 5 ...
 $ depth  : num  61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ...
 $ table  : num  55 61 65 58 58 57 57 55 61 61 ...
 $ price  : int  326 326 327 334 335 336 336 337 337 338 ...
 $ x      : num  3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ...
 $ y      : num  3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ...
 $ z      : num  2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ...

> sapply(diamonds, class)
$carat
[1] ""numeric""

$cut
[1] ""ordered"" ""factor"" 

$color
[1] ""ordered"" ""factor"" 

$clarity
[1] ""ordered"" ""factor"" 

$depth
[1] ""numeric""

$table
[1] ""numeric""

$price
[1] ""integer""

$x
[1] ""numeric""

$y
[1] ""numeric""

$z
[1] ""numeric""



The error message seems to suggest that 
h2o
 does not support that class. You should convert them to a different class first, e.g. 
factor
 or 
character
.",2019-10-29T21:17:49,Axeman,https://stackoverflow.com/users/4341440/axeman,34.8k,58615510
58583275,58583275,2,"I guess you are facing this error because:-


H2o xgboost
 is not currently supported in Windows.",2019-10-27T20:53:32,ashwin agrawal,https://stackoverflow.com/users/7702120/ashwin-agrawal,"1,611",58581866
58586887,58586887,0,"As you have stated that your data is around 
131GB
, which is quite large, so the model training and testing will take significant amount of time.


Below are the official docs for training the 
GLM-poisson
 model in 
h2o
, this also includes all the parameters present during training, and also explains how to interpret the model output parameters.


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html


https://www.h2o.ai/wp-content/uploads/2018/01/GLM-BOOKLET.pdf",2019-10-28T07:11:19,ashwin agrawal,https://stackoverflow.com/users/7702120/ashwin-agrawal,"1,611",58576117
58547988,58547988,0,"Quick Note H2O.ai has a few products. The open source platform is called H2O-3 and it contains the AutoML algorithm. AutoML does not currently do feature engineering for you. If you want automatic feature engineering, you might be thinking of H2O's product 
Driverless-AI
. 


As for the error you are seeing, this is a bug and you can track the fix 
here
.


Depending on what you pass to the 
.train()
 method, you may or may not hit this bug.",2019-10-24T19:27:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",58524136
60904562,60904562,0,"I am not sure on the mojo runtime library that you used. Use the one that you get when you download your MOJO pipeline from H2O DAI. 
mojo2-runtime-api
 also offers the same methods to load the MOJO pipeline (
MojoPipeline.loadFrom()
). E.g. If it's a maven project and if you used the mojo runtime api as below:


<dependency>
    <groupId>ai.h2o</groupId>
    <artifactId>mojo2-runtime-api</artifactId>
    <version>2.3.1</version>
</dependency>



Use the below instead:


First install the dependency to your local file repo using the below command:


mvn install:install-file -Dfile=<<folder where the mojo runtime jar is stored>>/mojo2-runtime.jar -DgroupId=ai.h2o -DartifactId=mojo2-runtime -Dversion=1.0.0 -Dpackaging=jar



Then add the below block in your pom.xml:


<dependency>
    <groupId>ai.h2o</groupId>
    <artifactId>mojo2-runtime</artifactId>
    <version>1.0.0</version>
    <!-- NOT RECOMMENDED THE SYSTEM SCOPE WAY. INSTEAD, INSTALL IT IN YOUR LOCAL REPO
         USING THE COMMANDS GIVEN ABOVE
        <scope>system</scope>
        <systemPath>${project.basedir}/<<h2o>>/mojo2-runtime.jar</systemPath>
        OR
        <url>file://${basedir}/my-repo</url>
    -->
</dependency>



Hopefully the above should work! Make sure the path of 
pipeline.mojo
 is correct .",2020-03-28T17:44:34,unm,https://stackoverflow.com/users/3993359/unm,31,58515602
58483076,58483076,0,"I've found a workaround. I firstly join two h2o frames with the first column. This causes to duplicate columns. After then, I filter just rows have same timestamp value in t1 and t2 columns.


train_meta_df.columns[2] = ""t1"" #rename timestamp column
weather_train_df.columns[1] = ""t2""

df = h2o.H2OFrame.merge(df1, df2, by_x = [""site_id""], by_y=[""site_id""])
df = df[df[""t1""] == df[""t2""]]



Still, I believe this is a bug to be fixed.",2019-10-21T09:08:00,sefiks,https://stackoverflow.com/users/7846405/sefiks,"1,585",58482743
58780441,58780441,0,"as.data.frame(h2o.predict(gbm, newdata=split[[3]]))",2019-11-09T14:56:23,littleturtle,https://stackoverflow.com/users/10829854/littleturtle,105,58482180
60455826,60455826,1,"This seems to be a bug by h2o package. The code in 
https://github.com/h2oai/h2o3-sagemaker/blob/master/automl/automl_scripts/train#L106
 shows that it's reading categorical_columns directly from the hyperparameters, not nested under the training field. However when move up the categorical_columns field a level, the algorithm doesn't recognize it. So no solution for this.",2020-02-28T16:33:41,Sophia,https://stackoverflow.com/users/12980480/sophia,11,58469273
58494695,58494695,0,"It seems based on the code here: 
https://github.com/h2oai/h2o3-sagemaker/blob/master/automl/automl_scripts/train#L106


that the parameter is looking for a comma separated string. E.g. 
""cat,dog,bird""


I would try: 
""primary_type,description,location_description,domestic""
as the input parameter, rather than 
['primary_type', 'description'... etc]",2019-10-21T22:04:50,Nicholas Png,https://stackoverflow.com/users/9801753/nicholas-png,36,58469273
58469171,58469171,0,"aml = H2OAutoML(max_runtime_secs = 600, exclude_algos = [""GLM"", ""DeepLearning"", ""GBM"",""DRF"",""StackedEnsemble""] ,
                seed = 42,project_name = 'gtp')
aml.train(x = X, 
          y = y, validation_frame =hf_v
          training_frame = hf_train,
          leaderboard_frame = hf_test,)",2019-10-20T00:45:09,shafi Q,https://stackoverflow.com/users/11489179/shafi-q,77,58467247
58403629,58403629,1,"We have had a 
ticket open
 for this for a while, but we will re-visiting this soon due to increased demand for this feature.  For now, you will have to convert your H2OFrame to a Pandas DataFrame using the 
as_data_frame()
 method and then apply one of the following 
solutions
.",2019-10-15T23:03:16,,,,58326351
58293495,58293495,0,"No, I don't believe scikit-learn algorithms have any sort of automatic early stopping mechanism (that's what 
stopping_rounds
 relates to in H2O algorithms).  You will have to figure out the optimal number of trees manually.",2019-10-08T20:17:09,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",58293412
58293568,58293568,0,"Per the 
sklearn random forest classifier docs
, early stopping is determined by the 
min_impurity_split
 (deprecated) and 
min_impurity_decrease
 arguments. It doesn't seem to have the same functionality as H2O, but it might be what you're looking for.",2019-10-08T20:21:32,RNHTTR,https://stackoverflow.com/users/7004653/rnhttr,"2,515",58293412
58293681,58293681,0,"We don't yet have a convenience function to grab non-default parameters from an H2O model in Python, but there's a 
ticket open
 for it.  


My suggestion is that you just write a function to do this (check all the params to see if the ""default"" and ""actual"" values are the same, return non-default ones), so you can re-use it on any model in the future.  If you do write a function, please update your post and perhaps we can use your code to complete the task (or feel free to create a pull request). :-)",2019-10-08T20:29:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",58284800
58275180,58275180,1,"Yes, XGBoost MOJO and XGBoost Java predictor are both thread-safe.",2019-10-07T18:25:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",58253197
58226069,58226069,1,"here are the available installation instructions: 
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/installing.html


here's the Linux in the Cloud section: 
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/install/linux-in-the-cloud.html",2019-10-03T19:55:05,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",58107832
58106255,58106255,1,"No, there is no way to produce a jupyter notebook instead.


However, you can write your own jupyter notebook to drive H2O using the python client api.


Here are some references:


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/ntrees.html


http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/index.html",2019-09-25T20:41:06,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",58106200
58107278,58107278,2,"You are most likely not using the latest version of H2O, please get it from out website h2o.ai/download or just run 


install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-yau/5/R"")


You can find an example here: 
https://github.com/h2oai/h2o-3/blob/rel-yau/h2o-r/tests/testdir_algos/targetencoder/runit_targetencoder_model.R#L7",2019-09-25T22:21:58,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,58092586
58108885,58108885,0,"I think you have converted your response column into a factor column (I can't tell for sure because you don't have all of your code there), so it's doing classification instead of regression.  Your screenshot of the prediction output shows a multiclass output (with 655 ""classes"").


It's also possible you had quotes around the numbers in the CSV file and H2O interpreted them as categories instead of numbers.  You will need to convert the response column back to numeric and then re-train your model:


train_frame[target] = train_frame[target].asnumeric()",2019-09-26T02:45:09,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",58091045
58330818,58330818,0,"The first column in 
prediction
 is the predicted class. Try 
max(prediction)[-c(1)]
 to get the maximum value from the probabilities.",2019-10-10T20:43:19,Joe,https://stackoverflow.com/users/10913732/joe,268,58051707
58261975,58261975,1,"I found one solution to this authentication issue: Because I am running h2o in Docker swarm, I can set an environment variable for the container in Docker Compose. 


The relevant parts of the docker compose file look like this:


environment:
  - GOOGLE_APPLICATION_CREDENTIALS=/run/secrets/google_auth_secret
secrets:
  - google_auth_secret
...

secrets:
  google_auth_secret:
    file: ./gcloud_auth.json



Where gcloud_auth.json is the credentials file described 
here
 for your GCS bucket.",2019-10-06T23:15:17,caewok,https://stackoverflow.com/users/5786863/caewok,91,58051432
58050090,58050090,0,"I have found a solution, replace JAVA10 with JAVA8",2019-09-22T14:20:15,ZORO,https://stackoverflow.com/users/12101911/zoro,14,58047102
74831525,74831525,0,"I'm not sure if you can return an entire H2OCoxPH model from 
sparklyr::spark_apply()
: Errors are 
no method for coercing this S4 class to a vector
 if you set the 
fetch_result_as_sdf
 argument to 
FALSE
 and 
cannot coerce class ‘structure(""H2OCoxPHModel"", package = ""h2o"")’ to a data.frame
 if set to 
TRUE
.


But if you can make your own vector or dataframe from the relevant parts of the model, I think you can do it.


Here I'll use a sample Cox Proportional Hazards file from 
H2O Docs Cox Proportional Hazards (CoxPH)
 and I'll use 
group_by = ""surgery""
.


heart_hf <- h2o::h2o.importFile(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv"")

##### Convert to Spark DataFrame since I assume that is the use case
heart_sf <- sparklyr::copy_to(sc, heart_hf %>% as.data.frame())

##### Use sparklyr::spark_apply() on Spark DataFrame to ""distribute and fit h2o model by group""
sparklyr::spark_apply(
    x = heart_sf,
    f = function(x) {
        h2o::h2o.init()
        
        heart_coxph <- h2o::h2o.coxph(x = c(""age"", ""year""),
                                      event_column = ""event"",
                                      start_column = ""start"",
                                      stop_column = ""stop"",
                                      ties = ""breslow"",
                                      training_frame = h2o::as.h2o(x, strict_version_check = FALSE))
        
        return(data.frame(conc = heart_coxph@model$model_summary$concordance))
    },
    columns = list(surgery = ""integer"", conc = ""numeric""),
    group_by = c(""surgery""))
# Source: spark<?> [?? x 2]
  surgery  conc
    <int> <dbl>
1       1 0.588
2       0 0.614",2022-12-17T03:04:42,josephD,https://stackoverflow.com/users/15723919/josephd,152,58011829
58015557,58015557,0,"The response value is set to .1, to prevent taking the log of 0. You can find the line of code where this takes place 
here
.


double y1 = yr == 0?.1:yr;",2019-09-19T16:43:24,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",58011382
57998576,57998576,1,"Naive Bayes is a classification (not regression) algorithm so the response column must be a factor column.  This is required for all classification models in H2O.


You will have to do this before you train the model:


train_frame[y] = train_frame[y].asfactor()",2019-09-18T18:09:45,,,,57998383
57987997,57987997,0,"How to manage impersonation in a non-kerberized Hadoop cluster, for...

* creating the HDFS HomeDir for an arbitrary Hadoop user

* running a job under that user (that will use the HomeDir for temp files)


## create HDFS HomeDir for new user, with ""hdfs"" privileged account
## note the workaround for the bug in ""chmod"" parser which
##  fails on ""=<nothing>"" in most Hadoop versions
export HADOOP_USER_NAME=hdfs
hdfs dfs -mkdir -p               /user/zorro
hdfs dfs -chown zorro:zorro      /user/zorro
hdfs dfs -chmod u=rwx,g=rx,o-rwx /user/zorro
unset HADOOP_USER_NAME



export HADOOP_USER_NAME=zorro
# just to check who's there
hdfs groups

run-my-H2O-job-on-command-line
unset HADOOP_USER_NAME",2019-09-18T08:10:44,Samson Scharfrichter,https://stackoverflow.com/users/5162372/samson-scharfrichter,"9,047",57981830
57998887,57998887,0,"you can get the threshold for a specific metric by using:


find_threshold_by_max_metric


api documentation is 
here",2019-09-18T18:30:21,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",57979819
58014202,58014202,1,"thanks @Marcel Mendes Reis for following up on your solution in the comments. I will repost here for others to easily find:


I realized the issue was due to the max_runtime. When I trained the model with more time I didn't have the problem.",2019-09-19T15:16:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",57978333
58011906,58011906,0,"Doing some tests I realized that the problem was because of the max_runtime, I believe I didn't allow the model to train enough.",2019-09-19T13:16:32,Marcel Mendes Reis,https://stackoverflow.com/users/8836963/marcel-mendes-reis,107,57978333
57975364,57975364,0,"After I asked I came across an explanation from 
SageMaker examples.


{classification': 'true', 'categorical_columns': 'SIT','HOL','CTH','YTT','target': 'y'}.


Problem solved!",2019-09-17T13:30:43,Marcel Mendes Reis,https://stackoverflow.com/users/8836963/marcel-mendes-reis,107,57966245
57954276,57954276,0,"I figured it out


it's because of the wrong use of the data frames.
here is the corrected code:


# initializing the H2O service via internet
h2o.init(nthreads = -1)

# data preperation
data = readxl::read_excel(""C:\\Users\\frzd\\Desktop\\mtx.xlsx"")
data_order <- data[order(data$gold),]
data_order=h2o.asfactor(data_order)

# data split
Split_ts = .2
Split_vl = .1
indx <- 1:round(length(data$gold)*Split_ts)
ts <- max(indx)
ts <- round(indx*length(data$gold)/ts)
test = as.h2o(data_order[ts,])
train = data_order[-ts,]

indx <- 1:round(length(train$gold)*Split_vl)
ts <- max(indx)
ts <- round(indx*length(train$gold)/ts)
valid = as.h2o(train[ts,])
train = as.h2o(train[-ts,])

# perform fitting
fit <- h2o.gbm(y = 15, 
               distribution= ""gaussian"",
              training_frame = train, 
              validation_frame=valid
                    # cvControl = list(V = 5),
               )",2019-09-16T09:49:42,felegant,https://stackoverflow.com/users/12042615/felegant,13,57951856
57907016,57907016,1,"changesplit <- c(0,.01,.02)
usersplit <- list(c(""change"", changesplit))
h2o.partialPlot(data
     , cols = ""change""
     , user_splits = usersplit 
     , object = h2o.getModel(""gbm_model"")
     , plot = FALSE)




I don't know why this works.  The documentation isn't particularly helpful. 
Because 


changesplit <- c(0,.01,.02)
is.list(changesplit)
[1] FALSE

is.list(c(""change"", changesplit))
[1] FALSE



If you want to have additional variables and splits


usersplit <- list(
   c(""change"", changesplit)
   , c(""x"", seq(1:10,by = 1))
)",2019-09-12T12:43:37,,,,57896105
58921667,58921667,4,"You can plot the PRROC of e.g. the test set in the following way, where 
mod
is your H2O model object and 
test_hf
is your test set.


library(tidyverse)

perf <- h2o.performance(mod,test_hf)

metrics <- as.data.frame(h2o.metric(perf))

metrics %>%
  ggplot(aes(recall,precision)) + 
  geom_line() +
  theme_minimal()",2019-11-18T19:33:44,,,,57885421
57877753,57877753,1,"i get one column which consist predict. 




If your predictions look like this, it means you have trained a regression model instead of a classification model.  My guess is that your 
""Survived""
 column is binary, encoded as 0/1.  Since it's numeric, H2O thinks you are trying to do regression.  If you want to do a classification, you need to convert it into a factor column as follows:


h2o_data = as.h2o(train_df)
train = h2o_data
Survived = 'Survived'
train[,Survived] = as.factor(train[,Survived])",2019-09-10T20:23:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57877561
58452683,58452683,0,H2o Which function is not same as R which function specially in the above case. So we used subset function.,2019-10-18T14:15:35,Divya Mereddy,https://stackoverflow.com/users/9311050/divya-mereddy,31,57828268
57814156,57814156,1,"H2O AutoML
 contains a handful of algorithms and one of them is 
XGBoost
, which has been part of H2O AutoML since H2O version 3.22.0.1.  XGBoost is the only GPU-capable algorithm inside of H2O AutoML, however, a lot of the models that are trained in AutoML are XGBoost models, so it still can be useful to utilize a GPU. Keep in mind that you must use H2O 3.22 or above to use this feature.


My suggestion is to test it on a GPU-enabled instance and compare the results to a non-GPU instance and see if it's worth the extra cost.",2019-09-05T23:49:07,,,,57811873
57778839,57778839,1,"The main differences are how the jobs start and whether they have convenient access to HDFS.


There is no difference in the model training behavior if you give the same amount of nodes and memory/cpu per node.",2019-09-03T21:16:35,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",57778445
57778286,57778286,0,Yes.  As long as you have the client jars and appropriate configs similar to an edge node for your container it should work.,2019-09-03T20:23:15,tk421,https://stackoverflow.com/users/7852833/tk421,"5,949",57778138
57759360,57759360,1,"I spent hours on this problem but I can resolve it immediately when I post this question. It would be a typical 
rubber duck programming
.


It seems that the engine consumes all resources of the server and exceeded its limits. This is the reason of ""Thread creation failed: Resource temporarily unavailable"" message.


Limiting memory and number of threads solves this problem.


h2o.init(ip=""127.0.0.1"",max_mem_size_GB = 40, nthreads = 2)",2019-09-02T15:17:24,sefiks,https://stackoverflow.com/users/7846405/sefiks,"1,585",57758996
57749967,57749967,5,"The 
Changes.md
 file is the easiest place to look for links to where you can download every version.  Just search for the version you want (e.g. ""3.26.0.2"") and you will see the URL there.  


Click on the link and it will bring you to the 
download page for that version
 and you can click on the ""Install in Python"" tab which will show some code like this that you can copy/paste into your terminal:


# The following command removes the H2O module for Python.
pip uninstall h2o

# Next, use pip to install this version of the H2O Python module.
pip install http://h2o-release.s3.amazonaws.com/h2o/rel-yau/2/Python/h2o-3.26.0.2-py2.py3-none-any.whl



The URLs are ""predictable"" but you have to know the name of the release as well as the version number to correctly guess the URL.",2019-09-01T22:40:25,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57749892
70171016,70171016,0,"If you are installing h2o via pip, go to 
Release History page in the PyPi page for H2O
. Look for the specific version you need and install that version based on the command provided over there. It should be similar to the following command.


pip install h2o==3.26.0.2",2021-11-30T14:30:06,,,,57749892
57752985,57752985,1,"In R you would use 
options(digits=12)
, or something like that, to not have it use scientific precision until that number of digits. But in Python there seems no way to override the global default (which I think is 6 digits), and all the answers I found were about doing the formatting yourself.


But you can control it in ipython/Jupyter with:


%precision 12



(See 
https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-precision
 )


Or, assuming you have pandas imported, the table H2O returns is actually a pandas table, so there are formatting options there. I think 
pd.options.display.float_format = '{:.0f}'.format
 would do it.  Or change the column data type to an int64, as suggested here: 
https://stackoverflow.com/a/49910142/841830


All the options for pandas are here: 
https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html#available-options
 or search for pandas ways to format data. (I.e. just remember that H2O gives you a pandas data set, so it is a pandas question once you have the data in python.)",2019-09-02T07:32:59,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,57741388
57778137,57778137,0,"I was able to get model metrics from a MOJO model in Python(H2O), it can be done either ways : 
a. The exported zip of the mojo model has model json that contains all the metrics information. 
Path : /experimental/modelDetails.json


b. Second way is to import and invoke model_performance()


import h2o


h2o.init()


model = h2o.import_mojo(""/Users/sonamsharma/delete/GLM_model_python_1567539104058_1.zip"")


model.model_performance()


This can be either used as is or json can also be extracted. 


For JAVA, i tried taking reference of the below issue fix and the code, but was unable to do that. 

https://github.com/h2oai/h2o-3/pull/3642",2019-09-03T20:08:37,curios,https://stackoverflow.com/users/12001172/curios,11,57732980
57856568,57856568,0,"I believe if you use these parameters for 'performance' 
valid=TRUE, xval=FALSE
 and ignore the newdata parameter you will get what you are after.",2019-09-09T14:57:32,runningbirds,https://stackoverflow.com/users/3788557/runningbirds,"6,565",57704535
57669379,57669379,0,"extra_classpath
 is for use when starting H2O 
from Python
. When you are connecting to H2O that is running on another machine, it has to already be started. So it is up to whoever started it, to have given that extra classpath, as part of the java command, when 
starting it
. (And if a cluster, you have to make sure every node of the cluster uses the exact same command.)


The snowflake jar has to be available, on the path you give, 
on the server
. In fact, there is no need for it to be on the client, unless you are also using it directly from your Python script (i.e. outside of h2o).


BTW, see 
https://github.com/h2oai/h2o-3/blob/master/h2o-py/h2o/h2o.py#L147
 for the code. If you search for uses of 
extra_classpath
 you see it is only used when starting the local server.",2019-08-27T07:09:45,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,57595703
57599747,57599747,0,"If you want fine control over how your data is split, I would recommend using the H2O R or Python API. Currently, Flow only has the option to do a random split.


Flow is converting your time column to milliseconds since the Unix Epoch. In the Python and R API there has been an update so that when you view your frame you see a more human readable format.


If you'd like to see these features (more ways to split data frames and your original time format), you can create JIRA tickets here:  
http://jira.h2o.ai
. H2O-3 is open source and takes feature requests from the community.


But again, the fastest option is to use the Python or R API, since the functionality you'd like exists there.",2019-08-21T22:11:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",57585109
57580842,57580842,0,"h2o models are not zip files. Try this


# path to your file
model_file <- ""/Users/bernardo/Desktop/DRF_1_AutoML_20190816_133251.zip""

# prediction based on your mojo/pojo file. 
preds = h2o.mojo_predict_df(df, model_file, genmodel_jar_path = NULL, classpath = NULL, java_options = NULL, verbose = F)



If they are zipped, then unzip and run them again. More info is here 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html


https://rdrr.io/cran/h2o/man/h2o.mojo_predict_df.html",2019-08-20T20:03:57,,,,57580680
57700010,57700010,0,"Ok, I actually found the solution I needed. The trick is to convert your dataframe (
df
) to json format, and then use the 
.zip
 file generated with 
h2o
 to predict using the 
h2o.predict_json
 instead of 
h2o.mojo_predict_df
. I think it's pretty straight forward and less complicated. At least it worked as I needed it to work.


library(jsonlite)
library(h2o)
json <- toJSON(df)
output <- h2o.predict_json(zip_directory, json) 



NOTE
: No need to unzip the zip file.


If by any chance you've used the 
lares
 package, simply use the 
h2o_predict_MOJO
 function. 


Hope it helps any other people trying to achieve the same result.",2019-08-28T21:03:21,Bernardo,https://stackoverflow.com/users/7227825/bernardo,498,57580680
57578655,57578655,1,"Edit based on your update:
 the "".1252"" you see is not Unicode. See 
https://en.wikipedia.org/wiki/Windows-1252


This answer
 shows some ways to change the locale for R. (You might also want to look into ways to set the default locale for mingw, if you don't want to set this in R each time.)
I'll paste in my sessionInfo output below, but I think anything that shows 
.UTF-8
 at the end of each will be fine, e.g. ""de_DE.UTF-8""


BTW, one workaround is to strip out the special characters, see 
Remove accents from a dataframe column in R
 for a couple of ways you could do this. E.g. 


sodata <- ...
...
colnames(sodata) <- iconv(colnames(sodata),to=""ASCII//TRANSLIT"")
sohex <- as.h2o(sodata)
...





An unhelpful ""works for me"". I'm using h2o 3.22 (which is not that recent) with R 3.4.4, on Linux.
You didn't say which line you got the error on, but after doing 
as.h2o()
 I can see ""Erklärung"" in the column headers, and the same when looking at 
training
 and 
testing
. And when doing 
summary(gbm1)
 on the produced model, I see the umlaut in the variable importances:


   variable relative_importance scaled_importance percentage
1     isPot            0.676265          1.000000   0.708690
2 Erklärung            0.277981          0.411054   0.291310



My guess would be that you need to make sure your script is in UTF-8. And maybe check the locale you are running your R session in?


My sessionInfo() (running in RStudio; R from the commandline has identical locale settings):


> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 19.1

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C               LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8     LC_MONETARY=en_GB.UTF-8   
 [6] LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.4 tools_3.4.4",2019-08-20T17:17:01,,,,57576662
57763395,57763395,1,"The problem here is that you are comparing 
training metrics
 for XGBoost to 
CV metrics
 for AutoML models. 


The code you posted for the manual XGBoost models provides training metrics.  Instead, you will need to grab the CV metrics if you want to make a fair comparison to the performance of the models in AutoML (CV metrics are reported by default in the AutoML leaderboard and that's what you're reporting in your code).


Change this:


# now export metrics to file
MRD = xgb.mean_residual_deviance()
RMSE= xgb.rmse()
MSE= xgb.mse()
MAE= xgb.mae()
RMSLE= xgb.rmsle()



To: 


# now export metrics to file
MRD = xgb.mean_residual_deviance(xval=True)
RMSE= xgb.rmse(xval=True)
MSE= xgb.mse(xval=True)
MAE= xgb.mae(xval=True)
RMSLE= xgb.rmsle(xval=True)



The description of the metrics and what they return is in the 
Python module docs
.


Once you make this change you should see the issue resolved and have comparable performance between the manual XGBoost models and the AutoML models.",2019-09-02T23:07:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57571722
57575551,57575551,1,"I've no experience with 
h2o
 learners or their deep learning approach.


However, specifying the same parameter twice in a single ParamSet (as your first try) won't work. So you will always need to use two ParamSets anyways.


I cannot say anything about the second error you are getting. This looks like a h2o related problem.


Using 
makeModelMultiplexer()
 is one option. You can also use single 
benchmark()
 calls and aggregate them afterwards.",2019-08-20T14:09:14,pat-s,https://stackoverflow.com/users/4185785/pat-s,"6,272",57570144
57527234,57527234,0,"This is not available (yet) in the H2O User Guide, but we have a ticket 
open
 to add it.  In the ticket, there is a link to the 
AutoML.java
 file which contains this information.",2019-08-16T15:23:09,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57526304
66777374,66777374,4,"This issue related is with new examples data in particular column that doesn't exist in traing set.
I use parsing column types to numeric (or string) in this cases.


def _convert_h2oframe_to_numeric(h2o_frame, training_columns):
    for column in training_columns:
        h2o_frame[column] = h2o_frame[column].asnumeric()
    return h2o_frame



Remember to use this function for training and prediction process.",2021-03-24T08:35:13,CezarySzulc,https://stackoverflow.com/users/6422477/cezaryszulc,"1,999",57524459
75453785,75453785,0,"Maybe a Little late, but this problem still ocurrs, specially if you have lots of columns, what I dit to solve this problem was:


H2O gives one of two possible messages:




Test/Validation dataset has a non-categorical column '
<YOUR-COLUMN>
' which is categorical in the training data




or




Test/Validation dataset has categorical column '
<YOUR-COLUMN>
' which is real-valued in the training data




So, what I did was to extract the column name from the message and convert the column according to the message in categorical or numeric.


so, my python code looks like this:


hf = h2o.H2OFrame(df)
transform = True
while transform:
    try:
        prediction = rf_model.predict(hf)
        transform = False
    except Exception as inst:
        err_msg = str(inst)
        tarr = err_msg.split('categorical')
        column = tarr[1].split(""'"")[1]
        if tarr[0][-1] == '-': # convert to categorical
            hf[column] = hf[column].asfactor()
            print(f'{column} converted to categorical')
        else: # convert to numeric
            hf[column] = hf[column].asnumeric()
            print(f'{column} converted to real-valued')



Hope it helps!",2023-02-14T22:21:21,William Castrillon,https://stackoverflow.com/users/5408334/william-castrillon,82,57524459
57472463,57472463,0,"I think you need to convert 
newdata
 into an R data.frame before passing it to the 
consume()
 function: 


newdata <- as.data.frame(newdata)



This looks like the same issue here: 
https://stackoverflow.com/a/49415285/5451344",2019-08-13T06:46:54,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57469702
57490426,57490426,0,"Are you running h2o as a Hadoop job or standalone outside of Hadoop? delegationToken auth is only used when H2O is running as a Hadoop job. 


If you you are running standalone you need to use kerberos authentication with something like jdbc:hive2://host:10000/default;principal=hive/
[email protected]
.


If you are running as hadoop job via h2o_driver.jar then you need to make sure hive is on mapreduce classpath, either via libjars or via hadoop conf. More details are available in the docs.",2019-08-14T07:54:39,,,,57454662
57421285,57421285,2,"You can do this:


data = h2o.import_file(path='training_dataset.csv')
original_model = H2OGeneralizedLinearEstimator()
original_model.train(x = [""Some column"", ""Another column""], y = ""response"", training_frame=data)

path = '/path/to/model/directory/model.zip'
original_model.download_mojo(path)



And then in a new notebook do this:


path = '/path/to/model/directory/model.zip'
imported_model = h2o.import_mojo(path)
new_observations = h2o.import_file(path='new_observations.csv')
predictions = imported_model.predict(new_observations)





[ Taken from this page in the documentation:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/mojo_import.html
 ]",2019-08-08T22:14:46,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",57420788
57668884,57668884,0,"AIX is big endian and windows (intel) is little endian. So as far as I know the H2O model generated on windows will not directly work on AIX, I think there is some work needed in H2O to make that work. But you can host that model on a PowerVM linux box next to AIX on same power system if that helps. Because you can have a little endian Linux. 

https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Power%20Systems/page/H2O%20Driverless%20AI%20for%20Data%20on%20IBM%20AIX",2019-08-27T06:36:23,Sanket Rathi,https://stackoverflow.com/users/11982129/sanket-rathi,1,57340746
57316319,57316319,1,"This looks like a bug and I don't have a work-around right now.  I have tagged it to be fixed in the next fix/minor release: 
https://0xdata.atlassian.net/browse/PUBDEV-6745",2019-08-01T20:08:45,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57309381
57362772,57362772,0,"To print the summary, try 
mDL.summary().as_data_frame()
. In general, 
as_data_frame()
 will fix the formatting of most tables in h2o3.",2019-08-05T16:42:14,Joe,https://stackoverflow.com/users/10913732/joe,268,57308335
57304970,57304970,1,"There is no way that I am aware of.


But as an alternative, inside your loop, you could call 
h2o.rm()
 on the return value from 
h2o.predict()
. It is worth calling 
h2o.gc()
 as well. Something like:


for(data in alldata){
  # ... prepare newdata
  p = h2o.predict(model, newdata)
  # ... do something with p here
  h2o.rm(p)
  h2o.rm(newdata)  # If also not needed any more
  h2o.gc()
}



Aside:
 you said ""I'm making a few thousand predictions in a loop"". Assuming they were all against the same model, remember you can batch them up, and give all thousand predictions in a single 
newdata
 dataframe. One call to 
h2o.predict()
 with 1000 entries is much more efficient than making 1000 
h2o.predict()
 calls, for one 
newdata
 entry at a time.",2019-08-01T08:36:56,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,57273916
57699900,57699900,1,"Problem appears to be related to How to properly change uid for HDP / ambari-created user? and the fact that having a user exist on a node and have a hdfs://user/ directory with correct permissions (as I was lead to believe from a Hortonworks forum post) is not sufficient to be acknowledges as ""existing"" on the cluster. This jives with discussions I've had with Hortonworks experts where they have said that 
the YARN-using user must exist on all of the cluster's datanodes
.


Running the hadoop jar command for a different user (in this case, the Ambari-created hdfs user) that exists on all cluster nodes (even though Ambari created this user having different uids across nodes (IDK if this is a problem)) and has a hdfs://user/hdfs dir, found that the h2o jar ran as expected.


I was initially under the impression that users only needed to exist on whatever client machine was being used plus the need for a hdfs://user/ dir (see 
https://community.cloudera.com/t5/Support-Questions/Adding-a-new-user-to-the-cluster/m-p/130319/highlight/true#M93005
). 




Side note
:


One concerning / confusing thing that has come from this is the fact Ambari apparently created the hdfs user on the various cluster nodes with differing uid and gid values, eg...


[root@HW01 ~]# clush -ab id hdfs
---------------
HW[01-04] (4)
---------------
uid=1017(hdfs) gid=1005(hadoop) groups=1005(hadoop),1003(hdfs)
---------------
HW05
---------------
uid=1021(hdfs) gid=1006(hadoop) groups=1006(hadoop),1004(hdfs)
[root@HW01 ~]# 
[root@HW01 ~]#
# wondering what else is using a uid 1021 across the nodes 
[root@HW01 ~]# clush -ab id 1021
---------------
HW[01-04] (4)
---------------
uid=1021(hbase) gid=1005(hadoop) groups=1005(hadoop)
---------------
HW05
---------------
uid=1021(hdfs) gid=1006(hadoop) groups=1006(hadoop),1004(hdfs)



This does not seem like that is how it is supposed to be (just my suspicion from having worked with MapR (which requires the uid and gids to be same across nodes) and looking here: 
https://www.ibm.com/support/knowledgecenter/en/STXKQY_BDA_SHR/bl1adv_userandgrpid.htm
). Note that HW05 was a node that was added later. If this is actually fine in HDP, I plan to just add the user I actually indent to use h2o with across all the nodes with whatever arbitrary uid and gid values. Any thoughts on this? Any docs to support either why this is right or wrong you could link me to?


Looking into this a bit more here: 
HDFS NFS locations using weird numerical username values for directory permissions",2019-08-28T20:52:50,,,,57226758
57211994,57211994,2,"Think I found the problem, 
TLDR: firewalld (nodes running on centos7) was still running, when should be disabled on HDP clusters
.


From another community 
post
:




For Ambari to communicate during setup with the hosts it deploys to and manages, certain ports must be open and available. The easiest way to do this is to temporarily disable iptables, as follows:


systemctl disable firewalld


service firewalld stop




So apparently 
iptables
 and 
firewalld
 need to be disabled across the cluster (supporting docs can be found 
here
, I only disabled them on the Ambari installation node). After stopping these services across the cluster (I recommend using 
clush
), was able to run the yarn job without incident.",2019-07-26T01:24:11,Community,https://stackoverflow.com/users/-1/community,1,57211993
63745132,63745132,1,"Normally, this problem is either due to bad DNS configuration, firewalls, or network unreachability. To quote 
this
 official doc:






The hostname of the remote machine is wrong in the configuration files


The client's host table /etc/hosts has an invalid IPAddress for the target host.


The DNS server's host table has an invalid IPAddress for the target host.


The client's routing tables (In Linux, iptables) are wrong.


The DHCP server is publishing bad routing information.


Client and server are on different subnets, and are not set up to talk to each other. This may be an accident, or it is to deliberately lock down the Hadoop cluster.


The machines are trying to communicate using IPv6. Hadoop does not currently support IPv6


The host's IP address has changed but a long-lived JVM is caching the old value. This is a known problem with JVMs (search for ""java negative DNS caching"" for the details and solutions). The quick solution: restart the JVMs






For me, the problem was that the driver was inside a Docker container which made it impossible for the workers to send data back to it. In other words, workers and the driver not being in the same subnet. The solution as given in 
this answer
 was to set the following configurations:


spark.driver.host=<container's host IP accessible by the workers>
spark.driver.bindAddress=0.0.0.0
spark.driver.port=<forwarded port 1>
spark.driver.blockManager.port=<forwarded port 2>",2020-09-04T16:48:06,Iman Akbari,https://stackoverflow.com/users/2546146/iman-akbari,"2,186",57211993
57210872,57210872,2,"The ""java -version"" command not working is definitely something you need to resolve.


CalledProcessError: Command '['/usr/bin/java', '-version']' returned non-zero exit status 2.



H2O-3 uses Java underneath the hood to do it's work.  I recommend installing Java 8 on your host.


Start debugging this by running 
java -version
 by hand in a terminal and see if that helps pinpoint the problem.  Chances are you just need to install java itself.",2019-07-25T22:26:48,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",57203896
57210018,57210018,0,"The 
officially recommended
 way to install the conda package is 


conda install -c h2oai h2o



I would start with a fresh environment that doesn't contain the other h2o packages you tried. Note that 
h2o-py
 is not an official h2o package and it's not recommended to ever use it.",2019-07-25T20:57:12,Joe,https://stackoverflow.com/users/10913732/joe,268,57203896
57205953,57205953,3,"The AutoML algorithm has tried it's best on the data you gave it, however there are few things you can try:




You can run the AutoML process for longer than you are currently running it by increasing 
max_runtime_secs
.


It sounds like you have imbalanced data in your binary classification problem (where the minority class is 10%) so you could try setting 
balance_classes
 to True.


You can do doing some manual 
feature engineering
 on your data to transform existing features or create additional features.


The best solution is to collect more training data (though that may not be possible).",2019-07-25T15:51:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",57196545
59954500,59954500,0,"I don't know the direct solution to your question, but the following steps should work:


gbm_var_imp = cv_gbm._model_json['output']['variable_importances'].as_data_frame()

x = gbm_var_imp['scaled_importance']
x.index = gbm_var_imp['variable']

fig = plt.figure(figsize=(8, 8))
x.sort_values().plot(kind='barh')
fig.savefig('gbm_variable_importance.png', dpi=600)",2020-01-28T17:56:11,J.S,https://stackoverflow.com/users/10881436/j-s,1,57154630
76420670,76420670,0,"In R, the following should work ...
VarImp_model <- as.data.frame (h2o.varimp (model))
VarImp_model$variable <- factor(VarImp_model$variable) %>%
fct_reorder(VarImp_model$scaled_importance)


ggplot(VarImp_model[1:10,], aes(variable, scaled_importance))+
  geom_col(width = 0.5) +
  ggtitle(""Variable importance"")+
  xlab("""") + ylab("""")+
  coord_flip()+
  theme_minimal()+
  theme(axis.title = element_text(size=14), axis.text = 
         element_text(size=12), 
         plot.title = element_text(hjust = 0.5, size=16), strip.text = 
         element_text(size=14))",2023-06-07T07:01:31,meklit chernet,https://stackoverflow.com/users/17309429/meklit-chernet,11,57154630
57147888,57147888,0,"As per the documentation 
here
, it is the same in Python as well as R: 




A transform function is available for use with Word2vec. This function
  transforms words to vectors using an existing Word2Vec model and has
  the following usage 
(in both R and Python)




Code from the documentation:


h2o.transform(word2vec, words, aggregate_method)",2019-07-22T14:10:04,Ankur Sinha,https://stackoverflow.com/users/1592364/ankur-sinha,"6,639",57147822
57147922,57147922,0,"As stated in my comment, it's the same:


 h2o.transform(word2vec, words, aggregate_method)



Documentation:
 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/word2vec.html


Source code:
 
https://github.com/h2oai/h2o-3/blob/master/h2o-py/h2o/model/word_embedding.py#L28",2019-07-22T14:11:26,seralouk,https://stackoverflow.com/users/5025009/seralouk,32.9k,57147822
57130323,57130323,0,Please install a version of sparkling_water_core_2_11_2_4_x-xxxxx.jar that matches with the version of h2o installed in your databricks runtime.,2019-07-21T04:25:58,Harish Vasudev,https://stackoverflow.com/users/11813897/harish-vasudev,1,57127895
57085156,57085156,0,I was not able to find a coding solution. But found an easier way - saved the pyspark df as a parquet in hdfs and imported it into h2o. All string columns were auto-recognised as Enum.,2019-07-17T23:22:21,ViShank,https://stackoverflow.com/users/11795392/vishank,1,57068435
57209947,57209947,0,"The answer is quite simple:
- export the model using the UI


on another day/running a clean instance:
- import the model using the UI
- import and parse the files used
- run predict, select the imported model


Important: h2o version used on exporting and importing should be the same",2019-07-25T20:49:36,mfulvio,https://stackoverflow.com/users/10200522/mfulvio,33,57046562
57075838,57075838,1,"you have to call 
prediction.pr_auc()
 method instead of 
prediction.aucpr()
 method.


See the doc: 

http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/metrics.html#h2o.model.metrics_base.MetricsBase.pr_auc",2019-07-17T12:26:47,Maurever,https://stackoverflow.com/users/5036600/maurever,157,57044168
57013941,57013941,0,"If you want to visualize an H2O Tree you can use the Mojo Visualizer (documentation 
here
) or see previous questions/posts on this:


How to visualize H2O Tree?


Visualizing H2O GBM and Random Forest MOJO Models Trees in Python",2019-07-12T20:55:58,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",57004020
56996841,56996841,1,"Unless the model perfectly fit the training dataset you won't see a perfect score. If you only provide a training dataset and don't use nfolds, then H2O will only use your training data.",2019-07-11T20:27:47,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56965370
56971231,56971231,1,"If you don't set the parameter threshold, it returns an array with one result for optimal threshold - [[optimal threshold, mcc]]. You can set the array of own thresholds - [threshold1, threshold2, ...] it will return [[threshold1, mcc1], [threshold2, mcc2], ... ].",2019-07-10T12:57:18,Maurever,https://stackoverflow.com/users/5036600/maurever,157,56959385
56979048,56979048,-1,"def listToString(lis):
    return "","".join(lis)

df[""Colors""] = df['Colors'].apply(listToString)



This will convert 
[red,blue,green]
 to 
red,blue,green
 i.e. a string.",2019-07-10T21:44:54,secretive,https://stackoverflow.com/users/9165263/secretive,"2,112",56957790
56956107,56956107,1,"If you are constructing a simple decision tree, then the values at leaf nodes are the output probability, not correlation and the levels are not count of categorical values as you can have multiple features repeating in the tree at different levels. The levels are decided by the depth you provide when training the model.




The greater than or smaller than sign shows which direction you have to go to. For example at level 1, if 
z>10.0325
 than you go right but if it is smaller than you go left in the tree. 
NA
 basically shows that you go left if value is smaller than threshold or is null. Your model is considering categorical variables at numerical and H2O provides you the option to change that using 
categorical_encoding
. Since the data is in numerical format, it is interpreted as numerical.


The reason there is decision 
1
 again is because your model is checking a different feature now to verify the results. If first level fails and model is not sure about output, it will check second level and do the same thing and will go further down the tree till it reaches a prediction.",2019-07-09T15:35:45,secretive,https://stackoverflow.com/users/9165263/secretive,"2,112",56955913
56940361,56940361,1,"You can use the workflow described in the documentation below:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo




java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i model.zip -o model.gv -f 20 -d 3
dot -Tpng model.gv -o model.png
open model.png",2019-07-08T18:03:36,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56938966
65680506,65680506,1,"For Windows/python users I put together a small recipe including links for all steps:


General info:

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/mojo-quickstart.html




install graphViz:

https://forum.graphviz.org/t/new-simplified-installation-procedure-on-windows/224




install java JDK 14:

https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html




add Java to PATH environment variable (to be able to execute from console)




Compile H2O model in python and export model with the .download_mojo(path) function:






decTreeModel.download_mojo('C:/User/L/mojoExports/myMojoModel.zip')




Go to location of the myMojoModel.zip and start CMD in this directory.In CMD type:




java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 --levels 21 --title ""title for tree"" -i myMojoModel.zip -o model.gv -f 20 -d 3


meaning of parameters:

--tree n        : n is the number of the tree to be exported if there are more than one model in the mojo model (e.g. when using cross validation)

--levels n      : n is number of categorical levels to be printed (default 10)

--title ""string""    : you can specify the title here

-i ""path""       : ""path"" is path to input model (myMojoModel.zip)

-o ""path""       : ""path"" is path to output graph (model.gv)

-f n            : n is the font size

-d n            : n is the number of decimals displayed for numbers





in CMD, create the .png with graphViz. Type




dot -Tpng model.gv -o model.png




it will create a .png in that directory which you can view with any png viewer",2021-01-12T08:42:32,Len,https://stackoverflow.com/users/14989300/len,11,56938966
56953821,56953821,1,"Ok so the problem seems to be indeed in the writing of the svm file I used this : 


write_svmlight(x, y = numeric(nrow(x)), file = filename, zero_based = FALSE) 



and it works for now",2019-07-09T13:32:59,,,,56937847
56931994,56931994,4,"My dataset has 2 classes, 0, 1 instead of yes and no from the example. 




What will have happened is that H2O has decided that was a numeric column, rather than a categorical (aka factor) column. The fix is simply to use 
as.factor()
 on that column. Do this just after importing the data, but before using it to build a model.


Then it will know to build a classification model, not a regression model, and you will get the metrics you expect to see.


Here is an example: 
https://stackoverflow.com/a/41441578/841830
 (or search for as.factor in the H2O docs, where you will find loads more)


In Flow
, you first upload the file, then you click parse files, and it shows a list of the columns. The categorical/factor columns are called ""Enum"" there (yes, it is confusing). Your column is presumably showing as numeric, so go to the dropdown box and change it to be enum. Then start the parse. Then, after that, build your model.",2019-07-08T09:30:30,,,,56930004
56956600,56956600,1,"You have to change the type of response column to ""enum"", 




or change distribution in the model parameters setting to ""bernoulli"" (binomial classification).




In the image, you share there is ""Enum(3)"" so the result is multinomial classification not binomial. So you should see Confusion Matrix but not the ROC curve. The ROC curve is able to display only for 2-class classification (more about ROC here: 
https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
).


You should see something like this (if you set distribution to ""multinomial""):",2019-07-09T16:04:23,,,,56930004
71311757,71311757,0,My problem was fixed by changing the target variable from 0s and 1s to False and True values.,2022-03-01T16:35:57,Renata Ghisloti,https://stackoverflow.com/users/1779666/renata-ghisloti,557,56930004
56943396,56943396,0,"H2O-3's split frame option is not designed to provide exact splits. 


H2O-3 is designed to be efficient on big data using a probabilistic splitting method rather than an exact split. For example when specifying a split of 0.75/0.25, H2O-3 will produce a test/train split with an expected value of 0.75/0.25 rather than exactly 0.75/0.25. On small datasets, the sizes of the resulting splits will deviate from the expected value more than on big data, where they will be very close to exact.",2019-07-08T22:49:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56928872
56907485,56907485,5,"you can install the h2o-3 package for python, for example, from h2o.ai/downloads or from pypi.


the h2o package handles categorical values automatically efficiently.  it is recommended to not one-hot-encode them first.


you can find lots of documentation at docs.h2o.ai.",2019-07-05T17:58:08,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56907349
56939735,56939735,0,"As per, 
https://datascience.stackexchange.com/a/32623/51879


You can use other encoding techniques using this wrapper for 
scikit-learn
 
http://contrib.scikit-learn.org/categorical-encoding/


Also check out this great article for more details 
https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931
.",2019-07-08T17:15:56,Ankush Chauhan,https://stackoverflow.com/users/1561981/ankush-chauhan,93,56907349
56894701,56894701,2,"train=True
 shows the models performance at the end of the training which means tthat it returns the training metric constructed during training while 
test_data = train
 sends the 
train
 data to the model for prediction and checks models performance on that prediction.",2019-07-04T22:20:37,secretive,https://stackoverflow.com/users/9165263/secretive,"2,112",56893769
56873438,56873438,2,"The threshold is max-F1.


If you want to apply your own threshold, you will have to take the probability of the positive class and compare it yourself to produce the label you want.


If you use your web browser to connect to the H2O Flow Web UI inside of H2O-3, you can mouse over the ROC curve and visually browse the confusion matrix for each threshold, which is convenient.",2019-07-03T15:25:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56862368
56843635,56843635,0,"TLDR
: Need to unpack the keys/values as **kwargs keywords in order to get the expected behavior of updating the 
_parms
 dict. So do 


model = model.set_params(**HYPARAMS)  #see https://stackoverflow.com/a/22384521/8236733





Example:


# here's a basic standin for the set_params method
>>> def kfunc(**parms):
...     print parms
... 

# what I was doing
>>> kfunc({1:2})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: kfunc() takes exactly 0 arguments (1 given)
# and also tried
>>> kfunc(parms={1:2})
{'parms': {1: 2}}
>>> kfunc({u'1':2, u'2':3})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: kfunc() takes exactly 0 arguments (1 given)

# what should have been done
>>> kfunc(**{'1':2})
{'1': 2}
>>> kfunc(**{u'1':2, u'2':3})
{u'1': 2, u'2': 3}




Can now see that this is not directly related to h2o, but keeping post up anyway so others with this problem may find, since did not immediately think to do this from just reading the popup docs for the method (and also since the other SE post commented in the example that I used to actually use variables as **kwarg keywords was not even on the first page of a Google search of ""How to use python variable as keyword for kwargs parameter?"" so would like to add more avenues to it).",2019-07-01T23:35:32,,,,56842876
56772260,56772260,3,"This is currently not possible, however I created a feature request 
here
.  There is a related question 
here
 which shows a solution for R (could be adapted to Python).  The work-around is just to rename the file manually using a few lines of R/Python code.",2019-06-26T11:57:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",56763772
56710216,56710216,1,"The attribute is still there, it looks like the tutorial is missing a line of code right after the file import, which means the model is being considered as a regression problem instead of a classification problem. So if you add the following line after you import the covtype dataset:


covtype_df[54] = covtype_df[54].asfactor()


which converts the target to a factor, it should work.


If you want to play around with the 
hit_ratio_table()
 you can look at this 
code snippet
 in the H2O-3 user guide.",2019-06-21T20:42:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56706274
56695428,56695428,0,"Found the cause of the error by checking the logs in the h2o 
Flow UI
 (which I would say is a good h2o debugging tip in general (as it appears some errors only print there and not the standard error output)).


06-20 12:39:02.188 172.18.4.64:54321     27694  FJ-1-11   INFO: Building H2O DRF model with these parameters:
06-20 12:39:02.188 172.18.4.64:54321     27694  FJ-1-11   INFO: {""_train"":{""name"":""py_9_sid_827e"",""type"":""Key""},""_valid"":{""name"":""py_10_sid_827e"",""type"":""Key""},""_nfolds"":0,""_keep_cross_validation_models"":false,""_keep_cross_validation_predictions"":false,""_keep_cross_validation_fold_assignment"":false,""_parallelize_cross_validation"":true,""_auto_rebalance"":true,""_seed"":111,""_fold_assignment"":""AUTO"",""_categorical_encoding"":""AUTO"",""_max_categorical_levels"":10,""_distribution"":""AUTO"",""_tweedie_power"":1.5,""_quantile_alpha"":0.5,""_huber_alpha"":0.9,""_ignored_columns"":null,""_ignore_const_cols"":true,""_weights_column"":""weight"",""_offset_column"":null,""_fold_column"":null,""_check_constant_response"":true,""_is_cv_model"":false,""_score_each_iteration"":false,""_max_runtime_secs"":28800.0,""_stopping_rounds"":0,""_stopping_metric"":""AUTO"",""_stopping_tolerance"":0.001,""_response_column"":""DENIAL"",""_balance_classes"":false,""_max_after_balance_size"":5.0,""_class_sampling_factors"":null,""_max_confusion_matrix_size"":20,""_checkpoint"":null,""_pretrained_autoencoder"":null,""_custom_metric_func"":null,""_export_checkpoints_dir"":null,""_ntrees"":96,""_max_depth"":13,""_min_rows"":64.0,""_nbins"":13,""_nbins_cats"":16,""_min_split_improvement"":1.0E-5,""_histogram_type"":""AUTO"",""_r2_stopping"":1.7976931348623157E308,""_nbins_top_level"":1024,""_build_tree_one_node"":false,""_score_tree_interval"":0,""_initial_score_interval"":4000,""_score_interval"":4000,""_sample_rate"":0.6320000291,""_sample_rate_per_class"":null,""_calibrate_model"":false,""_calibration_frame"":null,""_col_sample_rate_change_per_level"":1.0,""_col_sample_rate_per_tree"":1.0,""_binomial_double_trees"":true,""_mtries"":5}
06-20 12:39:02.189 172.18.4.64:54321     27694  FJ-1-11   ERRR: _weights_column: Weights column 'weight' not found in the training frame
06-20 12:39:02.189 172.18.4.64:54321     27694  FJ-1-11   ERRR: _weights_column: Weights column 'weight' not found in the training frame



It turns out that the problem was due to the fact that the column assigned to be used as the 
weights_column
 param in the grid search was not actually present in the H2OFrame being used.


Will try to pare down question post to be more relevent to others that may find this problem based only on the title (since the standard error printed in the console gives no indication of the specific problem).",2019-06-21T00:24:18,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",56693407
56685387,56685387,1,"There is a library on github which can convert a Java Pojo output from H2O.ai into dotnet. 


https://github.com/cozmoash/h2o-ai-pojo-to-dotnet


Disclaimer - I am the owner of this library.",2019-06-20T11:52:40,ashley aberneithy,https://stackoverflow.com/users/586316/ashley-aberneithy,520,56685354
56692667,56692667,0,There is a (not well known) C# MOJO shim library with an integrated C++ implementation that enterprise customers of H2O.ai can ask (their sales rep) about.,2019-06-20T19:25:15,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56685354
56677701,56677701,1,"The argument to 
set()
 is an iterable, and it creates a set of each element of the iterable. So if 
left_key
 is a string, 
set(left_key)
 will create a set of each of the unique characters of the string, not a set whose element is the string.


The solution is to use 
set([left_key])
. The argument will be the list, and the set will then contain its single element, the string. Or you can just use a set literal 
{left_key}


left_non_pk_cols = set(left_frame.columns) - {left_key}



Another way is to just remove the element from the set.


left_non_pk_cols = set(left_frame.columns)
left_non_pk.cols.discard(left_key)



I used 
discard
 rather than 
remove
 because it doesn't signal an error if the element isn't found.",2019-06-20T01:02:32,Barmar,https://stackoverflow.com/users/1491895/barmar,777k,56677557
56673001,56673001,2,"H2O-3 does not support traditional time series algorithms (e.g., ARIMA).  Instead, the recommendation is to treat the time series use case as a supervised learning problem and perform time-series specific pre-processing. 


For example, if your goal was to predict the sales for a store tomorrow, you could treat this as a regression problem where your target would be the Sales.  If you try to train a supervised learning model on the raw data, however, chances are your performance would be pretty poor.  So the trick is to add historical attributes like lags as a pre-processing step.


If we trained a model on an unaltered dataset, the Mean Absolute Error is around 35%. 




If we start adding historical features like the sales from the previous day for that store, we can reduce the Mean Absolute Error to about 15%.




While H2O-3 does not support lagging, you can leverage Sparkling Water to perform this pre-processing.  You can use Spark to generate the lags per group and then use H2O-3 to train the regression model.  Here is an example of this process: 
https://github.com/h2oai/h2o-tutorials/tree/master/best-practices/forecasting",2019-06-19T17:24:13,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56666876
56675387,56675387,0,"The training data, 
train_df
 has to have all the columns listed in both 
x
 (
c(""month"", ""lag12"", ""trend"", ""trend_sqr"")
) and 
y
 (
""y""
), whereas the data you give to 
h2o.predict()
 just has to have the columns in 
x
; the y-column is what will be returned as the prediction.


As you have features (in 
x
) that are things like lag, trend, etc. the fact that it is a time series does not matter.  (But you do have to be very careful when preparing those features to make sure you do not use any information in them that was not known at that point in time - but I would imagine the book has already been emphasizing that.)


Normally with a time series, for a given row in the training data, your 
x
 data is the data known at time t, and the value in the 
y
 column is the value of interest at time t+1. So when doing a prediction, you give the 
x
 values as the values 
at the moment
, and the prediction returned is what will happen next.",2019-06-19T20:27:26,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,56666876
56649727,56649727,2,"H2O's AutoML (first released in 2017) is built on the Open Source 
H2O
 distributed machine learning stack. It's built on Java but it has Python and R bindings, so you can use those languages.",2019-06-18T12:57:51,desertnaut,https://stackoverflow.com/users/4685471/desertnaut,60.1k,56648018
56638584,56638584,0,"As of 3.24.0.4 it isn't implemented (as the error indicates), but I've created a JIRA ticket 
here
 where you can track the progress of this feature request and add comments if needed.",2019-06-17T20:35:55,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56636206
56672464,56672464,0,"You have the function you need as indicated 
here
. So you just need to convert the output of your H2OFrames to a Pandas Dataframe. Example is shown below:


import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator
import numpy as np
import matplotlib.pyplot as plt

from sklearn import svm, datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels
%matplotlib inline

h2o.init()
h2o.cluster().show_status()

# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")


# print(cars[""economy_20mpg""].isna().sum())
cars[~cars[""economy_20mpg""].isna()][""economy_20mpg""].isna().sum()
cars = cars[~cars[""economy_20mpg""].isna()]


# convert response column to a factor
cars[""economy_20mpg""] = cars[""economy_20mpg""].asfactor()

# set the predictor names and the response column name
predictors = [""displacement"",""power"",""weight"",""acceleration"",""year""]
response = ""economy_20mpg""

# split into train and validation sets
train, valid = cars.split_frame(ratios = [.8], seed = 1234)

# try using the `y` parameter:
# first initialize your estimator
cars_gbm = H2OGradientBoostingEstimator(seed = 1234, sample_rate=.5)

# then train your model, where you specify your 'x' predictors, your 'y' the response column
# training_frame and validation_frame
cars_gbm.train(x = predictors, y = response, training_frame = train, validation_frame = valid)



function from sklearn:


def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """"""
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """"""
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    classes = classes[unique_labels(y_true, y_pred)]
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print(""Normalized confusion matrix"")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha=""right"",
             rotation_mode=""anchor"")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha=""center"", va=""center"",
                    color=""white"" if cm[i, j] > thresh else ""black"")
    fig.tight_layout()
    return ax




extract values


# specify the threshold you want to use to create integer labels
maxf1_threshold = cars_gbm.find_threshold_by_max_metric('f1')

# specify your tru and prediciton labels
y_true = cars[""economy_20mpg""].as_data_frame()
y_pred = cars_gbm.predict(cars)

# convert prediction labels (original uncalibrated probabilities into integer labels)
y_pred = (y_pred['p1'] >= maxf1_threshold).ifelse(1,0)
y_pred = y_pred.as_data_frame()
y_pred.columns = ['p1']

y_true1 = y_true.economy_20mpg 
y_pred1 = y_pred.p1
class_names = np.array(cars[""economy_20mpg""].levels()[0])

# Plot non-normalized confusion matrix
plot_confusion_matrix(y_true1, y_pred1, classes=class_names,
                      title='Confusion matrix')



image result:



Please note that there is a bug in the H2O-3 confusion matrix that has been noted here",2019-06-19T16:46:52,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56635755
56683304,56683304,6,"When you use H2O auto ml with the following lines of code : 


aml = H2OAutoML(max_models=10, seed=1, nfolds = 3,
                keep_cross_validation_predictions=True,
                exclude_algos = [""GLM"", ""DeepLearning"", ""DRF"", ""GBM""])
aml.train(x=x, y=y, training_frame=train)



you use the option 
nfolds = 3
, which means each algorithm will be trained three times using 2 thirds of the data as training and one third as validation. This allows the algorithm to be more stable and sometimes have better performance than if you only give your entire training dataset in one go.


This is what you do when you train your XGBoost using 
fit()
. Even though you have the 
same
 algorithm (XGBoost) with the 
same
 hyperparameters, you don't use the training set the same way H2O does. Hence the difference in your confusion matrices ! 


If you want to have the same performance when copying the best model, you can change the parameter 
H2OAutoML(..., nfolds = 0)




Furthermore there H2O's takes into account approximately 60 different parameters, you missed a few important ones in your dictionary like the 
min_child_weight
. So your xgboost is not exactly the same as your H2O which could explain the differences in performance",2019-06-20T09:50:14,marc_s,https://stackoverflow.com/users/13302/marc-s,752k,56629764
56551971,56551971,1,"Currently no such feature is implemented. This is is simply because contrary to CSV where there is no difference between and empty string and NULL, SQL has the notion of NULL so no such feature seems necessary.


But you are saying that for string columns you are not getting any N/A values in your H2O Frame, which sounds like a bug and I will look into it.",2019-06-11T21:35:19,Honza,https://stackoverflow.com/users/8621/honza,"4,409",56551679
56571210,56571210,1,"You could use 
randomsplit
 on your spark dataframe.


If you want to use the H2O-3 split_frame method, you would first have to convert your spark frame to an h2o frame. In which case you could use 
hc.as_h2o_frame(spark_df)
 where 
hc
 is your h2o_context (note: you would also need to create the 
h2o_context
 for this to work).",2019-06-12T22:38:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56535161
56571184,56571184,0,"take a look at the checkpointing option, details on how this works can be found in the user guide 
here


I will repost some of the content for your convenience:


In real-world scenarios, data can change. For example, you may have a model currently in production that was built using 1 million records. At a later date, you may receive several hundred thousand more records. Rather than building a new model from scratch, you can use the checkpoint option to create a new model based on the existing model.


The checkpoint option is available for DRF, GBM, and Deep Learning algorithms. This allows you to specify a model key associated with a previously trained model. This will build a new model as a continuation of a previously generated model. If this is not specified, then the algorithm will start training a new model instead of continuing building a previous model.


When setting parameters that continue to build on a previous model, specifically ntrees (in GBM/DRF) or epochs (in Deep Learning), specify the total amount of training that you want if you had started from scratch, not the number of additional epochs or trees you want. Note that this means the ntrees or epochs parameter for the checkpointed model must always be greater than the original value. For example:


If the first model builds 1 tree, and you want your new model to build 50 trees, then the continuation model (using checkpointing) would specify ntrees=50. This gives you a total of 50 trees including 49 new ones.
If your original model included 20 trees, and you specify ntrees=50 for the continuation model, then the new model will add 30 trees to the model, again giving you a total of 50 trees.


If your oringinal model included 20 trees, and you specify ntrees=10 (a lower value), then you will receive an error indicating that the requested ntrees must be higher than 21.",2019-06-12T22:33:41,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56517949
56510513,56510513,1,"As of this post, H2O-3 does not yet have native support of xgboost on Windows.


Your best bet in the short term is to try WSL, docker, or a virtual machine like VMware workstation or Virtualbox.


Of those options, at the moment, I would favor WSL.",2019-06-08T22:18:51,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56495634
56510541,56510541,0,"If you supply the “—detail” parameter to the PrintMojo tree printing tool you will get more information out.


In particular, you will see the weight of each node, which is the sum of row weights that passed in to the node.  (The default weight for each row is 1.0, but you can change it on a row-by-row basis by providing a weight column.)


The source code for PrintMojo is here:




https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/tools/PrintMojo.java",2019-06-08T22:25:08,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56430009
56346643,56346643,0,"I resolved the issue by adding the following maven coordinates to the packages option in spark-submit


--packages ai.h2o:h2o-jetty-8:3.24.0.3",2019-05-28T16:35:43,user238607,https://stackoverflow.com/users/3238085/user238607,"2,428",56346607
56358795,56358795,0,"If 
validation_frame
 is provided and 
nfolds
 >= 2 at the same time then first cross validation metrics will be computed and as a next step 
gbm
 will score on 
validation_frame
. So for example in Flow there will be two sections: 




Output - Validation Metrics


Output - Cross Validation Metrics",2019-05-29T10:49:05,Deil,https://stackoverflow.com/users/1020472/deil,512,56323306
56306038,56306038,5,"It is possible to access models like this: 


model_ids <- as.vector(automl_model@leaderboard$model_id)
index <- 2
model_2 <- h2o.getModel(model_ids[index])



, where 
index
 is a position of the model in the leaderboard.",2019-05-25T15:09:04,Deil,https://stackoverflow.com/users/1020472/deil,512,56297085
56290908,56290908,1,"Pass your option to the 
jvm_custom_args
 argument, not 
extra_classpath
, as in 
h2o.init(jvm_custom_args = ""-Dfile.encoding=UTF-8"")",2019-05-24T10:34:39,meriops,https://stackoverflow.com/users/2358685/meriops,"1,037",56288957
56307990,56307990,0,"My guess is that java process was still running( and holding port 54321) as restarting R(RStudio) does not kill it. Following attempts to start 
h2o
 from the console by default were choosing next available ports ( 54323, 54325).


If demo script has port being specified in 
h2o.init()
 it makes it a requirement to either connect to 
h2o
 process running on this port or to launch a new one on this port. Hanged process was an obstacle for both scenarios.  


So one solution is to find hanged process and kill it or change port in the demo script to a free one ( or just don't specify it as by default it will launch 
h2o
 at a next available port).",2019-05-25T19:22:42,Deil,https://stackoverflow.com/users/1020472/deil,512,56271717
56225573,56225573,0,"You can't install packages into Flow, Flow is simply the web UI that comes with H2O-3 (H2O-3 has multiple APIs). For more details on what Flow is please see the 
documentation
. Note: Sparkling Water is H2O-3's integration with Spark.",2019-05-20T17:24:52,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56215238
56187032,56187032,2,"@spore234 My guess is that your leader is a Stacked Ensemble model and this model is not supposed to have any cross validation predictions.


We should probably provide a meaningful warning for this case.


Let me also to point out that following line:


h2o.cross_validation_predictions(aml)



will throw a meaningful error as user is supposed to pass a 
H2OModel
 object but 
aml
 is an instance of 
H2OAutoML
 class.",2019-05-17T13:05:35,Deil,https://stackoverflow.com/users/1020472/deil,512,56181979
56226089,56226089,0,"This is not a bug in the algorithm (the splits are still correct) but in the way H2O-3 represent splits in the MOJO Tree visualizer and the tree API. I've created a JIRA ticket that you can track 
here
 (or add to), which will ensure the MOJO Tree Visualizer and tree API splits are less confusing (i.e., using numeric splits or showing the list of categorical levels instead of both). The numeric splits you see correspond to our internal method for doing categorical splits.",2019-05-20T18:07:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56140284
56134436,56134436,3,"You can do something like this-


valid_A <- as.data.frame(h2o.predict(gbmA,valid))
valid_B <- as.data.frame(h2o.predict(gbmB,valid))
valid_df <- as.data.frame(valid)
roc1 <- roc(valid_df$survived,valid_A$p1)
roc2 <- roc(valid_df$survived,valid_B$p1)


> roc.test(roc1,roc2)

    DeLong's test for two correlated ROC curves

data:  roc1 and roc2
Z = -0.087489, p-value = 0.9303
alternative hypothesis: true difference in AUC is not equal to 0
sample estimates:
AUC of roc1 AUC of roc2 
  0.9500141   0.9504367",2019-05-14T16:00:03,Rushabh Patel,https://stackoverflow.com/users/7120667/rushabh-patel,"2,764",56133829
56160757,56160757,0,"Make sure you have all the dependencies:


pip install requests tabulate  ""colorama>=0.3.8"" future


And install H2O from here:


pip install -f 
http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html
 h2o


It worked for me with no errors.",2019-05-16T04:15:04,TKMaker,https://stackoverflow.com/users/11506491/tkmaker,16,56120443
56134226,56134226,-1,"Change the Java version.
Use java 8.",2019-05-14T15:46:42,asb,https://stackoverflow.com/users/11499456/asb,1,56120443
60963764,60963764,0,"Firstly check the firewall on your system using tcping from another linux server or your windows to server which you installed h2o dai.


ex) tcping -t host-ip port (linux to linux)


If you get a response like bellows, have to open a specific port which your solution use.


[root@localhost /]# tcping -t 5 your-ip port


your-ip port port# closed.",2020-04-01T04:32:46,,,,56115850
56066992,56066992,0,"This error indicates that the data type of the column you want to merge on is of type string. Merges are not allowed on columns of type string, so when you parse your datasets, set the data type of your merge column to 
enum
. After that you should be able to do the merge.",2019-05-09T20:22:02,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56064670
56047978,56047978,1,"As Tom says, your autoencoder first layer is too big.


51,200 is a lot of features. How much correlation is there between them? The more correlation you have, the smaller the first layer of your autoencoder can happily be. 


Try 
h2o.prcomp()
 and seeing how many dimensions cover 99% of the variance, is often a good guide to how big your first layer can/should be.


Or, if you prefer a more experimental approach:




Start with, e.g. 200 neurons in one layer.


Look at the MSE it gets to, after enough epochs to stop improving.


Double the number of neurons in that layer.


See if the MSE gets any better. If not, stop there.


If it did, double again, and repeat.




You could then try moving to multiple layers. But not much point using a bigger first layer than the best you can get from trying a single layer.",2019-05-08T19:43:37,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,56036749
56039805,56039805,1,"Since your dataset has 51,200 features, and your layers array has 50,000 as the first value, 51200 * 50000 == 2.56e9 weights in that first set of network connections.


It’s too many, try smaller numbers.",2019-05-08T11:31:42,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",56036749
56067119,56067119,0,"For details on how to set up your JDBC driver or 
allowed data sources
 see the documentation 
here
. Feel free to update your question, if you run into issues getting setup.


Here is the 
list
 of acceptable file formats:


H2O currently supports the following file types:

CSV (delimited) files (including GZipped CSV)
ORC
SVMLight
ARFF
XLS (BIFF 8 only)
XLSX (BIFF 8 only)
Avro version 1.8.0 (without multifile parsing or column type modification)
Parquet",2019-05-09T20:30:31,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56027486
56137278,56137278,2,"yes you can apply the function to a single fold of interest, here is some example code:


library(h2o)
h2o.init()
prostate_path <- system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate <- h2o.uploadFile(path = prostate_path)
prostate_gbm <- h2o.gbm(3:9, ""AGE"", prostate, nfolds = 3)
h2o.predict(prostate_gbm, prostate)
h2o.predict_contributions(prostate_gbm, prostate)

# take a look at the output to see which key you want to use
# there are also other options to key names
prostate_gbm@model$cross_validation_models

# update this with the key of interest
key = 'GBM_model_R_1557326910287_7702_cv_2'
cv2 = h2o.getModel(key)
h2o.predict_contributions(cv2, prostate)

# RACE       DPROS      DCAPS         PSA        VOL     GLEASON __internal_cv_weights__ BiasTerm
# 1 -0.006481315 -0.19211742 -0.0836791 -0.06186131 -0.9217098 -0.20128664                       0 66.37209
# 2 -0.005238285 -1.09128833  0.9614767 -0.95340544 -0.7698430  0.06820074                       0 66.37209
# 3 -0.006481315  0.98101193  0.1770813  1.21195042 -1.0359415 -0.23213011                       0 66.37209
# 4  0.069538474 -0.01738315 -0.2000238  4.11799049  0.1177490 -0.01457024                       0 66.37209
# 5  0.012923095  0.40362182 -0.1132747  1.21669090  0.9920316 -0.37245926                       0 66.37209
# 6 -0.002282504 -0.91798097  0.9024866 -0.17398398 -0.6048008  0.42300656                       0 66.37209



Note: you can ignore the 
__internal_cv_weights__
 column. I've created a ticket to clean up the output that can be tracked 
here
.",2019-05-14T19:24:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",56009244
56009403,56009403,0,"Not directly with OOTB supported serv engines, but Watson OpenScale has a feature of supporting custom serv engines, documented in the below links, using which you can monitor the said models using AWS Lambda functions.


https://cloud.ibm.com/docs/services/ai-openscale?topic=ai-openscale-co-connect


https://developer.ibm.com/patterns/monitor-custom-machine-learning-engine-with-ai-openscale/


https://github.com/IBM/monitor-custom-ml-engine-with-watson-openscale


Thanks",2019-05-06T16:53:05,Ravi,https://stackoverflow.com/users/9068785/ravi,15,56008884
55959404,55959404,1,"Generally, no preprocessing is needed and the methods DAI uses for internal preprocessing are dependent on the algorithms behind the models. 


However, there are specific use cases that may require preprocessing and h2o can assist you with that if you contact them. For example, if you want to predict something at a customer level but your data is transactions, then you need to do preprocessing - say you have grocery store transactions and you want to predict how much the store will make tomorrow. Then you need to aggregate to the day store level since that is the level you want predictions at. Basically any case where the data is more granular than the level you want predictions at needs preprocessing.


For missing values it's best to let Driverless AI handle them unless you know why the values are missing and thus can use domain rules to fill them in. For example if you have transaction = NA but you know that means no money was spent, you'd want to change the NA to 0.


I think the following docs may be helpful: 
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/faq.html#data-experiments-predictions
. In particular the sections 'Can Driverless AI handle data with missing values/nulls?' and 'Does Driverless AI standardize the data?'.


You also can find a lot of information about what your experiment is doing in the experiment report: 
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/experiment-summary.html
. We don't currently report methods of standardization because it happens differently for each model in an ensemble that is potentially quite complex.",2019-05-02T19:58:07,,,,55954142
55952771,55952771,0,"The large difference between AUC and AUCPR is most likely caused, as you suggest, by the class imbalance. You can either try to set 
balance_classes = True
 or set weights to a column that would weight the minority class more, e.g. taking the inverse of the class frequency. If you have really small number of observations for the minority class, you can try to synthesise more using e.g. 
SMOTE
.",2019-05-02T12:44:52,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,55941654
55938118,55938118,0,"If you are interested in how the weights column in H2O-3 works you can review the documentation 
here
 and code examples 
here
.


I am included a copy of this document for your convenience:


weights_column


Available in: GBM, DRF, Deep Learning, GLM, AutoML, XGBoost, CoxPH
Hyperparameter: no


Description


This option specifies the column in a training frame to be used when determining weights. Weights are per-row observation weights and do not increase the size of the data frame. This is typically the number of times a row is repeated, but non-integer values are also supported. During training, rows with higher weights matter more, due to the larger loss function pre-factor.


For scoring, all computed metrics will take the observation weights into account (for Gains/Lift, AUC, confusion matrices, logloss, etc.), so it’s important to also provide the weights column for validation or test sets if you want to up/down-weight certain observations (ideally consistently between training and testing). Note that if you omit the weights, then all observations will have equal weights (set to 1) for the computation of the metrics. For example, a weight of 2 is identical to duplicating a row.


Notes:


Weights can be specified as integers or as non-integers.
The weights column cannot be the same as the fold_column.
If a weights column is specified as both a feature (predictor) and a weight, the column will be used for weights only.
Example unit test scripts are available on GitHub:

https://github.com/h2oai/h2o-3/blob/master/h2o-py/tests/testdir_algos/gbm/pyunit_weights_gbm.py


https://github.com/h2oai/h2o-3/blob/master/h2o-py/tests/testdir_algos/gbm/pyunit_weights_gamma_gbm.py


Observation Weights in Deep Learning


The observation weights are handled differently in Deep Learning than in the other supported algorithms. For algorithms other than Deep Learning, the weight goes into the split-finding and leaf-node prediction math in a straightforward way. For Deep Learning, it’s more difficult. Using the weight as a multiplicative factor in the loss will not work in general, and that would not be the same as replicating the same row. Also, applying the same row over and over isn’t a good idea either, so sampling during training should still be active. To address these issues, Deep Learning is implemented with importance sampling using the inverse cumulative distribution function. It also includes a special case that picks a random row from the dataset for every second row it trains, just to keep outliers in the game. Note that observation weights for Deep Learning that are neither 0 nor 1 are difficult to handle properly. In this case, it might be better to explicitly oversample using balance_classes=TRUE.


Related Parameters




balance_classes


offset_column


y",2019-05-01T14:49:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55930870
55893702,55893702,1,"The h2o package is not automatically installed in Google Colab. If you attempt to run 
import h2o
 without installing it, you will get the following error.


---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-1-accdebc0c7de> in <module>()
----> 1 import h2o

ModuleNotFoundError: No module named 'h2o'

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
""Open Examples"" button below.
---------------------------------------------------------------------------



Based on the error message you can then start a new code block and run 
!pip install h2o
 to install the package. Then, running 
import h2o
 should be successful. 


One more thing to keep in mind is that you need to include parentheses to call a function. Running 
h2o.init
 will return the description 
<function h2o.h2o.init>
. Try 
h2o.init()
 to initialize an h2o cluster.


Edit: The “not connected to a cluster”  means you have not initialized a cluster. Try the 
h2o.init()
 command again, but using parenthesis so that the function is called and not printed.",2019-04-28T19:11:28,,,,55893482
55873979,55873979,-1,"Actually I think I figured it out. In case you're running this tutorial don't try to download the file. Just un-comment the following lines 


from this :


# This takes time to run - left commented out
#w2v_model = H2OWord2vecEstimator(vec_size = 100, model_id = ""w2v.hex"")
#w2v_model.train(training_frame=words)



to this :


# This takes time to run - left commented out
w2v_model = H2OWord2vecEstimator(vec_size = 100, model_id = ""w2v.hex"")
w2v_model.train(training_frame=words)



Hope this helps someone out :)",2019-04-26T19:37:24,lol123,https://stackoverflow.com/users/8162260/lol123,9,55873785
55856332,55856332,2,"The short answer to the question is that you cannot use different training frames in a single grid.  Each grid of models must be associated with a single training set (the idea is that you do not want to compare models trained on different training sets).  This is why you are hitting the error.  It looks like each of your 
df.h2o
 training frames are different subsets of the original 
df
 frame. 


Another note: H2O and R's parallel functionality don't mix well.  H2O model training is already parallelized, but in a different way (for scalability reasons). The training of a single model is parallelized within H2O (on multiple cores), but H2O is not designed to train multiple models at once.  If you want to train multiple models at once on a single machine, then you would have to start multiple H2O clusters in different R sessions on different ports.",2019-04-25T19:23:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",55845076
64702631,64702631,2,"h2o.shutdown()
sometimes the session is running twice with two training datasets",2020-11-05T17:47:46,lsangha,https://stackoverflow.com/users/12287144/lsangha,39,55845076
56956445,56956445,0,"It could also be that you open the same h2o session twice at the same ip, with different training data and the h2o backend does not allow that.",2019-07-09T15:54:47,,,,55845076
55823688,55823688,3,"As per the comment instead of saving model using saveDRS/readRDS, save model as


h2oModelsaved <- h2o.saveModel(object = h2orf_model, path = ""C:/User/Models/"") 



Re-call model


h2o.init()
h2oModelLoaded <- h2o.loadModel(h2oModelsaved)



Convert the test data as h2o Frame


newdata <- as.h2o(testdata)



Then Call the predict


pred_h2orf2 <- predict(h2oModelLoaded, newdata = newdata)



This works perfect",2019-04-24T06:31:42,hanzgs,https://stackoverflow.com/users/11053801/hanzgs,"1,596",55823004
55776934,55776934,0,"Yes it the pkg appears to have been removed from the repository. I created the following on Mar 26th and it built successfully that day...


From ubuntu:16.04
RUN apt-get update
RUN apt-get upgrade -y
RUN apt-get install -y  software-properties-common
RUN add-apt-repository ppa:webupd8team/java -y
RUN apt-get update
RUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | /usr/bin/debconf-set-selections
RUN apt-get install -y oracle-java8-installer



And today this is the result


Step 8/8 : RUN apt-get install -y oracle-java8-installer
 ---> Running in 1bba5bac63e9
Reading package lists...
Building dependency tree...
Reading state information...
Package oracle-java8-installer is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or is only available from another source

E: Package 'oracle-java8-installer' has no installation candidate
The command '/bin/sh -c apt-get install -y oracle-java8-installer' returned a non-zero code: 100



I've already moved to OpenJDK and am experimenting with Corretto


Update
:


The PPA has been discontinued... see their notice here:

https://launchpad.net/~webupd8team/+archive/ubuntu/java",2019-04-20T19:22:50,Rondo,https://stackoverflow.com/users/442968/rondo,"3,681",55768013
55866246,55866246,0,You can just use openjdk-8 instead.,2019-04-26T11:03:41,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55768013
62729560,62729560,0,"I had a similar issue and I found the following image which is a prebuilt image to run h2o flow UI .


https://hub.docker.com/r/h2oai/h2o-open-source-k8s",2020-07-04T13:10:38,Rajesh Rajamani,https://stackoverflow.com/users/3510820/rajesh-rajamani,501,55768013
55713731,55713731,0,"The x argument takes in a list (or vector) of column names or indices. Check the data type of your predictors to verify whether you are passing in a vector of names or a dataframe. You can see an example of how to use this parameter 
here
.",2019-04-16T17:34:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55701958
55673357,55673357,0,"You either do this change before you load the data into the h2o cluster, or you do the change inside on the h2o cluster side on your flight.hex. See below an example with mtcars.


# change before loading data into h2o:
mtcars$new_condition <- ifelse(mtcars$mpg >= 20, 1, 
                               ifelse(mtcars$mpg <20, 0, NA))

library(h2o)
h2o.init()

mtcars.hex <- as.h2o(mtcars)

# change when data is inside h2o cluster
mtcars.hex$new_condition2 <- ifelse(mtcars.hex$mpg >= 20, 1, 
                                   ifelse(mtcars.hex$mpg <20, 0, NA))

mtcars.hex

   mpg cyl disp  hp drat    wt  qsec vs am gear carb new_condition new_condition2
1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4             1              1
2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4             1              1
3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1             1              1
4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1             1              1
5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2             0              0
6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1             0              0

[32 rows x 13 columns]",2019-04-14T08:26:45,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,55672999
55623852,55623852,0,"Ok i solved this embarrassingly quickly after submitting this question. Still it's worth keeping for others with similar problems.


The weights_column has to be specified by the 
name
 of the column in the h2o.data.frame. I.e. it has to be enclosed with quotation marks. It can't be a different h2o object or the index of the column. The following code works.


library(h2o)
x <- rnorm(1000)
y <- x-x^2+rnorm(1000,sd=0.2)
w <- vector(length=1000) #weights vector
w[] <- 1
dfx <- data.frame(x,y,w)
h2o.init()
dfx <- as.h2o(dfx)


H <- h2o.deeplearning(x = 1, y = 2,training_frame=dfx,weights_column = ""w"", hidden=c(5,4))",2019-04-11T02:34:02,Ingolifs,https://stackoverflow.com/users/8968617/ingolifs,311,55623803
55621782,55621782,1,"An alternative is to use an H2O 
MOJO
 model (instead of a 
binary model
 which needs to exist in H2O cluster memory to make predictions).  MOJO models can sit on disk and do not require a running H2O cluster.  Then you can skip Step 2 and use the 
h2o.mojo_predict_pandas()
 function in Step 3.",2019-04-10T21:48:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",55621457
55751434,55751434,0,"a VIF function isn't currently available in H2O-3, but you can always create a 
JIRA ticket
 and make a feature request for it, or try to do the calculation manually.


Alternatively, depending on your end goal, you could use the 
remove_collinear_columns
 which, as stated in the docs is used to: 
""specify whether to automatically remove collinear columns during model-building. When enabled, collinear columns will be dropped from the model and will have 0 coefficient in the returned model. This can only be set if there is no regularization (lambda=0).""",2019-04-18T17:56:22,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55617205
55596922,55596922,0,"It took me a while to figure out. Below dependency worked for me.


        <dependency>
            <groupId>ai.h2o</groupId>
            <artifactId>h2o-genmodel-ext-xgboost</artifactId>
            <version>3.22.0.3</version>
        </dependency>",2019-04-09T16:02:23,Prashant Gupta,https://stackoverflow.com/users/4428110/prashant-gupta,113,55582972
55566508,55566508,0,"YES..


As per pySparkling document I find :


PySparkling is an integration of Python with Sparkling Water. It allows user to start H2O services on a Spark cluster from Python API.


In the PySparkling driver program, the Spark Context, which uses Py4J to start the driver JVM and the Java Spark Context, is used to create the H2O Context (hc). That in turn starts an H2O cloud (cluster) in the Spark ecosystem. 
Once the H2O cluster is up, the H2O Python package is used to interact with it and run H2O algorithms.
 All pure H2O calls are executed via H2O’s REST API interface. Users can easily integrate their regular PySpark workflow with H2O algorithms using PySparkling.",2019-04-08T04:57:36,ARKAPROVA SAHA,https://stackoverflow.com/users/11327040/arkaprova-saha,1,55566277
55538865,55538865,0,"Here is a pointer to a git repo that has an example of how to host an H2O-3 MOJO in a REST API:




https://github.com/h2oai/app-consumer-loan",2019-04-05T15:30:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55538659
55504435,55504435,1,"you can use:




.asfactor()
 to convert to enum 


.asnumeric()
 to convert to numeric


.ascharacter()
 to convert to a character",2019-04-03T21:17:43,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55504026
55504039,55504039,0,"The best I've been able to do so far is to convert the h2o dataframe back to a pandas frame, then back to h2o while specifying new column types for the desired columns. Eg.


frame_in_h2o = h2o.H2OFrame(
    frame_in_h2o.as_data_frame(), 
    column_types={
        u'C': u'enum'
    })",2019-04-03T20:49:41,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",55504026
55525913,55525913,0,"as long as the categorical levels are the same, the order will be the same and the indices will be in assigned in the same way. 


splits are referring to tree based models.",2019-04-04T22:39:12,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55503702
55498254,55498254,2,"15GB of memory might not be enough for a training process you expect to last 8hrs. (Aside: I'd recommend using 
early stopping
, rather than, or as well as, 
max_runtime_secs
.)


As a debugging step, I would recommend watching in the Flow interface (point your browser to port 54321 - see the connection URL in your 
h2o.init()
 output). Especially watch how memory usage is rising over time.


(Sometimes a ""500"" error just means it has gone unstable, and lack of memory is a common trigger.)


If you are getting the error immediately, that is less likely to be the problem (unless you have a huge dataset).


In that case I'd try to narrow down if a particular column or data row could be causing the problem. E.g. 




Experiment 1: first half of columns in 
train_features


Experiment 2: second half of columns in 
train_features


Experiment 3: first half of rows in 
train_u


Experiment 4: second half of rows in 
train_u


Experiment 5/6 (if still no luck): the same for 
valid_u




If one of the experiment pair crashes but the other doesn't, then repeat the experiment on the crashing half.",2019-04-03T14:58:38,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,55485950
55524714,55524714,0,"here you go:


import h2o
h2o.init()

df1 = h2o.H2OFrame({'receipt_key': ['a1', 'a2'] , 'b':[1,3] , 'c':[2,4], 'item_id': [1,1]})
df1['receipt_key'] = df1['receipt_key'] .asfactor()
df2 = h2o.H2OFrame({'receipt_key': ['a1', 'a1','a2'] , 'e':[5,7,9] , 'f':[6,8,10], 'item_id': [1,2,1]})
df2['receipt_key'] = df2['receipt_key'].asfactor()

df3 = df1.merge(df2)
df_subset = df3[['receipt_key','b','c','e','f','item_id']]
print(df_subset)

receipt_key b   c   e   f   item_id
a1          1   2   5   6   1
a2          3   4   9   10  1",2019-04-04T20:52:34,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55484531
55497915,55497915,0,"Unfortunately, there is no support for saving encoding maps in the model yet.  But this is something we are working on right now. To answer your questions:




No, for now model object has no information about encoding maps. Model takes data as input and have no idea about whether target encoding was applied or not.


As for now you can't save encodings along with the model.",2019-04-03T14:42:57,Deil,https://stackoverflow.com/users/1020472/deil,512,55473526
55465650,55465650,0,"Looking at the h2o docs for categorical encodings (
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/categorical_encoding.html
), for the 
enum
 types (which what I am using for the categorical types in my h2o dataframe) we see




enum or Enum: Leave the dataset as is, 
internally map the strings to
  integers, and use these integers
 to make splits - either via ordinal
  nature when nbins_cats is too small to resolve all levels or via
  bitsets that do a perfect group split. Each category is a separate
  category; 
its name (or number) is irrelevant
. For example, after the
  strings are mapped to integers for Enum, you can split {0, 1, 2, 3, 4,
  5} as {0, 4, 5} and {1, 2, 3}.




So if I am interpreting this correctly (and someone please tell if if this is not correct), what is happening is that when converting the pandas frame to h2o, it is going through the different values for the columns assigned as being 
enum
 types and assigning an internal unique ID integer value to that label (which is used in training and predictions and such, but we normally just don't see). Thus, when doing a 
df.group_by(.).sum(.)
 on those 
enum
 columns, 
we are just adding up all the internally mapped integer values for those columns
 that h2o assigned when the dataframe was converted to an h2o dataframe.


Again, if this is not the most complete interpretation of what is going on here, someone please let me know.",2019-04-02T01:23:42,,,,55465319
55526153,55526153,0,"It looks like you want to use the function 
makeGLMModel


This is further described in the 
documentation
, and I will repost here for your convenience:


Modifying or Creating a Custom GLM Model


In R and python, the 
makeGLMModel
 call can be used to create an H2O model from given coefficients. It needs a source GLM model trained on the same dataset to extract the dataset information. To make a custom GLM model from R or python:




R: call 
h2o.makeGLMModel
. This takes a model, a vector of coefficients, and (optional) decision threshold as parameters.


Pyton: 
H2OGeneralizedLinearEstimator.makeGLMModel
 (static method) takes a model, a dictionary containing coefficients, and (optional) decision threshold as parameters.",2019-04-04T23:10:09,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55383781
55410557,55410557,0,"No, this is not currently supported, but I created a 
ticket
 to support it in the future.  I have not tried it, but you might be able to get it to work if you use the 
blending_frame
 argument instead of relying on cross-validated base models.",2019-03-29T04:34:53,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",55378660
55379456,55379456,0,"The Deep Learning model in particular can continuously train forever if you keep presenting new data.  So you could do online training with that.


Models like DRM and GBM can “add another tree” from new data using a checkpoint, although you really don’t want to end up with infinity trees.


You could keep around a window of data and periodically train a new complete model.  (Swapping in a new model instance at runtime is pretty straighforward.  So you could just keep training in the background and update the model that predicts on streaming data periodically — like every hour or every few minutes, or whatever).


Or do your own ensembling by averaging the prediction of many models — by periodically throwing away older models and adding newer ones in a conveyor-belt type of strategy.  Similar to a moving average.",2019-03-27T14:17:17,,,,55378452
55362434,55362434,0,"The Word2Vec algorithm is a data transformation algorithm (converting rows of text to a matrix), not a supervised machine learning algorithm (which is what AutoML and all the algorithms inside of it do).  


The typical way that Word2Vec is used is it apply Word2Vec to your text data so that your data can be used to train a supervised ML algorithm.  From here you can run any supervised algorithm (GLM, Random Forest, GBM, etc) on this transformed dataset -- or my recommendation is to just pass the transformed data to AutoML, so it can find the best algorithm for you. 


You will have to try out different settings for Word2Vec manually and see how well they do, given some particular supervised learning algorithm that you want to apply to your problem.  Hopefully that clears up the confusion.",2019-03-26T16:54:05,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",55359773
55359544,55359544,0,"See algorithm 15.1 from the Elements of Statistical Learning:




https://web.stanford.edu/~hastie/Papers/ESLII.pdf




And then see the code for the implementation of the model training process in H2O-3:




https://github.com/h2oai/h2o-3/blob/master/h2o-algos/src/main/java/hex/tree/drf/DRF.java




Finally, the best way to understand how the actual generated model is used for producing scores is the genmodel MOJO implementation which you can find here (try using a java debugger to single-step through a call to score0()):




https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/drf/DrfMojoModel.java",2019-03-26T14:26:14,,,,55347180
55388834,55388834,0,"I found a solution which returns the exact probability rate of train data set as the prediction value in the sample tree. you just need to set your code as follow:


h2o.randomforest(sample_rate = 1, calibrate_model = TRUE, and calibration_frame = train )",2019-03-28T01:21:08,mohammad,https://stackoverflow.com/users/11257348/mohammad,1,55347180
55359757,55359757,1,"If you treat the problem as a binary classification problem then you not only get the “prediction” of 0 or 1, but also the p0 and p1 probabilities that add up to 1.  These are the probabilies that the predicted value is the negative and positive class, respectively.


Then just use p1 directly.",2019-03-26T14:35:09,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55346860
55386904,55386904,0,"Building on the example 
here
, you can access the mapping after calling 
targetEncoder.fit(ext_train)
 with:


encodingMapFramesKeys = list(map(lambda x: h2o.get_frame(x['key']['name']), targetEncoder._encodingMap.frames))

encodingMapFramesKeys[0].describe()
encodingMapFramesKeys[1].describe()",2019-03-27T21:41:19,Joe,https://stackoverflow.com/users/10913732/joe,268,55310289
55637039,55637039,2,"The issue is because you are trying encoding multiple categorical features. I think that is a bug of H2O, but you can solve putting the transformer in a for loop that iterate over all categorical names.


import numpy as np
import pandas as pd
import h2o
from h2o.targetencoder import TargetEncoder
h2o.init()

df = pd.DataFrame({
    'x_0': ['a'] * 5 + ['b'] * 5,
    'x_1': ['c'] * 9 + ['d'] * 1,
    'x_2': ['a'] * 3 + ['b'] * 7,
    'y_0': [1, 1, 1, 1, 0, 1, 0, 0, 0, 0]
})

hf = h2o.H2OFrame(df)
hf['cv_fold_te'] = hf.kfold_column(n_folds=2, seed=54321)
hf['y_0'] = hf['y_0'].asfactor()
cat_features = ['x_0', 'x_1', 'x_2']

for item in cat_features:
    target_encoder = TargetEncoder(x=[item], y='y_0', fold_column = 'cv_fold_te')
    target_encoder.fit(hf)
    hf = target_encoder.transform(frame=hf, holdout_type='kfold',
                                  seed=54321, noise=0.0)
hf",2019-04-11T16:16:42,,,,55306686
56107654,56107654,0,"Thanks everyone for letting us know. Assertion was a precaution as I was not sure whether there could be the case that order could be changed. Rest of the code was written with this assumption in mind and therefore safe to use with changed order anyway, but assertion was left and forgotten. Added test and removed assertion. Now this issue is fixed and merged. Should be available in the upcoming fix release. 
0xdata.atlassian.net/browse/PUBDEV-6474",2019-05-13T07:35:30,,,,55306686
55273532,55273532,2,"The first issue is likely that your 
""X""
 is of type string, you can do a check by running 
df1[""X""].types
. You can convert this to a factor column, which will then allow you to use 
table()
 by doing 
df1[""X""]=df1[""X""].asfactor()
.


The reason you are seeing the second error is probably because 
d3
 failed to be created when you ran 
df3 = df2.merge(df1)
.


I would recommend verifying your column data types, fixing those that need to be converted to factors and then trying the merge again.",2019-03-21T03:54:40,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55272948
55251437,55251437,2,"It is not lazy evaluation.


It is reading in the data and storing the data in a column-compressed in-memory distributed key-value store.


Here is a good picture describing the overall process:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html#how-r-and-python-interacts-with-h2o",2019-03-19T23:28:54,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55251381
55266596,55266596,0,"EDITED
 


The Sparkling Water Droplets were just updated as of a few hours ago. So hopefully you should have what you need now.",2019-03-20T17:13:44,,,,55222540
55225070,55225070,1,"If you want to install h2o from within R please follow the download instructions 
here
 (this link will provide you with the latest stable version). 
for your convenience I am also pasting what is currently listed under the R tab (below):


Please also note that it looks like you ran 
h20
 instead of 
h2o
 (like water) in 
conda install c -r anaconda h20
 and in addition looking at the 
anaconda docs
 if you want to install an r package you need to pre-fix the package with an 
r-
, and lastly if you want to install h2o from anaconda you should use the 
h2oai
 channel not the default anaconda channel. That being said if you do a search for the 
r-h2o
 package you will see if is not available for download in this manner 
conda search -f r-h2o
 so your best option is to install through R via the instructions pasted below. 


Copy and paste these commands into R one line at a time:

# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

# Next, we download packages that H2O depends on.
pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-xu/6/R"")

# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()",2019-03-18T15:43:25,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55218074
55215203,55215203,0,"When the job is done you can access the log output with the “yarn logs”
command.


When you run h2o on hadoop it prints the appropriate (filled in with your job id) yarn log command to stdout.


it will look something like:


yarn logs -applicationId nnn",2019-03-18T05:47:29,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55214516
55228284,55228284,1,"I would recommend upgrading to the latest version of Sparkling Water (currently 
2.3.26
 and available 
here
), since you are using 
2.3.12
 and there have been several fixes for hanging issues since then. Hopefully a quick upgrade fixes your issue.",2019-03-18T18:55:57,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55196441
55226755,55226755,0,"My recommendation would be to check the type of the two objects you are passing to the 
predict
 function and verify that your target column which contains labels is of the type you want it to be. The error message indicates that the predict function was expecting a label column of type integer but got something else.


In addition, I would take a look at the AutoML code example in the 
documentation
 and verify that you are replicating the same steps before using the predict function.",2019-03-18T17:17:44,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55194145
55337889,55337889,0,"This 
problem is related to the H2O version
. So try to downgrade (version 3.22.1.6):


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

# Next, we download packages that H2O depends on.
pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-xu/6/R"")

# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()



EDIT: 
https://github.com/h2oai/h2o-tutorials/issues/107",2019-03-25T12:33:36,,,,55194145
58243385,58243385,1,"I ran into the same problem in version 3.26.0.6 and solved it by changing the protocol to s3a instead of s3:


h2o.save_model(model=best_gbm1,path='s3a://bucketname/folder1/folder2', force=False)



I.e. use the object-based S3 overlay instead of the block-based one.",2019-10-04T21:32:33,Datoraki,https://stackoverflow.com/users/709910/datoraki,"1,223",55182284
55227354,55227354,0,"The ability to save an h2o-3 model to s3 via the 
save_model()
 is not currently supported (as of version 3.22.1.6).",2019-03-18T17:53:38,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55182284
55225163,55225163,0,"You should install the latest stable version of H2O from the h2oai channel rather than the default anaconda package as well as making sure you didn't install a package called 
h2o-py
 which is a different package than the 
h2o
 package.


You can do this by running the following which is further described in the h2o-3 
docs
.


conda install -c h2oai h2o=3.22.1.2




where 
3.22.1.2
 is whatever version you are interested in.


Once you have gotten the correct version of h2o, 
import h2o
 should work. The last thing to verify is that you installed the version of h2o in the same conda environment that you are trying to import h2o.",2019-03-18T15:48:15,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55177382
55180071,55180071,0,"You can't put an almost-unique categorical feature in a predictor (autoencoder or anything else) and expect it to work.


Instead you need to extract meaningful features from it, which depend on the problem you want to solve. For example if it is a credit card number you could add a feature encoding the card circuit (VISA, Mastercard, American Express, ...).

The limit is only your imagination and knowledge of the domain.",2019-03-15T10:04:41,marco romelli,https://stackoverflow.com/users/9055614/marco-romelli,"1,163",55177163
55224768,55224768,1,"There is a JIRA ticket 
here
 to help with the confusion by printing a clearer message. Currently this message is only available for the multinomial case but will be added for binary classification problems as well. 


For example if you run the confusion matrix on the iris dataset which solves a multi-class problem you will get the following output.


Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
                Iris-setosa Iris-versicolor Iris-virginica  Error      Rate
Iris-setosa              42               0              0 0.0000 =  0 / 42
Iris-versicolor           0              37              2 0.0513 =  2 / 39
Iris-virginica            0               1             35 0.0278 =  1 / 36
Totals                   42              38             37 0.0256 = 3 / 117



so to answer your question: the row labels are the Actual class, and the column labels are the Predicted class.",2019-03-18T15:27:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55160293
55157300,55157300,1,"What version of H2O are you using? The ""ordinal"" option for 
family
 
looks like
 it was added in 3.18.0.3.


Hopefully 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html#logistic-ordinal-regression-ordinal-family
 answers your other questions? It explains the mathematical differences between ""ordinal"" and ""multinomial"".


(But I think the short answer to the question in your edit is ""yes"", as it says: ""[it is for] variables that are discreet, as in classification, but that can be ordered, as in regression."")",2019-03-14T07:45:32,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,55138112
55110309,55110309,5,"After data ingestion into H2O-3, the data lives in-memory inside the java server process.  Once the H2O process is stopped, the in-memory data vanishes.


Probably the main thing to be aware of is your data is not sent to a SaaS cloud service or anything like that.  The H2O-3 java instance itself handles your data.  You can create models in a totally air-gapped, no-internet environment.


So the short answer is, it’s perfectly safe if you know what threats you are trying to secure against and do the right things to avoid the relevant vulnerabilities (including data vulnerabilities like leaking PII and software vulnerabilities like not enabling passwords or SSL).


You can read about how to secure H2O instances and the corresponding R client here:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/security.html




(Note if you have a high-value use case and want detailed personal help with this kind of thing, H2O.ai the company offers paid enterprise support.)",2019-03-11T20:58:40,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",55109739
55083154,55083154,13,"Here's a solution using the example from the 
H2O AutoML User Guide
.  The parameters for any model are stored in the 
model.params
 location.  So if you want to grab the parameters for the leader model, then you can access that here: 
aml.leader.params
.  If you wanted another model, you would grab that model into an object in Python using the 
h2o.get_model()
 function and similarly, access the params using 
.params
.


The 
.params
 object is a dictionary which stores all the parameter values (default and actual).  


import h2o
from h2o.automl import H2OAutoML

h2o.init()

# Import a sample binary outcome train/test set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()
test[y] = test[y].asfactor()

# Run AutoML for 20 base models (limited to 1 hour max runtime by default)
aml = H2OAutoML(max_models=20, seed=1)
aml.train(x=x, y=y, training_frame=train)



The top of the leaderboard looks like this:


In [3]: aml.leaderboard
Out[3]:
model_id                                                  auc    logloss    mean_per_class_error      rmse       mse
---------------------------------------------------  --------  ---------  ----------------------  --------  --------
StackedEnsemble_AllModels_AutoML_20190309_152507     0.788879   0.552328                0.315963  0.432607  0.187149
StackedEnsemble_BestOfFamily_AutoML_20190309_152507  0.787642   0.553538                0.317995  0.433144  0.187614
XGBoost_1_AutoML_20190309_152507                     0.785199   0.557134                0.327844  0.434681  0.188948
XGBoost_grid_1_AutoML_20190309_152507_model_4        0.783523   0.557854                0.318819  0.435249  0.189441
XGBoost_grid_1_AutoML_20190309_152507_model_3        0.783004   0.559613                0.325081  0.435708  0.189841
XGBoost_2_AutoML_20190309_152507                     0.782186   0.558342                0.335769  0.435571  0.189722
XGBoost_3_AutoML_20190309_152507                     0.7815     0.55952                 0.319151  0.436034  0.190126
GBM_5_AutoML_20190309_152507                         0.780837   0.559903                0.340848  0.436191  0.190263
GBM_2_AutoML_20190309_152507                         0.780036   0.559806                0.339926  0.436415  0.190458
GBM_1_AutoML_20190309_152507                         0.779827   0.560857                0.335096  0.436616  0.190633

[22 rows x 6 columns]



Here the leader is a Stacked Ensemble.  We can look at the parameter names like this:


In [6]: aml.leader.params.keys()
Out[6]: dict_keys(['model_id', 'training_frame', 'response_column', 'validation_frame', 'base_models', 'metalearner_algorithm', 'metalearner_nfolds', 'metalearner_fold_assignment', 'metalearner_fold_column', 'keep_levelone_frame', 'metalearner_params', 'seed', 'export_checkpoints_dir'])
In [7]: aml.leader.params['metalearner_algorithm']
Out[7]: {'default': 'AUTO', 'actual': 'AUTO'}



If you are interested in the GLM (as you mentioned above), then you can grab it like this and examine the hyperparameter values.


# Get model ids for all models in the AutoML Leaderboard
model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])
# Get the GLM model
m = h2o.get_model([mid for mid in model_ids if ""GLM"" in mid][0])  



Now look at the parameter names and then check out the default and actual values:


In [11]: m.params.keys()
Out[11]: dict_keys(['model_id', 'training_frame', 'validation_frame', 'nfolds', 'seed', 'keep_cross_validation_models', 'keep_cross_validation_predictions', 'keep_cross_validation_fold_assignment', 'fold_assignment', 'fold_column', 'response_column', 'ignored_columns', 'ignore_const_cols', 'score_each_iteration', 'offset_column', 'weights_column', 'family', 'tweedie_variance_power', 'tweedie_link_power', 'solver', 'alpha', 'lambda', 'lambda_search', 'early_stopping', 'nlambdas', 'standardize', 'missing_values_handling', 'compute_p_values', 'remove_collinear_columns', 'intercept', 'non_negative', 'max_iterations', 'objective_epsilon', 'beta_epsilon', 'gradient_epsilon', 'link', 'prior', 'lambda_min_ratio', 'beta_constraints', 'max_active_predictors', 'interactions', 'interaction_pairs', 'obj_reg', 'export_checkpoints_dir', 'balance_classes', 'class_sampling_factors', 'max_after_balance_size', 'max_confusion_matrix_size', 'max_hit_ratio_k', 'max_runtime_secs', 'custom_metric_func'])

In [12]: m.params['nlambdas']
Out[12]: {'default': -1, 'actual': 30}",2019-03-09T23:53:28,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",55081358
56652371,56652371,1,"To further Erin LeDell's answer, if you want to use the BestOfFamily model as recommended by the AutoMl documentation (""The 'Best of Family' ensemble is optimized for production use since it only contains six (or fewer) base_models""):


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html


Getting the hyperparameters of the base_models so that you can retrain on different data is a bit more involved:


Similar to the last answer, we can start by outputting the leaderboard:


from h2o.automl import H2OAutoML
aml = H2OAutoML(max_runtime_secs=int(60*30), seed = 1)
aml.train(x=predictors, y=response, training_frame=df_h20)
lb = aml.leaderboard
lbdf = lb.as_data_frame()
lbdf.head()



yields:


AutoML progress: |████████████████████████████████████████████████████████| 100%

model_id    mean_residual_deviance  rmse    mse mae rmsle
0   StackedEnsemble_BestOfFamily_AutoML_20190618_1...   6.960772    2.638328    6.960772    1.880983    0.049275
1   StackedEnsemble_AllModels_AutoML_20190618_145827    6.960772    2.638328    6.960772    1.880983    0.049275
2   GBM_1_AutoML_20190618_145827    7.507970    2.740068    7.507970    1.934916    0.050984
3   DRF_1_AutoML_20190618_145827    7.781256    2.789490    7.781256    1.959508    0.051684
4   GLM_grid_1_AutoML_20190618_145827_model_1   9.503375    3.082754    9.503375    2.273755    0.058174
5   GBM_2_AutoML_20190618_145827    18.464452   4.297028    18.464452   3.259346    0.079722



However, using 
m.params.keys()
 shows no way of getting the base_model hyperparameters:


model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])
m = h2o.get_model(model_ids[0])
m.params['base_models']



returning:


{'default': [],
 'actual': [{'__meta': {'schema_version': 3,
    'schema_name': 'ModelKeyV3',
    'schema_type': 'Key<Model>'},
   'name': 'GBM_1_AutoML_20190618_145827',
   'type': 'Key<Model>',
   'URL': '/3/Models/GBM_1_AutoML_20190618_145827'},
  {'__meta': {'schema_version': 3,
    'schema_name': 'ModelKeyV3',
    'schema_type': 'Key<Model>'},
   'name': 'DRF_1_AutoML_20190618_145827',
   'type': 'Key<Model>',
   'URL': '/3/Models/DRF_1_AutoML_20190618_145827'},
  {'__meta': {'schema_version': 3,
    'schema_name': 'ModelKeyV3',
    'schema_type': 'Key<Model>'},
   'name': 'GLM_grid_1_AutoML_20190618_145827_model_1',
   'type': 'Key<Model>',
   'URL': '/3/Models/GLM_grid_1_AutoML_20190618_145827_model_1'}]}



You have to get a list of the URL of every base_model:


urllist = []
for model in m.params['base_models']['actual']:
    urllist.append(model['URL'])

print(urllist)



giving:


['/3/Models/GBM_1_AutoML_20190618_145827', '/3/Models/DRF_1_AutoML_20190618_145827', '/3/Models/GLM_grid_1_AutoML_20190618_145827_model_1']



And then after that, you can see which hyperparameters are non-default by using the requests library:


for url in urllist:
    r = requests.get(""http://localhost:54321""+url)
    model = r.json()
    print(url)

    for i in np.arange(len(model['models'][0]['parameters'])):

        if model['models'][0]['parameters'][i]['label'] in ['model_id','training_frame','validation_frame','response_column']:
            continue

        if model['models'][0]['parameters'][i]['default_value'] != model['models'][0]['parameters'][i]['actual_value']:
            print(model['models'][0]['parameters'][i]['label'])
            print(model['models'][0]['parameters'][i]['actual_value'])
            print("" "")",2019-06-18T15:21:45,David Jacques,https://stackoverflow.com/users/7535311/david-jacques,348,55081358
60871936,60871936,1,"Besides the above, you can connect to the H2O server (FLOW) at the local URL ""
http://localhost:54321
"" (or other port you are running on) and click on the model you want and inspect the parameters.",2020-03-26T16:36:57,Stavros Limberopoulos,https://stackoverflow.com/users/13130213/stavros-limberopoulos,11,55081358
60288127,60288127,0,"supporting DaveJay's answer. 


As mentioned in the following URL, get_params helps 
https://0xdata.atlassian.net/browse/PUBDEV-6396


Unfortunately, it does not work for getting parameters for AutoML leader. I added comment on the board 
https://0xdata.atlassian.net/browse/PUBDEV-6396
 and would re-open this issue if I do not get a response in some time.",2020-02-18T19:26:19,,,,55081358
55041253,55041253,1,"pomOnly()
 in 
build.sbt
 indicates to the dependency management handlers that jar libs/artifacts for this dependency should not be loaded and to only look for the metadata.


Try to use 
libraryDependencies += ""ai.h2o"" % ""h2o-core"" % ""3.22.1.3""
 instead.


Edit 1:
 Additionally I think you are missing (at least) one library dependency:

libraryDependencies += ""ai.h2o"" % ""h2o-automl"" % ""3.22.1.3""
 


see: 
https://search.maven.org/artifact/ai.h2o/h2o-automl/3.22.1.5/pom


Edit 2:

The last dependency you are missing is sparkling-water-core: 

libraryDependencies += ""ai.h2o"" % ""sparkling-water-core_2.11"" % ""2.4.6""
 should do the trick.


Here is the github of 
sparkling-water/core/src/main/scala/org/apache/spark/h2o

.",2019-03-07T10:15:53,,,,55039924
55227811,55227811,0,"If you get an ""out of bounds"" error (e.g. 
java.lang.ArrayIndexOutOfBoundsException
), you should check if there is anything you are iterating over, during multiple runs of your glm function. To help debug the issue I would remove all but the simplest arguments and then slowly add arguments in while running whatever set of steps led to the issue, until you can identify the parameter that is causing the out of bounds error.",2019-03-18T18:23:54,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55029227
55290120,55290120,1,"The following code works for me without duplicates. The only major difference from the code you posted is I uncommented the line 
fold_column = ""fold""
:


library(h2o)

h2o.init()

loan <- readr::read_csv(""loan.csv"")
#> Parsed with column specification:
#> cols(
#>   loan_amnt = col_double(),
#>   term = col_character(),
#>   int_rate = col_double(),
#>   emp_length = col_double(),
#>   home_ownership = col_character(),
#>   annual_inc = col_double(),
#>   purpose = col_character(),
#>   addr_state = col_character(),
#>   dti = col_double(),
#>   delinq_2yrs = col_double(),
#>   revol_util = col_double(),
#>   total_acc = col_double(),
#>   bad_loan = col_double(),
#>   longest_credit_length = col_double(),
#>   verification_status = col_character()
#> )

loan$ID <- seq.int(nrow(loan))
dplyr::glimpse(loan)
#> Observations: 163,987
#> Variables: 16
#> $ loan_amnt             <dbl> 5000, 2500, 2400, 10000, 5000, 3000, 5600,…
#> $ term                  <chr> ""36 months"", ""60 months"", ""36 months"", ""36…
#> $ int_rate              <dbl> 10.65, 15.27, 15.96, 13.49, 7.90, 18.64, 2…
#> $ emp_length            <dbl> 10, 0, 10, 10, 3, 9, 4, 0, 5, 10, 0, 3, 3,…
#> $ home_ownership        <chr> ""RENT"", ""RENT"", ""RENT"", ""RENT"", ""RENT"", ""R…
#> $ annual_inc            <dbl> 24000.00, 30000.00, 12252.00, 49200.00, 36…
#> $ purpose               <chr> ""credit_card"", ""car"", ""small_business"", ""o…
#> $ addr_state            <chr> ""AZ"", ""GA"", ""IL"", ""CA"", ""AZ"", ""CA"", ""CA"", …
#> $ dti                   <dbl> 27.65, 1.00, 8.72, 20.00, 11.20, 5.35, 5.5…
#> $ delinq_2yrs           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
#> $ revol_util            <dbl> 83.70, 9.40, 98.50, 21.00, 28.30, 87.50, 3…
#> $ total_acc             <dbl> 9, 4, 10, 37, 12, 4, 13, 3, 23, 34, 9, 11,…
#> $ bad_loan              <dbl> 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, …
#> $ longest_credit_length <dbl> 26, 12, 10, 15, 7, 4, 7, 7, 13, 22, 7, 8, …
#> $ verification_status   <chr> ""verified"", ""verified"", ""not verified"", ""v…
#> $ ID                    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…

df <- as.h2o(loan)

df$bad_loan <- as.factor(df$bad_loan)
df$addr_state <- as.factor(df$addr_state)

# Split Frame into training and testing
splits <- h2o.splitFrame(df, seed = 1234,
                         destination_frames=c(""train.hex"", ""test.hex""),
                         ratios = 0.75)
train <- splits[[1]]
test <- splits[[2]]

response <- ""bad_loan""
predictors <- c(""loan_amnt"", ""int_rate"", ""emp_length"", ""annual_inc"", ""dti"",
                ""delinq_2yrs"", ""revol_util"", ""total_acc"", ""longest_credit_length"",
                ""verification_status"", ""term"", ""purpose"", ""home_ownership"",
                ""addr_state"")


train$fold <- h2o.kfold_column(train, 5, seed = 1234)
te_map <- h2o.target_encode_create(train, x = list(""addr_state""),
                                   y = response, fold_column = ""fold"")

ext_train <- h2o.target_encode_apply(train, x = list(""addr_state""), y = response,
                                     target_encode_map = te_map, holdout_type = ""KFold"",
                                     fold_column = ""fold"",
                                     blended_avg = TRUE, noise_level = 0, seed = 1234)
#> Warning in h2o.target_encode_apply(train, x = list(""addr_state""),
#> y = response, : The string columns: term, home_ownership, purpose,
#> verification_status were dropped from the dataset

ext_test <- h2o.target_encode_apply(test, x = list(""addr_state""), y = response,
                                    target_encode_map = te_map, holdout_type = ""None"",
                                    fold_column = ""fold"",
                                    blended_avg = FALSE, noise_level = 0)
#> Warning in h2o.target_encode_apply(test, x = list(""addr_state""),
#> y = response, : The string columns: term, home_ownership, purpose,
#> verification_status were dropped from the dataset

nrow.H2OFrame(test)
#> [1] 40925
nrow.H2OFrame(ext_test)
#> [1] 40925



Created on 2019-03-21 by the 
reprex package
 (v0.2.1)",2019-03-21T22:21:41,Joe,https://stackoverflow.com/users/10913732/joe,268,55028999
55228193,55228193,0,"H2O-3 requires that when building a model, your: ""Training data must have at least 2 features (incl. response).""


There are however functions like 
h2o.mean()
 or 
h2o.sd()
 that allow you to get the mean and standard deviation of a column in an H2OFrame, respectively, which might be of use to your task.",2019-03-18T18:50:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",55009590
55000205,55000205,3,"The calculations don't match because MSE is calculated in the normalised space. If you set 
standardize=FALSE
 param in 
h2o.deeplearning()
 it will match:


unmod.dl <- h2o.deeplearning(x=feature_names, standardize = FALSE,
                             training_frame=unmod.hex,
                             autoencoder = TRUE,
                             reproducible = T,
                             hidden = c(3,2,3), epochs = 50,
                             activation = ""Tanh"")

mod.out <- as.data.frame(h2o.predict(unmod.dl, mod.hex, type=response))

mod.anon <- h2o.anomaly(unmod.dl, mod.hex, per_feature=FALSE)
mse.list <- as.data.frame(mod.anon)
mse.list

> mse.list
  Reconstruction.MSE
1           1512.740
2           1777.491
3           1458.438
4           1587.593
5           1648.999

> mod.anon.validate <- apply((test_dat - mod.out)^2, 1, mean)
> mse.list.validate <- as.data.frame(mod.anon.validate)
> mse.list.validate
  mod.anon.validate
1          1512.740
2          1777.491
3          1458.438
4          1587.593
5          1648.999",2019-03-05T10:04:26,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,54975474
55717738,55717738,2,"Here's an example of how to normalize:


#Load test and training data.
test_dat <- sample.test
train_dat <- sample.train

#Start H2O
library(h2o)
localH2O <- h2o.init(port =54321, strict_version_check = FALSE)

#Training and deep learning
feature_names <- names(train_dat[1:3])
unmod.hex <- as.h2o(train_dat, destination_frame=""train.hex"") 
mod.hex <- as.h2o(test_dat, destination_frame=""test.hex"")
unmod.dl <- h2o.deeplearning(x=feature_names,
                             training_frame=unmod.hex,
                             autoencoder = TRUE,
                             reproducible = T,
                             hidden = c(3,2,3), epochs = 50,
                             activation = ""Tanh"")

# Anomaly Detection
mod.anon <- h2o.anomaly(unmod.dl, mod.hex, per_feature=FALSE)
mse.list <- as.data.frame(mod.anon)

# Manual MSE
mod.out <- as.data.frame(h2o.predict(unmod.dl, mod.hex, type=response))

# Scale Output
s <- apply(train_dat, 2, max) - apply(train_dat, 2, min)
m <- apply(train_dat, 2, mean)

original_scaled <- t(apply(test_dat, 1, function(x) (x-m)/s))
recreate_scaled <- t(apply(mod.out, 1, function(x) (x-m)/s))

mod.anon.validate <- apply((original_scaled - recreate_scaled)^2, 1, mean)
mse.list.validate <- as.data.frame(mod.anon.validate)

# Compare Outputs
print(mse.list)
print(mse.list.validate)",2019-04-16T23:08:01,Joe,https://stackoverflow.com/users/10913732/joe,268,54975474
54988674,54988674,1,"Based on your naming convention, are you expecting input_file_column_names to be a list of 12 strings? When printing we see the following 10 column names:


['Date',
 'GenOut',
 'GenVar',
 'TurbBearingVib1',
 'TurbBearingVib2',
 'TurbBearingVib3',
 'TurbBearingVib4',
 'TurbBearingVib5',
 'GenBearingVib7',
 'GenBearingVib8']



In H2O-3 version 3.22.1.3, 
data.set_names(input_file_column_names)
 worked successfully for any dataset that had 10 columns but gave the following error if the number of columns was more or less than the number of strings:


H2OValueError: Argument 
names
 (= ['Date', 'GenOut', 'GenVar']) does not satisfy the condition len(names) == self.ncol",2019-03-04T17:39:04,mtanco,https://stackoverflow.com/users/2317054/mtanco,76,54968458
54967014,54967014,0,"Got it working! I guess there is a bug in H2O.. I ran the grid 3 times before I ran it for classification. When I restarted the Anaconda Server the above code started working properly.


Thanks!",2019-03-03T08:39:06,Rupesh Acharya,https://stackoverflow.com/users/11140923/rupesh-acharya,31,54961216
55228937,55228937,0,"The prediction labels are based on a threshold and the threshold used is generally based on the threshold that maximizes the F1 score. See the following 
post
 to learn more on how to interpret the probability results.


Details on how the calibration frame and model work can be found 
here
 and 
here
.",2019-03-18T19:40:58,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54943424
54927780,54927780,2,"I don't know anything about H20, but generally that type of error,




H2OValueError: File ‪train_FD004.txt does not exist




Means it cannot find the file you are trying to upload.


You should try:




Make sure you have typed the name of the file correctly, including spelling, white-space and extension.


Make sure the file is in the correct directory, whether that is the same directory as your program or whatever directory you're attempting to reference.",2019-02-28T14:19:36,Jack Whelan,https://stackoverflow.com/users/10782878/jack-whelan,66,54927475
55228432,55228432,0,"It will depend on your setup and what version of DAI you are using, but you can specify the number of CPUs you want to use in the 
config.toml
 file. For your convenience I have pasted the relevant section of the toml file below as well as provided the documentation link that includes details for setting up this file.


## Hardware: Configure hardware settings here (GPUs, CPUs, Memory, etc.)

# Max number of CPU cores to use per experiment. Set to <= 0 to use all cores.
# One can also set environment variable ""OMP_NUM_THREADS"" to number of cores to use for OpenMP
# e.g. In bash: export OMP_NUM_THREADS=32 and export OPENBLAS_NUM_THREADS=32
#Set to -1 for all available cores.
#max_cores = -1



documentation 
link",2019-03-18T19:05:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54919798
55247402,55247402,1,"Yes you can get this from the scoring history table 
h2o.scoreHistory(model)
 which will give you something like:


Scoring History: 
            timestamp   duration iterations negative_log_likelihood objective
1 2019-03-19 11:58:57  0.000 sec          0               509.21546   1.34004
2 2019-03-19 11:58:58  0.053 sec          1               489.50869   1.28818
3 2019-03-19 11:58:58  0.073 sec          2               488.06524   1.28438
4 2019-03-19 11:58:58  0.090 sec          3               487.83225   1.28377
5 2019-03-19 11:58:58  0.106 sec          4               487.79622   1.28367
6 2019-03-19 11:58:58  0.116 sec          5               487.78870   1.28365
7 2019-03-19 11:58:58  0.126 sec          6               487.78701   1.28365
8 2019-03-19 11:58:58  0.136 sec          7               487.78659   1.28365



Which gives you the negative log likelihood and the penalized negative log likelihood - which is in the objective column.


so you would just need to grab the last iteration to get the value of interest, which you can do with:


score_table = h2o.scoreHistory(model)
score_table[length(score_table),'objective']



where 
model
 is your H2O-3 model object.",2019-03-19T18:06:39,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54903280
54907711,54907711,1,"The answer to your second question (i.e. ""is it the data, or did I do something wrong"") is hard to know. This is why you should always try to make a baseline model first, so you have an idea of how learnable the data is.


The baseline could be 
h2o.glm()
, and/or it could be 
h2o.randomForest()
, but either way without the PCA step. (You didn't say if you are doing a regression or a classification, i.e. if 
OUTCOME
 is a number or a factor, but both glm and random forest will work either way.)


Going to your first question: yes, it is a reasonable thing to do, and no you don't have to (in fact, should not) involve the outcomes vector.


Another way to answer your first question is: no, it unreasonable. It may be that a random forest can see all the relations itself without needing you to use a PCA. Remember when you use a PCA to reduce the number of input dimensions you are also throwing away a bit of signal, too. You said that the 8 components only capture 95% of the variance. So you are throwing away some signal in return for having fewer inputs, which means you are optimizing for complexity at the expense of prediction quality.


By the way, concatenating the original inputs and your 8 PCA components, is another approach: you 
might
 get a better model by giving it this hint about the data. (But you might not, which is why getting some baseline models first is essential, before trying these more exotic ideas.)",2019-02-27T14:28:10,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,54888889
54948873,54948873,0,"Right now the answer is no. We've created an issue for implementing a new feature in the Tree API. You can track the progress here: 
https://0xdata.atlassian.net/browse/PUBDEV-6322
.",2019-03-01T16:40:43,Joe,https://stackoverflow.com/users/10913732/joe,268,54887717
54896262,54896262,0,H2O is trying to and failing to load the GPU version XGBoost. It then loads the CPU version. This is not something to be worried about unless you think the GPU version should be loading.,2019-02-27T00:30:25,Joe,https://stackoverflow.com/users/10913732/joe,268,54885921
75236310,75236310,0,"This problem can be solved by specifiying what particular algos to use. You can check this: 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/include_algos.html


This error is reproducible by using: 
include_algos=c(""StackedEnsemble""),
 only.",2023-01-25T15:39:18,Djawadk,https://stackoverflow.com/users/20677722/djawadk,16,54882451
54896480,54896480,2,"For the supplied dataset which has 69 examples, you would need the following arguments in the 
h2o.gbm
 call:


nfolds = 69,
fold_assignment = ""Modulo""



For example, this full code block runs your example with leave-one-out cross validation and includes some extra lines to confirm the folds were assigned properly:


library(h2o)

h2o.init(strict_version_check = FALSE)

u$dc=as.factor(u$dc)
train <- as.h2o(u)
model <- h2o.gbm(x= colnames(train)[1:15],
                 y=""dc"", training_frame=train,
                 nfolds = 69,
                 fold_assignment = ""Modulo"",
                 keep_cross_validation_fold_assignment = TRUE, # keep track of fold assignment to confirm leave-one-out
                 learn_rate = 0.06,
                 ntrees = 90, max_depth = 3,   
                 min_rows = 2,
                 distribution = ""bernoulli"")

folds <- h2o.cross_validation_fold_assignment(model) # get fold assignments
print(folds, n = 69) # print all assignment for the 69 folds
print(h2o.dim(h2o.unique(folds))) # count the number of unique values",2019-02-27T01:03:39,Joe,https://stackoverflow.com/users/10913732/joe,268,54871817
54871324,54871324,4,"H2O-3, Sparkling Water and H2O4GPU are all open-source (also this is software, H2O.ai doesn't provide hardware for these).


Driverless AI is a closed source product.


If you go to the 
company page
 and click on Products you will see that the open source products are listed separate from the closed-source products.",2019-02-25T17:10:15,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54869578
56076425,56076425,0,"# R
df <- read.csv('../examples/example_yosemite_temps.csv')
m <- prophet(df, changepoint.prior.scale=0.01)
future <- make_future_dataframe(m, periods = 300, freq = 60 * 60)
fcst <- predict(m, future)
plot(m, fcst)



https://facebook.github.io/prophet/docs/non-daily_data.html",2019-05-10T11:08:24,Daniel James Canil,https://stackoverflow.com/users/2155214/daniel-james-canil,326,54862099
54914589,54914589,0,"The parameters are sent in JSON format through a POST command. For example, assuming a training frame named 
airlines
 has already been loaded, you can train an AutoML model through curl with:


curl -X POST http://localhost:54321/99/AutoMLBuilder -H ""Content-Type: application/json"" -d '{""input_spec"": {""training_frame"":""airlines"", ""response_column"":""IsDepDelayed""}, ""build_control"": {""project_name"":""aml_curl_test"", ""stopping_criteria"":{""max_models"":3} } }'



You can find the full REST API reference here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/rest-api-reference.html
, which will tell you the JSON object names each parameter belongs to.",2019-02-27T21:13:40,Joe,https://stackoverflow.com/users/10913732/joe,268,54853550
54859079,54859079,4,"Stacked Ensembles (usually the leader model) does not yet support variable importance (JIRA 
here
).  However the variable importance for rest of the models can be retrieved in a loop over the model ids in the leaderboard.  See R code below.


library(h2o)
h2o.init()

# Import a sample binary outcome train/test set into H2O
train <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
y <- ""response""
x <- setdiff(names(train), y)

# For binary classification, response should be a factor
train[,y] <- as.factor(train[,y])

# Run AutoML for 10 models
aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# View the AutoML Leaderboard
lb <- aml@leaderboard
print(lb, n = nrow(lb))

# Get model ids for all models in the AutoML Leaderboard
model_ids <- as.data.frame(lb$model_id)[,1]

# View variable importance for all the models (besides Stacked Ensemble)
for (model_id in model_ids) {
  print(model_id)
  m <- h2o.getModel(model_id)
  h2o.varimp(m)
  h2o.varimp_plot(m)
}",2019-02-25T03:24:20,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",54852453
54853054,54853054,0,"Java 9 is a poor version of Java to use (for really anything at all).


I recommend using Java 8, which many, many people do use.",2019-02-24T14:47:49,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",54844476
54872046,54872046,1,"If you want to see which features were used at a given split in a give tree you can navigate the H2OTree object.


For R see documentation 
here
 and 
here


For Python see documentation 
here


You can also take a look at this 
Blog
 (if this link ever dies just do a google search for H2OTree class)",2019-02-25T17:55:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54820194
54852999,54852999,0,"I don’t know if I would call this easy, but the MOJO tree visualizer spits out a graphviz dot data file which is turned into a visualization.  This has the information you are interested in.


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo",2019-02-24T14:42:44,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",54820194
54813950,54813950,2,"h2o.init()
 takes a parameter called 
extra_classpath
. You can use this parameter to provide the path to the JDBC driver and H2O will launch with the driver.


This option is designed exactly for the purpose of not having to start H2O outside of the notebook interface.


Example:


import h2o
h2o.init(extra_classpath=[""/Users/michal/Downloads/apache-hive-2.2.0-bin/jdbc/hive-jdbc-2.2.0-standalone.jar""])",2019-02-21T18:32:02,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,54812865
54795667,54795667,1,"H2O's list of available algorithms can be found 
here
. The short answer to your question is no. Details on the Deep Learning algorithm that is available 
here
 and I will repost for your convenience: 


H2O-3's Deep Learning algorithm is based on a multi-layer feedforward artificial neural network that is trained with stochastic gradient descent using back-propagation. The network can contain a large number of hidden layers consisting of neurons with tanh, rectifier, and maxout activation functions. Advanced features such as adaptive learning rate, rate annealing, momentum training, dropout, L1 or L2 regularization, checkpointing, and grid search enable high predictive accuracy. Each compute node trains a copy of the global model parameters on its local data with multi-threading (asynchronously) and contributes periodically to the global model via model averaging across the network.


A feedforward artificial neural network (ANN) model, also known as deep neural network (DNN) or multi-layer perceptron (MLP), is the most common type of Deep Neural Network and the only type that is supported natively in H2O-3. Several other types of DNNs are popular as well, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). MLPs work well on transactional (tabular) data; however if you have image data, then CNNs are a great choice. If you have sequential data (e.g. text, audio, time-series), then RNNs are a good choice.",2019-02-20T21:41:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54755451
54794872,54794872,1,"The error seems to indicated that 
skewness
 is a problem. For a full list of aggregation methods that are allowed in the 
h2o.group_by()
 please see the Details section (bottom of the page) of the 
documentation
.


For your convenience I am adding the Details section here - you can see that skewness is not currently included (if this something you'd be interested in having feel free to create a 
JIRA ticket
): 


Details

In the case of na.methods within gb.control, there are three possible settings. ""all"" will include NAs in computation of functions. ""rm"" will completely remove all NA fields. ""ignore"" will remove NAs from the numerator but keep the rows for computational purposes. If a list smaller than the number of columns groups is supplied, the list will be padded by ""ignore"".
Note that to specify a list of column names in the gb.control list, you must add the col.names argument. Similar to na.methods, col.names will pad the list with the default column names if the length is less than the number of colums groups supplied.
Supported functions include nrow. This function is required and accepts a string for the name of the generated column. Other supported aggregate functions accept col and na arguments for specifying columns and the handling of NAs (""all"", ""ignore"", and GroupBy object; max calculates the maximum of each column specified in col for each group of a GroupBy object; mean calculates the mean of each column specified in col for each group of a GroupBy object; min calculates the minimum of each column specified in col for each group of a GroupBy object; mode calculates the mode of each column specified in col for each group of a GroupBy object; sd calculates the standard deviation of each column specified in col for each group of a GroupBy object; ss calculates the sum of squares of each column specified in col for each group of a GroupBy object; sum calculates the sum of each column specified in col for each group of a GroupBy object; and var calculates the variance of each column specified in col for each group of a GroupBy object. If an aggregate is provided without a value (for example, as max in sum(col=""X1"", na=""all"").mean(col=""X5"", na=""all"").max()), then it is assumed that the aggregation should apply to all columns except the GroupBy columns. However, operations will not be performed on String columns. They will be skipped. Note again that nrow is required and cannot be empty.",2019-02-20T20:39:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54754644
54814631,54814631,0,"Instead of 
aml.leader().getMojo().writeTo()
 try using 
aml.leader().exportMojo(...)
.",2019-02-21T19:20:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54753113
54812162,54812162,0,"If you want to see all the available frames in Flow. Click on the Data dropdown menu at the top of the page and then click on List All Frames. If you previously clicked on Split Frames and then that cell's 
Create
 button you will see that the two frames you just created will appear under the list of frames. Please note that when you split the frames, if you don't specify a naming convention, those frames will get a default name like 
frame_0.750
. 


Please also verify, before creating the Split Frames cell, that your titanic frame actually exists in your H2O Cluster - if the import wasn't successful or the titanic frame is not in the H2O Cluster it will not appear as a dataframe that you can split on within the Split Frame Cell. Again you can see what dataframes are in your cluster by using the List All Frames option.",2019-02-21T16:42:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54731322
54813046,54813046,0,"It looks like you are missing your 
h2o-genmodel.jar
 file - this is what the error message 
Could not find or load main class water.util.H2OPredictor
 indicates. You may want to provide all the arguments to checkoff that you have everything:


h2o.predict_json(model, json, genmodelpath, labels, classpath, javaoptions)


documentation 
here",2019-02-21T17:34:12,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54726489
54777321,54777321,4,"There are specific cases that could cause division by zero when calculating the ROC curve, which could cause an AUC to be NaN. It's probable that due to small data you have some folds that have no true positives and are causing this issue. 


We can test this by keeping the fold column and then counting the values of dc in each fold:


...

train <- as.h2o(u)
mod <- h2o.glm(family = ""binomial""
              , x = c(1:15)
              , y = ""dc""
              , training_frame = train
              , missing_values_handling = ""Skip""
              , lambda = 0
              , compute_p_values = TRUE
              , nfolds = 10
              , keep_cross_validation_fold_assignment = TRUE
              , seed = 1234)

fold <- as.data.frame(h2o.cross_validation_fold_assignment(mod))
df <- cbind(u,fold)

table(df[c(""dc"",""fold_assignment"")])

   fold_assignment
dc  0 1 2 3 4 5 6 7 8 9
  0 4 6 6 2 9 6 6 4 4 6
  1 2 2 3 4 0 2 0 0 1 2

mod@model$cross_validation_metrics_summary[""auc"",]

Cross-Validation Metrics Summary: 
          mean         sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid cv_5_valid cv_6_valid cv_7_valid
auc 0.70238096 0.19357596      0.875  0.6666667        0.5      0.375        NaN  0.5833333        NaN
    cv_8_valid cv_9_valid cv_10_valid
auc        NaN        1.0   0.9166667



We see that the folds with NaN are the same folds that have only dc=0.


Not counting the NaN, the wide variety of AUC for your folds (from 0.2 to 1) tells us that this is not a robust model, and it is likely being overfitted. Can you add more data?",2019-02-20T01:09:54,,,,54711909
54686680,54686680,1,"Solution: Don't use 
pd.read_csv()
 and 
h2o.H2OFrame()
, and instead use 
h2o.import_file()
 directly.


The error message is on the 
POST /3/PostFile
 REST command. Which, as far as I can tell from your code and log snippets, means it is uploading to localhost? That is horribly inefficient.


(If not localhost, i.e. your datafile.csv is on your computer, which is outside of AWS, then upload it to S3 first. If you are doing some data munging on your computer, do that, then save it as a new file, and upload that to S3. It doesn't have to be S3: it could be the hard disk if you only have a single machine in your H2O cluster.)


For some background see also my recent answers at 
https://stackoverflow.com/a/54568511/841830
 and 
https://stackoverflow.com/a/54459577/841830
.  (I've not marked as duplicate, as though the advice is the same, in each case, the reason is a bit different; here I wonder if you are hitting a limit for maximum HTTP POST file size, perhaps at 2GB? I suppose it could also be running out of disk space, from all the multiple temp copies be made.)",2019-02-14T09:07:00,,,,54671158
54680393,54680393,0,"Yes the model you save from Flow or Python (i.e. one of the APIs) can be loaded and used in another API (you just need to make sure that the binary model you save uses the same version as the running H2O Cluster where you want to upload the model)


Saving a model using Flow is described 
here


Saving and loading a model is also described 
here",2019-02-13T22:23:56,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54670342
63501353,63501353,0,"h2o.ai is really making me crazy, with AutoML, predict always have 
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index -22 out of bounds for length 630
 error.
trained with 
train.csv
, predict with 
train.csv
 is ok, predict with 
predict.csv
 is always error!

train.csv
 and 
predict.csv
 have the same headers and in order.",2020-08-20T08:39:23,iamsk,https://stackoverflow.com/users/620953/iamsk,356,54578226
54581287,54581287,1,"If you are using Anaconda, I would recommend creating a new conda environment and then conda installing all the packages you need (for H2O you would use 
conda install -c h2oai h2o=3.22.1.2
 ). This will help prevent package conflicts or having trouble pointing to the correct version.


you should also run 
conda list
 to see whether you have another version of colorma installed. Alternatively, you could do a 
pip uninstall colorama
 and see whether H2O still picks up a 0.3.7 version - at the very least it will help reveal whether you have multiple versions.",2019-02-07T19:55:48,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54564735
54568655,54568655,0,"Most Python/R API functions are wrappers around REST calls. See 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/_modules/h2o/model/model_base.html#ModelBase.deepfeatures


So, to convert an R example to a Python one, move the model to be the 
this
, and all other args should shuffle along. I.e. the example from the manual becomes (with dots in variable names changed to underlines):


prostate_hex = ...
prostate_dl = ...
prostate_deepfeatures_layer1 = prostate_dl.deepfeatures(prostate_hex, 1)
prostate_deepfeatures_layer2 = prostate_dl.deepfeatures(prostate_hex, 2)



Sometimes the function name will change slightly (e.g. 
h2o.importFile()
 vs. 
h2o.import_file()
 so you need to hunt for it at 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/index.html",2019-02-07T07:56:13,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,54546706
54568511,54568511,3,"Save the pandas data frame to a csv file.  (Skip this step if you loaded it from a csv file in the first place, and haven't done any data munging on it, of course.)


Put that csv file somewhere the h2o server can see it. (If you are running client and server on the same machine, this is already the case.)


Use 
h2o.import_file()
 (in preference to 
h2o.upload_file()
 or 
h2o.H2OFrame()
)




The 
h2o.import_file()
 is the quickest way to get data into H2O, but the file must be visible by the server. When dealing with a remote cluster, this might mean uploading it to that servers file system, or putting it on a web server, or an HDFS cluster, or on AWS S3, etc, etc.


(The reason 
h2o.upload_file()
 is slower is that it will do an HTTP POST of the data, from client to server, and 
h2o.H2OFrame()
 is slower because it exports your pandas data to a temp csv file, then uses 
h2o.upload_file()
, then deletes the temp file afterwards.)",2019-02-07T07:44:13,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,54541358
54555930,54555930,0,"Apparently, if I kill the Java process running in the background and re-knot the Markdown, it works fine, so this might have been a temporary issue.",2019-02-06T14:29:28,Nikhil Gupta,https://stackoverflow.com/users/8925915/nikhil-gupta,"1,486",54540948
54526525,54526525,0,"You can use 
.toCategoricalVec


Here is an example of the usage:


val trainFrame:H2OFrame = bigTable
withLockAndUpdate(trainFrame){ fr => fr.replace(19, fr.vec(""IsDepDelayed"").toCategoricalVec)}",2019-02-05T01:04:45,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54511042
56024525,56024525,0,"We have to transform our H2OFrame.


Here is an example:


NameOfH2OFrame.colToEnum(Array(<""NameOfColumnYouWantToChangeInEnum"">))

val h2oFrameTrain = h2oContext.asH2OFrame(trainingData)
h2oFrameTrain.colToEnum(Array(""WEEKDAY_LABEL"", ""EVENT_TYPE"", ""EVENT_NAME""))",2019-05-07T14:09:12,Wai Ha Lee,https://stackoverflow.com/users/1364007/wai-ha-lee,"8,775",54511042
54564379,54564379,5,"It looks like you are missing the parameter 
keep_cross_validation_predictions=True
 in each of your models. For example you would want to do the following for your GLM and then likewise for the other models you want to stack:


glm_grid = H2OGridSearch(model=H2OGeneralizedLinearEstimator(fold_assignment=assignment_type, nfolds=folds,
    keep_cross_validation_predictions=True),
                                 grid_id='glm_grid',
                                 hyper_params=glm_params,
                                 search_criteria=search_criteria)",2019-02-06T23:55:04,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54508507
54467473,54467473,2,"This is not currently available from the R API. If this is functionality you are interested in I would create a JIRA with your use case 
here
. You can use the other 
SO question Darren
 pointed to, for information on how to use this functionality through the Python API.",2019-01-31T18:57:21,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54438185
54421092,54421092,5,"After the first transformation with 
as.h2o(trainingset)
 you can export / save the file to disk and later import it again.


my_h2o_training_file <- as.h2o(trainingset)
path <- ""whatever/my/path/is""
h2o.exportFile(my_h2o_training_file , path = path)



And when you want to load it use either 
h2o.importFile
 or 
h2o.importFolder
. See the function help for correct usage.


Or save the file as csv / txt before you transform it with 
as.h2o
 and load it directly into h2o with one of the above functions.",2019-01-29T12:29:51,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,54417507
54459577,54459577,4,"as.h2o(d)
 works like this (even when client and server are the same machine):




In R, export 
d
 to a csv file in a temp location


Call 
h2o.uploadFile()
 which does an HTTP POST to the server, then a single-threaded import.


Returns the handle from that import


Deletes the temp csv file it made.




Instead, prepare your data in advance somewhere(*), then use 
h2o.importFile()
 (See 
http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.importFile.html
). This saves messing around with the local file, and it can also do a parallelized read and import.


*: For speediest results, the ""somewhere"" should be as close to the server as possible. For it to work at all, the ""somewhere"" has to be somewhere the 
server
 can see. If client and server are the same machine, then that is automatic. At the other extreme, if your server is a cluster of machines in an AWS data centre on another continent, then putting the data into S3 works well. You can also put it on HDFS, or on a web server.


See 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/importing-data.html
 for some examples in both R and Python.",2019-01-31T11:27:15,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,54417507
54412253,54412253,2,"If using windows command prompt switch the : with a ; and put in double quotes.  I put in the full path also.


java -cp ""postgresql-42.2.5.jar;h2o.jar"" water.H2OApp",2019-01-29T00:32:11,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,54410097
54380895,54380895,4,"Actually H2O 
did
 start here.  The message saying to open Flow in your web browser is the sign.


But the R client couldn’t reach H2O and decided to give up.


The message at the bottom has a 504.


That’s HTTP status 504.  Which is probably a RHEL firewall blocking port 54321.  You need to open port 54321 in the firewall.",2019-01-26T17:32:30,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",54380323
54408091,54408091,1,"It turned out to be a proxy issue.
Unsetting the 
http_proxy
 environment variable allows R to properly connect to H2O, i.e.:


library(h2o)
Sys.unsetenv(""http_proxy"")
h2o.init()

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /tmp/RtmpqEIs7x/h2o_ferreen2_started_from_r.out
    /tmp/RtmpqEIs7x/h2o_ferreen2_started_from_r.err

java version ""1.8.0_20""
Java(TM) SE Runtime Environment (build 1.8.0_20-b26)
Java HotSpot(TM) 64-Bit Server VM (build 25.20-b23, mixed mode)

Starting H2O JVM and connecting: . Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         2 seconds 257 milliseconds 
    H2O cluster timezone:       Europe/Zurich 
    H2O data parsing timezone:  UTC 
    H2O cluster version:        3.22.1.1 
    H2O cluster version age:    1 month  
    H2O cluster name:           H2O_started_from_R_enrico_azr433 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   26.67 GB 
    H2O cluster total cores:    32 
    H2O cluster allowed cores:  32 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.5.0 (2018-04-23)",2019-01-28T18:21:13,enricoferrero,https://stackoverflow.com/users/1540663/enricoferrero,"2,319",54380323
54350149,54350149,0,"According to the error message it looks like you incorrectly used the argument 
class_sampling_factors
. As the message says you can only provide 2 elements. I would recommend reviewing the documentation on this parameter 
here


In the future it would help if you provided a reproducible code snippet so we can reproduce the error.",2019-01-24T15:30:59,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54345247
54334643,54334643,1,"AutoML automatically runs the supervised learning models that are available in H2O-3. So how AutoML handles categoricals depends on the default categorical handling of the given model it is running. Documentation on the handling of categoricals can be found 
here
, if you are interested in a particular algorithm use the same documentation to find your algorithm of interest and review details of how it handles categorical values or use the Python or R API documentation to look up the default values.",2019-01-23T19:49:43,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54333537
54336174,54336174,0,"This general question comes up a lot for various reason, as recommended in the comments you should look at the 
stdout
 and 
stderr
 files (which are listed in your error message), or try to run the command to launch your h2o.jar yourself on the command line and see what happens - documentation help is 
here
.


I would also look at the 
trouble shooting
 in the user guide or search on 
h2ostream
 for your error.",2019-01-23T21:44:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54311898
54434824,54434824,0,"Interesting the sdtout & stderr did not show any error. The issue got resolved , it was due to Antivirus and Firewall restrictions to connect to local host.",2019-01-30T06:53:07,user9467123,https://stackoverflow.com/users/9467123/user9467123,11,54311898
54336070,54336070,0,"1) I'm not sure where you are seeing a timestamp in Flow or if you mean your dataset contains a timestamp that H2O-3 has converted. Either way it sounds like you may have encountered a bug. The timestamps you see in H2O-3 are milliseconds since the Unix epoch, so you have to divide by 1000 before using a unix time converter (for example you could use 
https://currentmillis.com/
). But again given that the number is so large, I'm leaning towards a bug - any code you can provide to make it reproducible would be great. 


1a) When you check 
standardize
 in flow in addition to “OUTPUT - CLUSTER MEANS” (which is not standardized) you will see ""OUTPUT - STANDARDIZED CLUSTER MEANS"" so the non-standardize output should reflect the unit of your input.


2) Standardization in H2O-3 is described 
here
 (which says: ""standardizes numeric columns to have zero mean and unit variance. ""). The link you provided points to a model for testing that has been saved as MOJO and I'm not sure it makes sense to use as an example. But in general the way standardization works for h2o-3 is as standardization is defined.",2019-01-23T21:38:16,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54299526
54336362,54336362,1,We suspect there may be a bug in the AUC code. We replicated your code with our data but could not reproduce. The best way moving forward is to provide us with your dataset if possible. Once we can reproduce we'll work on a fix. Thanks!,2019-01-23T22:02:21,Joe,https://stackoverflow.com/users/10913732/joe,268,54298102
54256617,54256617,4,"It’s the two things you would expect:  the number of trees and the depth.


But it also depends on your data.  For GBM, the trees can be cut short depending on the data.


What I would do is export MOJOs and then visualize them as described in the document below to get more details on what was really produced:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




Note the 60 MB range does not seem overly large, in general.",2019-01-18T15:05:42,,,,54255814
54266744,54266744,2,"If you look at the model info you will find out things about the number of trees, their average depth, and so on. Comparing those between the three best models should give you some insight into what is making the models large.


From R, if 
m
 is your model, just printing it gives you most of that information. 
str(m)
 gives you all the information that is held.


I think it 
is
 worth investigating. The cause is probably that two of those data windows are relatively clear-cut, and only a few fields can define the trees, whereas the third window of data is more chaotic (in the mathematical sense), and you get some deep trees being made as it tries to split that apart into decision trees.


Looking into that third window more deeply might suggest some data engineering you could do, that would make it easier to learn. Or, it might be a difference in your data. E.g. one column is all NULL in your 2016 and 2017 data, but not in your 2018 data, because 2018 was the year you started collecting it, and it is that extra column that allows/causes the trees to become deeper.


Finally, maybe the grid hyperparameters are unimportant as regards performance, and this a difference due to noise. E.g. you have 
max_depth
 as a hyperparameter, but the influence on MSE is minor, and noise is a large factor. These random differences could allow your best model to go to depth 5 for two of your data sets (but 2nd best model was 0.01% worse but went to depth 20), but go to depth 30 for your third data set (but 2nd best model was 0.01% worse but only went to depth 5).
(If I understood your question correctly, you've eliminated this as a possibility, as you then trained all three data sets on the same hyperparameters? But I thought I'd include it, anyway.)",2019-01-19T11:47:27,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,54255814
54227039,54227039,1,"Try setting the 
standardize
 argument equal to False (shown in the code below), you can read more about the beta_constraints parameter 
here
:


glm1 <- h2o.glm(x=c('x1','x2'),
                y='col',
                family='binomial',
                lambda=0,
                alpha=0,
                training_frame = as.h2o(df1),
                beta_constraints=beta_const_df,
                standardize = F
)
glm1@model$coefficients
> glm1@model$coefficients
#Intercept        x1        x2 
#27.6      -1.0      -2.6",2019-01-16T23:40:55,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54223663
54224177,54224177,0,"Workaround if all constraints are strict equality


I can inflict severe L2 penalty 
rho
 for deviating from 
beta_given
, and it seems like 
Intercept
 is supported here:


beta_const_df <- data.frame(names = c('Intercept','x1','x2'),
                            #lower_bounds = param_vals-0.1, #don't bound
                            #upper_bounds = param_vals+0.1,
                            #beta_start   = param_vals, # use beta_given
                            beta_given   = param_vals, # new
                            rho          = 1e9 )       # new



Then this works:


glm2 <- h2o.glm(x=c('x1','x2'),
                y='col',
                family='binomial',
                lambda=0,
                alpha=0,
                training_frame = 'df1',
                beta_constraints=beta_const_df)

glm2@model$coefficients
# Intercept        x1        x2 
#      27.5      -1.1      -2.7 
all.equal(glm2@model$coefficients, param_vals, check.names=FALSE) # TRUE



This only works if you have all equality constraints (not distinct upper and lower bounds).  


Either way, still wondering if there is a less hacky way to do it.",2019-01-16T19:39:59,,,,54223663
54191622,54191622,0,"Those are errors in the package, but not very serious ones.  For example, the first one you list


Rd warning: /tmp/RtmpdpaSKI/R.INSTALL1d3a6ccc7d9b/h2o/man/h2o.ascharacter.Rd:16: missing file link ‘as.character’



comes because that help file contains the link 
\link[base]{as.character}
 which does not exist.  It should be 
\link[base]{character}
 or 
\link[base:character]{as.character}
, since links to other packages are to the help page name, not to the topic alias.  If you ask for help using 
?h2o.ascharacter
, you might find the link in the help page to 
as.character
 doesn't work.  (Usually such links do work, because the R dynamic help system figures out what the author meant, but some installations use a static help system with pre-built 
.html
 files where the links won't work.)


The rules for cross-package links in the help system are pretty bizarre, and it looks like the 
h2o
 authors didn't learn them (or didn't care about static help). 


I don't know if your guess about the downstream error is right or not.",2019-01-15T01:41:46,,,,54191038
54205503,54205503,0,"Can you say more about the system that you're using and the version of R?  I am not able to reproduce this on Ubuntu 16.04.5 using R 3.4.4.  I tried installing exactly how you did and also just by installing the latest from CRAN (both are version 3.22.0.1).


> install.packages(""h2o"")
Installing package into '/home/ledell/R/x86_64-pc-linux-gnu-library/3.4'
(as 'lib' is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/h2o_3.22.1.1.tar.gz'
Content type 'application/x-gzip' length 432390 bytes (422 KB)
==================================================
downloaded 422 KB

* installing *source* package 'h2o' ...
** package 'h2o' successfully unpacked and MD5 sums checked
** R
** demo
** inst
** preparing package for lazy loading
Performing one-time download of h2o.jar from
     http://s3.amazonaws.com/h2o-release/h2o/rel-xu/1/Rjar/h2o.jar
(This could take a few minutes, please be patient...)
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (h2o)

The downloaded source packages are in
    '/tmp/RtmpGwtVRB/downloaded_packages'


> install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-xu/1/R"")
Installing package into '/home/ledell/R/x86_64-pc-linux-gnu-library/3.4'
(as 'lib' is unspecified)
trying URL 'http://h2o-release.s3.amazonaws.com/h2o/rel-xu/1/R/src/contrib/h2o_3.22.1.1.tar.gz'
Content type 'application/x-tar' length 120971891 bytes (115.4 MB)
==================================================
downloaded 115.4 MB

* installing *source* package 'h2o' ...
** R
** demo
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (h2o)

The downloaded source packages are in
    '/tmp/RtmpGwtVRB/downloaded_packages'



The downstream error is not related.  If you can post the code you are running as a separate question with reproducible code, we can try to sort that out.",2019-01-15T19:19:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",54191038
54190310,54190310,1,"Yes what you have (
pred_vs_actual
) will cbind your model's predictions with the corresponding row (record). As a quick check, when you look at the first few rows of 
pred_vs_actual
 you should be able to verify that the cbind does what you expect.",2019-01-14T22:44:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54190081
54167366,54167366,3,"word2vec is a type of unsupervised learning: it turns string data into numbers. So to do a classification you need to do a two-step process:




word2vec for strings to numbers


any supervised learning technique for numbers to categories




The 
documentation
 contains links to a categorization example in each of 
R
 and 
Python
. 
This tutorial
 shows the same process on a different data set (and there should be a H2O World 2017 video that goes with that).


By the way, in your original example, you don't just supply the words; the sentences are separated by NA. If you give 
h2o.tokenize()
 a vector of sentences, it will make this format for you. So your example would actually be:




'This' 'is' 'the' 'first' NA 'This' 'is' 'number' 'two'",2019-01-13T08:59:08,,,,54148173
54137124,54137124,0,"Watch the action using the Flow interface: 
http://127.0.0.1:54321
, and pay attention to memory use.


See 

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/flow.html#viewing-cluster-status
 for the screen that you should be watching. You will see the amount of free memory on each node updating live.




Without any more information, one guess would be that you are running out of memory, because you are using more memory on each iteration of your for loop.


If so, it is hard to give advice without seeing what you are doing inside the for loop; but if the training data is the same, make sure that is loaded outside the for loop. In worst case, you should do the H2O init and shutdown within the for loop (and save your model at the end of each iteration, for later use).


Oh, one more possibility, as you didn't mention it: specify explicitly how much memory to give H2O, in your h2o.init() call. You might find you can get away with giving it more than whatever the default is. (But don't give H2O 
all
 the machine's memory, or everything will become unstable!)",2019-01-10T21:24:46,,,,54131854
55179547,55179547,0,"I had the same issue. But when you specify (example) 
max_runtime_secs = 6000
 there will be no error. That indicator solved my problem.


BTW, try changing parameters within 
h2o.xgboost
, the problem is probably there.",2019-03-15T09:37:37,,,,54131854
54188377,54188377,2,"The h2o4gpu package for R requires the h2o4gpu python package to be installed as well. From the 
docs
:




At this point, you should have installed the H2O4GPU Python package successfully.




The error you are experiencing looks like it matches the description of a missing python package, described under ""Python issues"" here: 
https://github.com/h2oai/h2o4gpu/tree/master/src/interface_r
 


If you want to use h2o4gpu from within a Kaggle kernel, I'm not sure if this is possible, since Kaggle currently disables external packages when using a GPU.",2019-01-14T20:02:32,Joe,https://stackoverflow.com/users/10913732/joe,268,54123267
54102774,54102774,3,"Like this:


from h2o.targetencoder import TargetEncoder

# Fit target encoding on training data
targetEncoder = TargetEncoder(x= [""addr_state"", ""purpose""], y = ""bad_loan"", fold_column = ""cv_fold_te"")
targetEncoder.fit(ext_train)



But this requires version at least 3.22


Here is a link to an example: 
https://github.com/h2oai/h2o-tutorials/blob/78c3766741e8cbbbd8db04d54b1e34f678b85310/best-practices/feature-engineering/feature_engineering.ipynb


And the link to code itself: 
https://github.com/h2oai/h2o-3/blob/master/h2o-py/h2o/targetencoder.py",2019-01-09T03:17:16,,,,54102766
66113352,66113352,0,"It looks like the h2o connection 'open' too many files beyond the default limit set on the machine and that causes the crash.


The limit on open file descriptors can be checked with:


ulimit -n



And later the soft limit can be modified to a larger valuer:


ulimit -Sn 5000",2021-02-09T05:12:59,rdk77,https://stackoverflow.com/users/3849083/rdk77,67,54091323
54101260,54101260,0,"The file you posted corresponds to a tutorial that was created which includes a 
README.md
 and 
Jupyter Notebook
. While the tutorial is in Python the naming conventions between R and Python are generally similar enough that if you look at the R API 
DOCs
, you should be able to figure out the equivalent code in R.


From a similar word2vec tutorial from the same tutorials repo, here is a close equivalent to the Python Tutorial for 
R
.",2019-01-08T23:35:37,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54090209
54119247,54119247,0,"When you select standardize for K-Means in Flow, it does standardize the columns before computing the distances (setting shown below).




So to answer your question the ""within_cluster_sum_of_squares"" is the distance calculation that is computed 
after
 standardization is performed.


One reason your metric value may seem too big could be if you were expecting the H2O-3 Kmeans standardize option to perform normalization (e.g.normalize = x / ||x||) rather than standardization (e.g. standardize = (x - mean) / sd)


From the k-means 
documentation
 here is the overview of the standardization option:


standardize: Enable this option to standardize the numeric columns to have a mean of zero and unit variance. Standardization is highly recommended; if you do not use standardization, the results can include components that are dominated by variables that appear to have larger variances relative to other attributes as a matter of scale, rather than true contribution. This option is enabled by default.


Note: If standardization is enabled, each column of numeric data is centered and scaled so that its mean is zero and its standard deviation is one before the algorithm is used. At the end of the process, the cluster centers on both the standardized scale (centers_std) and the de-standardized scale (centers). To de-standardize the centers, the algorithm multiplies by the original standard deviation of the corresponding column and adds the original mean. Enabling standardization is mathematically equivalent to using h2o.scale in R with center = TRUE and scale = TRUE on the numeric columns. Therefore, there will be no discernible difference if standardization is enabled or not for K-Means, since H2O calculates unstandardized centroids.",2019-01-09T22:20:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54087676
54047118,54047118,2,"The giniCoef in H2O-3 only supports binary classification problems, this is a mistake in the documentation. I've created a 
jira
 ticket so that the user guide gets updated. Thanks for highlighting the issue!",2019-01-04T22:38:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54046112
54046949,54046949,0,"There is an example in Python (which you can read through and understand even if you prefer R), that is linked in to the 
docs
. The ""mapping"" means that you specify which features you want to enforce your monotonicity constraint on, for example:


in python you'd use a dictionary for the mapping: 
monotone_constraints = {""MedInc"": 1, ""AveOccup"": -1, ""HouseAge"": 1}
 where the keys correspond to column names. 


in R you'd use 
monotone_constraints=list('C1'=-1, 'C2'=1)
 where 
""C1""
 and 
""C2""
 would be the name of your columns. 


If you're interested in understanding how the monotonicity constraints are applied see the 
blog
 that the docs provide a link to as well.",2019-01-04T22:21:25,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",54045139
54581250,54581250,2,"This data is not suited for standard supervised machine learning algorithms such as GBM, Random Forest, H2O AutoML, etc.  This is a forecasting problem using a single sequence of observations, where as ""typical"" supervised machine learning algorithms are meant to be used when you have several (or many) predictor columns, in addition to the column that you are trying to predict (the response).  I would take a look at other time-series/forecasting algorithms such as ARIMA or use a deep neural network such as an LSTM.",2019-02-07T19:52:40,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",54042259
54040066,54040066,0,"H20 Manual says to do it like 
df = h2o.import_file(""/pathToFile/fileName"")
  When 
 you need 
to load data from the machine(s) running H2O to the machine running Python
. 


So if your server is not running H20 probably that's why it is showing error.",2019-01-04T13:39:26,Kartikey Singh,https://stackoverflow.com/users/7018323/kartikey-singh,894,54039594
54024327,54024327,3,"Check if the JAVA_HOME environment variable is set.  It may be pointing to the wrong spot, tricking H2O to find the wrong one.


You want JAVA_HOME/bin/java to be a good 64-bit java.


(The other thing you can optionally do is, when you do find a 32-bit java, uninstall it.  There is no real reason to have it unintentionally anymore these days; memory sizes are much bigger than 15 years ago.)",2019-01-03T14:32:34,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",54023053
54020876,54020876,1,"1. Performance on new data:


     h2o.confusionMatrix(object = yourXGBmodelHere, 
                        newdata = yourTestSetHere, 
                        metrics = ""absolute_mcc"")



2. CV performance assessment:


fold_ass <- h2o.cross_validation_fold_assignment(model)
cvTrain <- h2o.cbind(data.train, fold_ass)



Example: how model 1 performs on the first fold:


h2o.confusionMatrix(object=h2o.cross_validation_models(model)[[1]], 
                    newdata=cvTrain[fold_ass == 0, ], 
                    metrics = ""absolute_mcc"")



NB - it assumes that the model was trained with: 

keep_cross_validation_fold_assignment = TRUE

and 

keep_cross_validation_predictions = TRUE
. So that you can use: 


h2o.cross_validation_fold_assignment(model)
h2o.cross_validation_predictions(model)

h2o.cross_validation_models(model)",2019-01-03T10:52:14,djacobs7,https://stackoverflow.com/users/420098/djacobs7,11.8k,54020376
54007462,54007462,2,"Based on 
H2O-3 docs
 this can't be done:




Note that all three options are only suitable for datasets that are i.i.d. If the dataset requires custom grouping to perform meaningful cross-validation, then a fold_column should be created and provided instead.




One quick idea is using 
weights_column
 instead of duplicating rows. Then both 
balance_classes
 and 
weights_column
 are available together as parameters in 
GBM, DRF, Deep Learning, GLM, Naïve-Bayes, and AutoML.


Otherwise, I suggest following workflow performed in R or H2O on your data to achieve both fold assignment and consistency of duplicates between folds:




take original dataset (no repeats in data yet)


divide it into 2 sets based on the outcome field (the one that is unbalanced): one for positive and one for negative (if it's multinomial then have as many sets as there are outcomes)


divide each set into N folds by assigning new 
foldId
 column in both sets independently: this accomplishes stratified folds


combine (
rbind
) both sets back together


apply row duplication process that implements weights (which will preserve your fold assignments automatically now).",2019-01-02T13:44:25,,,,54005784
53985262,53985262,2,"H2O offers no support for importing/exporting(*) pmml models.


It is hard to offer a good suggestion without knowing your motivation for wanting to use both RapidMiner and H2O. I've not used RapidMiner in about 6 or 7 years, and I know H2O well, so my first choice would just be to re-build the model in H2O.


If you are doing a lot of pre-processing steps in RapidMiner, and that is why you want to use it, you could still do all that data munging there, then export the prepared data to csv, import that into H2O, then build the model.


*: Though I did just find this tool for converting H2O models to PMML: 
https://github.com/jpmml/jpmml-h2o
  But that is the opposite direction for what you want.",2018-12-31T08:32:56,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,53979651
54027462,54027462,2,"As of the latest version of H2O-3 3.22.1.1 the reproducibility requirements are listed in the documentation 
here
.


For your convenience, here are the requirements for reproducibility of a model on a single node:


Note that in addition to a seed, you need to use the same data (same splits), same parameters, and either don't use early stopping or use early stopping with score_tree_interval set. 


How to guarantee reproducibility in single node cluster?


The following criteria must be met to guarantee reproducibility in a single node cluster:




same training data




Note: If you have H2O import a whole directory with multiple files instead of a single file, we do not guarantee reproducibility because the data may be shuffled during import.




same parameters used to train the model


same seed set (this is required when any sampling is done)


no early stopping or early stopping with score_tree_interval set and same validation data",2019-01-03T17:59:11,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53961836
54009279,54009279,0,"The error you reported ""how to fix ""hist only applies to single numeric columns error"" in R. Is not an error that can be ""fixed"" because the function 
h2o.hist()
 is only designed to apply to a single column.


It looks like the only line of code that uses hist 
h <- h2o.hist(train[,col], breaks=30, plot = FALSE)
 is applying 
h2o.hist()
 to a single column and should function correctly.",2019-01-02T15:51:00,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53908238
54120112,54120112,-1,"I ran a quick test using the characters you provide and was able to get everything to display correctly on H2O-3 version 3.20.0.8 and python 3.5 so hopefully newer versions also work. 


In [7]: dd = [""Tässä vähän tekstiä åäö""]

In [8]: h2o.H2OFrame(dd)
Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%
Out[8]:
C1
-----------------------
Tässä vähän tekstiä åäö

[1 row x 1 column]



I also created a csv with the string as the first cell and it seemed to display correctly.


In [12]: hhf = h2o.import_file('Scandinavians.csv', header=-1)
Parse progress: |████████████████████████████████████████████████████████████████████████████| 100%

In [13]: hhf
Out[13]:
C1      C2     C3       C4
------  -----  -------  ----
Tässä  vähän  tekstiä  åäö

[1 row x 4 columns].



(If these code snippet's don't help I can try to update my response)",2019-01-09T23:50:08,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53883749
53991549,53991549,0,"Your question is related to Machine Learning Interpretability techniques. In H2O-3 the two available are: the 
variable importance plot
 (which tells you which features have the greatest impact on the models decisions) and 
Partial Dependence Plots
 which give you a sense of how an individual features (aka columns or variables) impact the model's average prediction.


For an overview of available machine learning interpretability techniques I'd recommend taking a look at H2O.ai's 
MLI booklet
 (though please note that these techniques are, for the most part, only provided in a different product - so if you wanted to use them you would have to code the techniques yourself).",2018-12-31T21:29:47,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53879528
54012463,54012463,1,"The jira ticket in the comments has been resolved, and this parsing issue is no longer an issue with newer version of H2O. My recommendation would be to upgrade - for example if you upgrade to latest version of H2O you shouldn't have any issues.


I did a test with version 3.22.0.2 with your example and got:


In [6]: h2o.H2OFrame(testing)
Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%
Out[6]:
C1
----
你
好
嗎

[3 rows x 1 column]",2019-01-02T20:03:16,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53863717
53810224,53810224,2,"This does not matter at all.


The h2o.jar bundled with Driverless AI is not for GPU use at all.


All of the GPU use is from the Driverless AI python processes.",2018-12-17T06:55:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53810177
53783235,53783235,2,"The max_mem_size parameter goes straight to the Xmx parameter for the Java heap allocated to the h2o backend process.


Because java is a garbage collected language, you never want to make the java heap size larger than about 90% of physical memory or you run the risk of uncontrollable swapping.",2018-12-14T16:08:31,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53782766
53777873,53777873,1,"No, you can only do a stacked ensemble of H2O models, i.e. the models must have been trained on H2O cluster.",2018-12-14T10:28:12,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,53777268
53766896,53766896,1,"Generally if you are not seeing the AUC metric it is because the H2O-Algo did not solve a binary classification problem. 


If you want the accuracy for a multinomial problem use 
[max_hit_ratio_k][1]
 and look at 
k=1
.


If you want to see metrics for multinomial in general, checkout what is available in the 
documentation
, for example a confusion matrix and 
mean_per_class_error
 are both available.


Please find an example below: where the goal is to get the hit_ratio k = 1 (see last few lines)


import h2o
from h2o.estimators.glm import H2OGeneralizedLinearEstimator
h2o.init()

# import the iris dataset:
# this dataset is used to classify the type of iris plant
# the original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Iris
iris = h2o.import_file(""http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"")

# convert response column to a factor
iris['class'] = iris['class'].asfactor()

# set the predictor names and the response column name
predictors = iris.columns[:-1]
response = 'class'

# split into train and validation sets
train, valid = iris.split_frame(ratios = [.8])

# try using the `link` parameter:
# Initialize and train a GLM
iris_glm = H2OGeneralizedLinearEstimator(family = 'multinomial', link = 'family_default')
iris_glm.train(x = predictors, y = response, training_frame = train, validation_frame = valid)

pd = iris_glm.hit_ratio_table().as_data_frame()
pd.loc[(0,'hit_ratio')]",2018-12-13T17:09:27,,,,53762743
53731254,53731254,2,"This looks like a bug to me. Do you happen to have the H2O log? It should have the full exception which could tell us what is wrong.


Please file a jira here: 
https://0xdata.atlassian.net/secure/Dashboard.jspa


We will look into it. Thank you for reporting this issue.",2018-12-11T19:42:58,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,53718511
76141408,76141408,0,"Encountered the same problem. Ran a SQL Server Profiler to see what exactly H2O is trying to do. When you send a Table Parameter it ignores whatever you sent in select_query and it does this:


SELECT * FROM testTable FETCH NEXT 1 ROWS ONLY


The funny thing is that it doesn't validate the Table parameter in any way, so you can just initiate a comment after the table name:


table = ""testTable --""


and it will produce the query below and import the data successfully :)


SELECT * FROM testTable -- FETCH NEXT 1 ROWS ONLY",2023-04-30T13:03:45,Georgi Lubomirov,https://stackoverflow.com/users/5986164/georgi-lubomirov,317,53718511
53764257,53764257,5,"In the iml package there are specific feature classes that are acceptable, namely numeric, integer, character, factor and ordered. If you have any Date objects, or any other data type than the 5 listed here than the Predictor object can not be created.",2018-12-13T14:37:59,Curtis,https://stackoverflow.com/users/4664321/curtis,459,53712777
53688186,53688186,3,"No, H2O only contains algorithms that learn to predict a single response variable at a time.  You could turn each unique combination into a single class and train a multi-class model that way, or predict each class with a separate model.",2018-12-08T23:57:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",53686728
53696531,53696531,1,"Any algorithm that creates a model that gives you ""finance,freelancers,contractors,zen99"" for one set of inputs, and ""cms,naytev"" for another set of inputs is horribly over-fitted. You need to take a step back and think about what your actual question is.


But in lieu of that, here is one idea: train some word embeddings (or use some pre-trained ones) on your answer words. You could then average the vectors for each set of values, and hope this gives you a good numeric representation of the ""topic"". You then need to turn your, say, 100 dimensional averaged word vector into a single number (PCA comes to mind). And now you have a single number that you can give to a machine learning algorithm, and that it can predict.


You still have a problem: having predicted a number, how do you turn that number into a 100-dim vector, and from there in to a topic, and from there into topic words? Tricky, but maybe not impossible.


(As an aside, if you turn the above ""single number"" into a factor, and have the machine learning model do a categorization, to predicting the most similar topic to those it has seen before... you've basically gone full circle and will get a model identical to 
the one you started with that has too many classes
.)",2018-12-09T20:47:14,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,53686728
53684511,53684511,1,"When you say you have 700 classes, do you mean your response variable is made up of 
arrays
 of those 700 unique numbers? Because you gave this example:


Response variable tags: 
[74]
[156, 89]
[153, 13, 133, 40]
[150]
[474, 277, 113]
[181, 117]
[15, 87, 8, 11]



H2O cannot predict arrays. Each unique combination of numbers will be counting as a single class. You therefore likely have a lot more than 700 classes, from H2O's point of view.


If you look at the data over on Flow ( 
http://127.0.0.1:54321/
 ) it will tell you how many unique levels there are in 'tags'. (You can also get it from the python API, using 
describe()
 on the frame, or 
categories()
 on the column in question will list all the levels.)


Your next question is going to be what to do about this. I suggest making that a new question, where you explain what the 700 values, and the arrays represent; it is almost certainly going to involve some domain-specific pre-processing. However you could try playing with 
categorical_encoding
 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/categorical_encoding.html",2018-12-08T16:24:20,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,53684039
53678211,53678211,2,"From the 
technical note
 on this topic


Why Deep learning results are not reproducible: 


Motivation


H2O's Deep Learning uses a technique called 
HOGWILD
! which greatly increases the speed of training, but is not reproducible by default.


Solution


In order to obtain reproducible results, you must set 
reproducible = TRUE
 and 
seed = 1
 (for example, but you can use any seed as long as you use the same one each time).  If you force reproducibility, it will slow down the training because this only works on a single thread.  By default, H2O clusters are started with the same number of threads as number of cores (e.g. 8 is typical on a laptop).


The R example below demonstrates how to produce reproducible deep learning models:


library(h2o)
h2o.init(nthreads = -1)

# Import a sample binary outcome train/test set into R
train <- read.table(""http://www.stat.berkeley.edu/~ledell/data/higgs_10k.csv"", sep="","")
test <- read.table(""http://www.stat.berkeley.edu/~ledell/data/higgs_test_5k.csv"", sep="","")


# Convert R data.frames into H2O parsed data objects
training_frame <- as.h2o(train)
validation_frame <- as.h2o(test)
y <- ""V1""
x <- setdiff(names(training_frame), y)
family <- ""binomial""
training_frame[,c(y)] <- as.factor(training_frame[,c(y)])  #Force Binary classification
validation_frame[,c(y)] <- as.factor(validation_frame[,c(y)])



Now we will fit two models and show that the training AUC is the same both times (ie. reproducible).


fit <- h2o.deeplearning(x = x, y = y, 
                            training_frame = training_frame, 
                            reproducible = TRUE, 
                            seed = 1)
h2o.auc(fit)
#[1] 0.8715931

fit2 <- h2o.deeplearning(x = x, y = y, 
                            training_frame = training_frame, 
                            reproducible = TRUE, 
                            seed = 1)
h2o.auc(fit2)
#[1] 0.8715931",2018-12-07T23:56:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53677325
53770193,53770193,1,"This question has been asked a few times, and generally the issue is that you forgot to either convert your numeric valued response as a factor (see the 
as.factor
 function) and/or specifying the 
distribution
 parameter in the algorithm as 
bernoulli
.


Take a look at the 
documentations
 overview of the distribution parameter it should help clear things up.",2018-12-13T21:16:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53677262
53674427,53674427,1,"Try using a smaller depth.  The default depth in DRF is much bigger than for GBM, and most of the size growth is probably due to that.


You can also use a smaller number of trees.


Switching to MOJO would probably also reduce size by about 10x.",2018-12-07T17:38:46,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53673953
53670856,53670856,0,"My first step would be to use K-LIME (K local interpretable model-agnostic explanations) to see if it can build a model to explain your autoencoder model. 


K-LIME is available in 
H2O's R package
 and (I believe) Python. 


This is a helpful explanation
 of the LIME concept.",2018-12-07T13:46:16,Frank B.,https://stackoverflow.com/users/2630758/frank-b,"1,873",53670600
53657518,53657518,1,"If the purpose is to monitor the progress of your model, I would highly recommend using Flow in parallel with the api you are using (i.e. the R or Python API). 


Specify a model ID to your model in say python, then open Flow, list all the models, then select your model and watch in build in real time.


That way you don't have to deal with a progress bar but you can still view the progress of your model 
plus
 you can stop your model and have it finish early using Flow.


If this is not your intention and you want the progress bar to disappear for some other reason, please make a 
jira ticket
 and detail this feature request since H2O-3 is open source and community input is really valued (so thanks!).",2018-12-06T18:21:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53657146
68821930,68821930,0,"min_split_improvment
 is only one of the factors you can play with. If I were you, I would have used 
GridSearch
 with a small range of factors for




ntrees


learn_rate


sample_rate


col_sample_rate_per_tree




All of them are important to avoid over-fitting.",2021-08-17T17:49:44,sds,https://stackoverflow.com/users/850781/sds,59.8k,53656780
53656670,53656670,0,"AUC is only available for binary classification, if you are interested in a multi-class classification metric you can try using logloss, for example.


Here's a description for AUC from the 
docs
 (you can also use this link to learn more about what metrics can be used for multi-class classification problems):


AUC (Area Under the ROC Curve)


This model metric is used to evaluate how well a binary classification model is able to distinguish between true positives and false positives. An AUC of 1 indicates a perfect classifier, while an AUC of .5 indicates a poor classifier, whose performance is no better than random guessing. H2O uses the trapezoidal rule to approximate the area under the ROC curve.
H2O uses the trapezoidal rule to approximate the area under the ROC curve. (Tip: AUC is usually not the best metric for an imbalanced binary target because a high number of True Negatives can cause the AUC to look inflated. For an imbalanced binary target, we recommend AUCPR or MCC.)",2018-12-06T17:22:40,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53654605
53656573,53656573,1,"If you want to use your model for scoring via python, you could use either 
h2o.mojo_predict_pandas
 or 
h2o.mojo_predict_csv
. But otherwise if you want to load a binary model that you previously saved, you will need to have compatible versions.


Outside of H2O-3 you can look into pyjnius as Tom recommended: 
https://github.com/kivy/pyjnius",2018-12-06T17:16:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53650846
62463357,62463357,0,"Another alternative is to use pysparkling, if you only need it for scoring:


from pysparkling.ml import H2OMOJOModel

# Load test data to predict
df = spark.read.parquet(test_data_path)

# Load mojo model
mojo = H2OMOJOModel.createFromMojo(mojo_path)

# Make predictions
predictions = mojo.transform(df)

# Show predictions with ground truth (y_true and y_pred)
predictions.select('your_target_column', 'prediction').show()",2020-06-19T04:40:00,,,,53650846
53658059,53658059,1,"You can find the returned object 
here
. 

classProbabilities
 is a 
Java array
 and Java arrays do not have the 
toString
 method, which is why your print statement is returning something non-human-readable.


One way to access this value would be to use 
py4j


for example this should work:


for i in easy_model.predictBinomial(r).classProbabilities:
...     print(i)



or you can covert it to a list.",2018-12-06T19:03:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53649801
53657441,53657441,0,"It looks like the closest thing to min_samples_split is 
min_split_improvement
: 
Minimum relative improvement in squared error reduction for a split to happen",2018-12-06T18:16:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53642304
45943695,45943695,2,"It seems as if 
h2o.distance
 calculates the sum of squares, without taking the square root: so take the square root to get the standard result.


distance.h2o <- h2o.distance(df1.h[1,],df2.h[1,],""l2"") 
sqrt(distance.h2o)",2017-08-29T16:06:00,user20650,https://stackoverflow.com/users/2250190/user20650,25.7k,53638457
53621603,53621603,1,"The name of the CV parameter for Stacked Ensemble is called 
metalearner_nfolds
 instead of 
nfolds
.  This is to emphasize that the cross-validation is for the metalearning algorithm.  The list of parameters for Stacked Ensemble can be found 
here
.",2018-12-04T21:23:06,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",53620950
53622558,53622558,1,"The file format should be the same (see option 3 at bottom of post), I did a quick test and it worked for me using 
importFiles [ ""s3a://<AWS_ACCESS_KEY>:<AWS_SECRET_KEY>@bucket/path/to/file.csv"" ]
. 


I would check if your connection is good, your cluster status, and if you can access the file any other way.


Here is what the current docs have for 
H2O running in standalone mode
 you can also go to this link to see multi-node mode:


When running H2O in standalone mode using the simple Java launch command, we can pass in the S3 credentials in two ways.


You can pass in credentials in standalone mode by creating a core-site.xml file and pass it in with the flag -hdfs_config. For an example core-site.xml file, refer to Core-site.xml.




Edit the properties in the core-site.xml file to include your Access Key ID and Access Key as shown in the following example:




<property>
      <name>fs.s3.awsAccessKeyId</name>
      <value>[AWS SECRET KEY]</value>
</property>


<property>
  <name>fs.s3.awsSecretAccessKey</name>
  <value>[AWS SECRET ACCESS KEY]</value>
</property>




Launch with the configuration file core-site.xml by entering the following in the command line:

java -jar h2o.jar -hdfs_config core-site.xml


Import the data using 
importFile
 with the S3 URL path: 
s3://bucket/path/to/file.csv
. You can pass the Minio Access Key and Secret Access Key in an S3 URL in Flow, R, or Python (where AWS_ACCESS_KEY represents your user name, and AWS_SECRET_KEY represents your password).




To import the data from the Flow API:

importFiles [ ""s3://<AWS_ACCESS_KEY>:<AWS_SECRET_KEY>@bucket/path/to/file.csv"" ]",2018-12-04T22:43:18,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53605264
53602709,53602709,1,"Without having a dataset to rerun your code on it's hard to say what caused the error. For your second error, check if the column 
Cover_Type
 exists in your test_gb dataframe. 


The code you have seems to be fine, so I would just double check your column names.


In addition here is a code snippet with xgboost that shows you, you can use the hit_ratio_table() successfully.


library(h2o)
h2o.init()
iris.hex <- h2o.importFile( ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"")
i.sid <- h2o.runif(iris.hex)
iris.train <- h2o.assign(iris.hex[i.sid > .2, ], ""iris.train"")
iris.test <- h2o.assign(iris.hex[i.sid <= .2, ], ""iris.test"")
iris.xgboost.valid <- h2o.xgboost(x = 1:4, y = 5, training_frame = iris.train, validation_frame = iris.test)


# Hit ratio
hrt.valid.T <- h2o.hit_ratio_table(iris.xgboost.valid,valid = TRUE)
print(hrt.valid.T)",2018-12-03T22:10:14,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53598898
53603945,53603945,1,"First make sure that you specify distribution=""multinomial"". If you don't have too many tags, then you can just use the original tag as a response level. Otherwise if you leave numeric value levels, you will need to have some mapping that you can use to see what values correspond to your original tags.


here is also an example of how to use word2vec with an H2O algo, to give you a sense of what your target should look like: 
https://github.com/h2oai/h2o-3/blob/master/h2o-py/demos/word2vec_craigslistjobtitles.ipynb
 as well as a tutorial for deep learning: 
https://github.com/h2oai/h2o-tutorials/tree/master/tutorials/deeplearning",2018-12-04T00:23:14,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53594777
53599637,53599637,3,"It is available in the REST API 
1
 (see screenshot) you can probably get to it in the H2OFrame object in Python as well but it is not directly exposed.",2018-12-03T18:24:08,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,53594136
53599770,53599770,1,"So here a complete solution in 
python
 based on Michal Kurka's and Tom Kraljevic's suggestions:


import h2o
import requests
import json

h2o.init()

iris_df = h2o.upload_file(path=""~/iris.csv"")

apiEndpoint = ""http://127.0.0.1:54321/3/Frames/""
res = json.loads(requests.get(apiEndpoint + iris_df.frame_id).text)

print(""Checksum 1: "", res[""frames""][0][""checksum""])

#change a bit
iris_df[0, 1] = iris_df[0, 1] + 1e-3

res = json.loads(requests.get(apiEndpoint + iris_df.frame_id).text)

print(""Checksum 2: "", res[""frames""][0][""checksum""])

h2o.cluster().shutdown()



This gives


Checksum 1:  8858396055714143663
Checksum 2:  -4953793257165767052



Thanks for your help!",2018-12-03T18:33:43,,,,53594136
53599539,53599539,1,"H2O-3 has the option for checkpointing, though not for Naive Bayes. from the 
docs
:


The checkpoint option is available for DRF, GBM, and Deep Learning algorithms. This allows you to specify a model key associated with a previously trained model. This will build a new model as a continuation of a previously generated model. If this is not specified, then the algorithm will start training a new model instead of continuing building a previous model.


If this is what you are looking for, the above link also links to python and R code examples on how to use the checkpointing parameter.",2018-12-03T18:16:25,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53588101
53788246,53788246,9,"Here are the specifics of how the prediction threshold is selected when a user runs 
h2o.predict()
 or 
.predict()
:


1) if you train a model with only training data - the Max F1 threshold from the train data model metrics is used.


2) if you train a model with train and validation data - the Max F1 threshold from the validation data model metrics is used.


3) if you train a model with train data and set the nfold parameter - the Max F1 threshold from the train data model metrics is used.


4) if you train a model with the train data, validation data and set the nfold parameter -  the Max F1 threshold from the validation data model metrics is used.",2018-12-14T23:40:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53587308
53592475,53592475,1,"It seems that I have found the reason, and it is rather a simple one:


F1 is appropriate only for models which have two possible classes as the response variable. Mine had more.


So, H2O did not suggest the metric.",2018-12-03T11:03:25,Sam,https://stackoverflow.com/users/9644821/sam,136,53583235
53553974,53553974,4,"These two MSE values are calculated differently.


The first one (0.1641124) is calculated using all the predictions on the hold out sets during cross validation: 


create model:  


m <- h2o.glm(x = 2:5,
             y = 1,
             train,
             nfolds = 10,
             seed = 123,
             keep_cross_validation_predictions = TRUE,
             keep_cross_validation_fold_assignment = TRUE)



extract hold out predictions 


preds <- as.data.frame(h2o.cross_validation_holdout_predictions(m))



calculate MSE:  


mean((preds$predict - as.data.frame(train)$Sepal.Length)^2)
#output
0.1641125



wheres the lower MSE (0.14977892) represents the average of MSE for each hold out set:


folds <- as.data.frame(h2o.cross_validation_fold_assignment(m))

library(tidyverse)
data.frame(preds = preds$predict,  #create a data frame with hold out predictions
           folds = folds$fold_assignment,  #folds assignement
           true = as.data.frame(train)$Sepal.Length) %>% #true values
  group_by(folds) %>% #group by folds 
  summarise(mse = mean((preds - true)^2)) %>% # calculate mse for each fold
  ungroup() %>%
  summarise(mse = mean(mse)) %>% #average them
  as.numeric
#output
0.1497789



to reproduce first run:


library(h2o)

h <- h2o.init()
data <- as.h2o(iris)
part <- h2o.splitFrame(data, 0.7, seed = 123)
train <- part[[1]]
test <- part[[2]]",2018-11-30T08:37:43,missuse,https://stackoverflow.com/users/8573068/missuse,19.6k,53552294
53552404,53552404,1,"You can get training metrics as follows:


m <- h2o.glm(x=2:5,y=1,train,validation_frame = test)


  #We would ideally use a validation set. 

h2o.performance(m,test)
m@model$training_metrics",2018-11-30T06:29:34,,,,53552137
53618422,53618422,1,"The equations for the Gains and Lift Chart can be found in this file: 
https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/hex/GainsLift.java


Which shows:


E  = total number of events


N  = number of observations


G  = number of groups (10 for deciles or 20 for demi-deciles)


P  = overall proportion of observations that are events (P = E/N)


ei = number of events in group i, i=1,2,...,G


ni = number of observations in group i


pi = proportion of observations in group i that are events (pi = ei/ni)


groups: are hard coded to 16; if there are fewer than 16 unique probability values, then the number of groups is reduced to the number of unique quantile thresholds. 


cumulative data fraction =  sum_n_i/N


lower_threshold = set by quantile bins


lift = pi/P


cumulative_lift = (Σiei/Σini)/P


response_rate = 100*pi


cumulative_response_rate = 100*Σiei/Σini


capture_rate = 100*ei/E


cumulative_capture_rate = 100*Σiei/E


gain = 100*(lift-1)


cumulative_gain = 100*(sum_lift-1)


average_response_rate = E/N


So here is a example walkthrough using the H2O-3 Python API:


import h2o
import pandas as pd
import numpy as np
from h2o.estimators.gbm import H2OGradientBoostingEstimator
h2o.init()

# import and split the dataset
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

convert response column to a factor
cars[""economy_20mpg""] = cars[""economy_20mpg""].asfactor()

# set the predictor names and the response column name
predictors = [""displacement"",""power"",""weight"",""acceleration"",""year""]
response = ""economy_20mpg""

# split dataset
train, valid = cars.split_frame(ratios=[.7],seed=1234)

# Initialize and train a GBM
cars_gbm = H2OGradientBoostingEstimator(seed = 1234)
cars_gbm.train(x = predictors, y = response, training_frame = train, validation_frame=valid) 

# Generate Gains and Lift Table
# documentation on this parameter can be found here:
# http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/model_categories.html?#h2o.model.H2OBinomialModel.gains_lift
gainslift = cars_gbm.gains_lift(train=False, valid=True, xval=False)



Table Overview


As expected we have 16 groups, because this is the hardcoded default behavior.




Cumulative data fractions


Threshold probability value


Response rates (proportion of observations that are events in a group)


Cumulative response rate


Event capture rate


Cumulative capture rate


Gain (difference in percentages between the overall proportion of events and the observed proportion of observations that are events in the group)


Cumulative gain




What if I Want Just the Deciles


By default the Gains and Lift Table provides you with more then just the deciles or ventiles, what this means is you have more flexibilty to pick out the percentiles in which you are interested.


Let's take the example of getting our deciles. In this example we see that we can start at row 6, skip row 7 and then take the rest of the rows to get our deciles.


Since the Gains and Lift Table returns a TwoDimTable we can use our group numbers as selection indices.


# show gains and lift table data type
print('H2O Gains Lift Table is of type: ', type(gainslift))
H2O Gains Lift Table is of type:  <class 'h2o.two_dim_table.H2OTwoDimTable'>

# since this table is small and for ease of use let's covert to a pandas dataframe
pandas_gl = gainslift.as_data_frame()
pandas_gl.set_index('group')


gainslift_deciles = pandas_gl.iloc[pd.np.r_[5,7:16], :]
gainslift_deciles



What if I Want Just the Ventiles


Those are available to select out as well, so let's do that next.


gainslift_ventiles = pandas_gl.iloc[pd.np.r_[7,9,11,13,15], :]
gainslift_ventiles",2018-12-04T17:26:06,,,,53545179
53590941,53590941,1,"From the error, I think your response variable is not binary. You can change your response variable to factor before putting it into model. i.e.


df$y <- as.factor(df$y)



""ROC is a graphical plot that illustrates the diagnostic ability of a 
binary classifier
 system as its discrimination threshold is varied"".


source:

ROC wiki",2018-12-03T09:37:52,Ralph Deint,https://stackoverflow.com/users/4959970/ralph-deint,380,53511976
53510090,53510090,2,"No it does not.


It does the simplest possible random split, handling each row independently with a ""coin flip"" row-by-row.


The thinking is, since H2O-3 is intended to handle big data, there are enough samples to not worry about it.",2018-11-28T00:00:16,,,,53508887
54119552,54119552,1,"Thank you for pointing this out, while the backend equation located 
here
 is correct (so the implementation is correct), the equation in the documentation appears to be incorrect. I have created this 
Jira ticket
 to update the equation in the documentation. The ticket contains the correct equation along with helpful information to derive it.",2019-01-09T22:51:10,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53485434
53659770,53659770,2,"Here are a few recommendations of what you can try. 




Train for more epochs


Decrease batch size


Increase the number of neurons in the hidden layers.




It is possible that a low number of epochs is the cause for worse train performance in your regression problem.",2018-12-06T21:14:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53477412
53507955,53507955,0,"Thanks for the detailed description. To better understand your problem - would you be able to provide a simplified example of how you are calling H2O-3 using the Java bindings?


You might be hitting a bug so if you are able to give us a reproducer we could expedite a fix for this issue.",2018-11-27T20:51:49,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,53474151
53466650,53466650,1,"It will be more efficient to use the H2O functions to load the data and split it.


data = h2o.importFile(""dataset.csv"")
y = 2 #Response is 2nd column, first is an index
x = 3:(ncol(data))  #Learn from all the other columns
data[,y] = as.factor(data[,y])

parts = h2o.splitFrame(data, 0.8)  #Split 80/20
train = parts[[1]]
test = parts[[2]]

# BELOW: Create h2o.deeplearning model with subset of dataset.
mlModel = h2o.deeplearning(x=x, y=y, training_frame=train,activation=""Rectifier"",
                           hidden=c(6,6),epochs=10,train_samples_per_iteration = -2)

h2o.performance(mlModel, test)



It is hard to say what the problem with your original code is, without seeing the contents of dataset.csv and being able to try it. My guess is that train and test are not being split, and it is actually being trained on the test data.",2018-11-25T10:38:18,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,53451856
53522214,53522214,0,@s.brunel has the right answer. Keep in mind when writing routines that with binary predictions it will return three variables. Whereas when predicting a continuous variable you get a single variable.,2018-11-28T14:53:36,Jsimp,https://stackoverflow.com/users/10298545/jsimp,58,53441181
53547212,53547212,0,"posting the answer to make it easier to find.


If you want to use R functions on an H2OFrame you will first need to convert that H2OFrame to an R frame and you can do that as follows for your particular case:


pre_df <- as.data.frame(pre)



Please also note that some H2O functions use the same naming convention as R functions, so while you may think the 
summary()
 function was an R function it was actually the H2O 
summary()
 function which does the same thing as the R function but for an H2OFrame.",2018-11-29T20:39:34,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53441181
53438299,53438299,2,"No specific Knox integration exists today, but you can contact 
[email protected]
 for information about the Enterprise version of Steam.


It has significant security integration for Kerberos, LDAP, Active Directory, SSL and Hadoop proxy user impersonation, so people get their own dedicated H2O jobs running as themselves with their personal HDFS-enforced authorized data access capabilities.",2018-11-22T21:44:32,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53437936
53438245,53438245,2,"h2o.init() will look for an existing h2o instance.  since you started one by hand with “java -jar h2o.jar” h2o.init() found it and connected to it.


if you don’t specify an IP address, and h2o.init() does not find an h2o instance already running, then h2o.init() will try to make one if startH2O is true.  the message saying that port 54321 or port 54322 is not available means exactly that.  one of them must have been taken even if it’s not what you intended.  Use “netstat -anp” to diagnose port usage on linux.",2018-11-22T21:38:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53428004
53458263,53458263,1,"Ok I found a solution with a software engineer working in my company.


He simply wrote a bash which will call ""java -jar h2o.jar"" that manually start h2o cluster and inside R script I connect to the existing h2o instance through


h2o.init(ip=""machine_ip"",port=number_port,startH2O=FALSE)",2018-11-24T12:43:12,Marco Fumagalli,https://stackoverflow.com/users/5654564/marco-fumagalli,"2,437",53428004
53438407,53438407,0,The message about dropping constant columns is not an error.  It is just telling you the model identified that those columns will not impact the predictions and so those columns will be ignored.,2018-11-22T21:58:34,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53421976
53384866,53384866,1,"What you are verifying is correct, H2O-3 orders levels in lexicographical order. 


You can use this confusion matrix as an example of how a confusion matrix will be ordered (i.e. if you have categoricals and you sort them in alphabetical order they will map over to the 0,1,2... as shown)




And here is an example of a binary outcome with No and Yes, where No maps to 0 and Yes maps to 1.",2018-11-20T01:14:21,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53383306
53966326,53966326,-2,"There is a better way to build decision trees with H2O - without extracting MOJOs or leaving R/Python - using new Tree API (starting with 3.22.0.1). For comprehensive explanations see:




Inspecting Decision Trees with H2O


Finally, You can Plot H2O Decision Trees in R",2018-12-29T02:56:11,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,53382158
53346309,53346309,1,"This is not something you can do with H2O's tree-based algorithm, and these algos are not designed for the user to decide which feature to split on - this is something the algorithm figures out for you.


From the H2O-3 user guide:


How does DRF decide which feature to split on?

It splits on the column and level that results in the greatest reduction in residual sum of the squares (RSS) in the subtree at that point. It considers all fields available from the algorithm. Note that any use of column sampling and row sampling will cause each decision to not consider all data points, and that this is on purpose to generate more robust trees. To find the best level, the histogram binning process is used to quickly compute the potential MSE of each possible split. The number of bins is controlled via nbins_cats for categoricals, the pair of nbins (the number of bins for the histogram to build, then split at the best point), and nbins_top_level (the minimum number of bins at the root level to use to build the histogram). This number will then be decreased by a factor of two per level. 


For nbins_top_level, higher = more precise, but potentially more prone to overfitting. Higher also takes more memory and possibly longer to run.


(same goes for GBM and for randomize trees you can look here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html#extremely-randomized-trees
)",2018-11-16T22:35:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53343397
53344170,53344170,0,"ddply is not available in the python api, you are linking to out-of-date documentation. 


For the latest stable documentation please see this link: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/index.html
 (and for 3.22.0.1 see 
http://h2o-release.s3.amazonaws.com/h2o/rel-xia/1/docs-website/h2o-py/docs/index.html
).",2018-11-16T19:24:21,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53343283
53499766,53499766,3,"I had the same problem while trying to initiate h2o inside a virtual environment using jupyter notebook. 


As it has been said on the previous thread 
OSError: Version mismatch while installing h2o?
 you probably have to kill the h2o cluster. In my case it worked with:


h2o.cluster().shutdown()",2018-11-27T12:31:22,MichalisOik,https://stackoverflow.com/users/10708478/michalisoik,31,53328131
53328604,53328604,0,"this question is a duplicate of this questions: 
OSError: Version mismatch while installing h2o?


basically you need to make sure your h2o.jar version matches the version you ahve for you python package. You can also find more of a walk through.


for the python package you might just need to uninstall the version you currently have with a pip uninstall and then reinstall the latest wheel file found on the H2O-3 downloads page: 
http://h2o-release.s3.amazonaws.com/h2o/rel-xia/1/index.html
 and click on the python tab.",2018-11-15T22:10:34,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53328131
53294254,53294254,2,During initiating h2o using h2o.init(max_mem_size = 8G) here set the amount of RAM you want h2o to utilize.,2018-11-14T06:25:11,Hunaidkhan,https://stackoverflow.com/users/9354364/hunaidkhan,"1,418",53294034
53291046,53291046,0,"Correction: Realized the inputs for precision and recall were in the wrong order. The order is always 
(y_true, y_pred)
, per the Scikit-Learn 
documentation
.


Corrected Evaluation Code


recall_score(y_test, rf_gpu_pred)
precision_score(y_test, rf_gpu_pred)",2018-11-13T23:33:56,Greg,https://stackoverflow.com/users/4317871/greg,29,53290612
53275815,53275815,1,"This works for me:


mydata<-readxl::read_excel(""nelg.xlsx"")
require(h2o)
h2o.init()          
as.h2o(mydata)",2018-11-13T07:22:37,NelsonGon,https://stackoverflow.com/users/10323798/nelsongon,13.3k,53275612
53275814,53275814,0,"Hi you can read the excel file using normal 
read.xlsx
 and later convert it to h2o data frame using 

train_h2o <- as.h2o(df)
 # Creating h2o dataframe",2018-11-13T07:22:28,Hunaidkhan,https://stackoverflow.com/users/9354364/hunaidkhan,"1,418",53275612
53522883,53522883,0,"An additional option is rio:
`


library(rio)

data<-rio::import(""C:/Users/USER/Desktop/iris.csv"")
h2o.init()
h2o_data<-as.h2o(data)



`",2018-11-28T15:28:40,Jsimp,https://stackoverflow.com/users/10298545/jsimp,58,53275612
53274996,53274996,0,"I did not realize that I was not installing the packages under the Edge node, when I installed the packages on all of the nodes I had no problems with the packages.",2018-11-13T06:24:37,Kreitz Gigs,https://stackoverflow.com/users/9275146/kreitz-gigs,379,53267763
53289385,53289385,0,"For H2O-3 version 3.22 and earlier the 
h2o.cor()
 function is only meant to be applied to numeric type columns (so it doesn't handle categorical columns). If you try to run 
h2o.cor()
 on categorical columns it should return NA (the exception being a binary column, because it can be mapped to numeric 0/1).",2018-11-13T20:56:56,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53265386
53235188,53235188,0,"As requested (thanks!) this question was reposted to cross-validated. So the answer on what the pros and cons are can be found at: 
https://stats.stackexchange.com/questions/376203/categorical-encoding-in-h2o-what-is-the-difference-between-the-options",2018-11-10T01:13:31,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53217878
53213576,53213576,0,"Worst case scenario, you can convert the 
H2OFrame
 to a list or pandas DataFrame using 
as_data_frame
, do the filtering there, then convert it back to an H2OFrame.",2018-11-08T17:58:46,Mr. Llama,https://stackoverflow.com/users/477563/mr-llama,20.8k,53213360
53212415,53212415,4,"try this:


performace = glm_fit_lambda_search.model_performance(train=True)
performace.plot()



should work in theory, I'm not able to verify right now. This will plot the performance on the ""train"" set.",2018-11-08T16:48:10,Karl,https://stackoverflow.com/users/141789/karl,"5,782",53212160
53212535,53212535,3,"Tried this and it worked


out = glm_fit_lambda_search.model_performance(testH2O)
fpr = out.fprs
tpr = out.tprs

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='blue', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=lw, linestyle='--')
plt.xlim([0.0, 1.05])
plt.ylim([0.0, 1.05])
plt.legend(loc=""lower right"")
plt.show()",2018-11-08T16:54:19,Joe,https://stackoverflow.com/users/8345236/joe,601,53212160
53337160,53337160,2,"The short answer is
: This is not offered as part of the Marketplace offering out of the box, but can be addressed along with the next release version.


The long answer is
: technically yes. You'd need to follow the steps documented in Google Cloud Docs 
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
, to reserve a static ip and then assign it to a vm. If you are creating a cluster manually, you'd start up N virtual machines, install the required software (e.g. java, python, h2o, h2o-depedencies, etc). Assign the static IP address to each of the VM's and then use the internal ips for clustering based on the flatfile. Theoretically, this should also be doable with the marketplace offering as well, where everything has already been preconfigured and flatfile.txt is generated with the internal ips. Just need to assign a static ip to the VM's",2018-11-16T11:40:56,Nicholas Png,https://stackoverflow.com/users/9801753/nicholas-png,36,53202796
53204782,53204782,0,"What API/language do you use? In R, Python, and also in Flow the progress bar is enabled by default. If you disable it by 
no_progress()
 (in Python), you can again enable it by 
show_progress()
.",2018-11-08T09:26:12,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,53202776
53206030,53206030,0,"You can always just go to the H2O Flow Web UI, look up the job, and view the progress.


It’s very popular to submit a job with R or Python and monitor or cancel it in Flow.",2018-11-08T10:41:33,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53202776
53205891,53205891,1,Make sure the column class is correct and accepted by the function.,2018-11-08T10:32:06,Oliver,https://stackoverflow.com/users/4301424/oliver,312,53202391
77475187,77475187,0,"I changed all character columns to factor and this solved the issue. I am using 
h2o.automl",2023-11-13T15:57:41,Soumya Boral,https://stackoverflow.com/users/8315634/soumya-boral,"1,329",53202391
53205979,53205979,1,"If you use the Easy wrapper, it does this for you automatically.


If you are not using the Easy wrapper then you need to invent the same kind of behavior.


With the Easy wrapper, new columns are ignored and missing columns are treated as N/A.",2018-11-08T10:38:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53197487
53194904,53194904,2,"You can download the R package for 3.22.0.1 from here:




http://h2o-release.s3.amazonaws.com/h2o/rel-xia/1/index.html




At the time of this comment, this is the latest stable release.


The version in CRAN is often a release or two behind, but you can always download the latest stable version from the H2O website.  All versions of H2O are archived in S3.  Every version is there, you just need to find the right link.


The message ""Found version 3.22.0.1, but running version 3.20.0.8"" means there is a mismatch between the version of the R package and a running H2O server on your host.  You might start by making sure the H2O java processes are all stopped before trying to start a new one from R.  (If you're not exactly sure how to do that, worst case just reboot your laptop.)",2018-11-07T17:42:13,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53191182
73899039,73899039,0,"To resolve any problem with H2O version mismatch try


h2o.shutdown()",2022-09-29T16:43:36,swarn,https://stackoverflow.com/users/11819913/swarn,49,53191182
53184188,53184188,0,"The URL is wrong.  Try this instead:


library(h2o)
h2o.init()

mydata <- h2o.importFile(""https://raw.githubusercontent.com/DarrenCook/h2o/bk/datasets/iris_wheader.csv"")",2018-11-07T05:51:02,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",53183466
53195861,53195861,0,"If you are using an H2O algorithm to predict a binary target (0/1), unless you convert your target column to a factor using (.asfactor() in python or as.factor() in R), H2O will assume this column is numeric and will solve a regression problem.


please verify the data type of your target column (it will likely show integer) and make sure that it shows enum.


more informations about your target distribution choices can be found here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/distribution.html",2018-11-07T18:46:10,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53177343
53174469,53174469,0,"I just found out how to solve this issue: simply increase memory allowed.


conf <- spark_config()
conf$`sparklyr.cores.local` <- 4
conf$`sparklyr.shell.driver-memory` <- ""16G""
conf$spark.memory.fraction <- 0.9",2018-11-06T15:00:07,Catiger3331,https://stackoverflow.com/users/5665986/catiger3331,641,53174325
53180280,53180280,2,"XGBoost has only been recently added to AutoML (you can see the changes for each version here: 
https://github.com/h2oai/h2o-3/blob/master/Changes.md
). 


If you would like to have access to XGBoost within H2OAutoML please upgrade to the latest version, which is currently 3.22.0.1: 
http://h2o-release.s3.amazonaws.com/h2o/rel-xia/1/index.html",2018-11-06T21:27:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",53173411
53148833,53148833,1,"h2o.saveModel() stores a binary H2O-3 specific model format suited for reading back with h2o.loadModel().


Note that H2O-3 binary models can only be read back with the same version of H2O that they were created with.  As a result, MOJOs have an easier-to-use backward compatibility contract and there are definitely situations where one would prefer MOJOs.",2018-11-05T05:31:55,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53148280
53154823,53154823,3,"I suggest to update to the newest version 3.22.0.1. Then initialise the cluster so that it does not bind only to localhost: 
init(bind_to_localhost=False)
. When you initialise H2O from R or Python, the instance binds by default to localhost only which means that you can access it from RStudio because it is running on the server, but not via Flow because then you access it from your distant browser.


Another option is to start H2O independently from command line.


Beware that if you do not bind H2O to localhost only, it is then accessible to anybody who can access the port and the network interface, which can pose a significant security hole (exposing your data, models, etc.).",2018-11-05T12:51:29,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,53142643
53161919,53161919,0,"Unfortunately H2O-3 doesn't support using 
ip=external
 when you want to connect to h2o from R. 


If you want to enable external access to an instance, you will need to upgrade to H2O-3 version 3.22.0.1 and use 
bind_to_localhost = false
 within h2o.init(), which will enable external access to the instance. 


please see the R reference with details on bind_to_local: 
http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.init.html",2018-11-05T20:43:19,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53115696
53114566,53114566,1,"Flow and Python are different ways how to use H2O platform so you cannot directly export the Flow notebook into Python, but you can very easily rewrite it into Python as the underlying functionality (calls to the platform) are the same. Have a look at the 
demo
 or the 
Python API Booklet
.",2018-11-02T07:47:05,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,53111770
53105960,53105960,1,"When creating your model, you can set 
keep_cross_validation_models=True
 and then obtain the models by calling 
cross_validation_models()
 on your model object. Then you can obtain each model's performance as usual. See 
the documentation
.",2018-11-01T17:02:51,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,53104998
53099800,53099800,1,"Yes, H2O will use all the cores on a single node to train one model.


nthreads lets you explicitly set the thread pool size that controls the amount of parallelism per process.",2018-11-01T10:53:21,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53097823
53085034,53085034,2,I recommend 4-5x the dataset size.  So at least 64 gb.,2018-10-31T13:52:19,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",53081964
53071472,53071472,0,"Looks like when you pasted the command, you missed the 
java -
 part",2018-10-30T19:20:01,lakeskysea,https://stackoverflow.com/users/1229993/lakeskysea,621,53070222
53072659,53072659,0,"Adding answer to your follow up question that you posed in response to lakeskysea's answer.


If you are seeing the error ""Could not find or load main class hex.genmodel.tools.PrintMojo""


It is likely because you have an old version of H2O, The PrintMojo functionality wasn't added until after version 3.10.4. Please verify that you are using a version of H2O-3 that has the PrintMojo ability.


(and just in case, please also double check that you have graphviz install with 
dot -V
)",2018-10-30T20:45:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53070222
53089051,53089051,0,"As nathan mentioned in the comments the error is due to a bug in Stacked Ensemble Mojo which can be tracked here: 0
xdata.atlassian.net/browse/PUBDEV-6026",2018-10-31T17:29:48,,,,53046533
53051186,53051186,0,"It looks like the error is related to a version miss match, since it is complaining about an illegal argument.


a quick way to see the model's corresponding h2o version number (if you used 
h2o.saveModel()
 to save the model) is to open the model's file - you should be able to see the version number within the first line (in the form 3.10.4.2).


Also you might get a version mismatch error, which would tell you what version you are trying to use versus what version you are currently using. 


There isn't a way within in R to port models from one version to another. From the 
documentation
:


Note:
 When saving an H2O binary model with h2o.saveModel (R), h2o.save_model (Python), or in Flow, you will only be able to load and use that saved binary model with the same version of H2O that you used to train your model. H2O binary models are not compatible across H2O versions. If you update your H2O version, then you will need to retrain your model. For production, you can save your model as a POJO/MOJO. These artifacts are not tied to a particular version of H2O because they are just plain Java code and do not require an H2O cluster to be running.",2018-10-29T17:52:00,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",53038253
53008673,53008673,3,"Seeing the way you generate the data, you should use standardize = F in the h2o.glm to avoid your problem.


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html


It's a issue with the coefff and the standarized coeffs. Note that the best results you should have with intercept = T and standardize = T.


You should avoid intercept when you must predict a 0 values and only in a few more cases.",2018-10-26T12:22:39,Carlos Vecina Tebar,https://stackoverflow.com/users/10546604/carlos-vecina-tebar,370,53007673
52996114,52996114,2,"I did a search on that function name and immediately found a document that explained the function of a list item in the arguments to the 
x
 parameter:




x

  A list containing the names or indices of the variables to encode. A target encoding map will be created for each element in the list. Items in the list can be multiple columns. For example, if 
x = list(c(""A""), c(""B"", ""C""))
, then there will be one mapping frame for A and one mapping frame for B & C (in this case, we group by two columns).",2018-10-25T18:44:14,IRTFM,https://stackoverflow.com/users/1855677/irtfm,263k,52994441
52985267,52985267,1,"If you use use ""docker run --network=host ..."" it will work.",2018-10-25T08:55:24,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52984157
56385617,56385617,0,"See my response to a similar issue 
here
. I describe how it is possible to start an H2O cluster using a flatfile and docker swarm. Basically, you have to run a script in each service before starting H2O, to identify the correct IP addresses for the cluster. This is because docker assigns two IPs to each service. The flatfile needs to use the $HOSTNAME IP for each cluster member, which is difficult to determine in advance.",2019-05-30T21:03:50,caewok,https://stackoverflow.com/users/5786863/caewok,91,52984157
52976032,52976032,1,"The sentence you pointed to that seemed to contradict other portions of the docs, is in fact outdated. I have made a 
Jira Ticket
 to update the FAQ with the correct answer (which is what you see for the GBM missing values section - i.e. the missing value handling is the same for GBM and DRF).


as a side note the enum data type are internally encoded as numeric values, you can learn more about the types of mapping's H2O can use here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/categorical_encoding.html
. For example, after the strings are mapped to integers for Enum, you can split {0, 1, 2, 3, 4, 5} as {0, 4, 5} and {1, 2, 3}.


Or take a look at how h2o-3 does binning for categoricals here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm-faq/histograms_and_binning.html",2018-10-24T18:48:56,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52965384
52974027,52974027,2,"I've summarized your question into a few distinct parts, so the answers will be in a Q/A type fashion.


1). When I use my_model.predict(X), how does H2O-3 know which columns to predict with?




H2O-3 will use the columns that you passed as predictors when you built your model (i.e. whatever you passed to the 
x
 argument in the estimator, or all the columns you included in your training_frame which were not: ignored using 
ignored_columns
, passed as a target to the 
y
 argument, dropped because the column has a constant value.). My recommendation would be to use the 
x
 argument to specify your predictors and ignore the 
ignore_columns
 parameter. If 
X
, the new dataframe you are predicting on includes columns that were not used when you were building a model, those columns will be ignored - so 
column names not column positions
.




2) Should the weights column name be in the ignored column list?




No, if you pass the weights column to the ignored column list, that column will not be considered in any fashion during the model building phase. In fact, if you test this out, you should get a null pointer error or something similar. 




3) Why is the ""weights"" column specified as a predictor and as the 
weights_column
 in the following 
code example
?




This is a great question! I've created two Jira tickets 
one
 to update the documentation to clear up the confusion and another 
one
 to potentially add a user warning.


The short answer, is if you pass the same column to the predictors argument 
x
 
and
 the 
weights_column
 argument, 
that column will only be used as a weight - it will not be used as a feature
.




4) Does the user guide recommend using the weights as a feature and as a weight?




No, in the paragraph you are pointing to, 
the recommendation is to ensure that the column you pass as your 
weights_column
 exists in your training frame and validation frame
 - not that it should also be included as a feature.",2018-10-24T16:35:54,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",52959724
52965741,52965741,1,"This is the key file:




https://github.com/h2oai/h2o-3/blob/master/h2o-r/h2o-package/R/zzz.R




Basically there is one R source file which does the download.  This technique was referred to me by Kurt Hornik from CRAN.


What's happening is the actual uploaded file set is small, but during the hosted package building process inside of CRAN the jar file is downloaded, and the actual CRAN package does contain the jar file.",2018-10-24T09:39:45,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52953545
52964593,52964593,0,"I was able to fix the problem. Gson usually does not like ""NaN"" of infinities for primitive values (or the object as well?)


the fix was to set lenient when configuring Gson. 


I also created a pull request: 
https://github.com/h2oai/h2o-3/pull/2962",2018-10-24T08:45:45,user1548791,https://stackoverflow.com/users/1548791/user1548791,1,52937340
52937782,52937782,0,"The call to parseSetup does not belong here.


as.h2o() already gave you a fully capable h2o frame.


Then binding two h2o frames gave you a third h2o frame.  You can just use it.",2018-10-22T21:07:31,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52937291
53402390,53402390,10,"You can specify a 
pip
 dependency in your 
environment.yml
 like so:


name: myenv
dependencies:
  - python
  - pip:
    - http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/8/Python/h2o-3.18.0.8-py2.py3-none-any.whl



See 
""Creating an environment file manually""
 for more details.",2018-11-20T22:13:11,Dustin Ingram,https://stackoverflow.com/users/328036/dustin-ingram,21.4k,52926610
52841382,52841382,4,"The 
partial_plot()
 method returns a list where the elements are of type 
h2o.two_dim_table.H2OTwoDimTable
 or a list and a plot if you set the 
plot
 parameter = True (see the 
api docs
 to learn more about the parameters and return types).


to see this do:


type(rf_pdp) # should return a list
type(rf_pdp[0]) # should return h2o.two_dim_table.H2OTwoDimTable



Once you have selected the H2OTwoDimTable corresponding to the pdp column of interest you either select the ""mean_response"" column or you could convert the H2OTwoDimTable to a pandas dataframe and select the mean_resp from there.


So to get the mean_response column for ""var1 "" for example you can do


rf_pdp[0][""mean_response""]



or


rf_pdp[0].as_data_frame()['mean_response']",2018-10-16T17:56:31,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52840437
72665770,72665770,0,"Reproducible example:


if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(h2o, tidyverse, modeldata)

h2o.init()

# load HR data from modeldata pkg
data(""attrition"", package = ""modeldata"")

df <-
  attrition %>%
    mutate_if(
      .predicate = is.ordered,
      .funs.     = factor,
      ordered    = FALSE
    ) %>%
    mutate(
      Attrition  = factor(Attrition, levels = c(""Yes"", ""No""))
    )

index <- 1:5

train.obs <- df[-index,]
loc.obs   <- df[index,]

# create h2o objects for modeling
y <- ""Attrition""
x <- setdiff(names(train.obs), y)

train.obs.h2o <- as.h2o(train.obs)
loc.obs.h2o   <- as.h2o(loc.obs)

# create h2o RF model
h2o_rf <- h2o.randomForest(x, y, training_frame = train.obs.h2o)

# create Partial Dependence Plots (PDP)
h2o_pdp <-
  h2o.partialPlot(
    object = h2o_rf,
    data   = train.obs.h2o,
    cols.  = c(""MonthlyIncome"", ""Age"")
)




Option 1:
 Export pdp dataframe for each of 
AGE
 and 
RACE
 directly to 
Excel
 in separate named sheets


writexl::write_xlsx(
  list(
    MonthlyIncome = h2o_pdp[[1]],
    Age           = h2o_pdp[[2]]),
    path          = ""pdp-metrics.xlsx""
)



Option 2:
 Store H2o PDP locally as dataframe object for each variable


pdpMonIncTbl <- as.data.frame(h2o_pdp[[1]])
pdpAgeTbl    <- as.data.frame(h2o_pdp[[2]])",2022-06-18T00:06:24,,,,52840437
52823119,52823119,2,"key
 is not a parameter in 
h2o.importFile
, which is why you are getting the 
unused argument
 error. Here are the current parameters


  h2o.importFile(path, destination_frame = """", parse = TRUE, header = NA,
  sep = """", col.names = NULL, col.types = NULL, na.strings = NULL,
  decrypt_tool = NULL)



all of which is explained in the 
docs


As others have noted in the comments ""bank_customer_data.csv"" doesn't exist in the h2o package which is why 
system.file
 is not returning anything. 


You should try to import a file you know exists using the process you have above, and see if that works for you. Otherwise if you want to use a dataset in the R package take a look at an example in the R docs for example


h2o.init(ip = ""localhost"", port = 54321, startH2O = TRUE)
prosPath = system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate.hex = h2o.importFile(path = prosPath, destination_frame = ""prostate.hex"")
class(prostate.hex)
summary(prostate.hex)",2018-10-15T18:55:58,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52815447
52767991,52767991,1,"Datatable will officially release Windows wheels starting from version 0.11. Right now it is possible to install the development version of datatable by following the instructions at 
https://datatable.readthedocs.io/en/latest/install.html#install-on-windows",2018-10-11T19:56:51,,,,52767224
52787159,52787159,1,"There isn't really a concept of a row iterator in quite this way for H2O-3.  The (big, distributed) data is stored in memory in a Distributed Key/Value store in Java.  The computations are done on H2O-3 Frames using Fork/Join underneath the hood, and it's moving the code to the data (via an H2O-3 specific in-memory implementation of MapReduce), not moving the data to the code.


A row iterator would be moving the data to the code.  The closest thing H2O-3 has to that is as.data.frame(), which copies an H2O-3 (distributed, big) data frame to an R data frame.  I would not recommend doing this for large data sets.


Introducing new ""custom algorithms"" to H2O-3 means writing them in Java using the (public, but developer-intended) H2O-3 API for adding algorithms.  It can definitely be done, but I wouldn't say it's common, and your best guide would be the code.


The complete code for the H2O-3 platform and algorithms implemented in H2O-3 is in github here:




https://github.com/h2oai/h2o-3",2018-10-12T21:22:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52747370
52746141,52746141,0,"This is a duplicate question, you can find previously posted answers 
here
 and 
here
.


The short answer is this is not currently an option in H2O-3, for alternative options please see the linked questions above. 


In addition a jira ticket has been created for this issue that you can track and comment on here: 
https://0xdata.atlassian.net/browse/PUBDEV-4027",2018-10-10T17:54:00,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52743699
52840362,52840362,0,"Here is the solution for plotting


import matplotlib
import matplotlib.pyplot as plt
import io

matplotlib.use('agg')

def show(p):
    img = io.StringIO()
    p.savefig(img, format='svg')
    img.seek(0)
    print(""%html <div>"" + img.getvalue() + ""</div>"")

plt.clf()
rf_model.partial_plot(data = htest, cols = plot_varimp_df[""variable""].tolist(), nbins=2, plot=True)
show(plt)",2018-10-16T16:47:48,Gavin,https://stackoverflow.com/users/5732164/gavin,"1,521",52732359
52748868,52748868,0,"As noted in the comments by ImportanceOfBeingErnest, this is a compatibility issue between H2O-3 and the newer versions of Matplotlib. The issue is being tracked 
here
 and the current workaround is to make sure you are using an older version of Matplotlib like version 2.2.3 or lower.",2018-10-10T21:12:54,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52723180
52749348,52749348,-1,"0.001 is the same as 0.1%, for AUC since bigger is better, you will want to see an increase of at least .001 after a specified number of scoring rounds.


You have linked to a portion of the documentation that is specific to the algorithms listed in 
Available in
 at the top of the page. So let's stick to answering this question with respect to individual models and not grid search. If you want to see what is being scored at each iteration take a look at your model results in Flow or use my_model.plot() (for the python api) to see what is getting scored at each iteration. For GBM and DRF this will be ntrees, but since different algorithms will have different aspects that change the word iteration is used since it is more generic. 


Did you test this out? what did you find when you did this? Take a look at the scoring history plot in flow and notice what happens when you set both score_tree_interval and score_each_iteration = True versus when you only set score_tree_interval (I would recommend trying to understand these parameters at the individual model level before you use grid search).  


yes, in once case you are specifying early stopping as you build an individual model in the case of grid search you are indicating whether on not to build more models.",2018-10-10T21:58:47,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52713094
52631306,52631306,0,"comment out the 
    'max_runtime_secs': 1800 
can solve the reproducibility issue. One more thing I found out but I don't know why is that if we move early stopping code from search criteria to H2OGradientBoostingEstimator, the code will run faster.


'stopping_metric': eval_metric, 
'stopping_tolerance': 0.001, 
'stopping_rounds': 3,",2018-10-03T16:02:52,,,,52617898
52655261,52655261,1,"Please note that there is a jira ticket for this 
here


It's interesting that you don't get an error when you run your code snippet. When I run your code snippet I get the following error:


Error: DistributedException from localhost/127.0.0.1:54321: 'Poisson loss L(u,a) requires variable a >= 0', caused by java.lang.AssertionError: Poisson loss L(u,a) requires variable a >= 0


I can resolve this error by removing 
transform=""STANDARDIZE""
, because standardization can lead to negative values. For more information on what the transformations do you can take a look at the user guide 
here
 for your convenience here is the definition of how standardize gets used 
Standardize: Standardizing subtracts the mean and then divides each variable by its standard deviation.",2018-10-04T21:16:58,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52606920
52599801,52599801,2,"The 
score_each_iteration
 parameter turns on/off scoring at each iteration -- and the 
score_tree_interval
 parameter defines what that interval is.  For example, if 
score_tree_interval = 5
, then an interval is a period of five trees (not one).  So it would score every 5 trees.


The default scoring is not based on fixed intervals -- it scores more often at the beginning and less often towards the end.  That's the reason we have these parameters to override this behavior.",2018-10-01T22:37:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",52599403
52656689,52656689,4,"As Darren Cook mentioned in the comments there is early stopping for each model you build and early stopping for grid search.


For an individual GBM, ntrees (the number of trees) is tuned with early stopping (i.e. using stopping_tolerance, stopping_rounds, stopping_metric specified within the algorithm). You can see this if you open up flow and take a look at the scoring history plot of your individual model. You will see that number of trees is the x-axis.


For Grid Search you have the added layer of your hyper parameters. So if you set ntrees = 100 in your GBM model, and you grid over learning rate = [0.01, 0.015] you will build two models one with ntrees = 100 and learn rate = 0.01, and a second model with ntrees = 100 and learn rate = 0.015. And, for example, in the first model each iteration will have a different number of trees while the learn rate will be fixed. 


So looking at your specific questions:




yes this is correct


the grid will see if there is any improvement between your different learning rates (0.01, 0.015, etc) and max depth. So again what you are saying is correct. The grid will stop if it's not seeing any improvement with different learn rates and max depth values (i.e. it will not continue to build new models).


So here you need to separate out the model and the grid search. An individual model will stop building (adding trees) if it doesn't see improvement after three scoring events (and here your learn_rate and max_depth would be fixed while the ntrees would change). Then we step out to the grid, the grid will stop building new models if it doesn't see a user-specified amount of improvement between the individual models it built.",2018-10-05T00:14:53,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52572541
52669983,52669983,2,"The black line is not the baseline, but the cumulative capture rate. The capture rate is the proportion of all the events that fall into the group/bin. E.g. if 90 out of total 100 positive outcomes/events fall into the first bin, then the capture rate for that bin is 0.9.


The green line is the cumulative lift curve, so by definition the two lines converge at 1.


Whether your model performs well or not depends on your goal. According to the validation metrics, you could capture about 80% of the events by targeting only 50% of the population, which means lift of about 1.6.",2018-10-05T16:38:57,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,52568040
52561009,52561009,0,"This is possible in Flow and it is also possible to get the model from the backend using its key and then continue with your model analysis in one of the apis (R/Py)


Please also take a look at the 
documentation
 on how to make predictions in Flow if needed.
After you build a model you will see that there is a predict button: 




Click on the predict button.


Specify a name for your prediction frame, the model will already be set, select the frame you want to predict on using the frame dropdown menu, and then click on the action button called predict.


In the next cell called 
Prediction
 you will see a table that will have three hyperlinks (model, frame, and predictions). The third hyperlink should correspond to your predictions dataframe, which you provided the name for or H2O-3 provided a default name for. 


Click on the hyperlink in the predictions row or create a new cell, type 
getFrameSummary ""prediction""
 (without the ` marks, and replace ""prediction"" with the name of your prediction frame).


Now click on the view data button, and if your binary target is of type 
enum
 (i.e. categorical and not numeric) you will see a table with prediction labels and probabilities.",2018-09-28T18:37:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52559784
52561236,52561236,1,"Currently, MLI will always display the same dashboard for any DAI algorithm, with the following exceptions: Shapley plots are not currently supported for RuleFit and TensorFlow models, Multinomial currently only show Shapley and Feature Importance (global and local), and Time Series experiments are not yet supported for MLI. What this means is you can expect to always see: K-LIME/LIME-SUP, Surrogate Decision Tree, Partial Dependence Plot and Individual Conditional Expectation. Note this may change in the future, for the most up-to-date details please see the 
documentation
.",2018-09-28T18:58:09,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52549026
52560164,52560164,1,"Please note that H2O-3 is a separate open-source product and is not the same as H2O.ai's DAI product.


The best way to find the answer to all your questions is to look at the Driverless AI documentation:
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/index.html


For your convenience I will post the answers to your questions, but for anyone coming across this question later on I would highly recommend just looking at the docs, since what I state now could quickly become outdated.


Can we see the full list of all algorithms provided with H2O DAI ?
 (answer in the 
FAQ
)


Which algorithms are used in Driverless AI?


Features are engineered with a proprietary stack of Kaggle-winning statistical approaches including some of the most sophisticated target encoding and likelihood estimates based on groupings, aggregations and joins, but we also employ linear models, neural nets, clustering and dimensionality reduction models and many traditional approaches such as one-hot encoding etc.


On top of the engineered features, sophisticated models are fitted, including, but not limited to: XGBoost (both original XGBoost and 'lossguide' (LightGBM) mode), GLM, TensorFlow (including a TensorFlow NLP recipe based on CNN Deeplearning models), and RuleFit. More will continue to be added later.


In general, GBMs are the best single-shot algorithms. Since 2006, boosting methods have proven to be the most accurate for noisy predictive modeling tasks outside of pattern recognition in images and sound (
https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf
). The advent of XGBoost and Kaggle only cemented this position.


Is there any way I can choose which algorithm to use manually ?
 (answer found in the Expert Settings 
Section
): 


To a certain extent yes, you can select which algorithms you want by using the expert settings described in the link above.",2018-09-28T17:27:07,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52548947
52543019,52543019,1,"This is a feature H2O is currently adding, you can track its progress here: 
https://0xdata.atlassian.net/browse/PUBDEV-5743
.


Note that in the ticket there is a suggestion in the comments on how to visualize the trees with native xgboost.",2018-09-27T18:21:46,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52542640
55761881,55761881,0,"I finally found the solution, that seem not documented for XGBoost, but it is indeed the same as for other trees-related algorithms.


Just run this command to generate the first 50 trees from your model:


for tn in {1..50}
do
   java -cp h2o-3.24.0.1/h2o.jar hex.genmodel.tools.PrintMojo --tree $tn -i <your mojo model> -o XGBOOST_$tn.gv
   dot -Tpng  XGBOOST_$tn.gv -o xgboost_$tn.png
done",2019-04-19T12:29:06,btbbass,https://stackoverflow.com/users/3408256/btbbass,145,52542640
52655371,52655371,1,"This parameter should actually not be used by a user and there is a ticket to hide it 
here
. For now please leave 
mini_batch_size
 as 1 (the default value) so that you don't hit any warnings or errors.",2018-10-04T21:25:41,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52538201
65565688,65565688,0,"You can try these two ""h2o-to-xgboost"" methods to extract XGBoost hyperparameters and DMatrix from a trained H2O model, that (according to 
the docs
) will give you exactly the same XGBoost native python model.


nativeXGBoostParam = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()
nativeXGBoostInput = data.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)
        
nativeModel = xgb.train(dtrain=nativeXGBoostInput,
                        params=nativeXGBoostParam[0],                        
                        num_boost_round=nativeXGBoostParam[1])



More info:




docs


example",2021-01-04T15:57:00,mirekphd,https://stackoverflow.com/users/9962007/mirekphd,"6,488",52528611
55592632,55592632,0,"I just found a novice solution. Copy all your project files to a new directory, set the Spyder to factory defaults, and create a new project in the new directory! Dead kernel revives!",2019-04-09T12:14:24,FUNDMANAGER,https://stackoverflow.com/users/11189862/fundmanager,1,52522640
65706028,65706028,0,"Something similar happened to me when using TensorFlow though. I fixed it by adding the following code at the start of my script


import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'



It might have something to do with the kernel trying to import a module multiple times that it just crashes.",2021-01-13T16:31:39,Mahmoud Gabr,https://stackoverflow.com/users/14804674/mahmoud-gabr,129,52522640
52539239,52539239,2,"The capture rate is the proportion of all the events that fall into the group/bin. E.g. if 90 out of total 100 positive outcomes/events fall into the first bin, then the capture rate for that bin is 0.9.",2018-09-27T14:21:17,vaclav,https://stackoverflow.com/users/10424088/vaclav,191,52521844
57777010,57777010,0,"For a given row x in the table:


cumulative_data_fraction = number in group x / all observations


lower_threshold = minimum of predicted probability in group x


lift = response_rate / overall response rate (i.e., cumulative_response_rate in group 16)


cumulative_lift = cumulative_response_rate / overall response rate


response_rate = percent of responses in group x


score = average of predicted probability in group x


cumulative_response_rate = response rate for all observations in groups 1 through x


cumulative_score = average of predicted probability for all observations in groups 1 through x


capture_rate = percent of all responses that are in group x


cumulative_capture_rate = percent of all responses that are in groups 1 through x


gain = (lift - 1) * 100


cumulative_gain = (cumulative_lift - 1) * 100",2019-09-03T18:29:30,coys,https://stackoverflow.com/users/5386571/coys,13,52521844
52502277,52502277,0,"Finally what I did is firstly to import the .csv file as pandas dataframe and then to convert it to H2O dataframe:


from pysparkling import H2OContext
from ssat_utils.spark import SparkUtilities
import h2o
import pandas as pd

h2o_context = H2OContext.getOrCreate(SparkUtilities.spark)
data_train = pd.read_csv('/u/users/vn505f6/data.csv')
data_train = h2o.H2OFrame(data_train)



I do not really know why this worked while directly importing the .csv file as H2O dataframe in two different ways above my post did not work.",2018-09-25T15:54:47,,,,52496836
52505245,52505245,1,"you can get your D, V, and U as follows:


# singular values (D)
my_svd@model$d

# singular vectors (U)
h2o.getFrame(my_svd@model$u_key$name)

# # singular vectors (V):
h2o.getFrame(my_svd@model$v_key$name)",2018-09-25T19:09:48,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52496397
59068609,59068609,7,"First remove any previously installed H2O packages for R.


if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }



And then,  download packages that H2O depends on.


 pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}



Download and install the H2O package for R.


install.packages(""h2o"", type=""source"", repos=(c(""http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R"")))



Optionally initialize H2O and run a demo to see H2O at work.


library(h2o)
localH2O = h2o.init()
demo(h2o.kmeans)



Or you can simply check the following link:


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html#install-in-r",2019-11-27T10:57:37,,,,52495778
52504579,52504579,0,"This is just an warning message, so if you want, you can continue to use the H2O version you are using.


Please note it is expected that you would get this warning message. H2O wants you to know whether or not you are using an up-to-date version.


If you want the message to go away, all you need to do is update to the latest stable release: 
http://h2o-release.s3.amazonaws.com/h2o/latest_stable.html",2018-09-25T18:23:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52495778
52454581,52454581,1,"For each category I need to fit h2o model.
  Is it possible to do it without splitting dataset on categories...




No.


You need the loop, and to build one model for each level in the enum (to use the h2o terms).  (To get a list of all values in a category see 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html#h2o.frame.H2OFrame.levels
  )


If your requirements were more fuzzy, then you can use a single model. I.e. if you think that the ""chr"" category is the most useful piece of information you have for predicting some other value, you could just build a model (e.g. random forest), and if you are right that will be the top-level split in every tree, and you will effectively get what you want.


But if this is for an academic report, or for regulatory reasons, and you need to show predictions split by your ""chr"" column, then you have no other way.",2018-09-22T07:41:25,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,52440401
52442128,52442128,1,"I didn't make it with 
h2o
 but maybe it can help you:


  iris%>%
   group_by(Species)%>%
   nest()%>%
   mutate(fit = map(data, ~ lm(Petal.Width ~ Petal.Length, data = .x)))
# A tibble: 3 x 3
  Species    data              fit     
  <fct>      <list>            <list>  
1 setosa     <tibble [50 x 4]> <S3: lm>
2 versicolor <tibble [50 x 4]> <S3: lm>
3 virginica  <tibble [50 x 4]> <S3: lm>",2018-09-21T10:51:30,jyjek,https://stackoverflow.com/users/7390738/jyjek,"2,697",52440401
52486874,52486874,1,"There are two places where you can specify a seed when using the Python API


1) The Estimator, let's take GBM as the example


gbm = H2OGradientBoostingEstimator(nfolds=5, seed=1234)
gbm.train(x=features,y=response,training_frame=train)



Notice how I don't specify a seed within the 
train
 method. If you pass a seed argument to 
train
 it will break.


From the API 
docs
 you can see that no seed argument is provided.


train(x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)


From the 
documentation
 here is the definition for an Estimator's seed.


This option specifies the random number generator (RNG) seed for algorithms that are dependent on randomization. When a seed is defined, the algorithm will behave deterministically.
The seed is consistent for each H2O instance so that you can create models with the same starting conditions in alternative configurations.


2) the 
search_criteria
 in 
H2OGridSearch
. For the 
docs
:


More about search_criteria:
This is a dictionary of control parameters for smarter hyperparameter search. The dictionary can include values for: strategy, max_models, max_runtime_secs, stopping_metric, stopping_tolerance, stopping_rounds and seed. The default value for strategy, “Cartesian”, covers the entire space of hyperparameter combinations. If you want to use cartesian grid search, you can leave the search_criteria argument unspecified. Specify the “RandomDiscrete” strategy to perform a random search of all the combinations of your hyperparameters. RandomDiscrete should be usually combined with at least one early stopping criterion, max_models and/or max_runtime_secs. Some examples below:


While you can pass in a seed parameter to the 
train
 method for grid search without having anything break, the seed parameter there does nothing. If you want to have reproducible grid search runs you need to specify the seed argument in the search_criteria parameter like so


# build grid search with previously made GBM and hyper parameters
grid = H2OGridSearch(model = my_model, hyper_params = hyper_params,
                     search_criteria = {'strategy': ""RandomDiscrete"", ""max_runtime_secs"" : 10, ""seed"" :1234})

# train using the grid
grid.train(x = predictors, y = response, training_frame = train, validation_frame = valid)",2018-09-24T20:27:31,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52433970
52426829,52426829,1,"The most common reason for this is you have used all the memory in the cluster.


Options include doing things like:




asking for a larger cluster size when you start it


calling h2o.rm or h2o.removeAll to remove in-memory objects to free up space




h2o.shutdown() uses an api call to the backend to do a cooperative shutdown, but if the backend is already in a bad state it may not work.


If you are running R on the same host as the H2O server, you can do things like system(“ps -ef”) in R to run linux shell commands and try to fix it up that way, even without a direct terminal prompt.  Find the h2o java process and kill it.",2018-09-20T13:55:18,,,,52424067
52486986,52486986,2,"This is a 
bug
 that has been 
fixed
 on master.  If you want, you can try out the fix now on the 
nightly
 release, otherwise, it will be fixed in the next stable release of H2O, 3.22.",2018-09-24T20:37:04,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",52414987
52415457,52415457,2,"You can use 
find_threshold_by_max_metric


model.find_threshold_by_max_metric('f1', train=True, valid=False, xval=False)",2018-09-19T23:26:11,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52410238
62793897,62793897,0,"Alternatively, for finding 
thresholds that maximize F1-scores
, one can use:


model.F1(train=True, valid=True, xval=False)



The sample output of the line above:




{u'train': [[0.3869697386893616, 0.7451099672437997]], u'valid':
[[0.35417599264806404, 0.7228980805623143]]}




The threshold value that maximizes the F1-score for each data set is the first value (index 0) of the list in each key. The second value (index 1) is the maximum of F1-score for each data set. To index a threshold value of, say the validity frame one can use:


values = model.F1(train=True, valid=True, xval=False)
values.get('valid')[0]



This method also works for the following metrics:




Gini Coefficient


Absolute MCC (Matthews Correlation Coefficient)


F0.5


F2


Accuracy",2020-07-08T11:34:33,Anastasiya-Romanova 秀,https://stackoverflow.com/users/3397819/anastasiya-romanova-%e7%a7%80,"3,358",52410238
52415437,52415437,0,"MapR 6 is not currently supported by H2O. Currently H2O supports up to MapR 5.2. 


Please see the 
downloads
 page for supported Hadoop versions.",2018-09-19T23:23:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52395198
52393103,52393103,0,"The nice thing about H2O is that you don't have to worry about manual categorical encoding. 
h2o.predict()
 will apply the same categorical encoding method that was specified during training. For more information on how to set the type of categorical encoding during training please see the 
documentation
 .",2018-09-18T19:05:19,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52383740
52316007,52316007,2,"The threshold is max-F1, not 0.5.


If you dont like that threshold, of course, then you can compare p1 with whatever threshold you like.",2018-09-13T14:33:23,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52315526
52316214,52316214,1,inclusiveNa and inclusiveLevels are for calculating the tree visualization.  the arcs from parent to child node show where the NA value travels and where the different levels for a categorical split travel.,2018-09-13T14:43:59,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52305760
52308136,52308136,6,"What you are describing is a threshold of 0.5. In fact a different threshold will be used, one that maximizes a certain metric. The default metric is F1 (*); if you print the model information you can find the thresholds used for each metric.


See the question: 
How to understand the metrics of H2OModelMetrics Object through h2o.performance?
 for more on this (your question was different, which was why I didn't mark it as a duplicate).


As far as I know you cannot change the F1 default to either 
h2o.predict()
 or 
h2o.performance()
. But instead you can use 
h2o.confusionMatrix()


Given your model 
fit
, and to use max F2 instead:


h2o.confusionMatrix(fit, metrics = ""f2"")



You can also just use the 
h2o.predict()
 ""p0"" column directly, with your own threshold, instead of the ""predict"" column. (That is what I have done, before.)


*: The definition is here: 
https://github.com/h2oai/h2o-3/blob/fdde85e41bad5f31b6b841b300ce23cfb2d8c0b0/h2o-core/src/main/java/hex/AUC2.java#L34
  Further down that file also shows how each of the metrics is calculated.",2018-09-13T06:54:01,,,,52304696
52309295,52309295,5,"It seems (also see 
here
) that the threshold that maximizes the 
F1 score
 on the 
validation
 dataset is used as the default threshold for classification with 
h2o.glm()
.  We can observe the following: 




the threshold value that maximizes 
F1 score
 on the validation dataset is 
0.363477
. 


all datapoints with predicted 
p1
 probability less than this threshold value are classified as 
0
 class (a datapoint predicted to be a 
0
 class has the highest 
p1
 probability = 
0.3602365
 < 
0.363477
). 


all datapoints with predicted 
p1
 probability greater than this threshold value are classified as 
1
 class (a datapoint predicted to be a 
1
 class has the lowest 
p1
 probability = 
0.3644026
 > 
0.363477
).  


min(result[result$predict==1,]$p1)
# [1] 0.3644026
max(result[result$predict==0,]$p1)
# [1] 0.3602365

# Thresholds found by maximizing the metrics on the training dataset
fit@model$training_metrics@metrics$max_criteria_and_metric_scores 
#Maximum Metrics: Maximum metrics at their respective thresholds
#                        metric threshold    value idx
#1                       max f1  0.314699 0.641975 200
#2                       max f2  0.215203 0.795148 262
#3                 max f0point5  0.451965 0.669856  74
#4                 max accuracy  0.451965 0.707581  74
#5                max precision  0.998285 1.000000   0
#6                   max recall  0.215203 1.000000 262
#7              max specificity  0.998285 1.000000   0
#8             max absolute_mcc  0.451965 0.395147  74
#9   max min_per_class_accuracy  0.360174 0.652542 127
#10 max mean_per_class_accuracy  0.391279 0.683269  97

# Thresholds found by maximizing the metrics on the validation dataset
fit@model$validation_metrics@metrics$max_criteria_and_metric_scores 
#Maximum Metrics: Maximum metrics at their respective thresholds
#                        metric threshold    value idx
#1                       max f1  0.363477 0.607143  33
#2                       max f2  0.292342 0.785714  51
#3                 max f0point5  0.643382 0.725806   9
#4                 max accuracy  0.643382 0.774194   9
#5                max precision  0.985308 1.000000   0
#6                   max recall  0.292342 1.000000  51
#7              max specificity  0.985308 1.000000   0
#8             max absolute_mcc  0.643382 0.499659   9
#9   max min_per_class_accuracy  0.379602 0.650000  28
#10 max mean_per_class_accuracy  0.618286 0.702273  11

result[order(result$predict),]
#   predict          p0        p1
#5        0 0.703274569 0.2967254
#6        0 0.639763460 0.3602365
#13       0 0.689557497 0.3104425
#14       0 0.656764541 0.3432355
#15       0 0.696248328 0.3037517
#16       0 0.707069611 0.2929304
#18       0 0.692137408 0.3078626
#19       0 0.701482762 0.2985172
#20       0 0.705973644 0.2940264
#21       0 0.701156961 0.2988430
#22       0 0.671778898 0.3282211
#24       0 0.646735016 0.3532650
#26       0 0.646582708 0.3534173
#27       0 0.690402957 0.3095970
#32       0 0.649945017 0.3500550
#37       0 0.804937468 0.1950625
#40       0 0.717706731 0.2822933
#41       0 0.642094040 0.3579060
#1        1 0.364577068 0.6354229
#2        1 0.503432724 0.4965673
#3        1 0.406771233 0.5932288
#4        1 0.551801718 0.4481983
#7        1 0.339600779 0.6603992
#8        1 0.002978593 0.9970214
#9        1 0.378034417 0.6219656
#10       1 0.596298925 0.4037011
#11       1 0.635597359 0.3644026
#12       1 0.552662241 0.4473378
#17       1 0.615302107 0.3846979
#23       1 0.628906297 0.3710937
#25       1 0.600791894 0.3992081
#28       1 0.216571552 0.7834284
#29       1 0.559174924 0.4408251
#30       1 0.489514642 0.5104854
#31       1 0.623958696 0.3760413
#33       1 0.504691497 0.4953085
#34       1 0.582509462 0.4174905
#35       1 0.504136056 0.4958639
#36       1 0.463076505 0.5369235
#38       1 0.510908093 0.4890919
#39       1 0.469376828 0.5306232",2018-09-13T08:09:57,,,,52304696
52300787,52300787,8,"Try this, it'll do your job:


 for(i in 1:nrow(mod_ids)) {

    aml1 <- h2o.getModel(aml@leaderboard[i, 1]) # get model object in environment
    h2o.saveModel(object = aml1, ""C:/Users/sm/Documents/stack/models"") # pass that model object to h2o.saveModel as an argument

  }",2018-09-12T17:42:40,sm925,https://stackoverflow.com/users/5269047/sm925,"2,678",52298858
52296927,52296927,2,"Note that I haven’t seen anybody do exactly this, but I don’t know of any reason why it should not work.  Driverless AI runs fine in a docker container on Windows 10, which I believe is virtualbox underneath.


From the logs, it looks like you probably started the guest OS with only 2 GB of RAM.  This just isn’t enough.


Give the guest at least 8 GB of RAM at the absolute rock-bottom minimum even just to run toy examples.


I don’t expect that to be a “good” experience, but chances are it will at least run.",2018-09-12T13:56:10,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",52296301
52284087,52284087,3,"The name for this parameter in H2O Random Forest is 
mtries
.",2018-09-11T20:56:05,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",52283577
52282483,52282483,5,"A common way of handling zip codes or any high cardinality categorical column is called ""target encoding"" or ""impact encoding"". In H2O, you can apply 
target encoding
 to any categorical columns.  As of H2O 3.20, this is only available in R, but in the next stable release, 3.22, it will be available in all clients (JIRA ticket 
here
).


If you are using R, my advice is to try both target encoding and also the GLRM method mentioned by Lauren and compare the results.  If you're in Python or another language, then try GLRM for now and give target encoding a try when H2O 3.22 is released.",2018-09-11T18:52:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",52281173
52322770,52322770,3,"I'd 2nd what Erin LeDell says about target encoding. 


Here are some other options and not all of them may apply:




Reduce the granularity of zip Code to the first 1,2,3 or 4 digits. So
zip code 90210 becomes 902 (902XX) and would represent Los Angeles
County. 
902 zipcodes


Can you group zip codes by 
MSA
 or 
CBSA
?


Is there a feature about zip codes that can be appended i.e. city/urban/rural etc.


Can you pull in some zip code demographics,population size or income


Distance to/from a key location (airport, city center, etc.)


Target encode but then group into very high, high, medium and low (or whatever makes sense) 
example
 this will help prevent over training your models.",2018-09-13T22:54:08,Ryan John,https://stackoverflow.com/users/6497137/ryan-john,"1,430",52281173
218510,218510,4209,"There are two overarching types of variables in Java:




Primitives
: variables that contain data. If you want to manipulate the data in a primitive variable you can manipulate that variable directly. By convention primitive types start with a lowercase letter. For example variables of type 
int
 or 
char
 are primitives.




References
: variables that contain the memory address of an 
Object
 i.e. variables that 
refer
 to an 
Object
. If you want to manipulate the 
Object
 that a reference variable refers to you must 
dereference
 it. Dereferencing usually entails using 
.
 to access a method or field, or using 
[
 to index an array. By convention reference types are usually denoted with a type that starts in uppercase. For example variables of type 
Object
 are references.






Consider the following code where you declare a variable of 
primitive
 type 
int
 and don't initialize it:


int x;
int y = x + x;



These two lines will crash the program because no value is specified for 
x
 and we are trying to use 
x
's value to specify 
y
. All primitives have to be initialized to a usable value before they are manipulated.


Now here is where things get interesting. 
Reference
 variables can be set to 
null
 which means ""
I am referencing 
nothing
"". You can get a 
null
 value in a reference variable if you explicitly set it that way, or a reference variable is uninitialized and the compiler does not catch it (Java will automatically set the variable to 
null
).


If a reference variable is set to null either explicitly by you or through Java automatically, and you attempt to 
dereference
 it you get a 
NullPointerException
.


The 
NullPointerException
 (NPE) typically occurs when you declare a variable but did not create an object and assign it to the variable before trying to use the contents of the variable. So you have a reference to something that does not actually exist.


Take the following code:


Integer num;
num = new Integer(10);



The first line declares a variable named 
num
, but it does not actually contain a reference value yet. Since you have not yet said what to point to, Java sets it to 
null
.


In the second line, the 
new
 keyword is used to instantiate (or create) an object of type 
Integer
, and the reference variable 
num
 is assigned to that 
Integer
 object.


If you attempt to dereference 
num
 
before
 creating the object you get a 
NullPointerException
. In the most trivial cases, the compiler will catch the problem and let you know that ""
num may not have been initialized
,"" but sometimes you may write code that does not directly create the object.


For instance, you may have a method as follows:


public void doSomething(SomeObject obj) {
   // Do something to obj, assumes obj is not null
   obj.myMethod();
}



In which case, you are not creating the object 
obj
, but rather assuming that it was created before the 
doSomething()
 method was called. Note, it is possible to call the method like this:


doSomething(null);



In which case, 
obj
 is 
null
, and the statement 
obj.myMethod()
 will throw a 
NullPointerException
.


If the method is intended to do something to the passed-in object as the above method does, it is appropriate to throw the 
NullPointerException
 because it's a programmer error and the programmer will need that information for debugging purposes.


In addition to 
NullPointerException
s thrown as a result of the method's logic, you can also check the method arguments for 
null
 values and throw NPEs explicitly by adding something like the following near the beginning of a method:


// Throws an NPE with a custom error message if obj is null
Objects.requireNonNull(obj, ""obj must not be null"");



Note that it's helpful to say in your error message clearly 
which
 object cannot be 
null
. The advantage of validating this is that 1) you can return your own clearer error messages and 2) for the rest of the method you know that unless 
obj
 is reassigned, it is not null and can be dereferenced safely.


Alternatively, there may be cases where the purpose of the method is not solely to operate on the passed in object, and therefore a null parameter may be acceptable. In this case, you would need to check for a 
null parameter
 and behave differently. You should also explain this in the documentation. For example, 
doSomething()
 could be written as:


/**
  * @param obj An optional foo for ____. May be null, in which case
  *  the result will be ____.
  */
public void doSomething(SomeObject obj) {
    if(obj == null) {
       // Do something
    } else {
       // Do something else
    }
}



Finally, 
How to pinpoint the exception & cause using Stack Trace




What methods/tools can be used to determine the cause so that you stop
the exception from causing the program to terminate prematurely?




Sonar with find bugs can detect NPE.

Can sonar catch null pointer exceptions caused by JVM Dynamically


Now Java 14 has added a new language feature to show the root cause of NullPointerException. This language feature has been part of SAP commercial JVM since 2006.


In Java 14, the following is a sample NullPointerException Exception message:




in thread ""main"" java.lang.NullPointerException: Cannot invoke ""java.util.List.size()"" because ""list"" is null




List of situations that cause a 
NullPointerException
 to occur


Here are all the situations in which a 
NullPointerException
 occurs, that are directly* mentioned by the Java Language Specification:




Accessing (i.e. getting or setting) an 
instance
 field of a null reference. (static fields don't count!)


Calling an 
instance
 method of a null reference. (static methods don't count!)


throw null;


Accessing elements of a null array.


Synchronising on null - 
synchronized (someNullReference) { ... }


Any integer/floating point operator can throw a 
NullPointerException
 if one of its operands is a boxed null reference


An unboxing conversion throws a 
NullPointerException
 if the boxed value is null.


Calling 
super
 on a null reference throws a 
NullPointerException
. If you are confused, this is talking about qualified superclass constructor invocations:




class Outer {
    class Inner {}
}
class ChildOfInner extends Outer.Inner {
    ChildOfInner(Outer o) { 
        o.super(); // if o is null, NPE gets thrown
    }
}





Using a 
for (element : iterable)
 loop to loop through a null collection/array.




switch (foo) { ... }
 (whether its an expression or statement) can throw a 
NullPointerException
 when 
foo
 is null.




foo.new SomeInnerClass()
 throws a 
NullPointerException
 when 
foo
 is null.




Method references of the form 
name1::name2
 or 
primaryExpression::name
 throws a 
NullPointerException
 when evaluated when 
name1
 or 
primaryExpression
 evaluates to null.


a note from the JLS here says that, 
someInstance.someStaticMethod()
 doesn't throw an NPE, because 
someStaticMethod
 is static, but 
someInstance::someStaticMethod
 still throw an NPE!






* Note that the JLS probably also says a lot about NPEs 
indirectly
.",2008-10-20T13:54:24,,,,52252770
218390,218390,969,"NullPointerException
s are exceptions that occur when you try to use a reference that points to no location in memory (null) as though it were referencing an object.  Calling a method on a null reference or trying to access a field of a null reference will trigger a 
NullPointerException
.  These are the most common, but other ways are listed on the 
NullPointerException
 javadoc page.


Probably the quickest example code I could come up with to illustrate a 
NullPointerException
 would be:


public class Example {

    public static void main(String[] args) {
        Object obj = null;
        obj.hashCode();
    }

}



On the first line inside 
main
, I'm explicitly setting the 
Object
 reference 
obj
 equal to 
null
.  This means I have a reference, but it isn't pointing to any object.  After that, I try to treat the reference as though it points to an object by calling a method on it.  This results in a 
NullPointerException
 because there is no code to execute in the location that the reference is pointing.


(This is a technicality, but I think it bears mentioning: A reference that points to null isn't the same as a C pointer that points to an invalid memory location.  A null pointer is literally not pointing 
anywhere
, which is subtly different than pointing to a location that happens to be invalid.)",2008-10-20T13:20:44,,,,52252770
24100776,24100776,750,"What is a NullPointerException?


A good place to start is the 
JavaDocs
. They have this covered:




Thrown when an application attempts to use null in a case where an
  object is required. These include:




Calling the instance method of a null object.


Accessing or modifying the field of a null object.


Taking the length of null as if it were an array.


Accessing or modifying the slots of null as if it were an array.


Throwing null as if it were a Throwable value.




Applications should throw instances of this class to indicate other
  illegal uses of the null object.




It is also the case that if you attempt to use a null reference with 
synchronized
, that will also throw this exception, 
per the JLS
:




SynchronizedStatement:
    synchronized ( Expression ) Block





Otherwise, if the value of the Expression is null, a 
NullPointerException
 is thrown.






How do I fix it?


So you have a 
NullPointerException
. How do you fix it? Let's take a simple example which throws a 
NullPointerException
:


public class Printer {
    private String name;

    public void setName(String name) {
        this.name = name;
    }

    public void print() {
        printString(name);
    }

    private void printString(String s) {
        System.out.println(s + "" ("" + s.length() + "")"");
    }

    public static void main(String[] args) {
        Printer printer = new Printer();
        printer.print();
    }
}



Identify the null values


The first step is identifying exactly 
which values are causing the exception
. For this, we need to do some debugging. It's important to learn to read a 
stacktrace
. This will show you where the exception was thrown:


Exception in thread ""main"" java.lang.NullPointerException
    at Printer.printString(Printer.java:13)
    at Printer.print(Printer.java:9)
    at Printer.main(Printer.java:19)



Here, we see that the exception is thrown on line 13 (in the 
printString
 method). Look at the line and check which values are null by
adding 
logging statements
 or using a 
debugger
. We find out that 
s
 is null, and calling the 
length
 method on it throws the exception. We can see that the program stops throwing the exception when 
s.length()
 is removed from the method.


Trace where these values come from


Next check where this value comes from. By following the callers of the method, we see that 
s
 is passed in with 
printString(name)
 in the 
print()
 method, and 
this.name
 is null.


Trace where these values should be set


Where is 
this.name
 set? In the 
setName(String)
 method. With some more debugging, we can see that this method isn't called at all. If the method was called, make sure to check the 
order
 that these methods are called, and the set method isn't called 
after
 the print method.


This is enough to give us a solution: add a call to 
printer.setName()
 before calling 
printer.print()
.


Other fixes


The variable can have a 
default value
 (and 
setName
 can prevent it being set to null):


private String name = """";



Either the 
print
 or 
printString
 method can 
check for null
, for example:


printString((name == null) ? """" : name);



Or you can design the class so that 
name
 
always has a non-null value
:


public class Printer {
    private final String name;

    public Printer(String name) {
        this.name = Objects.requireNonNull(name);
    }

    public void print() {
        printString(name);
    }

    private void printString(String s) {
        System.out.println(s + "" ("" + s.length() + "")"");
    }

    public static void main(String[] args) {
        Printer printer = new Printer(""123"");
        printer.print();
    }
}



See also:




Avoiding “!= null” statements in Java?




I still can't find the problem


If you tried to debug the problem and still don't have a solution, you can post a question for more help, but make sure to include what you've tried so far. At a minimum, 
include the stacktrace
 in the question, and 
mark the important line numbers
 in the code. Also, try simplifying the code first (see 
SSCCE
).",2014-06-07T19:22:14,,,,52252770
24347569,24347569,554,"Question: What causes a 
NullPointerException
 (NPE)?


As you should know, Java types are divided into 
primitive types
 (
boolean
, 
int
, etc.) and 
reference types
. Reference types in Java allow you to use the special value 
null
 which is the Java way of saying ""no object"".


A 
NullPointerException
 is thrown at runtime whenever your program attempts to use a 
null
 as if it was a real reference. For example, if you write this:


public class Test {
    public static void main(String[] args) {
        String foo = null;
        int length = foo.length();   // HERE
    }
}



the statement labeled ""HERE"" is going to attempt to run the 
length()
 method on a 
null
 reference, and this will throw a 
NullPointerException
.


There are many ways that you could use a 
null
 value that will result in a 
NullPointerException
. In fact, the only things that you 
can
 do with a 
null
 without causing an NPE are:




assign it to a reference variable or read it from a reference variable,


assign it to an array element or read it from an array element (provided that array reference itself is non-null!),


pass it as a parameter or return it as a result, or


test it using the 
==
 or 
!=
 operators, or 
instanceof
.




Question: How do I read the NPE stacktrace?


Suppose that I compile and run the program above:


$ javac Test.java 
$ java Test
Exception in thread ""main"" java.lang.NullPointerException
    at Test.main(Test.java:4)
$



First observation: the compilation succeeds! The problem in the program is NOT a compilation error. It is a 
runtime
 error. (Some IDEs may warn your program will always throw an exception ... but the standard 
javac
 compiler doesn't.)


Second observation: when I run the program, it outputs two lines of ""gobbledy-gook"". 
WRONG!!
 That's not gobbledy-gook. It is a stacktrace ... and it provides 
vital information
 that will help you track down the error in your code if you take the time to read it carefully.


So let's look at what it says:


Exception in thread ""main"" java.lang.NullPointerException



The first line of the stack trace tells you a number of things:




It tells you the name of the Java thread in which the exception was thrown.  For a simple program with one thread (like this one), it will be ""main"". Let's move on ...


It tells you the full name of the exception that was thrown; i.e. 
java.lang.NullPointerException
.


If the exception has an associated error message, that will be output after the exception name. 
NullPointerException
 is unusual in this respect, because it rarely has an error message.




The second line is the most important one in diagnosing an NPE.


at Test.main(Test.java:4)



This tells us a number of things:




""at Test.main"" says that we were in the 
main
 method of the 
Test
 class.


""Test.java:4"" gives the source filename of the class, AND it tells us that the statement where this occurred is in line 4 of the file.




If you count the lines in the file above, line 4 is the one that I labeled with the ""HERE"" comment.


Note that in a more complicated example, there will be lots of lines in the NPE stack trace. But you can be sure that the second line (the first ""at"" line) will tell you where the NPE was thrown
1
.


In short, the stack trace will tell us unambiguously which statement of the program has thrown the NPE.


See also: 
What is a stack trace, and how can I use it to debug my application errors?


1 - Not quite true. There are things called nested exceptions...


Question: How do I track down the cause of the NPE exception in my code?


This is the hard part. The short answer is to apply logical inference to the evidence provided by the stack trace, the source code, and the relevant API documentation.


Let's illustrate with the simple example (above) first. We start by looking at the line that the stack trace has told us is where the NPE happened:


int length = foo.length(); // HERE



How can that throw an NPE?


In fact, there is only one way: it can only happen if 
foo
 has the value 
null
.  We then try to run the 
length()
 method on 
null
 and... BANG!


But (I hear you say) what if the NPE was thrown inside the 
length()
 method call?


Well, if that happened, the stack trace would look different. The first ""at"" line would say that the exception was thrown in some line in the 
java.lang.String
 class and line 4 of 
Test.java
 would be the second ""at"" line.


So where did that 
null
 come from? In this case, it is obvious, and it is obvious what we need to do to fix it. (Assign a non-null value to 
foo
.)


OK, so let's try a slightly more tricky example. This will require some 
logical deduction
.


public class Test {

    private static String[] foo = new String[2];

    private static int test(String[] bar, int pos) {
        return bar[pos].length();
    }

    public static void main(String[] args) {
        int length = test(foo, 1);
    }
}

$ javac Test.java 
$ java Test
Exception in thread ""main"" java.lang.NullPointerException
    at Test.test(Test.java:6)
    at Test.main(Test.java:10)
$ 



So now we have two ""at"" lines. The first one is for this line:


return args[pos].length();



and the second one is for this line:


int length = test(foo, 1);
    



Looking at the first line, how could that throw an NPE?  There are two ways:




If the value of 
bar
 is 
null
 then 
bar[pos]
 will throw an NPE.


If the value of 
bar[pos]
 is 
null
 then calling 
length()
 on it will throw an NPE.




Next, we need to figure out which of those scenarios explains what is actually happening. We will start by exploring the first one:


Where does 
bar
 come from? It is a parameter to the 
test
 method call, and if we look at how 
test
 was called, we can see that it comes from the 
foo
 static variable. In addition, we can see clearly that we initialized 
foo
 to a non-null value.  That is sufficient to tentatively dismiss this explanation. (In theory, something else could 
change
 
foo
 to 
null
 ... but that is not happening here.)


So what about our second scenario? Well, we can see that 
pos
 is 
1
, so that means that 
foo[1]
 must be 
null
. Is this possible?


Indeed it is! And that is the problem. When we initialize like this:


private static String[] foo = new String[2];



we allocate a 
String[]
 with two elements 
that are initialized to 
null
. After that, we have not changed the contents of 
foo
 ... so 
foo[1]
 will still be 
null
.


What about on Android?


On Android, tracking down the immediate cause of an NPE is a bit simpler.  The exception message will typically tell you the (compile time) type of the null reference you are using 
and
 the method you were attempting to call when the NPE was thrown.  This simplifies the process of pinpointing the immediate cause.


But on the flipside, Android has some common platform-specific causes for NPEs.  A very common is when 
getViewById
 unexpectedly returns a 
null
.  My advice would be to search for Q&As about the cause of the unexpected 
null
 return value.",2014-06-22T02:16:56,,,,52252770
218394,218394,456,"It's like you are trying to access an object which is 
null
. Consider below example:


TypeA objA;



At this time you have just 
declared
 this object but not 
initialized or instantiated
. And whenever you try to access any property or method in it, it will throw  
NullPointerException
 which makes sense.


See this below example as well:                                        


String a = null;
System.out.println(a.toString()); // NullPointerException will be thrown",2008-10-20T13:21:21,,,,52252770
16050670,16050670,382,"A null pointer exception is thrown when an application attempts to use null in a case where an object is required. These include:




Calling the instance method of a 
null
 object.


Accessing or modifying the field of a 
null
 object.


Taking the length of 
null
 as if it were an array.


Accessing or modifying the slots of 
null
 as if it were an array.


Throwing 
null
 as if it were a Throwable value. 




Applications should throw instances of this class to indicate other illegal uses of the 
null
 object. 


Reference: 
http://docs.oracle.com/javase/8/docs/api/java/lang/NullPointerException.html",2013-04-17T02:57:16,,,,52252770
218408,218408,359,"A 
null
 pointer is one that points to nowhere.  When you dereference a pointer 
p
, you say ""give me the data at the location stored in ""p"".  When 
p
 is a 
null
 pointer, the location stored in 
p
 is 
nowhere
, you're saying ""give me the data at the location 'nowhere'"".  Obviously, it can't do this, so it throws a 
null pointer exception
.


In general, it's because something hasn't been initialized properly.",2008-10-20T13:25:08,,,,52252770
24407197,24407197,348,"A lot of explanations are already present to explain how it happens and how to fix it, but you should also follow 
best practices
 to avoid 
NullPointerException
s at all.


See also:

A good list of best practices


I would add, very important, make a good use of the 
final
 modifier.

Using the ""final"" modifier whenever applicable in Java


Summary:




Use the 
final
 modifier to enforce good initialization.


Avoid returning null in methods, for example returning empty collections when applicable.


Use annotations 
@NotNull
 and 
@Nullable


Fail fast and use asserts to avoid propagation of null objects through the whole application when they shouldn't be null.


Use equals with a known object first: 
if(""knownObject"".equals(unknownObject)


Prefer 
valueOf()
 over 
toString()
.


Use null safe 
StringUtils
 methods 
StringUtils.isEmpty(null)
.


Use Java 8 Optional as return value in methods, Optional class provide a solution for representing optional values instead of null references.",2014-06-25T11:17:08,,,,52252770
18974045,18974045,341,"A null pointer exception is an indicator that you are using an object without initializing it.


For example, below is a student class which will use it in our code.


public class Student {

    private int id;

    public int getId() {
        return this.id;
    }

    public setId(int newId) {
        this.id = newId;
    }
}



The below code gives you a null pointer exception.


public class School {

    Student student;

    public School() {
        try {
            student.getId();
        }
        catch(Exception e) {
            System.out.println(""Null pointer exception"");
        }
    }
}



Because you are using 
student
, but you forgot to initialize it like in the
correct code shown below:


public class School {

    Student student;

    public School() {
        try {
            student = new Student();
            student.setId(12);
            student.getId();
        }
        catch(Exception e) {
            System.out.println(""Null pointer exception"");
        }
    }
}",2013-09-24T06:01:46,,,,52252770
9043523,9043523,338,"In Java, everything (excluding primitive types) is in the form of a class.


If you want to use any object then you have two phases:




Declare


Initialization




Example:




Declaration: 
Object object;


Initialization: 
object = new Object();




Same for the array concept:




Declaration: 
Item item[] = new Item[5];


Initialization: 
item[0] = new Item();




If you are not giving the initialization section then the 
NullPointerException
 arise.",2012-01-28T06:45:54,,,,52252770
219697,219697,330,"In 
Java
 all the variables you declare are actually ""references"" to the objects (or primitives) and not the objects themselves.


When you attempt to execute one object method, the reference asks the living object to execute that method. But if the reference is referencing NULL (nothing, zero, void, nada)  then there is no way the method gets executed. Then the runtime let you know this by throwing a NullPointerException.


Your reference is ""pointing"" to null, thus ""Null -> Pointer"".


The object lives in the VM memory space and the only way to access it is using 
this
 references. Take this example:


public class Some {
    private int id;
    public int getId(){
        return this.id;
    }
    public setId( int newId ) {
        this.id = newId;
    }
}



And on another place in your code:


Some reference = new Some();    // Point to a new object of type Some()
Some otherReference = null;     // Initiallly this points to NULL

reference.setId( 1 );           // Execute setId method, now private var id is 1

System.out.println( reference.getId() ); // Prints 1 to the console

otherReference = reference      // Now they both point to the only object.

reference = null;               // ""reference"" now point to null.

// But ""otherReference"" still point to the ""real"" object so this print 1 too...
System.out.println( otherReference.getId() );

// Guess what will happen
System.out.println( reference.getId() ); // :S Throws NullPointerException because ""reference"" is pointing to NULL remember...



This an important thing to know - when there are no more references to an object (in the example above when 
reference
 and 
otherReference
 both point to null) then the object is ""unreachable"". There is no way we can work with it, so this object is ready to be garbage collected, and at some point, the VM will free the memory used by this object and will allocate another.",2008-10-20T20:05:30,,,,52252770
23852556,23852556,301,"Another occurrence of a 
NullPointerException
 occurs when one declares an object array, then immediately tries to dereference elements inside of it.


String[] phrases = new String[10];
String keyPhrase = ""Bird"";
for(String phrase : phrases) {
    System.out.println(phrase.equals(keyPhrase));
}



This particular NPE can be avoided if the comparison order is reversed; namely, use 
.equals
 on a guaranteed non-null object.


All elements inside of an array 
are initialized to their common initial value
; for any type of object array, that means that all elements are 
null
.


You 
must
 initialize the elements in the array 
before
 accessing or dereferencing them.


String[] phrases = new String[] {""The bird"", ""A bird"", ""My bird"", ""Bird""};
String keyPhrase = ""Bird"";
for(String phrase : phrases) {
    System.out.println(phrase.equals(keyPhrase));
}",2014-05-25T06:11:58,,,,52252770
52267326,52267326,4,"Unfortunately you can't pass additional parameters to the H2O R 
apply()
 method (I've reported the bug 
here
).


and even if you hardcode the original parameters to get the 
apply
 method to evaluate it, it won't evaluate correctly:


library(h2o)
h2o.init()
df <- data.frame( AGE = c(9,7,33,84,86,25))
df_A.hex <- as.h2o( df, 'df_A.hex' )
L = 12
U = 24
simple_spline <- function(x) { min( max(x-L,0), U-L )}
apply(df_A.hex, 1, simple_spline)

 C1
1 -3
2 -5
3 21
4 72
5 74
6 13



I think your best bet is to use your iterative method, or play around with the apply method (not passing additional parameters) until you can trust the results you see.",2018-09-11T00:59:22,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52230318
52228271,52228271,6,"While there currently isn't support for a custom loss function (though there is a 
jira ticket
 to add it in), there is some support for a custom evaluation function, you can find more details here: 
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/dev/custom_functions.md
.",2018-09-07T18:59:56,,,,52227446
52212217,52212217,1,"word2vec in h2o-3 uses hogwild implementation - the model parameters are updated concurrently from multiple threads and it is not possible to guarantee the reproducibility in this implementation.


How big is your text corpus? At the cost of a slowdown of the model training you could get reproducible result with limiting the algo to use just a single thread (h2o start-up parameter 
-nthread
).",2018-09-06T21:12:37,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,52210521
52261250,52261250,4,"Conceptually, weights can indicate which rows are important to get right, or indicate
which rows to replicate or compress. Including the 
weights_column
, however, does not change the actual
size of your dataset; it only affects the mathematical calculations for DRF.


Note: H2O trains regression trees, regardless of whether you are solving a classification or regression problem.


Bulleted Details




The 
weights_column
 does not affect the sampling rate.


multiplying the weights by a factor will not change the outcome (i.e. a weights column of all 1s is the same as a weights column of all 2s)


weights are used in several locations here are a few examples:




The first node in each tree


The loss function, which is used to decide on which feature to split at each internal node.


The terminal nodes.


All performance metric calculations.",2018-09-10T15:38:08,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52207399
52161668,52161668,3,"Why is the API done as two function calls?


I doubt there is a reason; just no-one particularly needed to reduce those two lines to one. (Or, maybe, whoever wrote them always envisaged having to specify the arguments.)


If you are always going to call those two functions in that way, and especially if it happens in more than one place in your code, it definitely makes sense to write the wrapper function you describe.


Why is there a download involved at all?


Remember that, even when using a Java client, H2O is running as two processes: the client and the server. So, even when the server part is running on localhost, they are still completely separate, with no shared memory.


Why is it a zip file


If you look inside a mojo file, you see lots of little binary files. That would be why it is a zip file: a simple container that can be easily moved around.",2018-09-04T08:10:15,,,,52146179
52147652,52147652,1,"please try to specify the metric as lowercase to have the leaderboard sorted in decreasing order when using ""auc"" (we don't seem to enforce the case on our side, I have filed a 
JIRA
 ticket to fix this):


autoMLBuildSpec.input_spec.sort_metric = ""auc"";



also FYI, you shouldn't need to ""start"" automl 2 times.
Basically


AutoML aml = AutoML.makeAutoML(Key.make(), new Date(), autoMLBuildSpec);
AutoML.startAutoML(aml);
AutoML.startAutoML(autoMLBuildSpec).get();



can be replaced with just


AutoML.startAutoML(autoMLBuildSpec).get();



Hope this helps!",2018-09-03T10:14:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",52124300
52121119,52121119,0,"please see the user guide: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/starting-h2o.html


please also run the following tests (reposted from 
here
) to debug your issue.




Does running h2o.jar from the commandline work? 
And if so, does h2o.init() then connect to it? 


What do the logs say? 


Disable your firewall, and see if it makes a difference. (Remember to 
re-enable it afterwards). 


Try a different port number (the default is 54321). 


Shutdown h2o (h2o.shutdown()) and try running h2o.init() and see if it works.",2018-08-31T18:39:26,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52120546
52123321,52123321,1,"When running H2O grid search you should only see models that use the same number of hidden layers you provided for your grid search. Here is a code example you can run and play around with to see if you can reproduce your issue.


#############################################################
library(h2o)
h2o.init()

train = h2o.importFile(""https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz"")

# Specify the response and predictor columns
y <- ""C785""
x <- setdiff(names(train), y)

# Encode the response column as categorical for multinomial classification
train[,y] <- as.factor(train[,y])
test[,y] <- as.factor(test[,y])

# do a random grid search
hidden_opt <- list(c(32,32), c(32,16,8), c(100,100))
l1_opt <- c(1e-4,1e-3)
hyper_params <- list(hidden = hidden_opt, l1 = l1_opt)
search_criteria = list(strategy = ""RandomDiscrete"", 
                       max_models = 10, 
                       seed=123456)



# grid search
model_grid <- h2o.grid(""deeplearning"", 
                       grid_id = ""mygrid_1"",
                       hyper_params = hyper_params, 
                       search_criteria = search_criteria,
                       x = x,
                       y = y,
                       distribution = ""multinomial"", 
                       training_frame = train, 
                       nfolds = 3,
                       score_interval = 2,
                       stopping_rounds = 3,
                       stopping_tolerance = 0.05,
                       stopping_metric = ""misclassification"")
model_grid

# Output
# H2O Grid Details
# ================
#   
#   Grid ID: mygrid_1 
# Used hyper parameters: 
#   -  hidden 
# -  l1 
# Number of models: 6 
# Number of failed models: 0 
# 
# Hyper-Parameter Search Summary: ordered by increasing logloss
# hidden     l1        model_ids             logloss
# 1  [100, 100] 1.0E-4 mygrid_1_model_0 0.11350390885225858
# 2  [100, 100]  0.001 mygrid_1_model_4 0.13184550642109982
# 3    [32, 32]  0.001 mygrid_1_model_3 0.13869444872607956
# 4 [32, 16, 8]  0.001 mygrid_1_model_5 0.16575514373784073
# 5    [32, 32] 1.0E-4 mygrid_1_model_2 0.17190959951587054
# 6 [32, 16, 8] 1.0E-4 mygrid_1_model_1 0.20832913000853842



Notice in the output you will only see models with hidden layers equal to the original values set: c(32,32), c(32,16,8), c(100,100)",2018-08-31T22:38:51,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52120263
52121646,52121646,0,"Lauren, thank u for your post. Here is an example of credit card fraud detection modeling


 hyper_params <- list(
   activation = c(""Rectifier"", ""Maxout"", ""Tanh"", ""RectifierWithDropout"", ""MaxoutWithDropout"", ""TanhWithDropout""), 
   hidden = list(c(17,16,15), c(19,15,11), c(16,14,12),c(20,15,10),c(25,17,10),c(15,10,5)),
   epochs = c(50, 100, 200),
   l1 = c(0, 0.001,0.00001, 0.0001), 
   l2 = c(0,0.001, 0.00001, 0.0001),
   rate = c(0, 0.1, 0.005, 0.001),
   rate_annealing = c(1e-8, 1e-7, 1e-6),
   rho = c(0.9, 0.95, 0.99, 0.999),
   epsilon = c(1e-10, 1e-8, 1e-6, 1e-4),
   momentum_start = c(0, 0.5),
   momentum_stable = c(0.99, 0.5, 0),
   input_dropout_ratio = c(0, 0.1, 0.2),
   max_w2 = c(10, 100, 1000, 3.4028235e+38)
 )

 search_criteria <- list(strategy = ""RandomDiscrete"", 
                         max_models = 100,
                         max_runtime_secs = 900,
                         stopping_tolerance = 0.001,
                         stopping_rounds = 15)

 dl_grid <- h2o.grid(algorithm = ""deeplearning"", 
                     x = X,
                     y = Y,
                     grid_id = ""dl_grid"",
                     training_frame = as_h2o(train.set),
                     validation_frame = as_h2o(valid.set),
                     nfolds = 25,                           
                     fold_assignment = ""Stratified"",
                     hyper_params = hyper_params,
                     search_criteria = search_criteria
 )",2018-08-31T19:27:54,Kuba,https://stackoverflow.com/users/10301217/kuba,25,52120263
52101244,52101244,1,"Since the error message seems to be coming from R, the error is more likely a R or sparklyr issue and not a bug in H2O. However, if you can post this issue to the sparkling water 
repo
 with a reproducible code example and logs (if possible)  the issue can be reviewed, and it will be easier to identify which package is causing the error and direct the bug to the correct project.",2018-08-30T16:01:48,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52087252
52105665,52105665,1,"One options is to download the MOJO, load it and use function 
_computeGraph
 on the MOJO object. Take a look at the H2O github 
repo
 to learn from the code.


please also take a look at the documentation on the POJOs and MOJOs 
here


Here some additional code that might help: 
https://github.com/h2oai/h2o-3/blob/43f8ab952a69a8bc9484bd0ffac909b6e3e820ca/h2o-algos/src/test/java/hex/XValPredictionsCheck.java#L59-L69",2018-08-30T21:34:38,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52073624
53599442,53599442,0,"Based on 
PUBDEV-4324 - Expose Decision Tree as a stand-alone algo in H2O
 most straight forward way would be using GBM:


titanic_1tree = h2o.gbm(x = predictors, y = response, 
                        training_frame = titanicHex,
                        ntrees = 1, min_rows = 1, sample_rate = 1,            
                        col_sample_rate = 1,
                        max_depth = 5,
                        seed = 1)



which creates a decision tree maximum 5 splits deep (
max_depth = 5
) on titanic dataset (available here: 
https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv
)


Starting with release 3.22.0.1 (Xia) it's possible to extract tree structures from H2O models:


titanicH2oTree = h2o.getModelTree(model = titanic_1tree, tree_number = 1)",2018-12-03T18:08:53,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,52068666
52180901,52180901,0,"(Problem Solved) 


Turns out the there was another 
sparkling-water-core_2.11-2.2.16.jar
 file within the 
/jar/
 directory in my spark-client path, and therefore was being directly read in as a part of the Classpath Entries, causing the conflict. (Confirmed through Spark UI Environment tab) I've played around with the Spark Classpath without any luck, so I had to request the file to be removed. 


After doing that, the problem was fixed. I've also tested this out with different versions of the sparkling water JAR and the h2o R package. (sw 2.2.11 & h2o 3.18.0.5, sw 2.2.19 & h2o 3.20.0.2)  


options(rsparkling.sparklingwater.version = ""2.2.16"")
options(rsparkling.sparklingwater.location = ""path to my sparkling water.jar"") 

Sys.setenv(SPARK_HOME = ""path to my spark"") 
Sys.setenv(SPARK_VERSION = ""2.2.0"") 
Sys.setenv(HADOOP_CONF_DIR = ""..."") 
Sys.setenv(MASTER = ""yarn-client"") 

library(sparklyr) 
library(h2o) 
library(rsparkling) 

sc = spark_connect(master = Sys.getenv(""SPARK_MASTER""), 
                   spark_home = Sys.getenv(""SPARK_HOME""), 
                   version = Sys.getenv(""SPARK_VERSION"")) 
h2o_context(sc) 



A bit a awkward answering my own question, but I hope this helps anyone else in need!",2018-09-05T08:46:53,Justin Lee,https://stackoverflow.com/users/10283625/justin-lee,21,52053444
52043349,52043349,1,"You can read all about productionizing a model in the H2O User Guide 
here",2018-08-27T16:19:43,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52036739
52011836,52011836,2,"This is likely a bug; I've created a jira ticket for it here: 
https://0xdata.atlassian.net/browse/PUBDEV-5860
.


please feel to update the ticket if you have a jira account.",2018-08-24T21:17:06,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52009091
52009683,52009683,0,"For help on tuning a H2O GBM in R I would recommend reviewing this tuning guide: 
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/gbm/gbmTuning.Rmd
.


There are a lot of reasons you could be seeing overfitting from the predictors you use, the features you engineer, the way you split up your data, and finally the way you tune your model. 


Without seeing your specific dataset and the specific code you ran, it would be hard do give you an exact reason for why you are having issues with overfitting.",2018-08-24T18:03:40,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",52005264
52043281,52043281,0,"This is a bug caused by setting the 
verbose
 parameter to True, the workaround is to leave the 
verbose
 parameter as the default which is 
FALSE
. I've created a jira ticket to track the issue 
here",2018-08-27T16:14:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51998925
51995457,51995457,0,"H2O's random forest doesn't perform bootstrapping, instead it samples at a rate of 63.2% (which is the expected value of unique rows in any bootstrapped sample).


If you want to get a balanced sample, you can use can use the parameter 
balance_classes
 with 
class_sampling_factors
, or 
weights_column",2018-08-23T23:14:53,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51986590
51995882,51995882,0,"To prevent overfitting you can set the 
hold_out
 parameter to ""KFOLD"" for the training set and ""None"" for the test set. 


For more details, I'd recommend focusing on the 
Holdout Type
 section of the docs on Target Encoding.",2018-08-24T00:14:41,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51985198
51983275,51983275,2,"Ad.1 Yes it's been fixed in version 3.18.0.1


Ad.2 The distro itself isn't really important. It's more important which exact version of RedHat are we talking about (since different versions come bundled with different lib versions) and whether you can upgrade libraries on your own if necessary. For example if you want to run the GPU version you'll need a certain version of glibc (2.17 or never if I remember correctly). For the CPU version most recent Linux distributions should be ok.",2018-08-23T10:05:29,,,,51982255
52062592,52062592,0,"Unfortunately the functionality to distinguish between words that are missing from your dictionary and NAs used to demarcate the start and end of a record is not currently available. I've made a jira ticket 
here
 to track the issue. Please feel free to comment or update the ticket.",2018-08-28T16:33:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51954502
51950942,51950942,3,"Java version 10 is not supported today.
Try installing java version 8.",2018-08-21T14:28:02,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51948440
52071620,52071620,10,"H2O is running in a separate process to R (whether H2O is on the local server or in a distant data centre). The H2O data and the H2O models are kept in that H2O process, and cannot be seen by R.


What 
dH <- as.h2o(dR)
 does is copy an R data frame, 
dR
, into H2O's memory space. The 
dH
 is then an R variable that describes the H2O data frame. I.e. it is a pointer, or a handle; it is not the data itself.


What 
dR <- as.data.frame(dH)
 does is copy the data from the H2O process's memory, into the R process's memory.  (
as.vector(dH)
 does the same for when dH describes a single column)


So, the simplest way to modify your 
mape_calc()
, assuming that 
sub_df
 is an R data frame, is to change the first two lines as follows:


mape_calc <- function(sub_df) {
  p <- h2o.predict(rforest.model, as.h2o(sub_df))
  pred <- as.vector(p)

  actual <- sub_df$Ptot
  mape <- 100 * mean(abs((actual - pred)/actual))

  new_df <- data.frame(date = sub_df$date[[1]], mape = mape)

  return(new_df)
}



I.e. upload 
sub_df
 to H2O, and give that to 
h2o.predict()
. Then use 
as.vector()
 to download the prediction that was made.


This was relative to your original code. So keep the original version of this:


# LIST OF ONE-ROW DATAFRAMES
df_list <- by(test_data, test_data$date, map_calc)



I.e. don't use 
by()
 directly on 
test_h2o
.




UPDATE
 based on edited question:


I made two changes to your example code. First, I removed the date column from 
sub_df
. That was what was causing the error message.


The second change was just to simplify the return type; not important, but you ended up with the date column duplicated, before.


mape_calc <- function(sub_df) {
  sub_df_minus_date <- subset(sub_df, select=-c(date))
  p <- h2o.predict(my_gbm, as.h2o(sub_df_minus_date))
  pred <- as.vector(p)
  actual <- sub_df$medv
  mape <- 100 * mean(abs((actual - pred)/actual))
  data.frame(mape = mape)
}





ASIDE:
 
h2o.predict()
 is most efficient when working on a batch of data to make predictions on. Putting 
h2o.predict()
 inside a loop is a code smell. You would be better to call 
h2o.predict(rforest.model, test_h2o)
 once, outside the loop, then download the predictions into R, and 
cbind
 them to test_data, and then use 
by
 on that combined data.


UPDATE
 Here is your example changed to work that way: (I've added the prediction as an extra column to the test data; there are other ways to do it, of course)


 test_h2o <- as.h2o(subset(test_data_finialized, select=-c(date)))
 p <- h2o.predict(my_gbm, test_h2o)
 test_data_finialized$pred = as.vector(p)

 mape_calc2 <- function(sub_df) {
   actual <- sub_df$medv
   mape <- 100 * mean(abs((actual - sub_df$pred)/actual))
   data.frame(mape = mape)
 }

 df_list <- by(test_data_finialized, test_data_finialized$date, mape_calc2)



You should notice that it runs much quicker.


ADDITIONAL UPDATE
: 
by()
 works by grouping same values of your 2nd argument, and processing them together. As all your timestamps are different, you are processing one row at a time.


Look into the 
xts
 library, and e.g. 
apply.daily()
 to group timestamps. But for the simple case of wanting to process by date, there is a simple hack. Change your 
by()
 line to:


df_list <- by(test_data_finialized, as.Date(test_data_finialized$date), mape_calc2)



Using 
as.Date()
 will strip off the times. Therefore all the rows on the same day now look the same and get processed together.


ASIDE 2:
 You would get better responses if your make the infamous 
minimal example
. Then people can run your code, and they can test their answers. It is also often better to use a simple data set everyone has, e.g. iris, rather than your own data. (You can do regression on any of the first 4 fields; using iris does not have to always be about predicting the species.)


ASIDE 3
: You can do MAPE completely inside H2O, as the 
abs()
 and 
mean()
 functions will work directly on H2O data frames (as do lots of other things - see the H2O manual): 
https://stackoverflow.com/a/43103229/841830

(I'm not marking this as a duplicate, as your question was how to adapt 
by()
 for use with H2O data frames, not how to calculate MAPE efficiently!)",2018-08-29T07:16:47,,,,51942913
51957138,51957138,5,"It looks like you are mixing up R and H2O data types. Remember H2O's R is simply an R API and is not the same as native R. This means that you can't apply an R function that expects an R dataframe to an H2OFrame. And likewise you can't apply an H2O Function to an R dataframe when it expects an H2OFrame.


As you can see from the R docs on 
by
 it's a function that expects ""an R object, normally a data frame, possibly a matrix"" so you can't pass in an H2O frame. 


Similarly you are passing 
date = H2OFrame
 to 
data.frame()
.


However you can use the 
as.data.frame()
 to convert an H2OFrame to an R dataframe and then go about your calculations entirely in R.",2018-08-21T21:47:31,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51942913
54953188,54953188,0,"Could it simply be the file format that is the problem?  I got ""Provided column type POSIXct is unknown"" after I imported from Excel and ran:


hr_data_h2o <- as.h2o(hr_data)
split_h2o <- h2o.splitFrame(hr_data_h2o, c(0.7, 0.15), seed = 1234)



I changed the source file to tab delimited (no other changes) and the problem went away.",2019-03-01T22:29:46,Dan Newton,https://stackoverflow.com/users/231791/dan-newton,41,51942913
51903318,51903318,1,"To format your data for forecasting, you need to aggregate your data for each group of interest and for a specific time period (in your case one day).


So if your forecast horizon is one day, you need to aggregate by user, your single-valued variable, and by day so that you have a target (label) as a total amount per day. You can find documentation on how to setup your data for driverless 
here
 and 
here
. 


EDIT

in response to comment: 


Here is another example to explain the expected data format using the assumption that each user should be aggregated at the day level:


If you have one day’s worth of data for 5 users your dataset should only have 5 rows, but if you have 10 days worth of data for 5 users you should have 50 rows of data.


Then in Driverless AI when you set up your experiment you would set your Time Group to the User column",2018-08-17T21:54:46,,,,51901091
51899909,51899909,0,"Responding to your questions inline:


1. Since, mojo Model import is not working using ModelsHandler.importModel(), is there another API available or work around which can help me to import Mojo Model in H2O?


No. MOJO was designed with the purpose of facilitating putting a model into production.


2. Can we convert, POJO or MOJO models into binary Model for import purpose?


No.


3. As per last reply for h2o, binary models are not backward compatible. So, if I upgrade H2O later, my older trained models will not work for training new stacked ensemble models. Actually, it will fail at import step itself.
 


Yes, you will only be able to load and use that saved binary model with the same version of H2O that you used to train your model. H2O binary models are not compatible across H2O versions.


a. So, is there a way to use the binary models without having the backward compatibility issue?


No.


b. If binary models are the only way to go, then is my approach right for training stacked Ensemble models(using previously exported/saved models)?


Yes.


c. Am I likely to face any other issue with binary models in future which I dont for see now?
 
Backwards compatibility is the main issue.


Please note that H2O.ai might support reading MOJOs into H2O-3 in the future, but currently there is no timetable for it.",2018-08-17T16:55:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51872773
51884117,51884117,0,"This does the trick, thx for the hunch Vivek. Still not an exact match but extremely close.


perf = model.model_performance(train)
threshold = perf.find_threshold_by_max_metric('f1')
model.model_performance(test).confusion_matrix(thresholds=threshold)",2018-08-16T19:26:41,QuanTomatic,https://stackoverflow.com/users/7700274/quantomatic,51,51869414
62996718,62996718,0,"I also meet the same issue. Here is what I would do to make a fair comparison:


model.train(x=x, y=y, training_frame=train, validation_frame=test)
cm1 = model.confusion_matrix(metrics=['F1'], valid=True)



Since we train the model using training data and validation data, then the 
pred['predict']
 will use 
the threshold which maximizes the F1 score of validation data
. To make sure, one can use these lines:


threshold = perf.find_threshold_by_max_metric(metric='F1', valid=True)
pred_df['predict'] = pred_df['p1'].apply(lambda x: 0 if x < threshold else 1)



To get another confusion matrix from scikit learn:


from sklearn.metrics import confusion_matrix

cm2 = confusion_matrix(y_true, pred_df['predict'])



In my case, I don't understand why I get slightly different results. Something like, for example:


print(cm1)
>> [[3063  176]
    [  94  146]]

print(cm2)
>> [[3063  176]
    [  95  145]]",2020-07-20T13:42:35,Anastasiya-Romanova 秀,https://stackoverflow.com/users/3397819/anastasiya-romanova-%e7%a7%80,"3,358",51869414
51863524,51863524,1,"This is something that you could get with H2O's GLM when using 
model.std_coef_plot()
, however the expected behavior of 
model.varimp(True)
 is to give you each feature's importance not the importance of individual levels.


If you want to understand the relationship between an individual level and the outcome I would recommend using H2O's partial dependence plots (documentation 
here
 and 
here
.",2018-08-15T17:24:34,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51863256
56218217,56218217,1,"What you want is called 
partial dependency plots
 and you can have it from the 
pdp_data = model.partial_plot(data=fi_data, cols=variable_list, plot=False, nbins=30,plot_stddev = False )
 command


Inside this data table you have the information you need so after some processing you can print for each variable in the model a graph like this. 




The red point represent the mean of Y and the dot the 
prediction
 for each level ceteris paribus",2019-05-20T09:41:43,George Sotiropoulos,https://stackoverflow.com/users/6346825/george-sotiropoulos,"2,103",51863256
51863436,51863436,0,"This is most likely because your Hadoop cluster is busy, and there just isn't space to start new yarn containers.


If you ask for N nodes, then you either get all N nodes, or the launch process times out like you are seeing.  You can optionally use the -timeout command line flag to increase the timeout.",2018-08-15T17:17:55,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51848917
51864105,51864105,2,"The issue here is that you only gave AutoML 90 seconds to run, so it did not have time to train even one model.  In the next stable release of H2O, the error message will be gone and instead you will simply get a Leaderboard with no rows (we are fixing this so that it's handled more gracefully). 


Rather than using 
max_runtime_secs = 90
, you could increase that to something much larger (the default is 3600 secs, or 1 hour).  Alternatively you can specify the number of models you want instead by setting 
max_models = 20
, for example.  


If you do use 
max_models
, I'd recommend setting 
max_runtime_secs
 to something large (e.g. 999999999) so that you don't run out of time.  The AutoML process will stop when it reaches the first of 
max_models
 or 
max_runtime_secs
.  


I posted a similar answer 
here
.",2018-08-15T18:05:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51847076
52928287,52928287,0,"My code was working fine, then I tweaked it and got the same error. 


To fix it, instead of using 
automl_models_h2o@leader
 to save the leader for predictions/performance, save the leader using 
h2o.getModel()
.


Change your 
automl_leader
 initialization:


...

# get model name from list
automl_models_h2o@leaderboard 

# change MODEL_NAME_HERE to a model name from your leaderboard list.
automl_leader <- h2o.getModel(""MODEL_NAME_HERE"") 

performance_h2o <- h2o.performance(automl_leader, newdata = test_h2o)

...",2018-10-22T11:28:34,agentcurry,https://stackoverflow.com/users/291938/agentcurry,"2,455",51847076
51775747,51775747,4,"I think what's happening is that you're not able to train a single model in one hour, so when you try to collect the leader model, it's trying to grab an incomplete model and you get an error.  You don't have very many rows, but you have a really large number of columns.  


Since it's hard to predict how long the model training will take, I'd use the 
max_models
 argument instead of limiting by time.  Since AutoML will stop when it reaches the first of 
max_models
 or 
max_runtime_secs
, I'd set 
max_runtime_secs
 to a very large number (e.g. 999999999) and then set 
max_models = 10
 or whatever number you like.  


Second, since you have very wide data, I'd recommend turning off the Random Forests and GBM models, and leaving the GLM and Deep Learning models.  To do that, set 
exclude_algos = c(""DRF"", ""GBM"")
.  It will take a really long time to train tree-based models on 120k columns.


Another good option to consider is to first apply 
PCA
 or 
GLRM
 to your data to reduce the dimensionality to <500 columns and then you can include the tree-based models in the AutoML run.",2018-08-09T21:05:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51747696
51789673,51789673,2,"This particular question is asking how to get the AUC for a multiclass classification problem (i.e. the target has more than two factor levels - see the posted image in the comments of the original question). H2O does not calculate the auc for individual categories, and therefore will return an error if you try to use its binary-classification metric 
auc()
.


To see what metrics are available for multiclass classification problems please see the 
documentation


Options include, for example: 
logloss()
 and 
mean_per_class_error()",2018-08-10T15:23:56,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51735459
51735807,51735807,2,"Error: Invalid argument for sort_by specified. Must be one of: [mae, residual_deviance, r2, mean_residual_deviance, rmsle, rmse, mse]




The problem is that 
""auc""
 is not a valid metric for your problem.  It looks like you have trained a regression model instead of a binary classification model, that's why AUC is not allowed.  The list of metrics in the error message is the list of allowed metrics for a regression problem.


If your response column is 0's and 1's and you did not convert it to a factor, then it's going to train a regression model instead of a binary classfication model.  If this is the case, and you want a binary classification model instead, then all you need to do is first convert the response to a factor:


train[target] = train[target].asfactor()",2018-08-07T21:40:21,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51735459
51789876,51789876,1,"In 
h2o.deeplearning()
 set 
export_weights_and_biases=T
 and then once your model has finished building you can extract the weights with 
h2o.weights()
. H2O doesn't provide methods to display a diagram for your neural net.",2018-08-10T15:37:52,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51734915
51728561,51728561,1,"Deep Water does not have support for the Power platform.


(Note Deep Water is now deprecated; instead, people are encouraged to use Keras directly.)",2018-08-07T13:55:43,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51722798
51732173,51732173,1,"The GLM algo thinks you are solving a regression problem. You need to specify that you are solving a classification problem. You can do this with the family parameter (please see the 
documentation
 for an example) and possibly you need to set your target to type 
enum
 using the 
asfactor()
 method.


For your convenience here is the example code snippet that the link points to:


import h2o
from h2o.estimators.glm import H2OGeneralizedLinearEstimator
h2o.init()

# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# convert response column to a factor
cars[""economy_20mpg""] = cars[""economy_20mpg""].asfactor()

# set the predictor names and the response column name
predictors = [""displacement"",""power"",""weight"",""acceleration"",""year""]
response = ""economy_20mpg""

# split into train and validation sets
train, valid = cars.split_frame(ratios = [.8])

# try using the `family` parameter:
# Initialize and train a GLM
cars_glm = H2OGeneralizedLinearEstimator(family = 'binomial')
cars_glm.train(x = predictors, y = response, training_frame = train, validation_frame = valid)

# print the auc for the validation data
cars_glm.auc(valid = True)",2018-08-07T17:15:51,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51722344
51826930,51826930,0,"there is a jira ticket to remove the output that is causing you trouble, you can follow it 
here
.


as a workaround you might be able to use 
capture.output
 within 
invisible
: 
invisible(capture.output())
 and then try and do some string munging from there.",2018-08-13T16:39:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51715175
51712102,51712102,7,"H2O-3 is only cpu enabled if you are interested in running an H2O.ai product that is GPU enabled please see 
H2O4GPU
 or Driverless AI (note: the latter is closed-source)",2018-08-06T16:35:27,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51711737
51732070,51732070,4,"please see the 
documentation
 for the full parameter list. For your convenience here is the list 
confusion_matrix(metrics=None, thresholds=None, train=False, valid=False, xval=False)
.


Here is a working example of how to use the method:


import h2o
from h2o.estimators.random_forest import H2ORandomForestEstimator
h2o.init()


# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# convert response column to a factor
cars[""economy_20mpg""] = cars[""economy_20mpg""].asfactor()

# set the predictor names and the response column name
predictors = [""displacement"",""power"",""weight"",""acceleration"",""year""]
response = ""economy_20mpg""

# split into train and validation sets
train, valid = cars.split_frame(ratios = [.8], seed = 1234)

# try using the binomial_double_trees (boolean parameter):
# Initialize and train a DRF
cars_drf = H2ORandomForestEstimator(binomial_double_trees = False, seed = 1234)
cars_drf.train(x = predictors, y = response, training_frame = train, validation_frame = valid)
cars_drf.confusion_matrix()
# or specify the validation frame
cars_drf.confusion_matrix(valid=True)",2018-08-07T17:09:27,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51697330
51688797,51688797,2,"The default metalearner algorithm is noted on the Stacked Ensemble User Guide page that you've linked above.  There is also more information available at the 
metalearner_algorithm
 page.


The default metalearner is:




""AUTO"" (GLM with non negative weights, and if validation_frame is present, lambda_search is set to True; may change over time). This is the default.",2018-08-04T19:11:34,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51688729
51681890,51681890,3,"There is a slight problem with how you are defining the grid.  You can only pass a dictionary of lists (of values to grid over for each hyperparamter) in the 
hyper_params
 argument.  The reason you are seeing the 
Error message: 'int' object is not iterable
 error message is because you are trying to pass an integer instead of a list for both 
score_validation_samples
 and 
stopping_rounds
.  


If there are arguments that you don't intend to grid over, then they should be passed instead to the grid's 
train()
 method.  I'd also recommend using a validation frame or cross-validation when doing grid search so you don't have to use training metrics to choose the best model.  See example below. 


import h2o
from h2o.estimators.deeplearning import H2ODeepLearningEstimator
from h2o.grid.grid_search import H2OGridSearch
h2o.init()

# Import a sample binary outcome training set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()

# Execute a grid search (also do 5-fold CV)
grid = H2OGridSearch(model=H2ODeepLearningEstimator, hyper_params = {
            'activation' :[""Rectifier"",""Tanh"",""Maxout"",""RectifierWithDropout"",""TanhWithDropout"",""MaxoutWithDropout""],
            'hidden':[[20,20],[50,50],[30,30,30],[25,25,25,25]]})
grid.train(x=x, y=y, training_frame=train, \
           score_validation_samples=10000, \
           stopping_rounds=2, \
           stopping_metric=""misclassification"", \
           stopping_tolerance=0.01, \
           nfolds=5)

# Look at grid results
gridperf = grid.get_grid(sort_by='mean_per_class_error')



There are more examples of how to use grid search in the 
H2O Python Grid Search tutorial
.",2018-08-04T02:16:55,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51681591
51681364,51681364,1,"Yikes, that's a bad bug (I reproduced it and it's broken on my end too in 3.20.0.4).  It looks like the bug was introduced a few days ago when we released 3.20.0.4 -- it's only broken on the latest fix release.  I have filed a 
bug report
 and we will fix this ASAP.  Thanks for the heads up.


In the meantime, you can use 
3.20.0.3
, which I have tested and is working properly.",2018-08-04T00:05:43,,,,51680643
51669529,51669529,0,"The [NA]s displayed close to node links mean that all nan values will go through this link.


I am not sure how h2o trees handle nan target values. Anyway, it is never a good idea to keep them. You should try to remove them or to replace them with 0 and 1 according to your problem.


The ""number at the bottom"" of your tree seem weird... Why is there written ""class 0"" at the top of your tree ? Are you training class 0 and class 1 separately ? Could you clarify how do you proceed your tree(s) training ? 


I am not sure what you mean by ""I have 4 trees"". Cross validation is only used to check how good you model can predict your data. But the model you will use to predict your future data is not the one you used to cross validate. It has to be a different model fitted with all your current data.",2018-08-03T09:30:47,,,,51668826
51677051,51677051,0,"Answering inline since there are a few questions:


My classification is a 0-1 classification.So what exactly are the numbers at the bottom telling me [ why are they negative and all] ?
 


You are showing an image of Tree 0, this is the first tree that is built (so not your main model). The tree leaf values are the corrections, you should use 
h2o.predict()
 to see what your final model's predictions are.


Also what do the NAs mean?
 


The 
[NA]
 refers to NAs in your dataset. The ones you see along the tree splits just specify which way an NA should go. 


This tree 0 is the main model right since i have done cv(n=3) and i have got 4 trees [0,1,2,3] and whatever i interpret should be based on the 0th tree right?


Tree 0 is the first tree built not your final model. Please see the 
documentation
 on cross-validation for a detailed explanation on the model building process for CV",2018-08-03T16:53:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51668826
51681378,51681378,0,"You can look at the underlying code that calculates the prediction from the tree here for GBM:


https://github.com/h2oai/h2o-3/blob/bddb258e612994c3b53fc7c73d24bf88b6b211ab/h2o-genmodel/src/main/java/hex/genmodel/algos/gbm/GbmMojoModel.java#L54",2018-08-04T00:07:47,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51668826
51677189,51677189,1,"I was not able to reproduce your specific error, but I was able to get the code to work on my end by updating 
loss=""automatic""
 to 
loss=""Automatic""
 (note that 
loss
 it is case sensitive).",2018-08-03T17:03:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51665333
51663901,51663901,7,"Currently there is only backend support for Python-based custom functions, which can be uploaded to the backend via the 
h2o.upload_custom_metric()
 function. This function will then return a function reference (this is a string that has a naming convention format of 
'language:keyName=funcName'
). That you can then pass to the 
custom_metric
 parameter.


For example:


custom_mm_func = h2o.upload_custom_metric(CustomRmseFunc, func_name=""rmse"", func_file=""mm_rmse.py"")



returns a function reference which has the following value:


> print(custom_mm_func)
python:rmse=mm_rmse.CustomRmseFuncWrapper



As for your second question about using the custom metric as a stopping metric, there is a jira ticket that you can follow here: 
https://0xdata.atlassian.net/browse/PUBDEV-5261
 


You can find more details on how to use the custom metric 
here
.",2018-08-03T00:42:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51657527
51655970,51655970,5,"This is a user error. 


The ""response"" is the y column.  And for the subset of data you have given, every row has the same value for y.  You cannot train a supervised machine learning model when every y value is the same — there is nothing for the model to learn.


This can happen if you have a rare outcome -- when you randomly split the data you might get a partition that only has one value represented.  To check how many unique values you have in the response column in Python, do the following:  
train[y].unique()",2018-08-02T14:22:16,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51655007
51641210,51641210,30,"It depends on which model you are using.  If you use the top model on the AutoML Leaderboard, that will probably be a Stacked Ensemble and we do not yet have a function to extract feature importance for that type of model yet (though there is a 
ticket open
 to add this).


If you want to use any other type of model (e.g. GBM), then you can use the regular way of getting variable importance from an H2O model.  Here's a demo using the example code from the 
H2O AutoML User Guide
.


import h2o
from h2o.automl import H2OAutoML

h2o.init()

# Import a sample binary outcome training set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()

# Run AutoML for 10 models
aml = H2OAutoML(max_models=10, seed=1)
aml.train(x=x, y=y, training_frame=train)

# View the AutoML Leaderboard
lb = aml.leaderboard
lb



The top two models are Stacked Ensembles, but the third is a GBM, so we can extract variable importance from that model.


In [6]: lb[:5,""model_id""]

Out[6]:
model_id
-----------------------------------------------------
StackedEnsemble_AllModels_0_AutoML_20180801_120024
StackedEnsemble_BestOfFamily_0_AutoML_20180801_120024
GBM_grid_0_AutoML_20180801_120024_model_4
GBM_grid_0_AutoML_20180801_120024_model_0
GBM_grid_0_AutoML_20180801_120024_model_1

[5 rows x 1 column]



Here's how to grab the variable importance.  First grab the GBM model object:


# Get third model
m = h2o.get_model(lb[2,""model_id""])



Then you can get the data back in a Pandas DataFrame (if you have 
pandas
 installed) as follows:


In [13]: m.varimp(use_pandas=True)
Out[13]:
   variable  relative_importance  scaled_importance  percentage
0       x26           997.396362           1.000000    0.224285
1       x28           437.546936           0.438689    0.098391
2       x27           338.475555           0.339359    0.076113
3        x6           306.173553           0.306973    0.068849
4       x25           295.848785           0.296621    0.066528
5       x23           284.468292           0.285211    0.063968
6        x1           191.988358           0.192490    0.043172
7        x4           184.072052           0.184553    0.041392
8       x10           137.810501           0.138170    0.030989
9       x14           100.928482           0.101192    0.022696
10      x12            90.265976           0.090502    0.020298
11      x22            89.900856           0.090136    0.020216
12      x20            87.367523           0.087596    0.019646
13      x19            83.130775           0.083348    0.018694
14       x5            82.661133           0.082877    0.018588
15      x16            81.957863           0.082172    0.018430
16      x18            80.794426           0.081005    0.018168
17       x7            80.664566           0.080875    0.018139
18      x11            75.841171           0.076039    0.017054
19       x2            75.037476           0.075233    0.016874
20       x8            72.234459           0.072423    0.016243
21      x15            70.233994           0.070417    0.015794
22       x3            60.015785           0.060172    0.013496
23       x9            40.281757           0.040387    0.009058
24      x13            35.475540           0.035568    0.007977
25      x17            25.367661           0.025434    0.005704
26      x24            22.506416           0.022565    0.005061
27      x21            18.564632           0.018613    0.004175



You can also plot the variable importance using 
m.varimp_plot()
 if you have 
matplotlib
 installed.",2018-08-01T19:46:19,,,,51640086
51614443,51614443,2,"You can use the below to save and retrieve the model.


build the model


model <- h2o.deeplearning(params)


save the model


model_path <- h2o.saveModel(object=model, path=getwd(), force=TRUE)


print(model_path)
/tmp/mymodel/DeepLearning_model_R_1441838096933


load the model


saved_model <- h2o.loadModel(model_path)


Reference - 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html


Hope this helps,
ND",2018-07-31T13:23:15,Nayan Dharamshi,https://stackoverflow.com/users/4827570/nayan-dharamshi,33,51614241
51613796,51613796,1,"As of Driverless AI 1.2.2 the only version of Ubuntu that is tested is Ubuntu 16.04.


If you are having dpkg installation problems, you can try the (beta) “TAR SH” installation package style of the most recent version on h2o.ai/download (today that is 1.2.2).


(This additional new approach just unpacks into the current directory.)


Additionally, CUDA 9.1 is not supported (and probably never will be, since CUDA 9.2 is already out).  But that’s not the cause of the error above.",2018-07-31T12:49:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51613450
51623315,51623315,1,"This is actually a bug in H2O -- it has nothing to do with tibbles.  There is no support for the ""ordered"" column type in data.frames or tibbles.  We will fix this 
(ticket here)
.


The work-around right now is to manually convert your ""ordered"" columns into un-ordered ""factor"" columns.


tb <- tibble(x = ordered(c(1,2,3)), y = 1:3)
tb$x <- factor(tb$x, ordered = FALSE)
hf <- as.h2o(tb)",2018-07-31T23:10:29,,,,51612472
51620358,51620358,0,"as.h2o()
 expects an R dataframe. You could use an R dataframe instead of your tibble dataframe or as Tom mentioned in the comments you could use one of the 
supported
 file formats for H2O.


train_h2o = as.h2o(as_data_frame(train_tbl))
valid_h2o = as.h2o(as_data_frame(valid_tbl))
test_h2o  = as.h2o(as_data_frame(test_tbl))",2018-07-31T19:03:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51612472
51683851,51683851,2,"This seems to be a bug (I filed the bug report 
here
).  It seems like the multinomial case is not working for either XGBoost or Naive Bayes (we are missing test coverage of these two cases).  If you run the code below which removes those two models, it works.  We will fix this ASAP.  Thanks.


ensemble <- h2o.stackedEnsemble(x = setdiff(colnames(trainPCA),c(depVars,""weightage"")),
                                y = depVars,
                                training_frame = trainPCA,
                                base_models = c(ModelThreeGLM@model_id, ModelFourGBM@model_id, ModelOneRF@model_id),
                                metalearner_algorithm = ""drf"",
                                metalearner_nfolds = nfolds)



EDIT:
 The bug is 
fixed and merged
 into master.  It will be available in the 
nightly release
 starting tonight (Aug 7, 2018) or the next fix release, 3.20.0.5 (released in the next few days).",2018-08-04T08:30:53,,,,51606637
51605639,51605639,1,"java version ""1.6.0_26""


Java(TM) SE Runtime Environment (build 1.6.0_26-b03)




H2O requires Java 7 or later (noted 
here
).  You are using Java 6.  You will need to upgrade Java. If you can, uninstall Java 6 and install Java 7 or 8.",2018-07-31T04:51:50,Community,https://stackoverflow.com/users/-1/community,1,51605417
51603198,51603198,1,"try converting the column type after you've converted it into an H2OFrame


# check types
In [38]: my_h2o1.types
Out[38]: {'a': 'int', 'b': 'real'}

In [39]: my_h2o2.types
Out[39]: {'a': 'real', 'b': 'real'}



Since we need 
my_h2o1['a']
 to be type real (since you will have a mix of reals and integers once you rbind the columns). We can use 
asnumeric()
.


my_h2o1['a'] = my_h2o1['a'].asnumeric()


Once we have matching types we can use the 
rbind
 method


my_h2o1.rbind(my_h2o2)",2018-07-30T22:37:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51602029
51598742,51598742,1,"H2O does not calculate permutation importance. Please see the 
documentation
 for the explanation of how variable importance is calculated. 


For your convenience I'll paste it as well below:


How is variable importance calculated for DRF?


Variable importance is determined by calculating the relative influence of each variable: whether that variable was selected during splitting in the tree building process and how much the squared error (over all trees) improved as a result.


A feature request has been previously made for this issue, you can follow it 
here
 (though note it is currently open).",2018-07-30T16:46:45,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51584970
51600441,51600441,0,"Closing out this question as the question has migrated, and more appropriately, belongs elsewhere (i.e. the Google Group).

Here's
 where the topic can be found.
Also a reference to H2O posting guidelines 
here
.


I'll recap the highlights here:




There's nothing outright that is known right now to do this, BUT:


H2O builds one model at a time, but the creation of that model is a parallel operation


You can potentially parallelize by having multiple API clients pointing to the same cluster, operating on different entries of  in the search space",2018-07-30T18:50:24,,,,51583633
51578067,51578067,1,"Deep Water is a legacy project (as of December 2017), which means that it is no longer under active development. The H2O.ai team has no current plans to add new features, however, contributions from the community (in the form of pull requests) are welcome.


Having said that, Deepwater was never built for AMD because we used Tensorflow and MXNet as backends and they did not support AMD.",2018-07-29T07:07:47,Magnus,https://stackoverflow.com/users/7816546/magnus,246,51566988
51566533,51566533,0,"EDITED Response


If you look at the bottom of your error message:


07-27 11:24:19.234 127.0.0.1:54321       14488  main      FATAL: On /127.0.0.1 some of the required ports 54321, 54322 are not available, change -port PORT and try again. 
[1] ""127.0.0.1""
[1] 54321
[1] TRUE
[1] -1
[1] ""Failed to connect to 127.0.0.1 port 54321: Connection refused""
curl: (1) Protocol ""'http"" not supported or disabled in libcurl
[1] 1


You can see that the issue should not be related to XGBoost. In addition, the expected behavior on Windows is that XGBoost is automatically disabled and no action is needed on your part.


To fix your problem try specifying a different port using the 
port =
 parameter in 
h2o.init()
 to see if you can get 
h2o.init()
 to work for you. 


Original Response


I will leave the prior answer up in case it helps others who come across the question of disabling xgboost:


you can disable xgboost by setting 
-Dsys.ai.h2o.ext.core.toggle.XGBoost
 to 
False


please see the documentation for more details: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html#disabling-xgboost",2018-07-27T23:00:35,,,,51561719
51640668,51640668,2,"This functionality is not currently available in H2O, but I've created a jira ticket to request it as a new feature, you can follow it here 
https://0xdata.atlassian.net/browse/PUBDEV-5801",2018-08-01T19:07:47,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51543937
51547413,51547413,1,"There is no native support for categorical columns in 
h2o4gpu
 (at least yet), so you will have to one-hot encode (or label encode) your categorical columns like you do in 
sklearn
 and 
xgboost
.",2018-07-26T20:58:08,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51543158
51900094,51900094,0,"The training metrics whether you get them through Flow or the Python API should be the same. 


One explanation could be that the frame was rebalanced for model training. You would need to take a look at your logs and see if says anything like 
INFO: Rebalancing train dataset into 8 chunks.
 which indicates rebalancing or 
train dataset already contains 32 (non-empty)  chunks. No need to rebalance.
 which indicates there wasn't rebalancing. In general the numbers you get from 
model.model_performance(test_data=train).r2()
 and 
model.r2(train=True)
 (which is likely the equivalent to the training metric in Flow you were referring to) should be the same as long as the number of CPUs is the same and the frame has the same layout.",2018-08-17T17:08:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51527546
51478779,51478779,1,"You are mixing python2 and python3. What you are using when running 
pip
 or 
python
 are all python2.7 (see also the output of 
pip show tensorflow
 where it is referring to 
/usr/local/lib/python2.7/dist-packages
).


The library you are trying to use only has 
.whl
 for python 3.6 (note the 
py36
 in the 
.whl
 files name)


Therefore, you need to either:




Switch to using 
pip3
 and 
python3


Find another library that works with python 2.7",2018-07-23T12:27:10,FlyingTeller,https://stackoverflow.com/users/5012099/flyingteller,20.2k,51478588
51527994,51527994,0,"We are not shipping python 2.7 wheels for H2O4GPU, so you will need to use pip3 as suggested by FlyingTeller.


It would be best to use virtualenv to create a python environment to cause minimal changes to system python.


sudo apt-get install python3-pip
sudo pip3 install virtualenv
virtualenv -p python36 h2o4gpuenv
. h2o4gpuenv/bin/activate
pip install h2o4gpu-*.whl



Now in this same virtual environment, start 
python
 and try 
import h2o4gpu
.",2018-07-25T21:33:34,Hemen Kapadia,https://stackoverflow.com/users/3705587/hemen-kapadia,1,51478588
51826245,51826245,1,"The nightly downloads page is meant to work for simple environments, and is not meant to capture all possible configurations.


However, since this question is specific to Windows, you can find documentation on how to Use Sparkling Water in Windows Environments 
here
 and how to Use Rsparkling in Windows Environments 
here
 (note these are for the latest stable, but the instructions should be similar for the nightly release).",2018-08-13T15:53:56,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51471526
52867620,52867620,1,"first install last version sparklyr and connect to Spark


library(sparklyr)
spark_install(version = ""2.3.2"")
sc <- spark_connect(master = ""local"", version = ""2.3.2"")



Install H2O of correct version:


install.packages(""h2o"", type = ""source"", repos = ""https://h2o-release.s3.amazonaws.com/h2o/rel-wright/10/R"")
packageVersion(""h2o"")
[1] ‘3.20.0.10’



Verify the compatibility of sparkling water with h2o


rsparkling::h2o_release_table()[1:5,]
   Spark_Version Sparkling_Water_Version H2O_Version H2O_Release_Name H2O_Release_Patch_Number
1            2.3                  2.3.16   3.20.0.10       rel-wright                       10
17           2.3                  2.3.15    3.20.0.9       rel-wright                        9
16           2.3                  2.3.14    3.20.0.8       rel-wright                        8
15           2.3                  2.3.13    3.20.0.7       rel-wright                        7
14           2.3                  2.3.12    3.20.0.6       rel-wright                        6



Set Sparkling Water version to be used with RSparkling


options(rsparkling.sparklingwater.version = ""2.3.16"")
library(rsparkling)



Now, H2OContext is available and we can use any H2O features available in R.
    h2o_context(sc)
    
      org.apache.spark.h2o.H2OContext


Sparkling Water Context:
 * H2O name: sparkling-water-USER_local-1539839100465
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)

h2o_flow(sc)



Initialize 
Spark UI




Now the integration of Spark with H2O through Sparkling Water works perfectly.",2018-10-18T05:39:25,Rafael Díaz,https://stackoverflow.com/users/8133525/rafael-d%c3%adaz,"2,257",51471526
51938730,51938730,0,"Although your question was specific to Windows, you may want to try 
this solution
 that worked fine in Mac.",2018-08-20T21:27:58,sm1231,https://stackoverflow.com/users/10247576/sm1231,33,51471526
66590475,66590475,0,"I got the same error and resolved it.


In my case, the mojo runtime file had a problem. I was using 1.8.1.1, and a bug discovered around the time of the version. I simply replaced the file with the latest one. Then everything worked like a charm.


Here is the link for the file. Please notice that this may not be the latest one for you. 
https://s3.amazonaws.com/artifacts.h2o.ai/releases/ai/h2o/mojo2-runtime/2.5.9/any/mojo2-runtime-2.5.9-all.jar",2021-03-11T20:59:47,,,,51469394
51460571,51460571,3,"The cross-validated predictions are stored in two different places -- once as a list of length k (for k-folds) in 
model.cross_validation_predictions()
, and another as an H2O Frame with the CV preds in the same order as the original training rows in 
model.cross_validation_holdout_predictions()
.  The latter is usually what people want (we added this later, that's why there are two versions).


Yes, unfortunately the 
R example
 to get this frame in the ""Cross-validation"" section of the H2O User Guide does not have a Python version (
ticket
 to fix that).  In the 
keep_cross_validation_predictions
 argument documentation, it only shows one of the two locations.


Here's an updated example using XGBoost and showing both types of CV predictions:


import h2o
from h2o.estimators.xgboost import H2OXGBoostEstimator
h2o.init()

# Import a sample binary outcome training set into H2O
train = h2o.import_file(""http://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()

# try using the `keep_cross_validation_predictions` (boolean parameter):
# first initialize your estimator, set nfolds parameter
xgb = H2OXGBoostEstimator(keep_cross_validation_predictions = True, nfolds = 5, seed = 1)

# then train your model
xgb.train(x = x, y = y, training_frame = train)

# print the cross-validation predictions as a list
xgb.cross_validation_predictions()

# print the cross-validation predictions as an H2OFrame
xgb.cross_validation_holdout_predictions()



The CV pred frame of predictions looks like this:


Out[57]:
  predict         p0        p1
---------  ---------  --------
        1  0.396057   0.603943
        1  0.149905   0.850095
        1  0.0407018  0.959298
        1  0.140991   0.859009
        0  0.67361    0.32639
        0  0.865698   0.134302
        1  0.12927    0.87073
        1  0.0549603  0.94504
        1  0.162544   0.837456
        1  0.105603   0.894397

[10000 rows x 3 columns]",2018-07-21T22:23:54,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51453164
51454985,51454985,1,"For Python there is 
an example of this on GBM
, and it should be exactly the same for XGB. According to that page, you should be able to do something like this: 


model = H2OXGBoostEstimator(keep_cross_validation_predictions = True)

model.train(x = predictors, y = response, training_frame = train)

cv_predictions = model.cross_validation_predictions()",2018-07-21T10:06:40,Michele Tonutti,https://stackoverflow.com/users/5236005/michele-tonutti,"4,348",51453164
55639815,55639815,1,"I know it's been 8 months and it's likely that you've already figured it out. However, I will post my solution for those who run into the same problem.


The importance here resides in the parameter 
export_weights_and_biases
 of 
h2o.deeplearning()
; and the 
h2o.weigths(neuralnet)
 and 
h2o.biases(neuralnet)
 functions, which gives the parameters you're looking for.


All that's left is ordering the data.


# Load your data
neuraldat.hex <- as.h2o(neuraldat)

h2o_neural_model <- h2o.deeplearning(x = 1:4, y = 5,
         training_frame= neuraldat.hex, 
         hidden = c(2,3),
         epochs = 10, 
         model_id = NULL,
         export_weights_and_biases = T) # notice this parameter!

# for each layer, starting from left hidden layer,
# append bias and weights of each node in layer to
# numeric vector.
wts <- c()
for (l in 1:(length(h2o_neural_model@allparameters$hidden)+1)){
    wts_in <- h2o.weights(h2o_neural_model, l)
    biases <- as.vector(h2o.biases(h2o_neural_model, l))
    for (i in 1:nrow(wts_in)){
        wts <- c(wts, biases[i], as.vector(wts_in[i,]))
    }
}
# generate struct from column 'units' in model_summary
struct <- h2o_neural_model@model$model_summary$units
# plot it
plotnet(wts, struct = struct)



The h2o object that it's returned by the deeplearning function it's quite complex and one can get lost in the 
documentation
.",2019-04-11T19:25:44,UseR10085,https://stackoverflow.com/users/6123824/user10085,"8,062",51432797
51408256,51408256,1,"This is a reasonable request and there's not currently a way to do this in H2O's grid search functionality, however I have created a ticket 
here
.  There is another 
ticket open
 for a similar request, which is to keep the ""top k"" models from the grid (and delete the rest) as you continue to run the grid search.


We have implemented this functionality for 
H2O AutoML
 via the 
keep_cross_validation_models
 argument, so if you're open to using H2O AutoML (which would be mostly GBMs), you could use that instead of a Random Forest grid.  If you set this argument to 
FALSE
, then CV models will be deleted, however the only 
problem
 with the current implementation is that the CV models are deleted at the end of the AutoML run instead of immediately after they are created and CV metrics are saved. 


So, in the meantime, for a work-around, I'd recommend the following:


You can execute the grid more than once by making use of the 
grid_id
 argument.  After each execution, you can manually delete the CV models.  Then you can ""train"" the grid again and set 
grid_id
 to be the same as before and it will add more models to the same grid.  If you are using cartesian grid search, you should change the search space, and if you are using random grid search, you can just change the seed so that you'll get different/new models the second time around.  It's manual, but it's still a bit easier than writing a loop and creating the grid from scratch.


Python Example:


import h2o
from h2o.estimators.random_forest import H2ORandomForestEstimator
from h2o.grid.grid_search import H2OGridSearch

h2o.init()

# Import a sample binary outcome training set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()

# RF hyperparameters
rf_params = {'max_depth': list(range(5, 30)),
             'sample_rate': [i * 0.1 for i in range(5, 11)],
             'min_rows': list(range(1, 25))}

# Search criteria
search_criteria = {'strategy': 'RandomDiscrete', 'max_models': 20}

rf_grid = H2OGridSearch(model=H2ORandomForestEstimator,
                        grid_id='rf_grid',
                        hyper_params=rf_params,
                        search_criteria=search_criteria)
rf_grid.train(x=x, y=y, 
              training_frame=train, 
              nfolds=5, 
              ntrees=300,
              seed=1)

# Code to delete CV models (you'll have to do this part)

rf_grid.train(x=x, y=y, 
              training_frame=train, 
              nfolds=5, 
              ntrees=300,
              seed=2)  #change seed for second random grid search run",2018-07-18T17:54:55,,,,51405410
51461212,51461212,3,"Usually you need to unset the “http_proxy” environment variable.


so:


del os.environ[“http_proxy”]",2018-07-22T00:59:33,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51377739
51461237,51461237,0,"I’ve seen a couple of examples of this over the years, but the real answer is this really isn’t supported well.


Here is a pointer to the best example I can remember:


https://github.com/h2oai/sparkling-water/blob/master/examples/flows/2016_H2O_Tour_Chicago.flow


If you really want to do this, the best guide is the source code of H2O Flow.",2018-07-22T01:04:23,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51376724
51375839,51375839,1,"I would queue them.


Additionally, I would restart the H2O cluster from scratch each time.


Finally, I would drive the H2O cluster from python or R.",2018-07-17T07:42:01,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51373908
51412235,51412235,1,"I think this depends mostly on how you want your user experience to be -- whether or not you are okay with users waiting, or if you'd rather have all users slowed down.  If it's a free service, then I think users would expect to wait.  I agree with Tom that it's probably better to queue the jobs, though it's a personal design/user experience choice.


If you run the jobs in parallel, I'd recommend starting each H2O instance (one per user) on a different port.  These sessions will still share (compete for) resources if running on the same machine, but at least it's a bit cleaner (they can't overwrite each other's models, etc).",2018-07-18T23:18:24,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",51373908
51423325,51423325,20,"In principle & in theory, hard & soft classification (i.e. returning 
classes
 & 
probabilities
 respectively) are different approaches, each one with its own merits & downsides. Consider for example the following, from the paper 
Hard or Soft Classification? Large-margin Unified Machines
:




Margin-based classifiers have been popular in both machine learning and statistics for classification problems. Among numerous classifiers, some are 
hard
 classifiers while some are 
soft
 ones. Soft classifiers explicitly estimate the class conditional probabilities and then perform classification based on estimated probabilities. In contrast, hard classifiers directly target on the classification decision boundary without producing the probability estimation. These two types of classifiers are based on different philosophies and each has its own merits.




That said, in practice, most of the classifiers used today, including Random Forest (the only exception I can think of is the SVM family) are in fact 
soft
 classifiers: what they actually produce underneath is a probability-like measure, which subsequently, combined with an implicit 
threshold
 (usually 0.5 by default in the binary case), gives a hard class membership like 
0/1
 or 
True/False
.




What is the right way to get the classified prediction result?




For starters, it is always possible to go from probabilities to hard classes, but the opposite is not true.


Generally speaking, and given the fact that your classifier is in fact a 
soft
 one, getting just the end hard classifications (
True/False
) gives a ""black box"" flavor to the process, which in principle should be undesirable; handling directly the produced probabilities, and (important!) controlling explicitly the 
decision threshold
 should be the preferable way here. According to my experience, these are subtleties that are often lost to new practitioners; consider for example the following, from the Cross Validated thread 
Reduce Classification probability threshold
:




the statistical component of your exercise ends when you output a probability for each class of your new sample. Choosing a threshold beyond which you classify a new observation as 1 vs. 0 is not part of the 
statistics
 any more. It is part of the 
decision
 component.




Apart from ""soft"" arguments (pun unintended) like the above, there are cases where you 
need
 to handle directly the underlying probabilities and thresholds, i.e. cases where the default threshold of 0.5 in binary classification will lead you astray, most notably when your classes are imbalanced; see my answer in 
High AUC but bad predictions with imbalanced data
 (and the links therein) for a concrete example of such a case.


To be honest, I am rather surprised by the behavior of H2O you report (I haven't use it personally), i.e. that the kind of the output is affected by the representation of the input; this should not be the case, and if it is indeed, we may have an issue of bad design. Compare for example the Random Forest classifier in scikit-learn, which includes two different methods, 
predict
 and 
predict_proba
, to get the hard classifications and the underlying probabilities respectively (and checking the docs, it is apparent that the output of 
predict
 is based on the 
probability estimates
, which have been computed already before).




If probabilities are the outcomes for numerical target values, then how do I handle it in case of a multiclass classification?




There is nothing new here in principle, apart from the fact that a simple threshold is no longer meaningful; again, from the Random Forest 
predict
 docs in scikit-learn:




the predicted class is the one with highest mean probability estimate




That is, for 3 classes 
(0, 1, 2)
, you get an estimate of 
[p0, p1, p2]
 (with elements summing up to one, as per the rules of probability), and the predicted class is the one with the highest probability, e.g. class #1 for the case of 
[0.12, 0.60, 0.28]
. Here is a 
reproducible example
 with the 3-class iris dataset (it's for the GBM algorithm and in R, but the rationale is the same).",2018-07-19T12:59:01,,,,51367755
51526227,51526227,6,"Adding to @desertnaut's answer, and since you tagged this question as Python, here is how you handle the last part of your question:




If probabilities are the outcomes for numerical target values, then how do I handle it in case of a multiclass classification?




y_pred = np.argmax(prob, axis=1)



This will convert a 
(num_examples, n_classes)
 array of probability values to a 
(num_examples, )
 array of predicted classes.",2018-07-25T19:20:51,doodhwala,https://stackoverflow.com/users/6649050/doodhwala,358,51367755
51366687,51366687,2,"Even without grid search, H2O-3's GLM uses L1 regularization (aka ""lasso"") to figure out which variables it can penalize out of the model.


Elastic net is the blending of L1 (lasso) and L2 (ridge regression), and is controlled by the alpha and lambda parameters.


The GLM booklet is a good reference on the details:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/GLMBooklet.pdf",2018-07-16T16:54:06,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51366109
51328798,51328798,0,"Never mind - I've found the problem : column sampling is the culprit!


Obviously this isn't a bug, but something to be aware of.",2018-07-13T15:50:49,TomFromWales,https://stackoverflow.com/users/4747599/tomfromwales,85,51328685
51344874,51344874,0,"As disucssed in the comments it is difficult to tell what the cause for the 
error
 could be without sample 
data
 and 
code
. The 
out-of-bounds
 
error
 could be because the 
code
 is trying to access a value that does not exist in the 
input
. So possibly, it could be either of the 
inputs
 to the 
h2o.grid()
. I would check columns and rows in the 
train
 and 
validation
 data sets. The 
hyperparameters
 from the question run fine with 
family=""binomial""
.


The 
code
 below runs fine with 
glm()
. I have made several assumptions such as: (1) 
family=binomial
 instead of 
family=gamma
 was used based on 
sample data
 created, (2) response 
y
 is 
binary
, (3) 
train
 and 
test
 
split ratio
, (4) number of 
responses
 are limited to three 
predictors
 or 
independent variables
 (
x1
, 
x2
, 
x3
), (5) one 
binary response variable (
y`).


Import libraries


library(h2o)
library(h2oEnsemble)



Create sample data


x1 <- abs(100*rnorm(100))
x2 <- 10+abs(100*rnorm(100))
x3 <- 100+abs(100*rnorm(100))
#y <- ronorm(100)
y <- floor(runif(100,0,1.5))
df <- data.frame(x1, x2, x3,y)
df$y <-  ifelse(df$y==1, 'yes', 'no')
df$y <- as.factor(df$y)
head(df)



Initialize 
h2o


h2o.init()



Prepare 
data
 in required  
h2o
 format


df <- as.h2o(df)
y <- ""y""
x <- setdiff( names(df), y )
df<- df[ df$y %in% c(""no"", ""yes""), ]
h2o.setLevels(df$y, c(""no"",""yes"") )

# Split data into train and validate sets
data <- h2o.splitFrame( df, ratios = c(.6, 0.15) )
names(data) <- c('train', 'valid', 'test')
data$train



Set 
parameters
 


grid_id <- 'glm_grid'
hyper_parameters <- list( alpha = c(0, .5, 1),
                          lambda = c(1, 0.5, 0.1, 0.01),
                          missing_values_handling = c(""Skip"", ""MeanImputation""),
                          tweedie_variance_power = c(0, 1, 1.1,1.8,1.9,2,2.1,2.5,2.6,3, 5, 7),
                          #tweedie_variance_power = c(0, 1, 1.1,1.8,1.9,2,2.1,2.5,2.6,3, 5, 7),
                          seed = 1234

)



Fit 
h2o.grid()


h2o.grid(
  algorithm = ""glm"", 
  #grid_id = grid_id,
  hyper_params = hyper_parameters,
  training_frame = data$train, 
  validation_frame = data$valid, 
  x = x, 
  y = y,
  lambda_search = TRUE,
  remove_collinear_columns = T,
  keep_cross_validation_predictions = F,
  compute_p_values = F,
  standardize = T,
  nfolds = 2,
  fold_assignment = ""Modulo"",

  family = ""binomial""     
)



Output",2018-07-15T02:59:59,Nilesh Ingle,https://stackoverflow.com/users/6005206/nilesh-ingle,"1,883",51328091
51325537,51325537,1,"Sorry, R and Python are not supported inside the H2O Flow Web UI.


Try installing RStudio for a nice R IDE.",2018-07-13T12:51:10,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",51319990
51267479,51267479,0,"It's not a feature of 
h2o.partialPlot
. You can verify that in the 
documentation
 and the 
source code
.


I think your options include




Requesting
 that as a feature


Using the approach you linked which will work fine with your 
h2o
 data after you change it back to a regular R class",2018-07-10T14:11:35,Hack-R,https://stackoverflow.com/users/3604745/hack-r,23.1k,51266468
51313978,51313978,1,"Currently, you need to do this manually.  It would be easier if we had a 
threshold
 argument for the 
predict()
 method, so I created a 
JIRA ticket
 ticket to make this a bit more straight-forward.


See a Python example below of how to do this manually below.


import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator
h2o.init()

# Import a sample binary outcome train/test set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()
test[y] = test[y].asfactor()

# Train and cross-validate a GBM
my_gbm = H2OGradientBoostingEstimator(distribution=""bernoulli"", seed=1)
my_gbm.train(x=x, y=y, training_frame=train)

# Predict on a test set using default threshold
pred = my_gbm.predict(test_data=test)



Look at the 
pred
 frame:


In [16]: pred.tail()
Out[16]:
  predict        p0        p1
---------  --------  --------
        1  0.484712  0.515288
        0  0.693893  0.306107
        1  0.319674  0.680326
        0  0.582344  0.417656
        1  0.471658  0.528342
        1  0.079922  0.920078
        1  0.150146  0.849854
        0  0.835288  0.164712
        0  0.639877  0.360123
        1  0.54377   0.45623

[10 rows x 3 columns]



Here's how to manually create the predictions you want.  More info on how to slice H2OFrames is available in the 
H2O User Guide
.


# Binary column which is 1 if >=0.2 and 0 if <0.2
newpred = pred[""p1""] >= 0.2 

newpred.tail()



Look at the binary column:


In [23]: newpred.tail()
Out[23]:
  p1
----
   1
   1
   1
   1
   1
   1
   1
   0
   1
   1

[10 rows x 1 column]



Now you have the predictions you want.  You could also replace the 
""predict""
 column with the new predicted labels.


pred[""predict""] = newpred



Now re-examine the 
pred
 frame:


In [24]: pred.tail()
Out[24]:
  predict        p0        p1
---------  --------  --------
        1  0.484712  0.515288
        1  0.693893  0.306107
        1  0.319674  0.680326
        1  0.582344  0.417656
        1  0.471658  0.528342
        1  0.079922  0.920078
        1  0.150146  0.849854
        0  0.835288  0.164712
        1  0.639877  0.360123
        1  0.54377   0.45623

[10 rows x 3 columns]",2018-07-12T20:31:07,,,,51262821
51235722,51235722,1,"I had the use the CURL command as below to make it work:


curl -X POST -H 'Content-Type: application/json' -d '{""input_spec"":{""training_frame"":""1acfbae9-af66-42fd-835f-13ccc5a508cb"",""response_column"":""mpg"",""ignored_columns"":[],""sort_metric"":null},""build_models"":{""exclude_algos"":[]},""build_control"":{""nfolds"":5,""keep_cross_validation_predictions"":true,""keep_cross_validation_models"":true,""balance_classes"":false,""class_sampling_factors"":[],""max_after_balance_size"":5,""stopping_criteria"":{""seed"":-1,""max_models"":0,""max_runtime_secs"":30,""stopping_rounds"":3,""stopping_tolerance"":-1},""project_name"":""automl-mpg""}}' http://localhost:54321/99/AutoMLBuilder



Above 1acfbae9-af66-42fd-835f-13ccc5a508cb is the training frame id.",2018-07-08T20:24:08,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,51217452
51221463,51221463,1,"All dates within h2o are represented like this. Even if you have a character column of dates (""2018-01-01"") and you use h2o.as_date() it will be represented in milliseconds.


What you can do if you want to filter on dates is use the 
h2o.day
, 
h2o.month
 and 
h2o.year
 functions.


data.hex[h2o.day(data.hex$date_used_dt) == 5, ]
 if you only want every 5th day of every month. 


Or any combination of month and year like 
data.hex[h2o.year(data.hex$date_used_dt) == 2017 & h2o.month(data.hex$date_used_dt) == 12, ]
  if you just want december 2017.",2018-07-07T08:45:59,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,51216030
51169475,51169475,0,"You dont connect two docker containers though ip addresses. Instead, you want to use docker internal network aliases: 


version: '3'
services:
  server:
    ...
    depends_on:
      - database
  database:
    ...
    expose:
      - 54321:54321



then you can define your connectio in server as:

h2o.connect(ip='127.0.0.1', port='54321')",2018-07-04T08:47:14,,,,51169089
51149904,51149904,2,"Try to start container exposing port 54321: add to your 
h2o-start:
 in docker-compose file: 


ports: 
  - ""54321:54321""
  - ""54322:54322""",2018-07-03T08:25:51,Alejandro Galera,https://stackoverflow.com/users/3351141/alejandro-galera,"3,651",51149201
51138428,51138428,1,"It appears to be a left over from preparation for a DeepWater integration that never happened. E.g. 
https://github.com/h2oai/h2o-3/search?l=Java&p=2&q=mini_batch_size


That makes sense, because the Hogwild! algorithm, that H2O's deep learning uses, does away with the need for batching training data.


To sum up, I don't think it is used.",2018-07-02T14:25:47,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,51136687
51142007,51142007,0,"There isn't a direct equivalent python api function for 
allStringVecToCategorical(_)
, the closest is 
.asfactor()
 (docs 
here
) which you can use to convert a single column to type enum/categorical. To get the subset of columns with type string you can use the method 
columns_by_type()
 (docs 
here
).


For 
.score()
 you can use the python api's 
.predict()
 method (docs 
here
).",2018-07-02T18:37:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51135888
51163791,51163791,1,"The documentation should say 16 groups not 20 (originally the default was 20 groups but has since been updated), I've made a jira ticket for the issue that you can follow: 
https://0xdata.atlassian.net/browse/PUBDEV-5709?filter=-2
.


You can't change the quantiles without touching the Java code, but you can subset on the cumulative data fractions (look at the cumuluative_data_fraction column) that you are interested in (the gains lift table gives you more information than you may need).",2018-07-03T22:57:57,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",51107672
51112485,51112485,1,"Error in elnet(x, is.sparse, ix, jx, y, weights, offset, type.gaussian,  :


y is constant; gaussian glmnet fails at standardization step




Just reading the error, there seems to be a problem with your training data, or possibly some subset of the data that is used to train a 
glmnet
 model (
elnet()
 is used inside the 
glmnet()
 function).


Specifically, the error indicates that the response column is constant and therefore cannot train an 
glmnet
 model -- training a 
glmnet
 model is a step inside the 
model_permutations()
 function, which itself is inside the 
explain()
 function.


You should check your response column to make sure that it's not constant.",2018-06-30T06:48:26,Community,https://stackoverflow.com/users/-1/community,1,51084343
63365324,63365324,1,"I was getting a similar error.


I changed 
labels = ""Yes""
 to 
labels = ""Response""
, to match my target variable which resolved my issue.",2020-08-11T19:44:00,M--,https://stackoverflow.com/users/6461462/m,28.4k,51084343
51071285,51071285,1,"The error says it cannot make a leaderboard. As Lauren says, this could be a bug, but it is a corner case. Instead, simply don't do this:


max_runtime_secs = 0,
max_models = NULL, 



Set one or the other (or both) to a non-zero value. Otherwise no models will ever get built, and there is no point calling 
h2o.automl()
. See 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#required-stopping-parameters


Setting 
max_models=1
 would seem to be the easiest fix, if you want 
h2o.automl()
 to make the minimum amount of machine effort.",2018-06-27T20:57:07,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,51059737
51107481,51107481,0,"openSparkUI used to exist around 2015, but has since been removed. As noted in the question 
h2oContext.openFlow
 is still functional and an available option (type 
q
 to convert a cell to a scala cell in flow, type 
h
 to see the the full keyboard shortcut list - note: keyboard shortcuts only work if you are not in editor mode and typing within a cell). 


Other possible interfaces for Scala code include Jupyter notebook and Zeppelin.",2018-06-29T18:25:02,,,,51007240
50989511,50989511,4,"The enum type is used for categorical variables with two or more categories. So it includes boolean. I.e. there is no distinct bool category in H2O, and there is nothing you need to fix here.


By the way, if you have a lot of boolean features because you have manually done one-hot encoding, don't do that. Instead give H2O the original (multi-level categorical) data, and it will do one-hot encoding when needed, behind the scenes. This is better because for algorithms like decision trees) they can use multi-level categorical data directly, so it will be more efficient.


See 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/categorical_encoding.html
 for some alternatives you can try. The missing category is added for when that column is missing in production.


(But ""What happens when you try to predict on a categorical level not seen during training?"" at 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html#faq
 does not seem to describe the behaviour you see?)


Also see 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/use_all_factor_levels.html
 (I cannot work out from that description if you want it to be true or false, so try both ways!)


UPDATE: set 
use_all_factor_levels = F
 and it will only have one input neuron (plus the NA one) for each boolean input, instead of two. If your categorical inputs are almost all boolean types I'd recommend setting this. If your categorical inputs mostly have quite a lot levels I wouldn't (because, overall, it won't make much difference in the number of input neurons, but it might make the network easier to train).


WHY MISSING(NA)?


If I have a boolean input, e.g. ""isBig"", there will be 3 input neurons created for it. If you look at 
varimp()
 you can see there are named:


isBig.1
isBig.0
isBig.missing(NA) 



Imagine you now put it into production, and the user does not give a value (or gives an NA, or gives an illegal value such as ""2"") for the isBig input. This is when the NA input neuron gets fired, to signify that we don't know if it is big or not.


To be honest, I think this cannot be any more useful than firing both the .0 and the .1 neurons, or firing neither of them. But if you are using 
use_all_factor_levels=F
 then it 
is
 useful. Otherwise all NA data gets treated as ""not-big"" rather than ""could be big or not-big"".",2018-06-22T13:51:04,,,,50987850
50969577,50969577,2,"Sorry, deploying non-H2O-3 models within H2O-3 is unsupported.",2018-06-21T13:18:45,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50968068
50952908,50952908,3,"if you are using H2O's python api you can convert numeric columns to enum using 
.asfactor()
 for example 
df['my_colummn'] = df['my_colummn'].asfactor()


In flow after you import the dataset you will see a data type drop-down menu next to each column name where you can convert the data type to enum by selecting 
enum
 from the drop-down menu. You can also do this after you have parsed the dataset when you view the data; there is a hyperlink within each row that you can click on to convert the data type from numeric to enum.


please see the documentation for more details: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/flow.html#parsing-data",2018-06-20T16:21:45,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50946104
50963304,50963304,2,"To run GLM on categorical data, set the family to ""multinomial"" (or ""binomial"" when there are only two classes).",2018-06-21T07:59:10,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,50946104
50952993,50952993,1,"Currently, as of version 1.2.0, unsupervised clustering is not supported in DAI; DAI is designed to solve supervised learning problems.


Here are the current supported problem types (
please review the documentation
 to see changes of future releases at 
http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/release_notes.html
):


Problem types supported
:




Regression (continuous target variable, for age, income, house price,
loss prediction, time-series forecasting) 


Binary classification (0/1
or “N”/”Y”, for fraud prediction, churn prediction, failure
prediction, etc.) 


Multinomial classification (0/1/2/3 or
“A”/”B”/”C”/”D” for categorical target variables, for prediction of
membership type, next-action, product recommendation, etc.)",2018-06-20T16:26:53,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50941901
50936640,50936640,1,"just in case someone runs in to same issue. I was able to persist mojos by calling following method (registerSchemasAndAlgos) right after H2OApp starts. 


import hex.api.RegisterAlgos;
import water.api.RequestServer;
import water.api.Schema;
import water.api.SchemaServer;
import java.util.ArrayList;
import java.util.List;
import java.util.ServiceLoader;

public void registerSchemasAndAlgos() {
    // schemas
    SchemaServer.registerAllSchemasIfNecessary(getAllSchemas());

    // algos
    RegisterAlgos algos = new RegisterAlgos();
    algos.registerEndPoints(new RequestServer.DummyRestApiContext());
}

public void registerAlgos() {
    RegisterAlgos algos = new RegisterAlgos();
    algos.registerEndPoints(new RequestServer.DummyRestApiContext());
}

public Schema[] getAllSchemas() {
    ServiceLoader<Schema> schemaLoader = ServiceLoader.load(Schema.class);
    List<Schema> allSchemas = new ArrayList<>();
    for (Schema schema : schemaLoader) {
        allSchemas.add(schema);
    }
    return allSchemas.toArray(new Schema[allSchemas.size()]);
}",2018-06-19T20:41:56,sanket,https://stackoverflow.com/users/921033/sanket,93,50932650
50994145,50994145,0,"I cannot reproduce this error on H2O 3.20.0.2:


> library(h2o)
> h2o.init()
 Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         18 hours 58 minutes 
    H2O cluster timezone:       America/Los_Angeles 
    H2O data parsing timezone:  UTC 
    H2O cluster version:        3.20.0.2 
    H2O cluster version age:    6 days  
    H2O cluster name:           H2O_started_from_R_me_ves048 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   3.28 GB 
    H2O cluster total cores:    8 
    H2O cluster allowed cores:  8 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.5.0 (2018-04-23) 

> # Load the HIGGS dataset
> train <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
  |=================================================================================================| 100%
> test <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")
  |=================================================================================================| 100%
> y <- ""response""
> x <- setdiff(names(train), y)
> family <- ""binomial""
> #For binary classification, response should be a factor
> train[,y] <- as.factor(train[,y])
> test[,y] <- as.factor(test[,y])
> # Some XGboost/GBM hyperparameters
> hyper_params <- list(ntrees = seq(10, 1000, 1),
+                      learn_rate = seq(0.0001, 0.2, 0.0001),
+                      max_depth = seq(1, 20, 1),
+                      sample_rate = seq(0.5, 1.0, 0.0001),
+                      col_sample_rate = seq(0.2, 1.0, 0.0001))
> search_criteria <- list(strategy = ""RandomDiscrete"",
+                         max_models = 10, 
+                         seed = 1)
> # Train the grid
> xgb_grid <- h2o.grid(algorithm = ""xgboost"",
+                      x = x, y = y,
+                      training_frame = train,
+                      nfolds = 5,
+                      seed = 1,
+                      hyper_params = hyper_params,
+                      search_criteria = search_criteria)
  |=================================================================================================| 100%
>",2018-06-22T18:58:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",50920389
50890536,50890536,1,"You have a typo -- you're missing a single quote after 
thresholds_and_metric_scores
.


perf['metrics']['thresholds_and_metric_scores']",2018-06-16T18:15:01,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",50883728
51006671,51006671,0,used dir() to find the various functions I needed.,2018-06-24T03:14:24,runningbirds,https://stackoverflow.com/users/3788557/runningbirds,"6,565",50883728
50854458,50854458,1,"There is only label-encoding, 
LabelEncoder
, together with OHE available in sklearn. However, it does not provide the functionality that you want, as categories are simply encoded as integers and this is meaningful for ordinal categories only, I believe. I believe, in sklearn it is left up to models to implement such enum category treatment (because there are many models in sklearn and most of them would not be able to benefit from such encoding). 


I think, 
LightGBM
 claims 
here
 that it implements internally such type of category treatment, but i'm actually not 100% sure if that is true. The advantage is that they have both RF and GBM tree builders, so you cab easily switch between those and it is faster than sklearn implementation.


Note also that 
CatBoost
 has a reach toolkit for internal category encoding, but I have zero experience with it so far.",2018-06-14T09:46:06,Mischa Lisovyi,https://stackoverflow.com/users/9640384/mischa-lisovyi,"3,303",50853542
50975024,50975024,1,"you can use 
myH2OFrame.toString(0, 20, false)
 which gives you a preview 


or


you can do 
myH2OFrame.toTwoDimTable(0, 20, false)
 to get first twenty rows as an object which holds actual numbers (or strings)",2018-06-21T18:04:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50851937
50841953,50841953,1,"The 
sort_metric
 argument was added in the most recent stable release of H2O, 3.20.0.1.  You must upgrade to the latest version of H2O to use it.  You can always tell which version of H2O is the latest version by looking at the version number listed in the user guide.  See screenshot below.",2018-06-13T16:20:02,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",50832187
50827748,50827748,1,"The problem that you are encountering is due to having multiple python versions on your machine, which is clearly visible in the screenshot. The default python version is not Anaconda python. After installing H2O using pip, it's not visible to python version installed via Anaconda distribution. There are a few options to solve this issue




Install H2O using anaconda pip (from anaconda terminal) 


Install H2O using conda installer 
conda install -c anaconda h2o
, which will install H2O version 3.18 from Anaconda channel


Install directly from a channel maintained by H2O - 
conda install -c h2oai h2o
, which is the up to date version of the library.




In addition, I would recommend correctly setting up environment variables and python path. Otherwise, it will become difficult to manage all of the packages and keep track which pip was used to install which package. Please see the following link for a discussion on how to add anaconda python to 
PYTHONPATH
 on a windows machine


https://docs.python.org/3/using/windows.html#excursus-setting-environment-variables",2018-06-13T00:57:28,karhayrap,https://stackoverflow.com/users/8502874/karhayrap,346,50827435
50820886,50820886,4,"The error message is telling you that one of your nodes is behaving slowly (something's gone wrong on that machine to have it behave slowly, not an H2O issue).  My recommendation is to shut down the H2O cluster using 
h2o.shutdown()
, then restart all your nodes, and then re-start the H2O cluster.  That should fix it.",2018-06-12T15:33:42,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",50819691
50917659,50917659,1,"Notice this:




H2O cluster total memory:   0.46 GB 




This is far too little memory for H2O to run.  I recommend nothing less than 5 GB.",2018-06-18T21:22:46,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50819691
50825813,50825813,0,The predictions are meant to run on CPU so you don't need a GPU to actually use the model.,2018-06-12T21:04:29,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50810039
50874444,50874444,1,"I think there may be some confusion here over the general use of weights. 


Here the weighting is applied on a row basis, so cannot be used to up-weight a variable. An example use case might be if we have time-varying data, where we believe that the most recent data is more like future samples than previous data. In this use case, we could up-weight the most recent samples and down weight less recent samples. 


The important point here is that it is a weighting of a sample (and all of its features), not of an individual feature across all samples. 


For your use case, if you have sufficient training data,  it is likely that an appropriate algorithm (GBM/RF) will make use of the feature that you consider to be important. If it does not then this may indicate that the feature you have identified is not as important as you first thought or is highly correlated with another feature.


If you still want to up-weight a feature then a hacky approach to this is to add multiple dummy variables to the data frame for the same feature.",2018-06-15T11:14:03,Sam Abbott,https://stackoverflow.com/users/9295446/sam-abbott,466,50809461
50792568,50792568,1,"RapidMiner has a security feature to prevent the unchecked execution of potentially risky extensions.To still execute your extension, you can check under the setting to give unsigned extensions (those that don't come from the RapidMiner marketplace) to be executed with additional rights.




For more detailed questions I also recommend to post at the 
RapidMiner community
 where a lot of experienced extensions developers can be found.",2018-06-11T07:35:39,David,https://stackoverflow.com/users/4940080/david,792,50755994
50766014,50766014,1,"please see the documentation on how to run H2O on Hadoop:
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html#hadoop-users


as well as this 
presentation


you can think of ""H2O on Hadoop"" as H2O's certified integration for Hadoop. However, you don't need Hadoop to run H2O in a multi-node environment, you could always do this manually if you wanted to.",2018-06-08T17:48:32,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50753130
50765012,50765012,0,"I tested out the special character issue from the post you specified, using the corresponding 
Jira Ticket
 code snippet. I was 
not
 able to reproduce an issue; the rendering of the character is correct, for both version 3.18.0.11 and 3.18.0.08. I used Mac OS X El Capitan, with R version 3.4.2. 


To install version 3.18.0.11, first make sure h2o isn't running somewhere then run the following code found in h2o's download instructions


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

Next, we download packages that H2O depends on.
pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/11/R"")



If you want to downgrade to 3.18.08, shutdown h2o, shutdown R and then rerun the above but specify the link for 3.18.08 
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/8/R"").",2018-06-08T16:37:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50749961
50766049,50766049,0,"So this ended up being a case of too hasty to post on SO




Using maven or SBT's transitive dependency exclusion doesn't work




ended up not being true. I simply needed to refresh SBT one time more.


I'll leave this question up though for reference. mvnrepository.com might indicate that this is a pom dependency and you should include the dependency like  


libraryDependencies += ""ai.h2o"" % ""h2o-genmodel"" % ""3.18.0.11"" % ""runtime"" pomOnly()



or 


<dependency>
    <groupId>ai.h2o</groupId>
    <artifactId>h2o-genmodel</artifactId>
    <version>3.18.0.11</version>
    <type>pom</type>
    <scope>runtime</scope>
</dependency>



but it seems from experimentation that that does not work, and 
hex.genmodel...
 packages will not be available


To get the dependencies working and not pull in the slf4j binding you should use


libraryDependencies += ""ai.h2o"" % ""h2o-genmodel"" % ""3.18.0.11"" exclude(""org.slf4j"", ""slf4j-log4j12"")



or


<dependency>
    <groupId>ai.h2o</groupId>
    <artifactId>h2o-genmodel</artifactId>
    <version>3.18.0.11</version>
    <exclusions>
        <exclusion>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
        </exclusion>
    </exclusions>
</dependency>",2018-06-08T17:51:48,kag0,https://stackoverflow.com/users/2133111/kag0,"6,014",50749476
50757881,50757881,0,"h2o-genmodel
 it's a pom type dependency. That means you use it as an aggregator for multiple dependencies to make your life easier. Your problem arise from the fact that the 
ai.h2o:deepwater-backend-api:jar:1.0.4
 dependency of 
h2o-genmodel
 has a transient dependency to 
org.slf4j:slf4j-log4j12:jar:1.7.5
. You can debug the dependency hierarchy by using the dependency maven plugin, run the following command:


> mvn dependency:tree
...
[INFO] \- ai.h2o:h2o-genmodel:pom:3.18.0.11
[INFO]    +- net.sf.opencsv:opencsv:jar:2.3
[INFO]    +- com.google.code.gson:gson:jar:2.6.2
[INFO]    +- com.google.protobuf.nano:protobuf-javanano:jar:3.1.0
[INFO]    \- ai.h2o:deepwater-backend-api:jar:1.0.4
[INFO]       \- org.slf4j:slf4j-log4j12:jar:1.7.5
[INFO]          +- org.slf4j:slf4j-api:jar:1.7.5
[INFO]          \- log4j:log4j:jar:1.2.17



To fix this, you can exclude the 
slf4j-log4j12
 dependency from 
h2o-genmodel
 dependency with this:


    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-genmodel</artifactId>
        <version>3.18.0.11</version>
        <type>pom</type>
        <exclusions>
            <exclusion>
                <groupId>org.slf4j</groupId>
                <artifactId>slf4j-log4j12</artifactId>
            </exclusion>
        </exclusions>
    </dependency>



You can run again the maven dependency tree command to check how many slf4j bindings remained.


Because the error complains of multiple slf4j bindings I assume once you make sure there is only one slf4j binding in the dependency tree everything will be fine at runtime.


UPDATE:


More details why this solution works:

First, the 
ai.h2o:h2o-genmodel
 dependency is declared as type pom is because this is how it is published. A maven artefact of type pom is used in two cases: as an aggregator for submodules or as an aggregator for dependencies. In this case, the pom type is used in second scenario, to pack dependencies for 
ai.h2o:h2o-genmodel
. To varify this, you can check your maven local repository (most likely at ${user.home}/.m2/repository/ai/h2o/h2o-genmodel/3.18.0.11 there is no jar file, only the .pom. Please read this documentation 
Introduction to the Dependency Mechanism
 and 
POM Relationships


Another issue, might be the fact that 
ai.h2o:h2o-genmodel
 doesn't adhere to recommended way to wrap dependencies because it doesn't use 
<dependencyManagement>
, but instead is using 
<dependencies>
. Because of this, the details on maven documentation is not working exactly as expected. To overcome this, you have to use 
ai.h2o:h2o-genmodel
 explicitly on 
<dependencies>
 and adjust manually the scope of each dependency behind it. I strongly suggest to run the 
mvn dependency:tree
 because will display the scope of each dependency. In my output I removed the scopes because I didn't want it to polute the answer.  


In conclusion, why in my solution works with dependency declared as pom and in @kag0 not as pom is because the 
ai.h2o:h2o-genmodel
 is of type pom and maven treat it in same way becaue when the 
<type>
 is missing it infers it from the artefact pom.",2018-06-08T09:49:32,,,,50749476
50744752,50744752,7,"you can use H2O's random forest (
H2ORandomForestEstimator
), set 
ntrees=1
 so that it only builds one tree, set 
mtries
 to the number of features (i.e. columns) you have in your dataset and 
sample_rate =1
. Setting 
mtries
 to the number of features in your dataset means the algo will randomly sample from all of your features at each level in the decision tree. 


here is more information about 
mtries
:
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/mtries.html",2018-06-07T15:13:54,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50740316
53599554,53599554,3,"To add to Lauren's answer: based on 
PUBDEV-4324 - Expose Decision Tree as a stand-alone algo in H2O
 both DRF and GBM can do the job with GBM being marginally easier:


titanic_1tree = h2o.gbm(x = predictors, y = response, 
                        training_frame = titanicHex,
                        ntrees = 1, min_rows = 1, sample_rate = 1,            
                        col_sample_rate = 1,
                        max_depth = 5,
                        seed = 1)



which creates a decision tree maximum 5 splits deep (max_depth = 5) on titanic dataset (available here: 
https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv
)


Starting with release 3.22.0.1 (Xia) it's possible to extract tree structures from H2O models:


titanicH2oTree = h2o.getModelTree(model = titanic_1tree, tree_number = 1)",2018-12-03T18:17:28,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,50740316
50739411,50739411,3,No. The biggest bottleneck is IO and that’s handled by the CPU.,2018-06-07T10:53:30,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,50738058
50740467,50740467,0,"The latest h2o-genmodel.jar will work with all MOJO files. (Note that this is not the case for POJOs or with early versions of the h2o-genmodel.jar.)


I can update the documentation to include this clarification.",2018-06-07T11:49:34,Angela Bartz,https://stackoverflow.com/users/9908630/angela-bartz,16,50727029
50697824,50697824,1,"One simplest way to solve this is, when you convet pandas frame to H2OFrame use argument 
column_types
 ,as below:


In [69]: col_types
Out[69]: ['categorical', 'categorical', 'categorical', 'categorical']

In [70]: h2o_frame = h2o.H2OFrame(df,column_types=col_types);h2o_frame ;h2o_frame.types ;h2o_frame
Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%
Out[70]: 
datetime             month    time      weekend
-------------------  -------  --------  ---------
2016-12-17 00:00:00  月       00:00:30  周六

[1 row x 4 columns]


In [71]: dff = h2o_frame.as_data_frame();dff
Out[71]: 
              datetime month      time weekend
0  2016-12-17 00:00:00     月  00:00:30      周六",2018-06-05T10:26:37,Henry Ecker,https://stackoverflow.com/users/15497888/henry-ecker,35.5k,50696160
71963331,71963331,0,"allfiles = h2o.import_file(path='data/', pattern="".csv"")
df = allfiles.as_data_frame()
df['datetime'] = pd.to_datetime(df[""datetime""], unit='ms')",2022-04-22T03:59:09,user1098761,https://stackoverflow.com/users/1098761/user1098761,579,50696160
50645249,50645249,0,"You don't need to pickle it, h2o provides its own persistence methods: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html


# build the model
model = H2ODeepLearningEstimator(params)
model.train(params)

# save the model
model_path = h2o.save_model(model=model, path=""/tmp/mymodel"", force=True)

print(model_path)
# outputs: /tmp/mymodel/DeepLearning_model_python_1441838096933

# load the model
saved_model = h2o.load_model(model_path)



be warned though, persisted models are 
NOT
 compatible between even the most minor version changes i.e. if you train and save a model in 3.18.0.1 you won't be able to load it in 3.18.0.2",2018-06-01T14:06:13,Dan,https://stackoverflow.com/users/1011724/dan,45.7k,50642358
50627227,50627227,1,"What you see is the expected behavior from H2O.


H2O just uses YARN to get containers for the H2O worker nodes to run.  Once those containers are up, H2O has CPU and memory resources to work, and doesn't interact with YARN anymore.  So the YARN Resource Manager knows that H2O is up, like you see, but doesn't know any details.


To see details, go to the H2O Flow Web UI (as directed in the ""Open H2O Flow"" message in the output above).  The Admin->Jobs menu item shows you what you are looking for.",2018-05-31T14:56:16,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50625442
50611180,50611180,3,"The 
h2o.importFile()
 function does not support loading only a subset of the columns.  Here are some work-arounds:




Load in the entire dataset and use the 
x
 argument in any modeling function to ignore certain columns.  
fit <- h2o.gbm(x = good_cols, y = y, training_frame = train)
 


Load in the entire dataset and then create a new H2OFrame which only contains the columns you want.  
newdf <- df[, good_cols]


Create a copy of your data on disk that contains only the columns you want.  This is easy to do using the 
cut
 tool (
example here
).  
cut -d, -f2-4,6-10 train.csv > newtrain.csv",2018-05-30T18:19:21,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",50607610
50608965,50608965,1,"you can specify how you would like NAs to be interpreted with the 
na.strings
 parameter in 
h2o.importFile()
 which by default is 
NULL
 (and is likely the reason your blanks are getting converted to NAs).


more details on the documentation of 
h2o.importFile()
 can be found here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.importFile.html",2018-05-30T15:54:40,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50601823
50726540,50726540,1,"It looks like this could be a bug. A jira ticket has been created for this issue, you can track it here: 
https://0xdata.atlassian.net/browse/PUBDEV-5454?filter=-1
.",2018-06-06T17:46:28,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50581125
50568859,50568859,1,"Enum (aka factor, aka categorical) in H2O are not ordinal.


So it's not possible to do comparisons in this way.


If you really want to do this, I recommend duplicating the column so that the original remains a factor and the duplicate is an integer.",2018-05-28T14:45:06,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50534675
50533542,50533542,0,"After finding out about the backend json data, I was able to find this:


variable_importances = model._model_json['output']['coefficients_table'].as_data_frame()",2018-05-25T16:35:41,Nate Thompson,https://stackoverflow.com/users/4008123/nate-thompson,635,50533113
50476348,50476348,5,"The function you're looking for is called 
h2o.relevel()
.  The 
h2o.setLevels()
 function only allows you to change the names of the levels, but 
h2o.relevel()
 will allow you to change the order of the levels.


EDIT:
Here's an example.


> hf <- as.h2o(iris)
> h2o.levels(hf['Species'])
[1] ""setosa""     ""versicolor"" ""virginica"" 
> hf['Species'] <- h2o.relevel(hf['Species'], y = ""virginica"")
> h2o.levels(hf['Species'])
[1] ""virginica""  ""setosa""     ""versicolor""",2018-05-22T20:57:16,,,,50476210
50476292,50476292,0,"I don't know what H2O is, but in general


df$x <- factor(df$x, levels = c(""1"", ""2"", ""3"", ""4"", ""5"")) 



would work",2018-05-22T20:52:49,kintany,https://stackoverflow.com/users/2907560/kintany,531,50476210
51622533,51622533,3,"H2O's 
h2o.predict()
 does not provide predictions for the OOB data. You have to specify what dataset you want to predict with the 
newdata =
 parameter. So when you have 
newdata=d.h2o
 then you are getting the predictions for the 
d.h2o
 dataframe you've specified. 


Currently there is no method to get the prediction for the oob data. However, there is a 
jira ticket
 to specify whether you would like oob metrics (note this ticket also links to another ticket which helps clarify how training metrics are currently being reported for Random Forest).",2018-07-31T21:42:48,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50458586
50450760,50450760,1,"H2O-3 MOJO/POJOs are row-based.  The EasyPredictModelWrapper is a convenient wrapper for making row-based predictions.


If you want to make more than one prediction, then using a for-loop is a fine answer.


Even if sometime in the future the API expands to accept some kind of frame, it won't do anything different than the for-loop would.


(Note that this should not be confused with Driverless AI MOJOs, which are not interchangeable and do have some different properties.)






I'm less sure about the underlying model implementation: the MojoFrame and FrameBuilder classes tend to imply that it's supported within DriverlessAI, which may or may not use the same MOJO. 




Despite sharing a common name of MOJO, H2O-3 MOJOs and Driverless AI MOJOs are different implementations and not interchangeable.


MOJO-ness qualities that they share are:




the resulting artifact doesn't need to be compiled (unlike the H2O-3 POJO, which is Java code)


a java runtime is supported


low latency, so suited for real-time applications


works efficiently on one row at a time, so suited for streaming applications




Driverless AI MOJOs include feature engineering transformations as well as a predictive model.






My question is: how can I pass a dataframe to a generated model object? I've gone over the source in the h2o-3 repo




You can't with the current H2O-3 MOJO API.  The H2O-3 MOJO API is a row-based API.  One could, of course, extend the API to do some kind of for-loop approach.






Now I want to use a more sophisticated model that considers all the rows simultaneously




I don't know what ""considers all the rows simultaneously"" means.  This isn't what the H2O-3 MOJO API or EasyPredictModelWrapper do.  The underlying math is row-by-row.  Even if you put a convenience function around the math to take a frame of values, it would still calculate the results row-by-row, with the individual rows calculated one-by-one in isolation in a theoretically embarrassingly parallel way using a simple for loop, or some other fancy way if you needed parallelism for speed.


In the H2O-3 MOJO API, the result calculated for row N has no impact on the result calculated for rows N-1 or N+1 (or, more generally, the result for any row other than N).


(Note that for Driverless AI MOJOs, since feature engineering is incorporated, it is possible the above row-by-row discussion may be different.  A good example is time-series windowing calculations.  Such a discussion is beyond the scope of this question and answer, but worth pointing out in this context.)",2018-05-21T14:12:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50447863
50472868,50472868,0,"Found the issue. I was using Spark 2.1 (Auto updating, Scala 2.11) cluster. But I should use cluster Spark 2.1.X-dbx (you must use a Spark 2.1 version and Scala 2.11) when working with H2O Sparkling water.",2018-05-22T16:53:57,Marvania Mehul,https://stackoverflow.com/users/5378027/marvania-mehul,165,50416866
53795115,53795115,1,"A sample python implementation could be found here:

https://gist.github.com/ahmedengu/e2cbc2d937e48de3f43b3c903d656143


https://dzone.com/articles/visualizing-h2o-gbm-and-random-forest-mojo-models


# save model to mojo and view it as an image
# R code sample and more information available here: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html#viewing-a-mojo-model
# another python example could be found here: https://dzone.com/articles/visualizing-h2o-gbm-and-random-forest-mojo-models

model = aml.leader # the model that we want to plot it can be any h2o model as long as it's not a StackedEnsemble model
model_path = model.download_mojo(get_genmodel_jar=True)

# download h2o jar 
!wget -c http://h2o-release.s3.amazonaws.com/h2o/rel-xia/2/h2o-3.22.0.2.zip
!unzip -n h2o-3.22.0.2.zip 

!java -cp h2o-3.22.0.2/h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i $model_path -o model.gv -f 20 -d 3
!dot -Tpng model.gv -o model.png

from IPython.display import display
from PIL import Image

# showing the image in notebook
display(Image.open('model.png'))",2018-12-15T16:34:35,ahmedengu,https://stackoverflow.com/users/2254875/ahmedengu,103,50407731
50416990,50416990,0,"Yes.


From this documentation:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo




The following code snippet shows how to download a MOJO from R and run the PrintMojo tool on the command line to make a .png file:


library(h2o)
h2o.init()
df <- h2o.importFile(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"")
model <- h2o.gbm(model_id = ""model"",
                 training_frame = df,
                 x = c(""Year"", ""Month"", ""DayofMonth"", ""DayOfWeek"", ""UniqueCarrier""),
                 y = ""IsDepDelayed"",
                 max_depth = 3,
                 ntrees = 5)
h2o.download_mojo(model, getwd(), FALSE)

# Now download the latest stable h2o release from http://www.h2o.ai/download/
# and run the PrintMojo tool from the command line.
#
# (For MacOS: brew install graphviz)
# java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i model.zip -o model.gv
# dot -Tpng model.gv -o model.png
# open model.png",2018-05-18T18:04:24,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50407731
50401234,50401234,5,"For logistic regression either the POJO or MOJO will be fine.  Prefer the MOJO for better backwards-compatibility properties.


For Random Forest of depth more than about 6, definitely use the MOJO.  Really big (for example 1 GB of java code or more) RF models won't even compile.


MOJOs don't need to be compiled, which is very convenient, and for really deep trees they run faster and have very consistent run times.",2018-05-17T22:16:45,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50400887
50436089,50436089,5,"The critical thing to understand here is whether you really want to train a model in your application, or do you just want to score a model.  Most people initially will just want to score a model.


SCORING


Scoring is easy and natural.  See the MOJO and POJO javadoc api here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




Follow the pattern shown in the javadoc to use the Easy API.  A snippet of the relevant code is included below:


EasyPredictModelWrapper model = new EasyPredictModelWrapper(MojoModel.load(""GBM_model.zip""));
RowData row = new RowData();
row.put(""AGE"", ""68"");
...
BinomialModelPrediction p = model.predictBinomial(row);



SCORING AND SAVING FOR DEFERRED TRAINING


What many people will do is score in their live application, and also save new data (somewhere) for deferred training.  Then train models offline and push them into production again for scoring.  This is a pretty typical model lifecycle which is easy to understand and manage.


TRAINING


Embedding H2O inside your application for actual training is more involved.


If I were going to embed H2O, I would do it one of two ways:


Well-supported option 1
. Start an H2O instance as a separate process (or set of processes in the distributed case) and communicate with it using R or Python.


The well documented APIs for H2O are the R API and the Python API.  (There is also a REST API with lots of generated documentation, but I would not consider that particularly easy to use.)


You will find lots of documentation and examples at:




http://docs.h2o.ai




Well-supported Option 2
.  Write a Spark application and use Sparkling Water and Scala or PySparkling and Python.


This doesn't actually require much Spark, since the embedded H2O inside Sparkling Water doesn't actually rely on the Spark side at all.  The Scala and Python APIs for Sparkling Water are well-documented.  The Sparkling Water User Guide is a good place to start for this:




http://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/index.html




... And then here are other options which are harder:


(Harder) Option 3
.  You can include H2O as a maven dependency and call it directly from Java.


The biggest problem here is Java API is not well documented, and you won't find friendly examples for how to use it.  The best documentation for the Java API is source code itself, and the unit tests (search for 'test' directories) inside the h2o-3 project github here:




https://github.com/h2oai/h2o-3




(Harder) Option 4
.  Some people have called H2O directly from the REST API.


I wouldn't recommend this because it's difficult, but if you want to try, the best way to learn how to use the REST API is to turn on logging from R and look at the message payloads between the R client and H2O:


# R program.
h2o.init()
h2o.startLogging()
h2o.importFile(""test.csv"")
...",2018-05-20T14:55:41,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50377307
50384449,50384449,1,"I found a better solution using modulo :


data.hex = h2o.importFile(filetoload, sep = "","" )
date.hex = data.hex[,3] 

#Number of minutes since the begining of Hour
#Divide by 1000 to work with seconds and Extract minutes + seconds
#Remove seconds and format in minutes
minu.hex = ((date.hex/1000)%%(60*60))%/%60",2018-05-17T06:09:42,,,,50367769
50377200,50377200,0,"This repo might be helpful for you. 
https://github.com/h2oai/h2o-kubeflow
. 
Basically, for k8s, create a docker image, make a deployment on k8s with proper specifications. If you use the steps in the above repo, make sure to have the proper RBAC authorizations.",2018-05-16T17:50:41,Nicholas Png,https://stackoverflow.com/users/9801753/nicholas-png,36,50361561
50282635,50282635,0,"What is the difference between the Dockerfile_runtime, and Dockerfile-build-centos.x86-64-centos7-cuda9.0? 




The 
build
 dockerfiles (we have 2) are intended to only contain things required to build the project, whereas the runtime one also contains stuff required by the project during runtime, adds some sample data and starts a Jupyter notebook. The Centos one was added as the binaries generated by the Ubuntu image cannot run on quite a few Linux distros easily (due to high glibc version used by Ubuntu). We have a PR which rewrites all our dockers as Centos based but still need to test it more before merging.




but is there a preferred one to use?




For building the 
whl
 either 
Dockerfile-build
 or the Centos one are ok. If you want a runtime docker then 
Dockefile-runtime
 is prefered.




After building the Centos Dockerfile




How are you building it? You can have a look at our docker building scripts how we do it 
https://github.com/h2oai/h2o4gpu/blob/master/scripts/make-docker-runtime.sh
 There should be no need to add that 
run.sh
 file as it's being copied in the dockerfile. The Centos docker file does not start Jupyter, expose 8888 nor contain 
run.sh
.",2018-05-10T22:56:00,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,50278965
50274655,50274655,1,"Your problem is mentioned in the last line


localhost/127.0.0.1 some of the required ports 54321, 54322 are not available, 
change -port PORT and try again. ""localhost"" 54321 FALSE 502



It says, ""some of the required ports 54321, 54322 are not available"". Check and make sure those ports are available


If you can't free them for any reason, you can always start  on a different port using the port argument in h2o.init().


see 
here",2018-05-10T13:58:04,A.A.,https://stackoverflow.com/users/5091507/a-a,"1,047",50274481
50268767,50268767,0,"In the sparkling water document:

http://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/requirements.html


Sparkling Water 2.1.27 is ok with jdk 1.7, but it only work successfully with jdk 1.8.",2018-05-10T08:36:52,liyuhui,https://stackoverflow.com/users/7124383/liyuhui,"1,250",50267961
50443354,50443354,0,"this was a known bug and it's already fixed on the latest Sparkling Water for Spark 2.1, 2.2 and 2.3. You can download Sparkling Water from 
https://www.h2o.ai/download/",2018-05-21T06:43:43,,,,50267961
50261540,50261540,1,"your encoding choice should work, though you may want to update to the latest stable release of H2O. Here is a code snippet you can run that works, and test if it works for you. If it works then you can try and pinpoint the difference between your previous code and the example below.


import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator
h2o.init()

# import the airlines dataset:
# This dataset is used to classify whether a flight will be delayed 'YES' or not ""NO""
# original data can be found at http://www.transtats.bts.gov/
airlines= h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"")

# convert columns to factors
airlines[""Year""]= airlines[""Year""].asfactor()
airlines[""Month""]= airlines[""Month""].asfactor()
airlines[""DayOfWeek""] = airlines[""DayOfWeek""].asfactor()

# set the predictor names and the response column name
predictors = [""Origin"", ""Dest"", ""Year"", ""DayOfWeek"", ""Month"", ""Distance""]
response = ""IsDepDelayed""

# split into train and validation sets
train, valid= airlines.split_frame(ratios = [.8], seed = 1234)

# try using the `categorical_encoding` parameter:
encoding = ""one_hot_explicit""

# initialize the estimator
airlines_gbm = H2OGradientBoostingEstimator(categorical_encoding = encoding, seed =1234)

# then train the model
airlines_gbm.train(x = predictors, y = response, training_frame = train, validation_frame = valid)

# print the auc for the validation set
airlines_gbm.auc(valid=True)",2018-05-09T20:29:27,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50254178
50237057,50237057,0,"The relevant message is coming from here:




https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/water/init/NetworkInit.java#L121




This is a very unusual message/error.


Each H2O node tries to open a port for the embedded HTTP server.  The first attempted port is the baseport, and if that fails, then H2O tries increasing the number in a loop until it goes past port number 64K and then gives up with the message you reported.


You will have to ask your system admin why ports cannot be opened.


Note you can change the starting baseport with the 
-baseport
 option.",2018-05-08T15:19:46,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50227205
50163583,50163583,5,"If you want to create a copy of a dataframe you can use 
h2o.deep_copy(data, xid)
. (where xid is the string id you give for the backend H2OFrame)


if you have a dataframe df and you do 


old_df = df
new_df = df



both old_df and new_df will point to the same h2oframe (df) in the backend, so any change made to old_df will be reflected in new_df.


if you want to keep changes separate you can do:


new_df = h2o.deep_copy(df, 'new_df')",2018-05-03T20:44:14,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50162987
50165313,50165313,0,"Use the -network option.


Here is the help output for the -network option:


-network <IPv4network1Specification>[,<IPv4network2Specification> ...]
      The IP address discovery code will bind to the first interface
      that matches one of the networks in the comma-separated list.
      Use instead of -ip when a broad range of addresses is legal.
      (Example network specification: '10.1.2.0/24' allows 256 legal
      possibilities.)



Provide the proper specification for the interface that you want the Flow Web UI to bind to.


For example:


hadoop jar h2odriver.jar -nodes 1 -mapperXmx 6g -network 10.1.2.0/24 -output h2otmp/junk001",2018-05-03T23:58:20,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",50141622
40536323,40536323,27,"From one hand, a machine learning model built with spark can't be served the way you serve in Azure ML or Amazon ML in a traditional manner. 


Databricks claims to be able to deploy models using it's notebook but I haven't actually tried that yet. 


On other hand, you can use a model in three ways :




Training on the fly inside an application then applying prediction. This can be done in a spark application or a notebook. 


Train a model and save it if it implements an 
MLWriter
 then load in an application or a notebook and run it against your data. 


Train a model with Spark and export it to PMML format using 
jpmml-spark
. PMML allows for different statistical and data mining tools to speak the same language. In this way, a predictive solution can be easily moved among tools and applications without the need for custom coding. e.g from Spark ML to R.




Those are the three possible ways. 


Of course, you can think of an architecture in which you have RESTful service behind which you can build using spark-jobserver per example to train and deploy but needs some development. It's not a out-of-the-box solution. 


You might also use projects like Oryx 2 to create your full lambda architecture to train, deploy and serve a model.


Unfortunately, describing each of the mentioned above solution is quite broad and doesn't fit in the scope of SO.",2016-11-10T20:20:00,,,,50127250
49781272,49781272,16,"One option is to use 
MLeap
 to serve a Spark PipelineModel online with 
no dependencies on Spark/SparkContext
. Not having to use the SparkContext is important as it will drop scoring time for a single record from ~100ms to 
single-digit microseconds
.


In order to use it, you have to:




Serialize your Spark Model with MLeap utilities


Load the model in MLeap (does not require a SparkContext or any Spark dependencies)


Create your input record in JSON (not a DataFrame)


Score your record with MLeap




MLeap is well integrated with all the Pipeline Stages available in Spark MLlib (with the exception of LDA at the time of this writing). However, things might get a bit more complicated if you are using custom Estimators/Transformers.


Take a look at the 
MLeap FAQ
 for more info about custom transformers/estimators, performances, and integration.",2018-04-11T17:33:36,Neil McGuigan,https://stackoverflow.com/users/223478/neil-mcguigan,48.1k,50127250
40536304,40536304,4,"You are comparing two rather different things. Apache Spark is a computation engine, while mentioned by you Amazon and Microsoft solutions are offering services. These services might as well have Spark with MLlib behind the scene. They save you from the trouble building a web service yourself, but you pay extra.


Number of companies, like Domino Data Lab, Cloudera or IBM offer products that you can deploy on your own Spark cluster and easily build service around your models (with various degrees of flexibility).


Naturally you build a service yourself with various open source tools. Which specifically? It all depends on what you are after. How user should interact with the model? Should there be some sort of UI or jest a REST API? Do you need to change some parameters on the model or the model itself? Are the jobs more of a batch or real-time nature? You can naturally build all-in-one solution, but that's going to be a huge effort.


My personal recommendation would be to take advantage, if you can, of one of the available services from Amazon, Google, Microsoft or whatever. Need on-premises deployment? Check Domino Data Lab, their product is mature and allows easy working with models (from building till deployment). Cloudera is more focused on cluster computing (including Spark), but it will take a while before they have something mature.


[EDIT] I'd recommend to have a look at 
Apache PredictionIO
, open source machine learning server  - amazing project with lot's of potential.",2016-11-10T20:18:19,,,,50127250
55739029,55739029,0,"I have been able to just get this to work. Caveats: Python 3.6 + using Spark ML API (not MLLIB, but sure it should work the same way)


Basically, follow this example provided on 
MSFT's AzureML github
.


Word of warning: the code as-is will provision but there is an error in the example 
run()
 method at the end:


        #Get each scored result
        preds = [str(x['prediction']) for x in predictions]
        result = "","".join(preds)
        # you can return any data type as long as it is JSON-serializable
        return result.tolist()



Should be:


        #Get each scored result
        preds = [str(x['prediction']) for x in predictions]
        #result = "","".join(preds)
        # you can return any data type as long as it is JSON-serializable
        output = dict()
        output['predictions'] = preds
        return json.dumps(output)



Also, completely agree with MLeap assessment answer, this can make the process run way faster but thought I would answer the question specifically",2019-04-18T04:12:11,JW_,https://stackoverflow.com/users/6770896/jw,176,50127250
56498825,56498825,0,"I had a similar problem.

Fixed it by uninstalling Java version 12 and installing Java version 8.

Then it worked perfectly.

Apparently Java 12 is not supported.",2019-06-07T17:25:29,Sander van den Oord,https://stackoverflow.com/users/3489155/sander-van-den-oord,12.7k,50115886
51546282,51546282,2,"It turns out to be quite tricky, but you can get the dynamic column name to be evaluated by using 
call()
. So, to follow on from your example:


var <- ""dist""
eval(call(""h2o.arrange"",df,var))



Gives:


  speed dist
1     4    2
2     7    4
3     4   10
4     9   10



Then:


var <- ""speed""
eval(call(""h2o.arrange"",df,var))



Gives:


  speed dist
1     4    2
2     4   10
3     7    4
4     7   22



(I'd love to say that was the first thing I thought of, but it was more like experiment number 54! I was about halfway down 
http://adv-r.had.co.nz/Expressions.html
  There might be other, better ways, to achieve the same thing.)


By the way, another approach to achieve the same result is:


var = 1
h2o:::.newExpr(""sort"", df, var)



and


var = 0
h2o:::.newExpr(""sort"", df, var)



respectively. I.e. The 3rd argument is the zero-based index of the column. You can get 
that
 with 
match(var, names(df)) - 1
. By this point you've implemented 75% of 
h2o.arrange()
.


(Remember that any time you end up using 
h2o:::
 you are taking the risk that it will not work in some future version of H2O.)",2018-07-26T19:32:07,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,50093334
50052695,50052695,3,"You have various problems. 


H2O currently does not support Java 10 (that you are using). You need to use Java 8 or Java 7.


Supported versions include: Java 7 or later. 
Note: Java 9 is released, but is not currently supported. 
Java 9 support will be added in an upcoming version.
h2o website


For 
rJava
 on Mac I send you to 

Loading rJava on Mac OS High Sierra


I am running h2o on a mac with high sierra (and rJava, for a different project) with R v. 3.4.4 and 
Java 8
. All good.",2018-04-26T22:25:57,,,,50052656
50030391,50030391,2,"There currently isn't a clean way to do this. An alternative method, which doesn't require calculating a max but is still clunk to do is 
model.summary()['number_of_trees'][0]
 if you want the number, 
model.summary()['number_of_trees']
 if you want the number in a list. Or just 
model.summary()
 if you just want to see the number.",2018-04-25T19:57:45,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",50027950
50007888,50007888,5,"actually just figured this out myself (assuming 
aml
 is the h2o automl object after training):



for m in aml.leaderboard.as_data_frame()['model_id']:
    print(m)
    print(h2o.get_model(m))",2018-04-24T17:46:15,slowD,https://stackoverflow.com/users/2177373/slowd,339,50007751
52771844,52771844,4,"You can also grab the corresponding model you're interested in using the following line:


model6 = h2o.get_model(aml.leaderboard.as_data_frame()['model_id'][6])


where 6 is the index number of the model in the leaderboard.",2018-10-12T03:31:22,Nev,https://stackoverflow.com/users/4321512/nev,117,50007751
50827864,50827864,2,"If you run H2O AutoML subsequent times on the same training set, by default, it will add more models to the leaderboard (because the auto-generated 
project_name
 will be identical).


The way to get separate leaderboards is to pass a unique value to the 
project_name
 argument for each execution of 
h2o.automl()
.  An easy thing to use for a 
project_name
 is 
Sys.time()
 wrapped in an 
as.character()
 since it should be unique each time you run it.  If you have unique names for your datasets, you could use that instead.  Example below.


for (df in dfs){

#run auto for each data frames and name it as id
assign(sprintf(""aml_%s"", df_id[count]) , h2o.automl(x = x,
         y = y,
         training_frame = df,
         max_models = 5,
         project_name = as.character(Sys.time())))

 #increase iterator
 count = count + 1

}",2018-06-13T01:18:02,,,,49985533
49980598,49980598,4,"Definitely possible. If the best fitting model that AutoML has selected is not an ensemble then you can use the following to plot the variable importances (where model is your 
model
 extracted from AutoML), 


library(h2o)
h2o.varimp_plot(model)



If the best fitting model is an ensemble then things are a little more complicated. A good option is to use the 
lime
 package to look at local importance.


 library(h2o)
 library(lime)

 ## Train explainer
 explainer <- lime(train, model)

 ## Get explanations for a subset of samples
 explanation <- explain(train[1:5, ], explainer, n_features = 10)

 ## Plot global explanations
 plot_explanations(explanation)

 ## Plot local explanations
 plot_features(explanation)",2018-04-23T12:00:33,Sam Abbott,https://stackoverflow.com/users/9295446/sam-abbott,466,49980180
49940418,49940418,0,"When using H2O with Python, it uses a client-server architecture where Python is the client and H2O is the server.


The REST API for H2O is exposed via the web port you mention, so you cannot just disable it.


However if you look at the following documentation, there are options for securing it, including authentication and HTTPS:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/security.html",2018-04-20T11:15:23,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49932493
49921563,49921563,1,"It looks like guys from H2O didn't hear about logging module: 
https://github.com/h2oai/h2o-3/blob/master/h2o-py/h2o/model/metrics_base.py#L669
... They are happily print messages instead of use proper logging. It's sad.",2018-04-19T12:49:40,omikron,https://stackoverflow.com/users/719457/omikron,"2,815",49920880
49926150,49926150,0,"According to the 
H2O Glossary
, the format for 
beta_constraints
 is:




A data.frame or H2OParsedData object with the columns [“names”,
  “lower_bounds”,”upper_bounds”, “beta_given”], where each row
  corresponds to a predictor in the GLM. “names” contains the predictor
  names, “lower_bounds” and “upper_bounds” are the lower and upper
  bounds of beta, and “beta_given” is some supplied starting values for
  beta.




First, you need to get the vector of betas from Model 2. Call them 
m2_betas
.


Next, because you want strict equality constraints, you need to and set those to the upper bounds, lower bounds, 
and
 starting value. 


I have done this in R (see 
related answer
), where 
beta_constraints
 are passed as a 
data.frame
 but I assume that the Python API is similar and uses a 
pandas.DataFrame
. Try:


constraints = pd.DataFrame({'names':x.columns, 
                             'lower_bounds':m2_betas, 
                             'upper_bounds':m2_betas, 
                             'beta_given':m2_betas})",2018-04-19T16:40:15,C8H10N4O2,https://stackoverflow.com/users/2573061/c8h10n4o2,18.9k,49909866
49911695,49911695,0,"Can the containers ping each others ip?


When launching h2o are you forcing the interface to use the container ip?
java -jar h2o.jar -flatfile flatfile -ip  -port 


Are these docker containers when run exposing the port 54321 to each other?
docker run -it -p 54321:54321",2018-04-19T02:17:06,Jeff,https://stackoverflow.com/users/8721385/jeff,1,49907249
49955204,49955204,0,"As of the current version of H2O (3.18.0.8) what you can do is:


1) Put the list of EC2 instance private IP and port in the flatfile:


private-ip-1:54321
private-ip-2:54321
private-ip-3:54321



private-ip-1 should be in the standard four octet a.b.c.d network address form. 


2) provide the 
--network host
 option to docker run:


docker run --network host [... rest of run command ...]





If you don't do this, what I think is happening is that each local H2O instance gets confused trying to figure out which node in the flatfile is itself.  Since none of the local interfaces match what's in the flatfile, the cluster formation doesn't work for whatever reason.


I would actually consider this a bug.",2018-04-21T11:18:24,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49907249
56385552,56385552,0,"Ultimately, the solution for running H2O in docker may be to use a network plugin like 
weave
, because weave can use multicasting (unlike docker overlay). 


But I managed to hack together a solution for running H2O in docker swarm on an overlay network and a flatfile. The issue with running in swarm is that docker assigns each H2O instance two IP addresses: one resolvable as the stack_service and the other seen as $HOSTNAME from within the instance. H2O needs to use the $HOSTNAME IP, but it is difficult to determine this IP in advance for the flatfile. So instead, pass a config file with the stack_service names and then change them to IP addresses using a script before launching H2O in each instance. 


So, for example, use a docker-compose file that defines three services:


services:
  h2o_worker1:
    image: [h2o image]
    configs:
      - source: flatfile
        target: /flatfile
    deploy:
      placement:
        constraints:
          - node.hostname == [node1]
    ... 
  h2o_worker2:
    image: [h2o image]
    configs:
      - source: flatfile
        target: /flatfile
    deploy:
      placement:
        constraints:
          - node.hostname == [node1]
    ... 
  h2o_worker3:
    image: [h2o image]
    configs:
      - source: flatfile
        target: /flatfile
    deploy:
      placement:
        constraints:
          - node.hostname == [node1]
    ... 

##### Configs #####
configs:
  flatfile:
    file: flatfile



Where ... is other docker compose parameters you need to enter, and [] represents things you need to define for your setup.


Now create a flatfile based on the service names that will be imported by the config:


h2o_worker1:54321
h2o_worker2:54321
h2o_worker3:54321



Obviously, change the ports if necessary. Then use an entrypoint script to lookup each service name's IP, and then add 1 to get the $HOSTNAME IP for each service. I just use sleep here to make sure all the services have started so that the IP lookup works. Docker always appears to assign the two IPS per service sequentially, but YMMV. As I said, this is a hack and probably not a great production-level solution. My entrypoint script looks something like this:


echo ""Moving flatfile to ${H2O_HOME}""
cp /flatfile ${H2O_HOME}

sleep 60
echo ""Replacing hostnames in flatfile with IP addresses.""
grep -o -P '.*(?=:)' ${H2O_HOME}/flatfile > ${H2O_HOME}/hostnames
grep -o -P '(?<=:).*' ${H2O_HOME}/flatfile > ${H2O_HOME}/ports
dig +short $(cat ${H2O_HOME}/hostnames) > ${H2O_HOME}/hostnames_ip
cat ${H2O_HOME}/hostnames_ip | awk -F""."" '{printf ""%d.%d.%d.%d\n"", $1, $2, $3, $4 + 1}' > ${H2O_HOME}/new_ips
paste -d "":"" ${H2O_HOME}/new_ips ${H2O_HOME}/ports > ${H2O_HOME}/new_flatfile

echo ""Starting H2O...""
bash -c ""java -Xmx${H2O_NODE_MEMORY:-1g} -jar ${H2O_HOME}/h2o.jar -flatfile ${H2O_HOME}/new_flatfile""



The key here is using dig to retrieve the IP addresses for each service host, and then incrementing by one to get the secondary address that we need to pass to H2O. Note I  define an environment variable in my Dockerfile so I can vary the node memory in the docker compose file. You don't need to do that. And the Dockerfile also sets a variable for the install location for H2O, to simplify things. 


This lets me deploy the containers using docker swarm, and H2O in fact finds all the nodes correctly. Because H2O does not permit additions or deletions of nodes after the initial setup, it is not a big deal (at least for me) to define most of this in advance. That said, I may yet try to move to weave or another network plugin that avoids some of these issues.",2019-05-30T20:58:31,caewok,https://stackoverflow.com/users/5786863/caewok,91,49907249
49897558,49897558,1,"No, H2O does not require you to convert all numerical values to categorical values.


If you want to view how trained H2O DRF models treat the different input columns, follow the instructions below for how to view a MOJO.




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo




Note in the picture below that numerical columns are treated with a ""less than"" value comparison, and categorical columns are treated by sending some of the levels to the left child and some to the right child.",2018-04-18T10:35:42,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49895721
49898753,49898753,0,"To build the project, you can follow this recipe:


git clone https://github.com/h2oai/h2o4gpu.git
cd h2o4gpu
make centos7_cuda9_in_docker



This will work on either an x86_64 or ppc64le host with a modern docker installed.
The python .whl file artifact is written to the 
dist
 directory.


Even if the build process is significantly refactored, this style of build API is very likely to remain.",2018-04-18T11:37:26,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49885093
49988208,49988208,5,"There is no need to merge the models. Unlike with boosting methods, every tree in a Random Forest is grown independently (just don't set the same seed prior to kicking off RF on each node!).


You are basically doing what Random Forest does on its own, which is to grow X independent trees and then average across the votes. Many packages provide an option to specify the number of cores or threads, in order to take advantage of this feature of RF.


In your case, since you have the same number of trees per node, you'll get 4 ""models"" back, but those are really just collections of 16 trees. To use it, I'd just keep the 4 models separate and when you want a prediction, average the prediction from each of the 4 models. Assuming you're going to be doing that more than once, you could write a small wrapper function to predict with the 4 models and average the output.",2018-04-23T19:02:50,Tchotchke,https://stackoverflow.com/users/2442196/tchotchke,"3,121",49866372
49898554,49898554,1,"10,000 rows by 1,000 columns is not overly large and should not take that long to train an RF model.


It sound like something unexpected is happening.


While you can try to average models if you know what you are doing, I don't think it should be necessary in this case.",2018-04-18T11:26:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49866372
49865810,49865810,4,"1) The .zip file is the model artifact and metadata itself.
The h2o-genmodel.jar is the execution runtime used to make predictions with the model.


2) The latest h2o-genmodel.jar can be used for all current and older mojo .zip models.


For MOJOs, you only need one current h2o-genmodel.jar.",2018-04-16T20:35:41,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49864021
49825349,49825349,1,"There is no out-of-the-box solution yet in open source h2o-3, but there are many examples of how to do this available. Here are the repos/notebooks:




https://github.com/jphall663/interpretable_machine_learning_with_python

/ 
https://github.com/jphall663/interpretable_machine_learning_with_python/blob/master/lime.ipynb


https://github.com/h2oai/mli-resources
 /

https://github.com/h2oai/mli-resources/blob/master/notebooks/lime.ipynb


https://content.oreilly.com/oriole/Interpretable-machine-learning-with-Python-XGBoost-and-H2O

/ 
https://content.oreilly.com/oriole/Interpretable-machine-learning-with-Python-XGBoost-and-H2O/blob/master/lime.ipynb




There is also some chance Marco Tulio's original LIME package will
work: 
https://github.com/marcotcr/lime
, be sure to look into this example: 
https://marcotcr.github.io/lime/tutorials/Tutorial_H2O_continuous_and_cat.html",2018-04-13T21:27:27,,,,49824276
49910070,49910070,3,"Yes, there is. See the H2OFrame doc here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html#h2oframe


You just need to use the 
column_types
 argument when you cast.


Here's a short example:


# imports
import h2o
import numpy as np
import pandas as pd

# create small random pandas df
df = pd.DataFrame(np.random.randint(0,10,size=(10, 2)), 
columns=list('AB'))
print(df)

#   A  B
#0  5  0
#1  1  3
#2  4  8
#3  3  9
# ...

# start h2o, convert pandas frame to H2OFrame
# use column_types dict to set data types
h2o.init()
h2o_df = h2o.H2OFrame(df, column_types={'A':'numeric', 'B':'enum'})
h2o_df.describe() # you should now see the desired data types 

#       A   B
# type int enum
# ...",2018-04-18T22:40:32,ph_,https://stackoverflow.com/users/2735828/ph,71,49823178
74661061,74661061,0,"# Filter a dictionary to keep elements only whose keys are even
newDict = filterTheDict(dictOfNames, lambda elem : elem[0] % 2 == 0)
print('Filtered Dictionary : ')
print(newDict)`enter code here`",2022-12-02T20:16:17,pubg pubg1,https://stackoverflow.com/users/20669869/pubg-pubg1,1,49823178
49800614,49800614,0,"options(java.parameters = ""- Xmx2400m"")



It looks like there is an extra space between ""- X"".
Remove it.",2018-04-12T15:35:24,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49780303
49779746,49779746,2,"Ok, think I solved this for myself. Sparkling Water allocates resources based on a number of settings which are non-default in Google DataProc.


I edited 
/etc/spark/conf/spark-defaults.conf
, and changed 
spark.dynamicAllocation.enabled
 to 
false
 and changed 
spark.ext.h2o.dummy.rdd.mul.factor
 to 
1
, which allowed the H2O cluster to start up in about 3 minutes with about a tenth of the resources.


If it is too slow starting up for you, try reducing 
spark.executor.instances
 from 
10000
 to 
5000
 or 
1000
, although this settings affects the performance of everything else you're running on the Spark cluster.",2018-04-11T16:03:35,cybermaggedon,https://stackoverflow.com/users/9630329/cybermaggedon,31,49774823
49778031,49778031,1,You're getting java.lang.OutOfMemoryError.  Give more memory.,2018-04-11T14:41:41,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49774823
51889351,51889351,1,The only time I've seen this happen is when H2O runs out of memory.  Please check that you have enough memory -- an H2O cluster should have at least 4x the amount of RAM as the dataset you're trying to train a model on (data size on disk).,2018-08-17T06:12:08,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49773582
49753780,49753780,7,"H2o xgboost is not currently supported in Windows.


Please see the attached screenshot from the latest docs page for h2o xgboost.",2018-04-10T12:32:43,George,https://stackoverflow.com/users/6510824/george,684,49752125
49777984,49777984,5,"You can vote for this feature here on github:


https://github.com/h2oai/h2o4gpu/issues/517",2018-04-11T14:39:13,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49752125
62964355,62964355,0,"XGBoost
 is not supported on 
Windows
.




The list of limitations include:




XGBoost is not supported on 
Windows
.


The list of supported platforms includes: Linux or OS X






When I met same issue I open my 
COLAB
 account and I try there. It did work for me.",2020-07-18T03:36:08,H.Elci,https://stackoverflow.com/users/13471621/h-elci,226,49752125
50687849,50687849,2,"You could try using try-catch to prevent that error message. This is how I initialize from my local machine:


  # Try to connect to existing cluster. If it does not exist then initialize.
  errorStatus <- tryCatch({
    h2o.init(startH2O = FALSE)
  }, error = function(err) {
    errorStatus <- err[1]$message
    message(paste0(errorStatus,""\n Initializing new H2O cluster...""))
    # Inititialize H2o cluster
    try({h2o.shutdown(prompt = FALSE)}, silent=TRUE)
    h2o.init(ip = 'localhost', port = 54321, nthreads= -1, max_mem_size = '4g')
    return(errorStatus)
  }) # END tryCatch

  # Shut down H2O cluster on app exit
  onStop(function() {
    try({h2o.shutdown(prompt = FALSE)}, silent=TRUE)
  })",2018-06-04T19:51:23,Javier Recasens,https://stackoverflow.com/users/8034372/javier-recasens,41,49716815
49721669,49721669,1,"When you get the error ""There is no H2O instance running"" it really means there is nothing to shut down so in your case it's not an error. Of course, you should test that by logging into your R-Server and when you get the error checking if the h2o process running or not:


ps -eaf | grep h2o



The method using 
global.R
 is completely legitimate for Shiny app. 


UPDATE:
Beware that if you run multiple Shiny apps each of them may start their own h2o instance, or they may share the same instance and run into conflicts. So test this in advance not to run into unexpected conflicts/errors/",2018-04-08T19:06:17,,,,49716815
49712644,49712644,0,"Just as the comment of @Goyo said, you need to import the 
matplotlib.pyplot
 where you call 
plot()
 method, and you can 
savefig
 there. It seems like that without return it is still possible, so I guess the info is shared between ""inside"" and ""outside"", i.e., they are ""static"" saying in the Java way.




At last I have to modify the source code, forcing it to return 
plt
 when 
server is True
, then I call 
plot(type=""roc"", server=True)
 from outside. I think it has no impact because before the change, by default it returns 
None
.


if not server: 
    plt.show()
else:
    return plt # return to use plt.savefig",2018-04-07T22:37:53,,,,49712632
49729650,49729650,1,"You're using:


 normalize = function(x) {(((x-min(x))/(max(x)-min(x))) - 0.5)}



They are using 
this Java code
:


 normMul[idx] = (v.max() - v.min() > 0)?1.0/(v.max() - v.min()):1.0;
 normSub[idx] = v.mean();



And then it is used 
like this
:


numVals[i] = (numVals[i] - normSub[i])*normMul[i];



I.e. subtract the mean, then divide by the range (or, equivalently, multiply by 1 over the range). So, ignoring the check for divide-by-zero, I think your R code needs to be:


 normalize = function(x) {(x-mean(x))/(max(x)-min(x))}



With the check for zero, something like:


 normalize = function(x) {mul=max(x)-min(x);if(mul==0)mul=1;return((x-mean(x))/mul)}



Just playing around with that, it seems to have a range of 1.0, but it is not centred around 0.0, i.e. it is not the -0.5 to +0.5 described in the H2O documentation (e.g. p.20 in deep learning booklet). Did I miss something in the Java code?


By the way 
this line
 is where it decides to NORMALIZE for auto-encoders, rather than STANDARDIZE for other deep learning.",2018-04-09T09:27:04,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49711455
49778204,49778204,1,"is whether Sparkling Water runs the H2O algorithms in a distributed manner and utilizes the available cluster resources




Yes.


Sparkling Water embeds H2O nodes within Spark executors.  So a Sparkling Water job will train H2O models in the exact same way that core H2O-3 does (with no Spark in the picture).


An H2O cluster does not like nodes to join or leave once running, so you must set the spark dynamicAllocation property to disabled.


There is 
no performance improvement or reduction
 from the Spark-ness of Sparkling Water.  Rather, it is a friendly way to introduce H2O machine learning models into a Spark environment or pipeline.


Here is a pointer to the Sparkling Water design documentation, which has a picture illustrating the above - 
http://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/design/design.html
.",2018-04-11T14:48:48,Marek Grzenkowicz,https://stackoverflow.com/users/95/marek-grzenkowicz,17.3k,49692830
49681471,49681471,2,"I did find people commenting about H2O. I also reached out to a vendor and asked him for a solution, he suggested Sparkly but you need Hadoop layer in your server to run Sparkly. 




Your vendor is mistaken; you don't need a Hadoop layer for 
sparklyr
 / 
RSparkling
, just Spark.


However, you could also just skip the Spark layer and use H2O directly.  That's the best option, and given my experience, I think your hardware is sufficient to train an 
H2O GBM
 on 10M rows.  Here's an 
H2O R tutorial
 that shows how to perform a grid search for GBM. When you start H2O, just make sure to increase the memory from the default 4G:


h2o.init(max_mem_size = ""48G"")



H2O also supports 
XGBoost
, an alternative GBM implementation, so that's another option.",2018-04-05T21:02:01,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49681116
49671699,49671699,1,"Is there any example that explains sparkling water using spark structured streaming with streaming source?




There isn't. Generic purpose transformations, including conversion to RDDs and external formats, are not supported in Structured Streaming.",2018-04-05T11:51:47,user9602094,https://stackoverflow.com/users/9602094/user9602094,11,49671640
49644917,49644917,6,"Think of 
as.h2o()
 as a convenience function, that does these steps:




converts your R data to a data.frame, if not already one.


saves that data.frame to a temp file on local disk (it will use 
data.table::fwrite()
 if available (*), otherwise 
write.csv()
)


call 
h2o.uploadFile()
 on that temp file


delete the temp file




As your updates say, writing huge data files to disk can take a while. But the other pain point here is using 
h2o.uploadFile()
 instead of the quicker 
h2o.importFile()
. The decision of which to use is visibility:




With 
h2o.uploadFile()
 your client has to be able to see the file.


With 
h2o.importFile()
 your cluster has to be able to see the file.




When your client is running on the same machine as one of your cluster nodes, your data file is visible to both client and cluster, so always prefer 
h2o.importFile()
. (It does a multi-threaded import.)


Another couple of tips: only bring data into the R session that you actually need there. And remember both R and H2O are column-oriented, so cbind can be quick. If you just need to process 100 of your 2300 columns in R, have them in one csv file, and keep the other 2200 columns in another csv file. Then 
h2o.cbind()
 them after loading each into H2O.


*: Use 
h2o:::as.h2o.data.frame
 (without parentheses) to see the actual code. For data.table writing you need to first do 
options(h2o.use.data.table = TRUE)
; you can also optionally switch it on/off with the 
h2o.fwrite
 option.",2018-04-04T07:13:11,,,,49634547
49613432,49613432,2,"If the training time is the main effort, and you have enough memory, then the speed up will be proportional to cores times core-speed. So, you might have expected a 40/14 = 2.85 speed-up (i.e. your 24hrs coming down to the 8-10 hour range).


There is a typo in your h2o.init(): 
96
 should be 
""96g""
. However, I think that was a typo when writing the question, as 
h2o.init()
 would return an error message. (And H2O would fail to start if you'd tried 
""96""
, with the quotes but without the ""g"".)


You didn't show your 
h2o.deeplearning()
 command, but I am guessing you are using early stopping. And that can be unpredictable. So, what might have happened is that your first 24hr run did, say, 1000 epochs, but your second 17hr run did 2000 epochs. (1000 vs. 2000 would be quite an extreme difference, though.)


It might be that you are spending too much time scoring. If you've not touched the defaults, this is unlikely. But you could experiment with 
train_samples_per_iteration
 (e.g. set it to 10 times the number of your training rows).




What can I do to achieve substantial speed-up?




Stop using cross-validation. That might be a bit controversial, but personally I think 80,000 training rows is going to be enough to do an 80%/10%/10% split into train/valid/test. That will be 5-10 times quicker.


If it is for a paper, and you want to show more confidence in the results, once you have your final model, and you've checked that test score is close to valid score, then rebuild it a couple of times using a different seed for the 80/10/10 split, and confirm you end up with the same metrics. (*)


*: By the way, take a look at the score for each of the 10 cv models you've already made; if they are fairly close to each other, then this approach should work well. If they are all over the place, you might have to re-consider the train/valid/test splits - or just think about what it is in your data that might be causing that sensitivity.",2018-04-02T14:46:10,,,,49592926
49551210,49551210,2,"To get a handle to an H2O frame called ""xxx"":


data <- h2o.getFrame(""xxx"")



If you also need that data in your R session (which you don't if you are just going to be using it to train models, make predictions on, etc.) then you follow it with:


df <- as.data.frame(data)



(Nothing special about the 
data
 and 
df
 naming.)",2018-03-29T08:22:00,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49535272
49521432,49521432,0,"The solution is actually explained in the 
getMojoModel
 (which accepts either a 
Model[_,_,_]
 or 
Array[Byte]
) on 
ModelSerializationSupport
 


The implementation of 
getMojoModel(Model[_,_,_])
 uses a byte array to store 
getMojoData(Model[_,_,_])
 to, and then reads it back from that byte array.


Quick test as follows works:


val config = new EasyPredictModelWrapper.Config()
config.setModel(ModelSerializationSupport.getMojoModel(gbmModel))
config.setConvertUnknownCategoricalLevelsToNa(true)
val easyPredictModelWrapper = new EasyPredictModelWrapper(config)



Thus now we can reproduce it, on our own, but without using the 
ModelSerializationSupport
 class (as it is part of sparkling water).


First store the mojo data to a file:


val path = java.nio.file.Files.createTempFile(""model"", "".mojo"")
path.toFile.deleteOnExit()
path.toString
import java.io.FileOutputStream
val outputStream = new FileOutputStream(path.toFile)
try {
  gbmModel.getMojo.writeTo(outputStream
}
finally if (outputStream != null) outputStream.close()



And then read the bytes (in another scala application):


val is = new FileInputStream(path.toFile)
val reader = MojoReaderBackendFactory.createReaderBackend(is, MojoReaderBackendFactory.CachingStrategy.MEMORY)
val mojoModel = ModelMojoReader.readFrom(reader)
val config = new EasyPredictModelWrapper.Config()
config.setModel(mojoModel)
config.setConvertUnknownCategoricalLevelsToNa(true)
val easyPredictModelWrapper = new EasyPredictModelWrapper(config)",2018-03-27T19:56:32,gerben,https://stackoverflow.com/users/691415/gerben,702,49515618
49510911,49510911,2,"This has nothing to do with H2O.


The clue here is the message ""PBS: job killed"".


A small amount of internet searching here suggests that you are somehow using the PBS scheduler (
https://en.wikipedia.org/wiki/Portable_Batch_System
) and this is killing your job.  (I've never actually seen anybody use PBS before, but this all seems pretty likely based on the information above.)


Since PBS is telling you your limit is 32 cores, I suggest you try specifying a value less than that.  Maybe with 
h2o.init(nthreads=30)
 PBS won't kill your process anymore.",2018-03-27T10:48:34,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49510134
49510720,49510720,4,"H2O-3 is a client-server architecture.  The H2O Flow Web UI, the R session, the Python session are all clients.  The H2O java process is the server.


Often, the client and server are often running on the same host (for example, in the case where h2o is started with h2o.init()), and in those situations it can be hard to tell the difference between the client and the server.  But when you start a multi-node H2O job on Hadoop and connect to it explicitly from an R session using an IP address, the client and server separation becomes quite obvious to the user.


So with that as background:




h2o.download_mojo() is the client pulling the mojo artifact, and storing it to the client filesystem


h2o.saveMojo() is the server pushing the mojo artifact, either to the server filesystem or to a network filesystem (e.g. HDFS)",2018-03-27T10:38:55,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49508870
49507985,49507985,0,"The learning is narrowing in on the best set of weights, and sometimes overshoots. Though, as you say, your chart is quite noisy.


When you say your network is 43-8-1, do you mean you gave 
hidden
 as [43,8,1], or you gave hidden as [8] ?


If the former, remember that H2O tries to be helpful, so the output layer (1 neuron as you are doing a regression) and input layer (43 neurons, if all data is numeric, otherwise more) are created for you.


If the latter, 
[2]
 and 
[8]
 are very low numbers, possibly too few (and too few layers) for it to be effective (depending on your data of course).


Whether the former, or the latter, did you try more neurons? E.g. the default of 
[200,200]
? It will obviously take more time to do each epoch, but is the scoring history smoother now?


I can imagine how only having a few neurons can make the training score get quite jumpy.


But if that isn't it, I've seen noisy scoring history charts when hitting numeric instability. So you could try switching from Rectifier to Tanh.


More generally, it is worth building the all-defaults model first, as a baseline to compare to; in particular I'd avoid touching rho, learning rate, momentum, etc. H2O does a good job of choosing defaults for them.",2018-03-27T08:32:47,,,,49506194
49742372,49742372,0,"I am responsible for that threshold. I developed it by running numerous datasets -- artificial and real -- through the k-means algorithm. I began some years ago working with SSW improvement and testing it as a chi-square variable, as recommended by John Hartigan. This criterion failed in a number of instances, so I switched to PRE. The equation above is the result of fitting a nonlinear model to results on datasets with a known number of clusters. When I wrote the k-means program for Tableau, I used this same PRE criterion. After I left Tableau for H2O, they substituted the Calinski-Harabasz index for my PRE rule, producing similar results. 
Leland Wilkinson, Chief Scientist, H2O.",2018-04-09T22:04:44,user1010628,https://stackoverflow.com/users/1010628/user1010628,36,49493980
49547009,49547009,3,"If I am understanding your question correctly, I think you are looking for something like the code below. Does this meet your needs? 


airlinesGroupBy <- function(by)
{
  do.call(h2o.group_by,
          list(data = airlines.hex, 
               by = by, 
               call(""nrow"", by), 
               call(""min"", by), 
               call(""max"", by), 
               gb.control = list(na.methods = ""rm"")))
}
airlinesGroupBy(""Origin"")",2018-03-29T02:20:10,Patrick Aboyoun,https://stackoverflow.com/users/9567228/patrick-aboyoun,46,49467713
49487038,49487038,0,"To answer your main question, use 
add()
:


val predFrame = gbmModel.predict(dataFrame)
dataAndPredFrame = dataFrame.add(predFrame)



(Shamelessly stolen from 
https://github.com/h2oai/sparkling-water/issues/194
 )


merge()
 is like an SQL join, and is for when you have two data frames of different sizes; the arguments you are asking about are used to specify which columns in each of the two frames need to match for the join to happen.


I cannot seem to find any sparkling water documentation for it (please post in the comments if anyone knows where it is!), but you can get the idea from looking at the R or Python API docs: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/merging-data.html",2018-03-26T08:28:11,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49448791
68535685,68535685,0,"I don't believe that h2o maintains the original row order as state above.  I've used h2o.cbind to merge the original data set with the predictions.  Then, using the actual response values against the predicted values, I reconstructed the confusion matrix.  Unfortunately, it had very different counts from the confusion matrix produced by the model.  If the rows in the original data set had the same order, the confusion matrix counts should be the same both inside the R script as well outside.",2021-07-26T19:52:37,Timothy Fisher,https://stackoverflow.com/users/16496273/timothy-fisher,13,49448791
49439559,49439559,0,"Pass the following arguments on the command line:


--conf spark.ext.h2o.client.port.base=26000
--conf spark.ext.h2o.node.port.base=26005",2018-03-22T22:37:36,user9537361,https://stackoverflow.com/users/9537361/user9537361,11,49439094
49496106,49496106,0,"Sparkling Water is tight to Spark cluster. If you want to be able to run multiple Sparkling Water clusters(H2OContext), then you need to create multiple separated Spark Clusters first",2018-03-26T16:18:44,,,,49439094
49454846,49454846,1,"Yes, as stated in the 
K-Means documentation
, it uses Euclidean distance.


If you can provide a reproducible example showing that this is a bug, please file a 
bug report
.  Thanks!",2018-03-23T16:57:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49431314
49414799,49414799,2,"It could be that the the 
cbind
 is only binding the last run element, basically, resulting in two 'x2' columns and by making it unique the column names could have changed to 'x20'.  One approach would be to assign it to a 
list
 and then 
cbind
.  


#initialize a `list` of length 2 
lst <- vector(""list"", 2)

for (i in 1:2) {
  #create the h2o dataset and assign it to each list element      
  lst[[i]] <- as.h2o(data.frame(x=c(1*i, 2*i, 3*i)))
  #change the column names of the h2o dataset
  names(lst[[i]]) <- paste0(""x"", i)        
}

#do the cbind outside the loop
do.call(h2o.cbind, c(df1.hex, lst))
#  y x1 x2
#1 A  1  2
#2 B  2  4
#3 C  3  6

#[3 rows x 3 columns] 





Or this can be done in pipe (
%>%
) with 
tidyverse
 function


library(tidyverse)
map(1:2, ~ tibble(x = (1:3) * .x) %>% 
                set_names(., paste0(""x"", .x)) %>% 
                as.h2o) %>%
         append(df1.hex, .) %>%
         do.call(h2o.cbind, .)
#   y x1 x2
#1 A  1  2
#2 B  2  4
#3 C  3  6

#[3 rows x 3 columns]",2018-03-21T19:12:09,,,,49414212
49426732,49426732,2,"Ok. I was able to resolve the issue. 


I just replaced the following code in my original post: 


  df1.hex = h2o.cbind(df1.hex, df2.hex) # Append x(i) to df1.hex data frame



with this...


  x.hex = h2o.cbind(df1.hex, df2.hex)
  df1.hex = h2o.assign(x.hex, 'df1')



I am not sure, but it may have something to do with how h2o stores data internally. 


The full code is shown below: 


# Let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()

# Initialize a data frame with a column 'y'
df1 = data.frame(y=c('A', 'B', 'C'))
df1.hex = as.h2o(df1)
print(df1.hex)

# Need to append additional columns to df1.hex named x1, x2 etc...
for (i in 1:2) {
  df2 = data.frame(x=c(1*i, 2*i, 3*i))
  colnames(df2) = c(paste(""x"", i, sep='')) # x1, x2 etc...
  df2.hex = as.h2o(df2)
  print(paste(""Iteration: "", i, "": Adding df2.hex..."", sep=''))
  print(df2.hex)
  # df1.hex = h2o.cbind(df1.hex, df2.hex) # Append x(i) to df1.hex data frame
  x.hex = h2o.cbind(df1.hex, df2.hex)
  df1.hex = h2o.assign(x.hex, 'df1')
}

print(""The final dataset df1.hex: "")
print(df1.hex)

h2o.shutdown(prompt=FALSE)



Now, I do get the desired output: 


> print(""The final dataset df1.hex: "")
[1] ""The final dataset df1.hex: ""
> print(df1.hex)
  y x1 x2
1 A  1  2
2 B  2  4
3 C  3  6

[3 rows x 3 columns] 
> 



Cheers!


Karthik",2018-03-22T10:49:41,Karthik,https://stackoverflow.com/users/211082/karthik,769,49414212
49415285,49415285,2,"This is not a Shiny issue.  The error indicates that you're trying to use 
toJSON()
 on an H2OFrame (instead of an R data.frame), which will not work because the 
jsonlite
 library does not support that.


Instead you can convert the H2OFrame to a data.frame using:


dataInput <- toJSON(as.data.frame(dataInput))



I can't guarantee that 
toJSON()
 will generate the correct input for  
h2o.predict_json()
 since I have not tried that, so you will have to try it out yourself. Note that the only way this may work is if this is a 1-row data.frame because the 
h2o.predict_json()
 function expects a single row of data, encoded as JSON. If you're trying to score multiple records, you'd have to loop over the rows.  If for some reason 
toJSON()
 doesn't give you the right format, then you can use a function I wrote in this post 
here
 to create the JSON string from a data.frame manually.


There is a 
ticket open
 to create a better version of 
h2o.predict_json()
 that will support making predictions from a MOJO on data frames (with multiple rows) without having to convert to JSON first.  This will make it so you can avoid dealing with JSON altogether.


An alternative is to use a 
H2O binary model
 instead of a MOJO, along with the standard 
predict()
 function.  The only requirement here is that the model must be loaded into H2O cluster memory.",2018-03-21T19:44:46,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49411393
49780374,49780374,0,"The following works now using the json formatting from first two lines and the single quote around var with spaces.


df<- data.frameV1=1,V2=1,CMPNY_EL_IND=1,UW_REGION_NAME = ""'LONDON & SE'"" )
    dfstr <- sapply(1:ncol(df), function(i) paste(paste0('\""', names(df)[i], '\""'), df[1,i], sep = ':'))
    json <- paste0('{', paste0(dfstr, collapse = ','), '}')
    dataPredict <- as.data.frame(h2o.predict_json(model = ""D:\\GBM_model_0_CMP.zip"", json = json, genmodelpath = ""D:\\h2o-genmodel.jar"", labels = TRUE))",2018-04-11T16:38:18,Siobhan,https://stackoverflow.com/users/9099971/siobhan,173,49411393
49511236,49511236,0,"Start your job in yarn-cluster mode.  This will make the driver run as another YARN container.


Here is another stackoverflow post describing the difference:




Spark yarn cluster vs client - how to choose which one to use?",2018-03-27T11:04:16,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49403802
49394307,49394307,3,"The right way to do it is to use the H2OFrame 
apply()
 function, however, this produces the same error that @MKR mentioned.  I have created a JIRA ticket 
here
.


In theory, this should work:


data.hex[,cols] <- apply(X = data.hex[,cols], MARGIN = 2, FUN = as.factor)



For now, the workaround is:


for (col in cols) {
  data.hex[col] <- as.factor(data.hex[col])
}",2018-03-20T21:20:52,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49393343
49394009,49394009,1,"I think you are referring to this 
known bug
 which is causing NaNs in the leaderboard in non-US locales.  It has been fixed on the 
nightly releases
, so feel free to download one of those, or you can wait until the next stable release of H2O (3.18.0.5 will be released next week).


If this is not the same bug, please provide more info, including a reproducible example.",2018-03-20T20:59:00,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49391938
49356186,49356186,1,"All you are missing is 
h2oContext's implicits
 as


import h2oContext.implicits._
val h2oResponse: H2OFrame = response.toDF()",2018-03-19T05:13:19,Ramesh Maharjan,https://stackoverflow.com/users/5880706/ramesh-maharjan,41.9k,49353079
55430322,55430322,2,"You have to use: 


list(range(...))


instead of: 


range(...) --> 'max_depth' : list(range(2,10)) etc.",2019-03-30T10:05:26,CAPSLOCK,https://stackoverflow.com/users/3284713/capslock,"6,473",49347630
49334850,49334850,2,"Troubleshooting Tip: build the all-defaults model first:


mDef = h2o.glm(predictors, response, allyears2k.hex, family=""binomial"")



This takes 2 seconds and gives almotst exactly the same AUC and confusion matrix as in your Flow screenshots.


So, we now know the problem you see is due to all the model customization you have done...


...except when I build your 
fit1
 I get basically the same results as my default model:


         NO   YES    Error          Rate
NO     4276 16611 0.795279  =16611/20887
YES    1573 21518 0.068122   =1573/23091
Totals 5849 38129 0.413479  =18184/43978



This was using your script exactly as given, so it fetched the remote csv file. (Oh, I removed the max_mem_size argument, as I don't have 12g on this notebook!)


Assuming you can get exactly your posted results, running exactly the code you posted (and in a fresh R session, with a newly started H2O cluster), one possible explanation is you are using 3.19.x, but the latest stable release is 3.18.0.2? (My test was with 3.14.0.1)",2018-03-17T10:21:06,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49319432
49397294,49397294,0,"Finally, I guess this is the explanation: both have the same parameter configuration for building the model (that is not the problem), but the H2o flow uses a specific parsing customization converting some variables values into 
Enum
, that the R-script did not specify. 


The Airlines Delay problem how it was specified in the h2o Flow example uses as predictor variables (the flow defines the ignored_columns): 


""Year"", ""Month"", ""DayOfWeek"", ""UniqueCarrier"", 
   ""FlightNum"", ""Origin"", ""Dest"", ""Distance""



Where all of the predictors should be parsed as: 
Enum
 except 
Distance
. Therefore the R-Script needs to convert such columns from 
numeric
 or 
char
 into 
factor
.


Executing using h2o R-package


Here the R-Script updated:


library(h2o)
h2o.init(max_mem_size = ""12g"", nthreads = -1) # To use avaliable cores

IS_LOCAL_FILE    = switch(2, FALSE, TRUE)
IS_DEFAULT_MODEL = switch(2, FALSE, TRUE)
if (IS_LOCAL_FILE) {
    data.input <- read.csv(file = ""allyears2k.csv"", stringsAsFactors = T)
    allyears2k.hex <- as.h2o(data.input, destination_frame = ""allyears2k.hex"")
} else {
    airlinesPath <- ""https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv""
    allyears2k.hex <- h2o.importFile(path = airlinesPath, destination_frame = ""allyears2k.hex"")
}

response <- ""IsDepDelayed""
predictors <- setdiff(names(allyears2k.hex), response)

# Copied and pasted from the flow, then converting to R syntax
predictors.exc = c(""DayofMonth"", ""DepTime"", ""CRSDepTime"", 
    ""ArrTime"", ""CRSArrTime"",
    ""TailNum"", ""ActualElapsedTime"", ""CRSElapsedTime"",
    ""AirTime"", ""ArrDelay"", ""DepDelay"", ""TaxiIn"", ""TaxiOut"",
    ""Cancelled"", ""CancellationCode"", ""Diverted"", ""CarrierDelay"",
    ""WeatherDelay"", ""NASDelay"", ""SecurityDelay"", ""LateAircraftDelay"",
    ""IsArrDelayed"")

predictors <- setdiff(predictors, predictors.exc)
column.asFactor <- c(""Year"", ""Month"", ""DayofMonth"", ""DayOfWeek"", 
    ""UniqueCarrier"",  ""FlightNum"", ""Origin"", ""Dest"", response)
# Coercing as factor (equivalent to Enum from h2o Flow)
# Note: Using lapply does not work, see the answer of this question
# https://stackoverflow.com/questions/49393343/how-to-coerce-multiple-columns-to-factors-at-once-for-h2oframe-object
for (col in column.asFactor) {
    allyears2k.hex[col] <- as.factor(allyears2k.hex[col])
}

if (IS_DEFAULT_MODEL) {
    fit1 <- h2o.glm(x = predictors, y = response, 
       training_frame = allyears2k.hex,
       family = ""binomial"", seed = 123456
    )
} else { # Copied and pasted from the flow, then converting to R syntax
    fit1 <- h2o.glm(
        x = predictors,
        model_id = ""glm_model"", seed = 123456, 
        training_frame = allyears2k.hex,
        ignore_const_cols = T, y = response,
        family = ""binomial"", solver = ""IRLSM"",
        alpha = 0.5, lambda = 0.00001, lambda_search = F, standardize = T,
        non_negative = F, score_each_iteration = F,
        max_iterations = -1, link = ""family_default"", intercept = T,
        objective_epsilon = 0.00001,
        beta_epsilon = 0.0001, gradient_epsilon = 0.0001, prior = -1,
        max_active_predictors = -1
    )
}

# Analysis
print(""Confusion Matrix for training dataset"")
confMatrix <- h2o.confusionMatrix(fit1)
print(confMatrix)
print(summary(fit1))
h2o.shutdown()



Here the result running the R-Script under default configuraiton 
IS_DEFAULT_MODEL=T
:


H2OBinomialMetrics: glm
** Reported on training data. **

MSE:                   0.2001145
RMSE:                  0.4473416
LogLoss:               0.5845852
Mean Per-Class Error:  0.3343562
AUC:                   0.7570867
Gini:                  0.5141734
R^2:                   0.1975266
Residual Deviance:     51417.77
AIC:                   52951.77

Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
          NO   YES    Error          Rate
NO     10337 10550 0.505099  =10550/20887
YES     3778 19313 0.163614   =3778/23091
Totals 14115 29863 0.325799  =14328/43978



Executing under h2o flow


Now executing the flow: 
Airlines_Delay_GLMFixedSeed
, we can obtain the same results. Here the detail about the flow configuration:


The 
parseFiles
 function:


parseFiles
  paths: [""https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv""]
  destination_frame: ""allyears2k.hex""
  parse_type: ""CSV""
  separator: 44
  number_columns: 31
  single_quotes: false
  column_names: 
  [""Year"",""Month"",""DayofMonth"",""DayOfWeek"",""DepTime"",""CRSDepTime"",""ArrTime"",
   ""CRSArrTime"",""UniqueCarrier"",""FlightNum"",""TailNum"",""ActualElapsedTime"",
   ""CRSElapsedTime"",""AirTime"",""ArrDelay"",""DepDelay"",""Origin"",""Dest"",
   ""Distance"",""TaxiIn"",""TaxiOut"",""Cancelled"",""CancellationCode"",
   ""Diverted"",""CarrierDelay"",""WeatherDelay"",""NASDelay"",""SecurityDelay"",
   ""LateAircraftDelay"",""IsArrDelayed"",
   ""IsDepDelayed""]
  column_types [""Enum"",""Enum"",""Enum"",""Enum"",""Numeric"",""Numeric"",
   ""Numeric"",""Numeric"", ""Enum"",""Enum"",""Enum"",""Numeric"",
   ""Numeric"", ""Numeric"",""Numeric"",""Numeric"",
   ""Enum"",""Enum"",""Numeric"",""Numeric"",""Numeric"",
   ""Enum"",""Enum"",""Numeric"",""Numeric"",""Numeric"",
   ""Numeric"",""Numeric"",""Numeric"",""Enum"",""Enum""]
  delete_on_done: true
  check_header: 1
  chunk_size: 4194304



where the following predictor columns are converted to 
Enum
: 
""Year"", ""Month"", ""DayOfWeek"", ""UniqueCarrier"", ""FlightNum"", ""Origin"", ""Dest""


Now invoking the 
buildModel
 function as follows, using the default parameters except for 
ignored_columns
 and 
seed
:


 buildModel 'glm', {""model_id"":""glm_model-default"",""seed"":""123456"",
  ""training_frame"":""allyears2k.hex"",
  ""ignored_columns"":[""DayofMonth"",""DepTime"",""CRSDepTime"",""ArrTime"",
  ""CRSArrTime"",""TailNum"",
  ""ActualElapsedTime"",""CRSElapsedTime"",""AirTime"",""ArrDelay"",""DepDelay"",
  ""TaxiIn"",""TaxiOut"",""Cancelled"",""CancellationCode"",""Diverted"",
  ""CarrierDelay"",""WeatherDelay"",""NASDelay"",""SecurityDelay"",
  ""LateAircraftDelay"",""IsArrDelayed""],""response_column"":""IsDepDelayed"",
  ""family"":""binomial""}



and finally we get the following result:




and Training Output Metrics:


model                   glm_model-default
model_checksum          -2438376548367921152
frame                   allyears2k.hex
frame_checksum          -2331137066674151424
description             ·
model_category          Binomial
scoring_time            1521598137667
predictions             ·
MSE                     0.200114
RMSE                    0.447342
nobs                    43978
custom_metric_name      ·
custom_metric_value     0
r2                      0.197527
logloss                 0.584585
AUC                     0.757084
Gini                    0.514168
mean_per_class_error    0.334347
residual_deviance       51417.772427
null_deviance           60855.951538
AIC                     52951.772427
null_degrees_of_freedom 43977
residual_degrees_of_freedom 43211



Comparing both results


The training metrics are almost the same for first 4-significant digits:


                       R-Script   H2o Flow
MSE:                   0.2001145  0.200114
RMSE:                  0.4473416  0.447342
LogLoss:               0.5845852  0.584585
Mean Per-Class Error:  0.3343562  0.334347
AUC:                   0.7570867  0.757084
Gini:                  0.5141734  0.514168
R^2:                   0.1975266  0.197527
Residual Deviance:     51417.77   51417.772427
AIC:                   52951.77   52951.772427



Confusion Matrix is slightly different:


          TP     TN    FP    FN   
R-Script  10337  19313 10550 3778
H2o Flow  10341  19309 10546 3782

          Error
R-Script  0.325799  
H2o Flow  0.3258



My understanding is that the difference are withing the acceptable threshold (around 
0.0001
), therefore we can say that both interfaces provide the same result.",2018-03-21T02:46:52,,,,49319432
49330603,49330603,3,"This inconsistency is an issue that has been documented and explained 
here
 and will be resolved in a future release.  The 
model$cross_validation_metrics_summary
 metrics are the correct CV metrics.  The metrics that appear in the Grid table or by using the utility functions like 
h2o.logloss(model, xval = TRUE)
 are slightly different because they aggregate the CV predictions and then compute the loss (instead of computing the loss separately across K folds and then taking the average).  This can lead to slight numerical differences.",2018-03-16T23:01:42,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49314440
75334817,75334817,0,"I suggest to use the following function


def sort_grid(grid,metric):
#input: grid and metric to order
if metric == 'accuracy':
    id = 0
elif metric == 'auc':
    id = 1
elif metric=='err':
    id = 2
elif metric == 'err_count':
    id=3
elif metric=='f0point5':
    id=4
elif metric=='f1':
    id=5
elif metric =='f2':
    id=6
elif metric =='lift_top_group':
    id=7
elif metric == 'logloss':
    id=8
elif metric == 'max_per_class_error':
    id=9
elif metric == 'mcc':
    metric=9
elif metric =='mena_per_class_accuracy':
    id=10
elif metric == 'mean_per_class_error':
    id=11
elif metric == 'mse':
    id =12
elif metric == 'pr_auc':
    id=13
elif metric == 'precision':
    id=14
elif metric == 'r2':
    id=15
elif metric =='recall':
    id=16
elif metric == 'rmse':
    id = 17
elif metric == 'specificity':
    id = 18
else: 
    return 0

model_ids = []
cross_val_values = []
number_of_models = len(grid.model_ids) 
number_of_models
for i in range(number_of_models):
    modelo_grid = grid[i]
    mean = np.array(modelo_grid.cross_validation_metrics_summary()[[1]])
    cross_val= mean[0][id]
    model_id = grid.model_ids[i]
    model_ids.append(model_id)
    cross_val_values.append(cross_val)

df = pd.DataFrame(
    {'Model_IDs': model_ids, metric: cross_val_values}
)
df = df.sort_values([metric], ascending=False)
best_model = h2o.get_model(df.iloc[0,0])
return df, best_model
#output ordered grid in pandas dataframe and best model",2023-02-03T11:05:57,Tomás Araujo,https://stackoverflow.com/users/13599653/tom%c3%a1s-araujo,15,49314440
49267726,49267726,2,"You're not missing anything.  The 
offset_column
 is available in H2O Random Forest, but it's not actually functional.  The bug is documented 
here
 and should be fixed in the next stable release of H2O.  Sorry about the confusion!


It should work for the rest of the H2O algos (except XGBoost).  If you wanted to try on a GBM, for example, you'd see it working.",2018-03-13T23:53:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49262383
49267663,49267663,2,"Good question -- this is not documented in the parameter description (we use a common definition of 
offset_column
 among all algos and there's no note about how its not working in XGBoost).  It is not functional and you should get an 
error
 if you try to supply it.


R example:


library(h2o)
h2o.init()

fit <- h2o.xgboost(x = 1:3, y = ""Species"", offset_column = ""Petal.Width"",
                   training_frame = as.h2o(iris))



Gives error:


Error: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_model_R_1520909592004_2.  Details: ERRR on field: _offset_column: Offset is not supported for XGBoost.",2018-03-13T23:46:17,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49261738
49226703,49226703,1,"It's not used.  There is no such thing as training and validation metrics in the PCA algorithm and the 
validation_frame
 argument should probably be deprecated.  You can verify this by looking at the validation metrics.


R example:


> library(h2o)
> h2o.init()
> fit <- h2o.prcomp(training_frame = as.h2o(iris), x = 1:5, validation_frame = as.h2o(iris), k = 3)
> fit@model$training_metrics
H2ODimReductionMetrics: pca

No model metrics available for PCA
> fit@model$validation_metrics
H2ODimReductionMetrics: pca

No model metrics available for PCA",2018-03-12T00:51:03,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49211864
49466444,49466444,0,"Here are some things to try:




Increase the timeout with the -timeout option


After increasing the timeout, does it still work sometimes and not other times?  If yes, then you may have a host-level networking issue within your hadoop cluster.


Get 
yarn logs -applicationId nnn
 and look at which of the hosts has the issue.  Is there a pattern in the IP address you can spot?",2018-03-24T15:25:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",49203443
49208353,49208353,1,"I had trouble (e.g. 
https://0xdata.atlassian.net/browse/PUBDEV-3370
 ) getting that approach to ever work. It felt like some kind of global dependency was in there, somewhere.


So, I personally just uninstall, and install the desired version, as I need to move between versions. (Actually, I am more likely to use a different VirtualBox or AWS image for each.)


However I noticed 
searching for conda on the H2O jira
 that there is a lot of activity recently. They might all be pointing out the same bug you have found, but if so it sounds like it is something getting enough attention to get fixed.


Aside:
 finding old versions (and your edit showing install problems)


To find, e.g. 3.14.0.7, google it with ""h2o"". The top hit is 
http://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/7/index.html


The ""rel-weierstrass"" represents 3.14.0, and the 7 is in the URL. (I've yet to see a full list of all the rel-XXX names, but google will always find at least one in the series, even if it won't find the exact minor version.)


Download the zip file you find there. Inside you will find both an R package, and a whl package for Python. So unzip it, extract the one you want, then pip install it.


These zip files are always on S3 (AFAIK). The link you showed was a 
source
 snapshot, on github.",2018-03-10T11:07:47,,,,49199204
49202383,49202383,0,"Install 
requirements
:


pip install requests tabulate numpy scikit-learn



Extract the archive:


zcat h2o-3-jenkins-rel-weierstrass-7.tar.gz | tar xvf -



cd
 into 
Python directory
 and build:


cd h2o-py
../gradlew build",2018-03-09T21:27:17,phd,https://stackoverflow.com/users/7976758/phd,92.8k,49199204
52874993,52874993,0,"I have this working now. I think the trick is to make sure you do NOT have h2o installed on your base python. I did the following:


pip uninstall h2o
conda create --name h2o-base pip
conda activate h2o-base
conda install numpy
conda install pandas
conda install requests
conda install tabulate
conda install colorama
conda install future
conda install jupyter
python -m pip install ipykernel
conda deactivate



And now to install specific versions of h2o, you need to URL of the .whl file for that version and you can find a list of the URLs of all the old versions here: 
https://github.com/h2oai/h2o-3/blob/master/Changes.md


So for example to install version 3.18.0.8:


conda create --name h2o-3-18-0-8 --clone h2o-base
conda activate h2o-3-18-0-8
pip install http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/8/Python/h2o-3.18.0.8-py2.py3-none-any.whl
python -m ipykernel install --user --name h2o-3-18-0-8 --display-name ""Python (h2o-3-18-0-8)""



or version 3.20.0.2 (make sure to 
conda deactivate
 first):


conda create --name h2o-3-20-0-2 --clone h2o-base
conda activate h2o-3-20-0-2
pip install http://h2o-release.s3.amazonaws.com/h2o/rel-wright/2/Python/h2o-3.20.0.2-py2.py3-none-any.whl
python -m ipykernel install --user --name h2o-3-20-0-2 --display-name ""Python (h2o-3-20-0-2)""



This set-up allows me to have multiple versions of h2o installed on the same computer and if I have to use serialized models I just have to run python from the virtual environment with the correct version of h2o installed. I think this is preferable to uninstalling and reinstalling h2o each time. 


Here is the environments.yml file if you want to skip all the manual installs above:


name: h2o-base
channels:
  - conda-forge
  - defaults
dependencies:
  - asn1crypto=0.24.0=py37_1003
  - backcall=0.1.0=py_0
  - bleach=3.0.2=py_0
  - ca-certificates=2018.10.15=ha4d7672_0
  - certifi=2018.10.15=py37_1000
  - cffi=1.11.5=py37hfa6e2cd_1001
  - chardet=3.0.4=py37_1003
  - colorama=0.4.0=py_0
  - cryptography=2.3=py37h74b6da3_0
  - cryptography-vectors=2.3.1=py37_1000
  - decorator=4.3.0=py_0
  - entrypoints=0.2.3=py37_1002
  - future=0.16.0=py37_1002
  - icu=58.2=vc14_0
  - idna=2.7=py37_1002
  - ipykernel=5.1.0=pyh24bf2e0_0
  - ipython=7.0.1=py37h39e3cac_1000
  - ipython_genutils=0.2.0=py_1
  - ipywidgets=7.4.2=py_0
  - jedi=0.13.1=py37_1000
  - jinja2=2.10=py_1
  - jpeg=9b=vc14_2
  - jsonschema=2.6.0=py37_1002
  - jupyter=1.0.0=py_1
  - jupyter_client=5.2.3=py_1
  - jupyter_console=6.0.0=py_0
  - jupyter_core=4.4.0=py_0
  - libflang=5.0.0=vc14_20180208
  - libpng=1.6.34=vc14_0
  - libsodium=1.0.16=vc14_0
  - llvm-meta=5.0.0=0
  - markupsafe=1.0=py37hfa6e2cd_1001
  - mistune=0.8.4=py37hfa6e2cd_1000
  - nbconvert=5.3.1=py_1
  - nbformat=4.4.0=py_1
  - notebook=5.7.0=py37_1000
  - openblas=0.2.20=vc14_8
  - openmp=5.0.0=vc14_1
  - openssl=1.0.2p=hfa6e2cd_1001
  - pandas=0.23.4=py37h830ac7b_1000
  - pandoc=2.3.1=0
  - pandocfilters=1.4.2=py_1
  - parso=0.3.1=py_0
  - pickleshare=0.7.5=py37_1000
  - pip=18.1=py37_1000
  - prometheus_client=0.4.2=py_0
  - prompt_toolkit=2.0.6=py_0
  - pycparser=2.19=py_0
  - pygments=2.2.0=py_1
  - pyopenssl=18.0.0=py37_1000
  - pyqt=5.6.0=py37h764d66f_7
  - pysocks=1.6.8=py37_1002
  - python=3.7.0=hc182675_1005
  - python-dateutil=2.7.3=py_0
  - pytz=2018.5=py_0
  - pywinpty=0.5.4=py37_1002
  - pyzmq=17.1.2=py37hf576995_1001
  - qt=5.6.2=vc14_1
  - qtconsole=4.4.2=py_1
  - requests=2.19.1=py37_1001
  - send2trash=1.5.0=py_0
  - setuptools=40.4.3=py37_0
  - simplegeneric=0.8.1=py_1
  - sip=4.18.1=py37h6538335_0
  - six=1.11.0=py37_1001
  - tabulate=0.8.2=py_0
  - terminado=0.8.1=py37_1001
  - testpath=0.4.2=py37_1000
  - tornado=5.1.1=py37hfa6e2cd_1000
  - traitlets=4.3.2=py37_1000
  - urllib3=1.23=py37_1001
  - vc=14=0
  - vs2015_runtime=14.0.25420=0
  - wcwidth=0.1.7=py_1
  - webencodings=0.5.1=py_1
  - wheel=0.32.1=py37_0
  - widgetsnbextension=3.4.2=py37_1000
  - win_inet_pton=1.0.1=py37_1002
  - wincertstore=0.2=py37_1002
  - winpty=0.4.3=4
  - zeromq=4.2.5=vc14_2
  - zlib=1.2.11=vc14_0
  - blas=1.0=mkl
  - icc_rt=2017.0.4=h97af966_0
  - intel-openmp=2019.0=118
  - m2w64-gcc-libgfortran=5.3.0=6
  - m2w64-gcc-libs=5.3.0=7
  - m2w64-gcc-libs-core=5.3.0=7
  - m2w64-gmp=6.1.0=2
  - m2w64-libwinpthread-git=5.0.0.4634.697f757=2
  - mkl=2019.0=118
  - mkl_fft=1.0.6=py37hdbbee80_0
  - mkl_random=1.0.1=py37h77b88f5_1
  - msys2-conda-epoch=20160418=1
  - numpy=1.15.2=py37ha559c80_0
  - numpy-base=1.15.2=py37h8128ebf_0",2018-10-18T13:18:35,,,,49199204
49191826,49191826,1,"The first part of the question is very subjective (work on H2O started when Redis was very young, we use highly optimized DKV for our needs for which Redis would most probably be slower, having everything in the JVM is much easier and faster than using an outside database which cannot be embedded easily within the JVM because its written in C etc.etc.).


As for the second part - because of certain reasons (some of them pointed out above) you cannot use other data stores.


All that being said, H2O Frames 
can
 be saved to disk, though (
exportFile
 in R, 
export_file
 in Python, there are also ways to do it in Java/Scala), as CSV files, which can be imported after a crash. Similarly models can be saved and loaded at any time. You can resume training or restart with new data using those models as your checkpoints.",2018-03-09T10:36:24,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,49189487
49208250,49208250,0,"H2O was designed to be an in-memory system. It was designed with speed and scaling to large data in mind, not high-availability. 


Persistence to disk would come with trade-offs against those primary design goals (or, at least, an increase in code complexity which can lower reliability and/or increase developer costs).


I'd love to see some high-availability features, and have plenty of ideas. E.g. every 10 minutes all threads are paused and each machine dumps its entire memory to disk, which could then be restored from very quickly. 15 seconds every 10 minutes won't be a major slowdown.


But I think the bottom-line is that H2O doesn't crash often enough for this to ever become a high enough priority.  As it is open source, maybe one day someone with that itch will come and scratch it.",2018-03-10T10:56:11,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49189487
49182745,49182745,5,"The native read/write functionality in R is not very efficient, so I'd recommend using 
data.table
 for that.  Both options below make use of 
data.table
 in some way. 


First, I'd recommend trying the following:  Once you install the 
data.table
 package, and load the 
h2o
 library, set 
options(""h2o.use.data.table""=TRUE)
.  What that will do is make sure that 
as.h2o()
 uses 
data.table
 underneath for the conversion from an R data.frame to an H2O Frame.  Something to note about how 
as.h2o()
 works -- it writes the file from R to disk and then reads it back again into H2O using 
h2o.importFile()
, H2O's parallel file-reader.


There is another option, which is effectively the same thing, though your RAM doesn't need to store two copies of the data at once (one in R and one in H2O), so it might be more efficient if you are really strapped for resources.  


Save the file as a CSV or a zipped CSV.  If you are having issues saving the data frame to disk as a CSV, then you should make sure you're using an efficient file writer like 
data.table::fwrite()
. Once you have the file on disk, read it directly into H2O using 
h2o.importFile()
.",2018-03-08T21:27:10,,,,49177418
51578092,51578092,0,"Deep Water is a legacy project (as of December 2017), which means that it is no longer under active development. The H2O.ai team has no current plans to add new features, however, contributions from the community (in the form of pull requests) are welcome.


To answer your question, Deepwater was built at the time with a pre-1.0 version of Tensorflow, probably doesn't work with 1.1.0.",2018-07-29T07:10:28,Magnus,https://stackoverflow.com/users/7816546/magnus,246,49174052
53829378,53829378,2,"Try this:


# build the model
model = H2ODeepLearningEstimator(params)
model.train(params)

# save the model
model_path = h2o.save_model(model=model, path=""/tmp/mymodel"", force=True)

print(model_path)
/tmp/mymodel/DeepLearning_model_python_1441838096933

# load the model
saved_model = h2o.load_model(model_path)",2018-12-18T08:55:08,CezarySzulc,https://stackoverflow.com/users/6422477/cezaryszulc,"1,999",49107634
49127256,49127256,0,"You need to export the model as a MOJO or POJO (prefer MOJO if your algorithm supports it). This is a Java object, so you need to use Java to run it. There are lots of options for how to do this:


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html


(BTW, the R API recently added h2o.predict_json() which does the conversion of arguments to JSON and the Java call for you; there appears to be nothing in the Python API yet, but if you read 
the R code
 you'll see it is not doing anything complex: just running a shell command.)


The other alternative is to stick with running the H2O server, and using it from Python. In that case you just want to save your model (a binary format), and then load it (back into the H2O cluster) in each time you want to make to make predictions: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html


The downside of this approach is you the binary format is always tied to the H2O version. So if you upgrade H2O you cannot use your saved models any more.",2018-03-06T09:19:14,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49107634
65610311,65610311,0,"Newer versions of H2O have the ability to import MOJOs via the python API:


# re-import saved MOJO
imported_model = h2o.import_mojo(path)

new_observations = h2o.import_file(path='new_observations.csv')
predictions = imported_model.predict(new_observations)



Caution: MOJO cannot be re-imported into python in older H2O versions, which lack the 
h2o.import_mojo()
 function.


So 
h2o.save_model()
 seems to have lost its role - we can use just 
my_model.save_mojo()
 (notice it's not a 
h2o
 method, but a property of the model object), as these files can be used not just for Java apps deployment, but also in python as well (in fact they still use a python-Java bridge for that internally).",2021-01-07T10:08:57,,,,49107634
49140456,49140456,0,"Unfortunately, there is not currently a way to do this from R or Python.  H2O has a method in 
Java
, but it was never exposed in R/Python, so I have added a ticket for that 
here
.


In the meantime, you could write custom code to do that, or you could use a Deep Learning Autoencoder for anomaly detection (example available in this 
tutorial
).",2018-03-06T21:42:15,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49106333
49077248,49077248,2,"This is caused by a temporary 
bug
 in H2O where the 
offset_column
 and 
distribution
 were removed from the Random Forest in H2O 3.18.0.1 and 3.18.0.2.  The 
h2oEnsemble
 wrapper functions are expecting those parameters to be there, which is why you see the error.


This has been fixed already in the nightly releases, so it should work if you download and install the latest nightly release of H2O 
here
.",2018-03-02T20:54:57,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49075982
52836310,52836310,2,"The main problem seems to be that the port 
54321
 is even locally blocked by Windows.


Just try to start it on the 
normally
 open port 
8080
.


h2o.init(ip=""127.0.0.1"", port=""8080"")",2018-10-16T13:14:54,Sven Rojek,https://stackoverflow.com/users/1167012/sven-rojek,"5,738",49002384
49026446,49026446,0,"I tried to import 
h2o
 in the jupyter notebook locally and it works for me.Please refer to my steps as below:


Step1: Follow the 
doc
 to installing Jupyter with pip ,then run the notebook locally.




Step2: Download h2o zip from this 
link
 and install it with the 
.whl
 file.




Step3: Create Terminal and run the command: 
java -jar h2o.jar
.






Step 4: Create Python2 notebook and run the python code.






I also create 
h2o
 cluster on my vm then access it via my azure notebook.


Please use 
h2o.init(ip=""<your vm ip>"")
 to specify the IP address of the access.




*Don't forger open port 
'54321'
 in the Network security group(it's important!).


Hope it helps you.",2018-02-28T09:47:58,Jay Gong,https://stackoverflow.com/users/8198946/jay-gong,23.8k,49002384
49025798,49025798,0,"Order does not matter. Only the names matter. See the below example that demonstrates this (sorry it is R, but the behaviour will be identical in Python: the only R-specific thing here is: a) using built-in 
iris
; b) using 
t(d)
, as otherwise I end up with a 4-row, 1-column, H2O frame.)


BTW, if you specify column indices, instead of names, the first thing H2O does is convert them to column names. (See the 
m@parameters$x
 output in the below.)


library(h2o)
h2o.init()

iris <- as.h2o(iris)

m <- h2o.randomForest(1:4, 5, iris)
m@parameters$x

d <- c(1.4,3.6,5.0,0.2)
names(d) <- c(""Petal.Length"", ""Sepal.Width"", ""Sepal.Length"", ""Petal.Width"")

test <- as.h2o(t(d))
test

h2o.predict(m, test)



P.S. regarding your example, you will need to rename (lowercase) the column names in your test data, so that they match the training data, and then it will work.",2018-02-28T09:13:12,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,49000226
49000468,49000468,0,"The arguments, 
x
 and 
y
, can be specified as either column names or column indices.




If you specify 
x
 as column names when you train the model, then the names at prediction time must also match, but they don't have to be in any particular order.


However, if you specify 
x
 as column indices when you train the model, then order matters.",2018-02-27T03:07:15,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",49000226
49025997,49025997,0,"The very strange thing in your example is you do not mention port in your 
h2o.init()
 and yet it has tried to start on port 2341.


Either:




you specified port, and didn't show it in your question


You have the environmental variable 
H2O_R_CMD_CHECK_DOC_EXAMPLES_PORT
 set.




Do try using the default port (54321).


Generally, when H2O won't start on a certain port it is because either something is already running there, or because of a firewall issue. Given that it works from the commandline, my guess is that the R application needs to be given permission to access localhost on your chosen port. (On Windows it has a dialog popup the first time you try to use it; is Mac doing something similar?)",2018-02-28T09:24:17,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,48989990
61319221,61319221,0,"I realize this is an old post, but I had a similar problem on Arch Linux. The issue was that my hosts file (
/etc/hosts
) was incorrect. I had written it to work with a static IP address using an ethernet connection. But on wifi with DHCP and a non-static IP, h2o.init() in R was apparently trying to grab and use the static (wrong) IP address. Changing 
/etc/hosts
 to use ""localhost"" rather than the fixed IP address solved the issue.",2020-04-20T09:32:58,user3037237,https://stackoverflow.com/users/3037237/user3037237,425,48989990
48979241,48979241,1,"Pretty sure this is a bug. As a workaround, 
rf.model_performance(h2o_df).r2()
 returns the correct value for R^2 (the same as when calculating manually).",2018-02-25T22:36:35,Logan Wilson,https://stackoverflow.com/users/8485963/logan-wilson,51,48978718
48961203,48961203,0,"The short answer is ""no"": you leave that decision up to H2O, so it can do it efficiently. The 
section just after the one you linked to
 explains why:




When GLM performs regression (with factor columns), one category can be left out to avoid multicollinearity. If regularization is disabled (lambda = 0), then one category is left out. However, when using a the default lambda parameter, all categories are included.


The reason for the different behavior with regularization is that collinearity is not a problem with regularization. And it’s better to leave regularization to find out which level to ignore (or how to distribute the coefficients between the levels).




As an aside, it seems all the other algorithms allow control over the categorical encoding:

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/categorical_encoding.html",2018-02-24T09:14:10,Community,https://stackoverflow.com/users/-1/community,1,48956020
49041711,49041711,0,"Try this one:



java -cp $H2O_EXTENDED_JAR water.H2OApp -name test



It looks like a bug in documentation.",2018-03-01T02:27:45,Michal,https://stackoverflow.com/users/5089773/michal,437,48954878
49051452,49051452,0,"The issue is that when you have extended h2o jar for h2odriver (with support for particular Hadoop), this h2odriver truly does not have 
-name
 argument. Instead, you need to use 
-jobname
 argument instead. We need to fix our documentation for this case.


If you are using the extended h2o driver for standalone h2o application, the 
-name
 argument should do the job.",2018-03-01T14:07:32,,,,48954878
48955115,48955115,1,"Totally reasonable question. In your case you should actually use the .ifelse() method instead of the apply method,  H2O’s apply method is limited to a set of implemented math functions which can be used in a limited way in a lambda style function as well (note your error is just saying you are trying to use apply with an unimplimented method):


The following may solve your problem but you may need to play around with it:


(df[‘resp_cd’].isin([‘00’,’10’,’11’])).ifelse(1,0)


(Statement you want to test).ifelse(return if true,return if false). 


You may need to change your column type to string or enum type with df[‘resp_cd’].ascharacter() or df[‘resp_cd’].asfactor() to get the code example above to work for you, but now you have a sense of how to apply a Boolean if else function to an H2OFrame.",2018-02-23T19:40:12,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48954257
48938657,48938657,3,"There's no way to do this while using the built-in cross-validation in H2O.  If H2O were written in pure R or Python, then it would be easy to extend it to allow a user to pass in a function to create custom features within the cross-validation loop, however the core of H2O is written in Java, so automatically translating an arbitrary user-defined function from R or Python, first into a REST call and then into Java is not trivial.


Instead, what you'd have to do is write a loop to do the cross-validation yourself and compute the features within the loop.


It sounds like you may be doing target encoding (or something similar), and if that's the case, you'll be interested in this 
PR
 to add target encoding in H2O.  In the discussion, we talk about the same issue that you're having.",2018-02-22T23:02:26,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48935263
48930789,48930789,3,"the output of a binary classification problem for H2O will give you the class label (where the threshold is set to get you the max F1 score), the predicted value of class 0 (p0), and the predicted value of class 1 (p1).  


These predicted values are uncalibrated probabilities, if you want actual probabilities you need to set H2O's model argument 
calibrate_model
 to True. 


So to answer your question
, yes 
p1
 is the predicted value between 0 and 1 (for example you will see values like .23, .45. , .89, etc.) and because H2O builds regression trees you could technically use 
1-p0
 to get your 
p1
 value (or vice versa)  and in fact unless you set 
binomial_double_trees = True
 this is exactly what H2O is doing: it builds a single regression tree for one of the classes and then takes 1-(that class value) to get the predicted values for the other class.",2018-02-22T15:10:16,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48925902
48916999,48916999,0,"yes, you can find all the information you need 
here


H2O currently supports the following file types:




CSV (delimited) files (including GZipped CSV)


ORC 


SVMLight 


ARFF 


XLS 


XLSX


Avro version 1.8.0 (without multifile parsing or column type modification)


Parquet




Notes:




ORC is available only if H2O is running as a Hadoop job.


Users can also import Hive files that are saved in ORC format.


When doing a parallel data import into a cluster:




If the data is an unzipped csv file, H2O can do offset reads, so each node in your cluster can be directly reading its part of the csv file in parallel.


If the data is zipped, H2O will have to read the whole file and unzip it before doing the parallel read.
So, if you have very large data files reading from HDFS, it is best to use unzipped csv. But if the data is further away than the LAN, then it is best to use zipped csv.",2018-02-21T23:02:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48915519
48918257,48918257,0,"H2O doesn't have an equivalent xgboostExplainer package. However, there is a way to get something close. 


1) if you want to know what decision path was taken for a single row/observation you can use 
h2o.predict_leaf_node_assignment(model, frame)
 to get an H2OFrame with the leaf node assignments which will generate something that looks like the following (showing the path for each tree built in the following case you can see that 5 trees were built):




2) you can visualize individual trees using H2O's 
MOJO
 which you can download once you've built your GBM or XGBoost model, which will look something like the following:




3) in an upcoming release you will be able to get the prediction value for each leaf node using the GBM (the pull request for this is 
here
)


Putting all these steps together should get you pretty close to getting the values you want so you can add them up for your individual feature impact.(For a python jupyter notebook with examples on how to generate the leaf node assignments and visualize a tree look 
here
)",2018-02-22T01:37:16,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48907176
48914199,48914199,1,"You didn't say whether you have re-trained the models using 3.18.  In general, H2O only guarantees model compatibility between major version of H2O.  If you have not retrained the models, that's probably the reason that XGBoost is not working properly.  If you have re-trained the models with 3.18 and XGBoost is still not working, then please post a reproducible example and we will check it out further.


EDIT:

I am adding reproducible example (the only difference from your code and this code is that I am not using 
fold_column
 here). This runs fine on 3.18.0.2.  Without a reproducible example that produces an error, I can't help you any further.


library(h2o)
h2o.init()

# Import a sample binary outcome train set into H2O
train <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
y <- ""response""
x <- setdiff(names(train), y)

# For binary classification, response should be a factor
train[,y] <- as.factor(train[,y])

xgb <- h2o.xgboost(x = x,
                   y = y, 
                   seed = 1,
                   training_frame = train,
                   keep_cross_validation_predictions = TRUE,
                   eta = 0.01,
                   max_depth = 3,
                   sample_rate = 0.8,
                   col_sample_rate = 0.6,
                   ntrees = 500,
                   reg_lambda = 0,
                   reg_alpha = 1000,
                   distribution = 'bernoulli')",2018-02-21T19:44:09,,,,48907003
48915353,48915353,2,"The best solution is to do a ""print to pdf"" from the browser.  On a Mac, you'd go to File -> Print -> click on the PDF button -> Save to PDF.




Here's an 
example
 of the PDF output for a simple AutoML run on the iris dataset.",2018-02-21T20:59:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48901169
48870126,48870126,3,"The easiest way to find the download artifacts for a specific H2O version x.y.z.w is to just do a google search of ""h2o x.y.z.w"".


Another trick is, if you have that version already running, you can go to the H2O Flow Web UI and find the documentation button.  Clicking that will take you to the online docs for that specific release.  You can tweak that URL so that it matches the form below:




http://h2o-release.s3.amazonaws.com/h2o/rel-BRANCH_NAME/BUILD_NUM/index.html",2018-02-19T16:19:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48869016
58563809,58563809,0,"You can also install the wheel from it's location on your machine using the terminal:




( pip install h2o-3.14.0.1-py2.py3-none-any.whl)




The file can be located in your H2O installation folder at this path:   




h2o-3.14.0.1/python/h2o-3.14.0.1-py2.py3-none-any.whl",2019-10-25T18:22:33,J. Murray,https://stackoverflow.com/users/5178801/j-murray,"1,450",48869016
48833654,48833654,4,"The name of the model file will be determined by the ID of the model.  So if you specify 
model_id
 when training your model, then you can customize it.  Right now there is no way to change the ID of the model after it's been trained.


The file can be renamed once saved:


h2o.saveModel(object = fit, path = path.value, force = TRUE) # force overwriting
name <- file.path(path.value, fileName) # destination file name at the same folder location
file.rename(file.path(path.value, fit@model_id), name)",2018-02-16T19:33:09,David Leal,https://stackoverflow.com/users/6237093/david-leal,"6,739",48833097
63390548,63390548,2,"I think a better work around would be to generate a unique folder each time saving the model. When loading model there will always be only one model file under the path.


saved_model = os.path.join('UNIQUE_MODEL_PATH', os.listdir('UNIQUE_MODEL_PATH')[0])
loaded_model = h2o.load_model(saved_model)",2020-08-13T07:53:23,,,,48833097
69496832,69496832,2,"in python :


model_path = h2o.save_model(model=model, path=""mymodel1"", force=True)
path = os.path.dirname(os.path.abspath(model_path))
os.rename(model_path, os.path.join(path,f'h2o_new_name'))",2021-10-08T13:42:20,DataYoda,https://stackoverflow.com/users/3505444/datayoda,805,48833097
51837632,51837632,0,"Here a possible way to do it:


output_dir <-getwd()
DRF_MO <- h2o.saveModel(object=aml, path=output_dir, force=TRUE)
DRF_MO <- file.path(output_dir, aml@algorithm) 
file.rename(file.path(output_dir, aml@model_id), DRF_MO)",2018-08-14T09:03:50,David Leal,https://stackoverflow.com/users/6237093/david-leal,"6,739",48833097
48833073,48833073,1,"EDIT
 If you have Java 9 but would like to use Java 7 or 8 for H2O, you can try running 
Sys.setenv(""JAVA_HOME"", ...)
 in R before running 
h2o.init()
, where you specify the path to Java 7 or 8 where I have left it as 
...


If you have an internet connection try following the instructions on the 
downloads page
 (select Install in R tab)


Please also post what version of Java you have. 


basically run all of the following lines of code:


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }

# Next, we download packages that H2O depends on.
pkgs <- c(""RCurl"",""jsonlite"")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Now we download, install and initialize the H2O package for R.
install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/rel-wolpert/1/R"")

# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()",2018-02-16T18:45:56,,,,48832512
48832161,48832161,4,"While running AutoML everything runs in memory (nothing is saved to disk unless you save one of the models to disk - or apply the option of saving an object to disk).


If you just want the ""Best of Family"" stacked ensemble, all you have to do is 
save that binary model
.  When you save a stacked ensemble, it saves all the required pieces (base models and meta model) for you.  Then you can re-load later for use with another H2O cluster when you're ready to make predictions (just make sure, if you are saving a binary model, that you can use the same version of H2O later on).


Python Example:


bestoffamily = h2o.get_model('StackedEnsemble_BestOfFamily_0_AutoML_20171121_012135')

h2o.save_model(bestoffamily, path = ""/home/users/me/mymodel"")



R Example:


bestoffamily <- h2o.getModel('StackedEnsemble_BestOfFamily_0_AutoML_20171121_012135')

h2o.saveModel(bestoffamily, path = ""/home/users/me/mymodel"")



Later on, you re-load the stacked ensemble into memory using 
h2o.load_model()
 in Python or 
h2o.loadModel()
 in R.


Alternatively, instead of using an H2O binary model, which requires an H2O cluster to be running at prediction time, you can use a 
MOJO model
 (different model format).  It's a bit more work to use MOJOs, though they are faster and designed for production use.  If you want to save a MOJO model instead, then you can use 
h2o.save_mojo()
 in Python or 
h2o.saveMojo()
 in R.",2018-02-16T17:40:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48830541
48810860,48810860,1,"An HTTP proxy is interfering.  You need to disable it.


In R:


Sys.unsetenv(""http_proxy"")
Sys.unsetenv(""https_proxy"")
# now call h2o.init





[ To debug further, try running the 
curl
 command-line program:


curl -v http://localhost:54321/3/Cloud



and see what the output says. ]",2018-02-15T15:34:37,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48810326
48810493,48810493,6,"In class imbalance settings, artificially balancing the test/validation set does not make any sense: these sets must remain 
realistic
, i.e. you want to test your classifier performance in the real world setting, where, say, the negative class will include the 99% of the samples, in order to see how well your model will do in predicting the 1% positive class of interest without too many false positives. Artificially inflating the minority class or reducing the majority one will lead to performance metrics that are unrealistic, bearing no real relation to the real world problem you are trying to solve.


For corroboration, here is Max Kuhn, creator of the 
caret
 R package and co-author of the (highly recommended) 
Applied Predictive Modelling
 textbook, in 
Chapter 11: Subsampling For Class Imbalances
 of the 
caret
 ebook:




You would never want to artificially balance the test set; its class frequencies should be in-line with what one would see “in the wild”.




Re-balancing makes sense only in the training set, so as to prevent the classifier from simply and naively classifying all instances as negative for a perceived accuracy of 99%.


Hence, you can rest assured that in the setting you describe the rebalancing takes action only for the training set/folds.",2018-02-15T15:15:34,,,,48805063
48811351,48811351,0,"A way to force balancing is using a weight columns to use different weights for different classes, in H2O 
weights_column",2018-02-15T15:59:53,,,,48805063
48795298,48795298,0,"The solution that I ended up using was to start the 
h2o
 process in a seperate thread and pass output back to main thread through a queue that we then read from and use regex to search for the connection IP. See example below.


# startup hadoop h2o cluster
import shlex
import re

from Queue import Queue, Empty
from threading import Thread

def enqueue_output(out, queue):
    """"""
    Function for communicating streaming text lines from seperate thread.
    see https://stackoverflow.com/questions/375427/non-blocking-read-on-a-subprocess-pipe-in-python
    """"""
    for line in iter(out.readline, b''):
        queue.put(line)
    out.close()

# series of commands to run in-order for for bringing up the h2o cluster on demand
startup_cmds = [
    # remove any existing tmp log dir. for h2o processes
    'rm -r /some/location/for/h2odriver.jar/output',
    # start h2o on cluster
    '/bin/hadoop jar {}h2odriver.jar -nodes 4 -mapperXmx 6g -output hdfsOutputDir'.format(""/local/h2o/start/path"")
]

# clear legacy temp. dir.
if os.path.isdir(/some/location/for/h2odriver.jar/output):
    print subprocess.check_output(shlex.split(startup_cmds[0]))

# start h2o service in background thread
startup_p = subprocess.Popen(shlex.split(startup_cmds[1]), 
                             shell=False, 
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)

# setup message passing queue
q = Queue()
t = Thread(target=enqueue_output, args=(startup_p.stdout, q))
t.daemon = True # thread dies with the program
t.start()

# read line without blocking
h2o_url_out = ''
while True:
    try:  line = q.get_nowait() # or q.get(timeout=.1)
    except Empty:
        continue
    else: # got line
        print line
        # check for first instance connection url output
        if re.search(""Open H2O Flow in your web browser"", line) is not None:
            h2o_url_out = line
            break
        if re.search('Error', line) is not None:
            print 'Error generated: %s' % line
            sys.exit()

# capture connection IP from h2o process output
print 'Connection url output line: %s' % h2o_url_out
h2o_cnxn_ip = re.search(""(?<=Open H2O Flow in your web browser: http:\/\/)(.*?)(?=:)"", h2o_url_out).group(1)
print 'H2O connection ip: %s' % h2o_cnxn_ip",2018-02-14T20:02:07,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",48795297
48776506,48776506,0,"Failed to connect to localhost port 54321: Connection refused




This is an issue caused by how Kaggle is running H2O in their kernels (which are probably Docker images).  The H2O R client is not able to connect to the local H2O server running at localhost:54321.


Something you can try is to start the H2O cluster on a different port. So instead of running 
h2o.init()
 do something like 
h2o.init(port=44444)
.  If they are allowing many people to start H2O clusters on the same machine/port, that may cause some issues.  If you are already connected to the H2O cluster in your session, then first run 
h2o.shutdown(prompt = FALSE)
 before re-starting H2O on a different port.


I also suggest that you contact a Kaggle admin to see if they can help debug the issue.  We've seen issues like this before with Kaggle kernels.",2018-02-13T22:11:16,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48761938
48955156,48955156,0,"You're not able to connect to the server because 
kernels don't have an internet connection
. :) 


Update: I've done some more digging and internet access shouldn't be the issue here. I'll file a bug.",2018-02-23T19:42:21,,,,48761938
48758239,48758239,1,"This is a bug, and you can track the progress of the fix 
here
 (this should be fixed in the next release, but it might be fixed sooner and available on the nightly releases).


I was going to suggest training the GLMs in a loop or apply function (instead of using 
h2o.grid()
) as a temporary work-around, but unfortunately, the same error happens.",2018-02-13T01:40:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48750531
48735469,48735469,0,"Rather than h2o.predict_leaf_node_assignment(), I would use h2o.download_mojo() [or pojo] and use the downloaded object.


Here are a couple of git repositories with examples:




https://github.com/h2oai/app-mojo-servlet


https://github.com/h2oai/app-consumer-loan




And here are pointers to the relevant documentation:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html




Mojos are easier to work with, so my preference would be to use those instead of pojos if it works for you.",2018-02-11T19:20:59,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48706347
48712462,48712462,5,"There is no difference between H2O and scikit-learn scoring, you just need to understand how to make sense of the output so you can compare them accurately.


If you'll look at the data in 
predictions['predict']
 you'll see that it's a predicted class, not a raw predicted value.  AUC uses the latter, so you'll need to use the correct column.  See below:


import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator
h2o.init()

# Import a sample binary outcome train/test set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()
test[y] = test[y].asfactor()

# Train and cross-validate a GBM
model = H2OGradientBoostingEstimator(distribution=""bernoulli"", seed=1)
model.train(x=x, y=y, training_frame=train)

# Test AUC
model.model_performance(test).auc()
# 0.7817203808052897

# Generate predictions on a test set
pred = model.predict(test)



Examine the output:


In [4]: pred.head()
Out[4]:
  predict        p0        p1
---------  --------  --------
        0  0.715077  0.284923
        0  0.778536  0.221464
        0  0.580118  0.419882
        1  0.316875  0.683125
        0  0.71118   0.28882
        1  0.342766  0.657234
        1  0.297636  0.702364
        0  0.594192  0.405808
        1  0.513834  0.486166
        0  0.70859   0.29141

[10 rows x 3 columns]



Now compare to sklearn:


from sklearn.metrics import roc_auc_score

pred_df = pred.as_data_frame()
y_true = test[y].as_data_frame()

roc_auc_score(y_true, pred_df['p1'].tolist())
# 0.78170751032654806



Here you see that they are approximately the same.  AUC is an approximate method, so you'll see differences after a few decimal places when you compare different implementations.",2018-02-09T19:02:24,,,,48698385
48697638,48697638,1,"Your measured observation is correct.
There is no difference.",2018-02-09T01:58:14,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48697292
48676565,48676565,2,"you can get the full regularization path with 
h2o.getGLMFullRegularizationPath(my_glm)
 where 
my_glm
 is the glm you trained, just remember to set 
lambda_search
 equal to TRUE (i.e. 
my_glm = h2o.glm(x,y,training_frame, lambda_search = TRUE
)",2018-02-08T02:32:14,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48676228
48670536,48670536,0,"If you want to get the performance on the training data you can either just type in the ensemble object and press enter 


ensemble


and it will give you all the metrics or you can do 


ensemble.auc()
 


which will default to the training metrics. (code example snippet can be found 
here
).


(quick note, however, to understand the performance of your ensemble you should really look at the performance on a new test data set or at the cross-validation metrics. The training evaluation metric (AUC in your case), is not going to tell you how well your model will generalize on new data.)",2018-02-07T18:04:20,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48656028
48675837,48675837,0,"T1, T2,...TN correspond to the first tree built, second tree built,....final tree you built. (so if you said 
ntrees =50
 you should see T1 - T50). If you were doing a multi-class classification problem you would see each tree appended with the class for example T1.C1 T1.C2 (where C1 is class one). 


In your posted image it looks like you passed in an H2OFrame with 10 or more rows. Try looking at a single row, you will see that you get a single row frame back - because 
predict_leaf_node_assignment
 gives you the path a row took to get to the final leaf node (aka terminal node) for each tree.


Take your T1 (first tree) for example, and first row in the frame you passed. We see that the path was RRR, this means the row was funneled right at each split. 


Question 1
: if you are asking for the actual prediction value at T1 for a given row in your data that would require downloading a mojo and scoring that row with the mojo (this has to be done with Java). Please note that the predicted value for that tree will actually be in the link space and you will need to take the corresponding inverse link function to get the original response value back. The link function used will be specified in the mojo.


(in response to your 
EDIT
: no you cannot take the example code (which is Java) and paste it into a jupyter notebook because the code is java not python - the walkthrough assumes you have java on your machine (1.7 or greater) and expects you to run the code from your terminal or command prompt.",2018-02-08T00:59:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48645255
48688304,48688304,0,"The python dependencies need to be available on all nodes where Spark/Sparkling Water is running - that means on both executors and driver. 


This is because the operations are executed in parallel and require the same dependencies as on driver. What I would suggest is to run your Spark application in the uniform environment - ie, have same environment, dependencies for all spark executors and driver to prevent bunch of issues",2018-02-08T14:52:40,,,,48642605
48647481,48647481,2,"you can use the method 
w2v_model.transform(words=words)


(complete options are: 
w2v_model.transform(words =, aggregate_method =)
 


where 
words
 is an H2O Frame made of a single column containing source words (Note that you can specify to include a subset of this frame) and 
aggregate_method
 specifies how to aggregate sequences of words. 


if you don't specify an aggregation method, then no aggregation is performed, and each input word is mapped to a single word-vector. If the method is AVERAGE, then the input is treated as sequences of words delimited by NA. 


For example:


av_vecs = w2v_model.transform(words, aggregate_method = ""AVERAGE"")",2018-02-06T16:22:48,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48639220
48633666,48633666,2,"You can’t publish R or Python code as REST services, but you can create REST services from POJOs and MOJOs.


For instructions and examples, see 
https://github.com/h2oai/steam/tree/master/prediction-service-builder",2018-02-06T00:30:02,Magnus,https://stackoverflow.com/users/7816546/magnus,246,48633281
48665188,48665188,0,"Just some quick things you can do to improve this:




Look at performance metrics on a validation set, including the confusion matrix


Perhaps try hyperparameter tuning to improve performance for your task (using 
h2o.grid
:
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html
)


Consider using h2o.word2vec for feature generation (Docs: 
https://github.com/h2oai/h2o-3/blob/master/h2o-r/demos/rdemo.word2vec.craigslistjobtitles.R
 and Example: 
https://github.com/h2oai/h2o-3/blob/master/h2o-r/demos/rdemo.word2vec.craigslistjobtitles.R
)




If you provide more details and a working example there is more that can be done to help you.",2018-02-07T13:34:00,Sam Abbott,https://stackoverflow.com/users/9295446/sam-abbott,466,48617076
48631376,48631376,2,"Currently H2O DAI only supports one target. (As noted in the comments you can run two separate experiments, for ideas on how to handle predicting lat and long the following kaggle competition may be of interesthttps://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i/).",2018-02-05T21:00:19,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48588299
48646234,48646234,1,"Statistics.




For example, the weighted number of rows for each of the child nodes.


You can look at the AuxInfo data structure here:




https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/tree/SharedTreeMojoModel.java




The MOJO printing tool has a special flag (--detail) that prints out this information.


See the tool used here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo




 




Strictly speaking, no.  The prediction calculation does not require the ""aux"" information.




However the I'm going to guess the current Java genmodel reader code (3.16.0.4) might not parse properly if that information isn't there.


(You can try yourself by unzipping the mojo, removing that aux file, and rezipping it again.)


 




No, as of the current version (3.16.0.4) this feature does not exist.",2018-02-06T15:14:29,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48580085
48569670,48569670,2,"Neither the Flow web interface nor R/Python expose the 
keep_cross_validation_predictions
 option for AutoML. 
EDIT:
 This parameter is now exposed as of H2O 3.20.0.1. 


However, under the hood, all the models will have this set to 
TRUE
 by default because this is required in order to build the Stacked Ensembles at the end of the AutoML run. 


If you wanted to prevent cross validation from occurring you can set 
nfolds=0
 for AutoML, in which case you will not get any Stacked Ensembles built (though I think the CV predictions will still be saved).


Please see the screen shot below that indicates there is no exposed parameter for 
keep_cross_validation_predictions
. Please note, however, that if you are building a regular model in H2O Flow or R or Python you will see the parameter 
keep_cross_validation_predictions
.",2018-02-01T18:40:43,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48569509
48553305,48553305,2,"I think the more common use of the term ""indicator variable"" is to refer to a binary predictor (not a unique identifier), but it sounds like you are asking if you can just keep the ID column in your data frames but not use it for prediction.  


That's easy to do in H2O -- you use the 
x
 argument to indicate which columns should be used as predictors, so if you leave the ID column out of that, it will ignore it.  Example with iris data:


library(h2o)
h2o.init()

iris$ID <- 1:nrow(iris)  #add ID column
train <- as.h2o(iris)
fit <- h2o.gbm(x = 1:4, y = 5, training_frame = train)  #fit a GBM



You can see that ID was not used by looking at variable importance:


> h2o.varimp(fit)

Variable Importances: 
      variable relative_importance scaled_importance percentage
1  Petal.Width          258.856262          1.000000   0.563269
2 Petal.Length          195.480728          0.755171   0.425364
3  Sepal.Width            2.891532          0.011170   0.006292
4 Sepal.Length            2.332296          0.009010   0.005075



If you predict on a test set (here I'll just use the training set for demonstration purposes), then the model already knows to ignore the ID column as well.


> pred <- h2o.predict(fit, train)
> head(pred)
  predict    setosa   versicolor    virginica
1  setosa 0.9989301 0.0005656447 0.0005042210
2  setosa 0.9985183 0.0006462680 0.0008354416
3  setosa 0.9989298 0.0005663071 0.0005038929
4  setosa 0.9989310 0.0005660443 0.0005029535
5  setosa 0.9989315 0.0005649384 0.0005035886
6  setosa 0.9983457 0.0011517334 0.0005025218",2018-01-31T23:47:48,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48553191
48551351,48551351,1,"The issue is likely that the comment fields have too many newlines so unfortunately changing the separator will not help.


As a workaround you can import the csv with pandas using 
pandas.read_csv()
 (which parses correctly) (Note: it's not working in 
data.table::fread()
 either as 
reported here
).


To use the data frame in H2O for modeling, you just need to convert the data frame to an H2O Frame (use 
df = h2o.H2OFrame(my_pandas_frame)
 in Python. 


I've created a 
JIRA ticket
 so that this issue is being tracked and worked on.",2018-01-31T21:02:01,,,,48538135
48529363,48529363,3,"You have four options:
(
EDIT
: added third option)
(
EDIT 2
: added fourth option for MOJOs -- recommended)




You can keep the prediction pipeline in R and make use of the 
h2o.predict_json()
 function, which allows you to pass your test data as JSON in R to a MOJO/POJO on disk to generate predictions.  This would allow you to use your R code for data munging, and then you'd take the munged data, convert it into a JSON string, and use 
h2o.predict_json()
 to generate the predictions.  The function expects a single row at a time, so if you have a whole data frame, you'd have to write a loop.  The predictions would be in R memory at that point, so you could choose to write them to a file/database or do something else with them in pure R.


Translate the R data munging code into Java and keep your application Java only, using the POJO/MOJO directly from your Java application.


Keep using your R code for munging, write the munged data to disk using a fast I/O tool like 
data.table::fwrite()
, then use that new file as the input to the POJO/MOJO and score in Java.  This way you can score a whole file at once rather than #1 where you have to score a row at a time. 


We now have two convenience functions, 
h2o.mojo_predict_df()
 and 
h2o.mojo_predict_csv()
, which allows you to score a dataset from R using an efficient MOJO model.  What you can do here is to write some data transformation code in R, and then pass the transformed data.frame to 
h2o.mojo_predict_df()
 (assuming you have exported the model to MOJO format using the 
h2o.download_mojo()
 function).  This allows you to keep your scoring pipeline entirely in R, but you will get the speed of using an optimized MOJO model.",2018-01-30T19:44:43,,,,48525653
48526844,48526844,-1,"Handling the data munging before an H2O makes a prediction is something you need to handle.


One strategy is to write your munging code in such a way that you can execute the same exact code for both training and production environments.",2018-01-30T17:05:05,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",48525653
48511488,48511488,1,"Here's an example of building a stacked ensemble for a regression problem (predicting age) in R:


library('h2o')
h2o.init()

files3 = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv""
col_types <- c(""Numeric"",""Numeric"",""Numeric"",""Enum"",""Enum"",""Numeric"",""Numeric"",""Numeric"",""Numeric"")
dat <- h2o.importFile(files3,destination_frame = ""prostate.hex"",col.types = col_types)
ss <- h2o.splitFrame(dat, ratios = 0.8, seed = 1)
train <- ss[[1]]
test <- ss[[2]]

x <- c(""CAPSULE"",""GLEASON"",""RACE"",""DPROS"",""DCAPS"",""PSA"",""VOL"")
y <- ""AGE""
nfolds <- 5


# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(x = x, 
                  y = y, 
                  training_frame = train, 
                  distribution = ""gaussian"",
                  max_depth = 3,
                  learn_rate = 0.2,
                  nfolds = nfolds, 
                  fold_assignment = ""Modulo"",
                  keep_cross_validation_predictions = TRUE,
                  seed = 1)

# Train & Cross-validate a RF
my_rf <- h2o.randomForest(x = x,
                          y = y, 
                          training_frame = train, 
                          ntrees = 30, 
                          nfolds = nfolds, 
                          fold_assignment = ""Modulo"",
                          keep_cross_validation_predictions = TRUE,
                          seed = 1)


# Train & Cross-validate a extremely-randomized RF
my_xrf <- h2o.randomForest(x = x,
                           y = y, 
                           training_frame = train, 
                           ntrees = 50,
                           histogram_type = ""Random"",
                           nfolds = nfolds, 
                           fold_assignment = ""Modulo"",
                           keep_cross_validation_predictions = TRUE,
                           seed = 1)

# Train a stacked ensemble using the models above
stack <- h2o.stackedEnsemble(x = x, 
                             y = y, 
                             training_frame = train,
                             validation_frame = test,  #also test that validation_frame is working
                             model_id = ""my_ensemble_gaussian"", 
                             base_models = list(my_gbm@model_id, my_rf@model_id, my_xrf@model_id))

# predict
pred <- h2o.predict(stack, newdata = test)",2018-01-29T23:08:01,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48490900
48518342,48518342,0,"The stacked ensemble example in my book (Practical Machine Learning with H2O) is a regression (on the building energy data set). :-)


But, if you ever think you've exhausted all the documentation with H2O, try searching the source code on github. Here is their unit test for stacked ensemble regressions:


https://github.com/h2oai/h2o-3/blob/master/h2o-r/tests/testdir_algos/stackedensemble/runit_stackedensemble_gaussian.R",2018-01-30T09:46:09,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,48490900
48479567,48479567,0,"Try to restart the jupyter kernel and then restart H2O.


h2o.init(ip=""127.0.0.1"",max_mem_size_GB = 2)",2018-01-27T19:15:38,Rushabh Patel,https://stackoverflow.com/users/7120667/rushabh-patel,"2,764",48470944
48529309,48529309,7,"High cardinality categorical predictors can sometimes hurt model performance, and specifically in the case of tree-based models, the tree ensemble (GBM or Random Forest) ends up memorizing the training data.  The model has a poor time generalizing on validation data.  


A good indication of whether this is happening is if your string/categorical column has very high variable importance.  This means that the trees are continuing to split on this column to memorize the training data.  Another indication is if you see much smaller error on your training data than on your validation data.  This means the trees are overfitting to the training data. 


Some methods for handling high cardinality predictors are: 




removing the predictor from the model


performing categorical encoding 
[pdf]


performing grid search on 
nbins_cats
 and 
categorical_encoding




There is a Python example in the 
H2O tutorials GitHub repo
 that showcases the effects of removing the predictor from the model and performing grid search 
here
.",2018-01-30T19:40:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48470043
48469972,48469972,3,"Yes, the recommended thing to do is use multiple instances of H2O (one for each user).  All you need to do is specify a different port when you start H2O for each user. The default port for H2O is 54321, so the second user should use something different.  


Here's how to specify a non-default port when you start an H2O cluster from R using 
h2o.init()
:


 h2o.init(port = 22222)",2018-01-26T21:42:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48469361
48468319,48468319,2,"I was able to replicate this in 3.16.0.2; it's a bug (at least on some systems).  You can follow the progress 
here
.  Thanks!",2018-01-26T19:32:53,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48463961
48413751,48413751,0,"Fortunately, the problem is resolved. 


If my data contains Inf, importing took a lot of time. I replaced Inf with a value, so I was importing quickly :)",2018-01-24T02:04:55,,,,48413425
48814414,48814414,0,"Sparkling-water 2.2.7 seems to work better.  However, it was looking for the ""h20.jar"" file for the parsers.  So, installed the latest version of h2o, then modified the ""sparkling-shell"" script to include the h2o.jar file while launching the spark-shell.


Shankar.",2018-02-15T18:57:09,VShankar,https://stackoverflow.com/users/6552685/vshankar,151,48410708
48465916,48465916,0,"There is no direct way or API available to load data into H2O from elasticsearch. h2o supports files and JDBC, so you can write the data into the CSV file from ES. Then import data into the h2o using POST /3/ImportFiles. You can refer my answer related to it at 
how to create an h2oframe",2018-01-26T16:53:49,,,,48397934
77263046,77263046,0,"Going to be dead blunt on this. One is asking about an ETL process. Basically, all one does is export your index as a csv into say a hadoop, a cloud bucket, or SQL database then follow one of the various tutorials to import the dataset into h2o.


Personally, I'd just use an Airflow DAG to export from ELK, convert it into a pandas dataframe, then upload the dataframe to a PostgreSQL database; then follow that up with a h2o wave script that's triggered as Airflow DAG off the new data in the database.


One could just do this all with a bunch of bash scripts and cron jobs too.",2023-10-10T05:00:09,Dwight Spencer,https://stackoverflow.com/users/522599/dwight-spencer,"1,570",48397934
57095278,57095278,-1,The latest version of elasticsearch comes with an sql interface that can be connected to via jdbc or odbc. I haven't attempted to use this with H2O but in theory...,2019-07-18T13:09:55,nick robinson,https://stackoverflow.com/users/3983621/nick-robinson,59,48397934
48392216,48392216,3,"The reason you see this error is that you are trying specify the folds in two different ways.  If you want randomly created folds, then you can use the 
nfolds
 argument and H2O will create the folds for you.  


If you want custom folds (so that you have control over which observations go into which fold), then you can add a column to your training frame that contains fold indices.  Then you set 
fold_column
 equal to the name of that column.


You must choose one or the other (not both).",2018-01-23T00:07:11,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48392125
48388545,48388545,4,"This functionality is currently not available in the R API, so I created a jira ticket here: 
https://0xdata.atlassian.net/browse/PUBDEV-5248


In the Python API, however, you can do 


my_model.model_id = ‘my_new_model_id’",2018-01-22T19:01:00,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48387458
48376016,48376016,0,"This is a 
known bug
 with XGBoost models in H2O, and is currently scheduled to be fixed in the next major release of H2O, v3.18 (there's already a 
pull request
 with a fix).  It does not affect any other types of models in H2O.",2018-01-22T06:49:30,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48375715
48330650,48330650,13,"H2O AutoML uses H2O algos (e.g. RF, GBM) underneath, so if you're not able to get good models there, you will suffer from the same issues using AutoML.  I am not sure that I would call this overfitting -- it's more that your models are not doing well at predicting outliers.


My recommendation is to log your response variable -- that's a useful thing to do when you have a skewed response.  In the future, H2O AutoML will try to detect a skewed response automatically and take the log, but that's not a feature of the the current version (H2O 3.16.*).


Here's a bit more detail if you are not familiar with this process.  First, create a new column, e.g. 
log_response
, as follows and use that as the response when training (in RF, GBM or AutoML):


train[,""log_response""] <- h2o.log(train[,response])



Caveats: If you have zeros in your response, you should use 
h2o.log1p()
 instead. Make sure not to include the original response in your predictors.  In your case, you don't need to change anything because you are already explicitly specifying the predictors using a 
predictors
 vector.


Keep in mind that when you log the response that your predictions and model metrics will be on the log scale.  So if you need to convert your predictions back to the normal scale, like this:


model <- h2o.randomForest(x = predictors, y = ""log_response"", 
                          training_frame = train, valid = valid)
log_pred <- h2o.predict(model, test)
pred <- h2o.exp(log_pred)



This gives you the predictions, but if you also want to see the metrics, you will have to compute those using the 
h2o.make_metrics()
 function using the new preds rather than extracting the metrics from the model.


perf <- h2o.make_metrics(predicted = pred, actual = test[,response])
h2o.mse(perf)



You can try this using RF like I showed above, or a GBM, or with AutoML (which should give better performance than a single RF or GBM).


Hopefully that helps improve the performance of your models!",2018-01-18T21:32:18,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48330026
54102734,54102734,0,"When your target variable is skewed, mse is not a good metric to use. I would try changing the loss function because gbm tries to fit the model to the gradient of the loss function and you want to make sure that you are using the correct distribution. if you have a spike on zero and right skewed positive target, probably Tweedie would be a better option.",2019-01-09T03:09:38,Rio,https://stackoverflow.com/users/4614379/rio,398,48330026
48332378,48332378,5,"Let me start with a small clarification. You can't reshape a 
1000 x 25
 array into a 
5 x 5
 array. The number of elements in the original and reshaped arrays has to be the same. 


From your code, looks like you are trying to reshape each row of h2o frame, with 
1 x 25
, dimension into 
5 x 5
 numpy array, which should results in a 
1000 x 5 x 5
 array, since there are 1000 rows. Here is an example to do that and you can modify/apply it to your specific case. 


import h2o
import numpy as np

# initialize h2o
h2o.init()

# create a (1000, 25) h2o frame with real values (no missing values)
hf = h2o.create_frame(rows=1000, cols=25, real_fraction=1, missing_fraction=0) 

# First convert to a pandas df, then to a numpy array
num_array = hf.as_data_frame().as_matrix()

# Reshape the array
reshaped_array = num_array.reshape(1000, 25, 25)

# Check the dimensions of the reshaped array
reshaped_array.shape
# The output should be: (1000, 5, 5) 



Hope this helps with your problem.",2018-01-19T00:19:16,karhayrap,https://stackoverflow.com/users/8502874/karhayrap,346,48317921
48309526,48309526,2,"For h2o.glm, all you need to add is an 
interactions
 parameter, which takes the form a list of attributes in 
x
 whose interactions you want to include. In your case, it might look like:


# supposing x contains variables A, B, C, etc.
interacting_variables <- c('B', 'D', 'E', 'F')

my_glm.hex <- h2o.glm(y=y_idx,x=x_idx,
                      training_frame = ""my_train"",
                      validation_frame = ""my_valid"",
                      model_id = ""my_glm.hex"",
                      family = ""binomial"",
                      lambda_search = TRUE,
                      balance_classes = TRUE,
                      interactions = interacting_variables)



For a list like the one above, all pairwise combinations of the four variables will be computed.


You can find more on the 
h2o site
.",2018-01-17T20:32:32,data princess,https://stackoverflow.com/users/8414180/data-princess,"1,160",48309192
51600885,51600885,2,"you can know set these parameters to 
TRUE
 in the latest version of AutoML. Please see the 
documentation
 on 
h2o.automl()
 parameters for more details.",2018-07-30T19:19:04,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48306967
48307885,48307885,1,"Short answer: Yes. There is an example in the 
H2O Python booklet
, copied here for clarity:


In [25]: from h2o.transforms.decomposition import H2OPCA

In [26]: pca_decomp = H2OPCA(k=2, transform=""NONE"", pca_method=""Power"")

In [27]: pca_decomp.train(x=range(0,4), training_frame=iris_df)

pca Model Build Progress: [#######################################] 100%

In [28]: pca_decomp
Out[28]: Model Details
=============
H2OPCA :  Principal Component Analysis
Model Key:  PCA_model_python_1446220160417_10

Importance of components:
                        pc1      pc2
----------------------  -------  --------
Standard deviation      7.86058  1.45192
Proportion of Variance  0.96543  0.032938
Cumulative Proportion   0.96543  0.998368

ModelMetricsPCA: pca

**
Reported on train data.
**
MSE: NaN
RMSE: NaN

In [29]: pred = pca_decomp.predict(iris_df)

pca prediction progress: [#######################################] 100%

In [30]: pred.head() # Projection results
Out[30]:
    PC1      PC2
-------  -------
5.9122   2.30344
5.57208  1.97383
5.44648  2.09653
5.43602  1.87168
5.87507  2.32935
6.47699  2.32553
5.51543  2.07156
5.85042  2.14948
5.15851  1.77643
5.64458  1.99191



There are technically two ways to use the PCA estimator in Python.  The old method is located here 
h2o.transforms.decomposition.H2OPCA
.  A few years ago, we rewrote the Python API and moved some things around, including turning PCA into a proper ""H2OEstimator"", so now it's also located here: 
h2o.estimators.pca.H2OPrincipalComponentAnalysisEstimator
.  Both methods work, though for new code we recommend the new one because it's consistent with the other H2O Estimators.  


The API is the same, so, though not necessary, if you want to, you could switch over to the new one by changing your import statement:


from h2o.transforms.decomposition import H2OPCA



to:


from h2o.estimators.pca import H2OPrincipalComponentAnalysisEstimator as H2OPCA",2018-01-17T18:38:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48306081
48284872,48284872,1,"h2o.deeplearning
 is H2O's built-in deep-learning algorithm. It parallelizes very well, works well with large data, but does not use GPUs.


h2o.deepwater
 is a wrapper around (probably) Tensorflow, and (probably) using your GPU (but it can use the CPU, and it can use different back-ends).


In other words, this is not a difference in using the CPU or using the GPU: you are using two different implementations of deep learning.


BTW, I'd suggest you increase the number of 
epochs
 (from the default of 10, to something like 200 - bearing in mind this means it will take 20x longer to run), and see if the difference is still there. Or compare the score history charts, and see if Tensorflow is getting there, but just needs, say, 50% more epochs to get the same logloss score.",2018-01-16T15:38:38,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,48274614
51578100,51578100,0,"Please note that Deep Water is a legacy project (as of December 2017), which means that it is no longer under active development. The H2O.ai team has no current plans to add new features, however, contributions from the community (in the form of pull requests) are welcome.",2018-07-29T07:11:54,Magnus,https://stackoverflow.com/users/7816546/magnus,246,48273808
48235353,48235353,2,"If you specify 
weights_column
 to GLM or any of the H2O algos, it will store the column name (not the actual column data) in the model object.  In R, it stores it in both 
model@parameters
 and 
model@allparameters
.  Here's an example:


library(h2o)

model <- h2o.glm(x = 1:3, y = 5, 
                 training_frame = as.h2o(iris),
                 weights_column = names(iris)[4], 
                 family = ""multinomial"")



You can see the relevant info here:


> model@parameters$weights_column
$`__meta`
$`__meta`$schema_version
[1] 3

$`__meta`$schema_name
[1] ""ColSpecifierV3""

$`__meta`$schema_type
[1] ""VecSpecifier""


$column_name
[1] ""Petal.Width""

$is_member_of_frames
NULL",2018-01-12T23:21:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48235159
48233323,48233323,0,"In this case the command presented is suggesting you want to mount


the docker host /log into the docker containers /log


The /log folder in question must have the privileges to write
of the user who launched the docker run command.


Or launch the container with sudo",2018-01-12T20:08:34,Jeff,https://stackoverflow.com/users/8721385/jeff,1,48213625
48216516,48216516,1,"There are 2 methods you can have a try:


Use 
factor
 as oppose to 
character


Before feeding data into machine learning function, you can combine your train and test data, and convert 
character
 variable to 
factor
. 


Hence unique values will be recorded as level info even you split combined data later.


library(h2o)

h2o.init()

#using dummy data as combined training and testing data
prostatePath = system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate.hex = h2o.importFile(path = prostatePath, destination_frame = ""prostate.hex"")

#assuming GLEASON is the character variable, and transform it to factor
prostate.hex$GLEASON <- h2o.asfactor(prostate.hex$GLEASON)

#split data such that 0,4,5,8 only in test set, and not in train set.
h2o.test <- prostate.hex[prostate.hex$GLEASON %in% c(""0"",""4"",""5"",""8""),]
h2o.train <- prostate.hex[!prostate.hex$GLEASON %in% c(""0"",""4"",""5"",""8""),]

#train model
model <- h2o.glm(y = ""CAPSULE"", x = c(""AGE"",""RACE"",""PSA"",""DCAPS"",""GLEASON""), training_frame = h2o.train,
       family = ""binomial"", nfolds = 0)

#predict without error
pred <- predict(model,h2o.test)



Use 
one-hot-encoding
 Explicitly


I know that 
h2o
 machine learning functions provide internal encoding methods (via 
categorical_encoding
 parameters) including one-hot-encoding, which turns character variable into lots of 
1/0
 integer variables.


As oppose to use this technique implicitly, you can use it explicitly.  Hence those levels don't exist in training will not be used in model.  New levels in testing are simply not used for prediction.",2018-01-11T22:01:49,,,,48212530
48222464,48222464,8,"Assuming ""build 9.0.1+11"" means Java 9, that is your problem: H2O currently only supports Java 7 or Java 8. This is the 
ticket to follow for adding Java 9 support
. In the meantime uninstall your current Java, then install Java 8.


UPDATE:
 It seems Java 9 is now supported, so upgrade to h2o 3.20 or later.




BTW, normally you should be giving a lot more information: which language you are using, what code you used to try and start H2O (or the commandline if you started it that way), what OS, what versions of Java, R, Python, etc., number of cores, amount of memory, etc.",2018-01-12T08:42:34,,,,48208691
48140754,48140754,4,"You can run 
h2o.automl()
 repeatedly with the same 
project_name
 and different seeds to build additional models and add them to the same 
leaderboard
.  I do this all the time.


There's a 
pull request
, which should go in soon, which allows you to specify algos not to run.  This allows you to tune which hyperparameter searches get executed on each 
AutoML
 run.


You'll need to keep the 
h2o-3
 instance running to achieve your aim since you can't currently persist the state of an 
AutoML
 run to disk and load it into a new 
h2o-3
 instance, or add models loaded from disk into a 
leaderboard
.  Those would be useful feature requests.  :-)",2018-01-07T19:26:01,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48140279
50827909,50827909,1,"There's no way to continue running an H2O AutoML job if you shut down the H2O cluster (or machine) and restart the H2O cluster at a later date.  If you leave the H2O cluster running, you can add more models to your leaderboard by running 
h2o.automl()
 again with the same value for 
project_name
.


If you need to shut down the H2O cluster between runs, then the best you can do is to set a different 
seed
 in the 
h2o.automl()
 function when you run it a second, third, fourth, etc. time because your random grid searches within the AutoML run will be different.  That way you're likely to get new models instead of models you've already trained in previous AutoML runs.",2018-06-13T01:24:51,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",48140279
48216661,48216661,2,"checkpoint
 parameter may meet your needs, which trains model further from original model.


This functionality is available for 
gbm
,
random forest
 and 
deep learning
 in 
h2o
 package.


Example code below copying from: 
http://s3.amazonaws.com/h2o-release/h2o/master/3689/docs-website/h2o-docs/data-science/algo-params/checkpoint.html


library(h2o)
h2o.init()

# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars <- h2o.importFile(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# convert response column to a factor
cars[""economy_20mpg""] <- as.factor(cars[""economy_20mpg""])

# set the predictor names and the response column name
predictors <- c(""displacement"",""power"",""weight"",""acceleration"",""year"")
response <- ""economy_20mpg""

# split into train and validation sets
cars.split <- h2o.splitFrame(data = cars,ratios = 0.8, seed = 1234)
train <- cars.split[[1]]
valid <- cars.split[[2]]

# build a GBM with 1 tree (ntrees = 1) for the first model:
cars_gbm <- h2o.gbm(x = predictors, y = response, training_frame = train,
                    validation_frame = valid, ntrees = 1, seed = 1234)

# print the auc for the validation data
print(h2o.auc(cars_gbm, valid = TRUE))

# re-start the training process on a saved GBM model using the ‘checkpoint‘ argument:
# the checkpoint argument requires the model id of the model on which you wish to continue building
# get the model's id from ""cars_gbm"" model using `cars_gbm@model_id`
# the first model has 1 tree, let's continue building the GBM with an additional 49 more trees, so set ntrees = 50

# to see how many trees the original model built you can look at the `ntrees` attribute
print(paste(""Number of trees built for cars_gbm model:"", cars_gbm@allparameters$ntrees))

# build and train model with 49 additional trees for a total of 50 trees:
cars_gbm_continued <- h2o.gbm(x = predictors, y = response, training_frame = train,
                    validation_frame = valid, checkpoint = cars_gbm@model_id, ntrees = 50, seed = 1234)

# print the auc for the validation data
print(h2o.auc(cars_gbm_continued, valid = TRUE))

# you can also use checkpointing to pass in a new dataset (see options above for parameters you cannot change)
# simply change out the training and validation frames with your new dataset



Edit (Based on @Edward's comment below:)


h2o.grid
 will return a series of models, and you can get the best model handel.  All the parameters are saved in the model handel, then you can apply the parameters to new model.


grid <- h2o.getGrid(h2o.grid@grid_id,sort_by = ""auc"",decreasing=TRUE)
model.h2o <- h2o.getModel(grid@model_ids[[1]])



model@allparameters
 includes all parameters used, and you can use those to create a new model and new data.",2018-01-11T22:13:36,,,,48134000
48142940,48142940,1,"The core H2O function 
importSqlTable
 in 
water.jdbc.SQLManager
 class is called by both 
h2o.import_sql_table
 and 
h2o.import_sql_select
 (H2O R API - must be similar with Python counterparts). After inspecting 
importSqlTable
 source code I found a problem that will likely prevent you from loading with Teradata due to 
SELECT
 syntax. 


Still I'd suggest trying and reporting in comments on result and error if it fails. When starting H2O server add the following to your command line:


  -cp <path_to_h2o_jar>:<path_to_Teradata_jdbc_driver_jar> jdbc.drivers=com.teradata.jdbc.TeraDriver



UPDATE:
Use version 
Xia (3.22.0.1) - 10/26/2018
 or later that fixed JDBC support for Teradata.",2018-01-08T00:37:55,,,,48130735
48105119,48105119,3,"There is no other apply type method at the moment. the H2O apply method is suppose to be a close equivalent to pandas apply. It is true that H2O's apply function is limited to certain operations such as addition (+), subtraction (-), division, etc. If you use one that H2O doesn't have you will get the error above.


here are a few examples to try to see how the apply function can work (first one gets the mean across columns, the second returns a boolean column):


h2oframe = h2o.import_file(""http://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv"")

h2oframe.apply(lambda x: x.mean(), axis=0)

h2oframe.apply(lambda x: x['PSA'] > x['VOL'],axis=1)



And here is the current documentation on it:


apply(fun=None, axis=0):
    Apply a lambda expression to an H2OFrame.

    Parameters: 
    fun – a lambda expression to be applied per row or per column.
    axis – 0 = apply to each column; 1 = apply to each row
    Returns:    
    a new H2OFrame with the results of applying fun to the current frame.",2018-01-04T23:33:57,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48103924
49061443,49061443,3,"As evident from the error logs and from documentation of 
mxnet.sym.Convolution
 your data needs to be in 
[batch, channels, height, width]
 format. However it looks like your data contains only two dimensions (based on this log: 
mxnet data input shape: (32,100)
). Reformatting the data, even including two dimensions of size 1 such that your input shape is (1,1,32,100) should resolve this issue.",2018-03-02T01:34:04,Sina Afrooze,https://stackoverflow.com/users/9015998/sina-afrooze,980,48090102
55731468,55731468,2,"This is particularly frustrating because it waits until after training all models to generate this error.


It was happening to me after running one grid search, changing hyperparameters, then doing a second grid search. Somewhere online saw a way to append new grid search results to old ones, but short of that, restarting h2o got it at least working again for me:


h2o.cluster().shutdown()
h2o.init()",2019-04-17T15:46:17,Dan Garmat,https://stackoverflow.com/users/11364714/dan-garmat,36,48086448
48126963,48126963,0,"I've found some messy Spark ticket 
https://issues.apache.org/jira/browse/SPARK-18075
 describing the same problem related to different ways of submitting Spark application. Take a look, maybe it'll give you a clue about your problem.",2018-01-06T11:37:52,,,,48076913
48464552,48464552,0,"You can't call prediction.toInt. The prediction returned is a tuple. You need to extract the second element of that tuple to get the actual score for level 1. I have a complete example here: 
https://stackoverflow.com/a/47898040/9120484",2018-01-26T15:36:03,jliu3230,https://stackoverflow.com/users/9120484/jliu3230,56,48076913
48076658,48076658,5,"As the name tells, Machine Learning needs a machine (PC). What's more, it requires a suitable machine for a specific work. Even though there are some techniques to deal with it:


1. Down-Sampling


Most of the time, you don't need all data for a machine learning, you can sample you data to get a much smaller one which can be used on your laptop.


Of cause, you may need to use some tool(s) (e.g. database) for sampling work on your laptop.


2. Data Points


Depends on the number of variables you have, each record may not be unique. You can ""aggregate"" your data by your key variables.  Each unique combination of variable is called a data point, and the number of duplicates can be used as the weight for clustering methods.


But depends on the chosen clustering method and purpose of the project, this aggregated data may not provide you the best model. 


3. Split into Parts


Assuming you have all your data in one csv file, you can read data in chunks using 
data.table::fread
 by specifying the rows that can fit your laptop.


https://stackoverflow.com/a/21801701/5645311


You can process each data chunk in R separately, and build model on those data. Eventually, you will have lots of clustering results as a kind of bagging method.


4. Cloud Solution


Nowadays, cloud solutions are really popular, and you can move your work to
cloud for data manipulation and modelling.


If you feels like it quite expensive for a whole project, you can down-sampling using cloud then back to your laptop if you cannot find a suitable tool locally for sampling work.


5. A New Machine


This is a way I'd think first.  A new machine may still not handle your data (depends on number of variables in your data).  But it will definitely make the other calculation more efficient.


For personal project, a 32gb RAM with i7 CPU would be good enough to start machine learning. A Titan GPU would give you speed boost on some machine learning methods (e.g. xgboost, lightgbm keras etc.)


For commercial purpose, a server solution or cluster solution makes more sense to deal with a 70m records data on a clustering job.",2018-01-03T11:40:01,Sixiang.Hu,https://stackoverflow.com/users/5645311/sixiang-hu,"1,019",48075535
48069505,48069505,0,"Try this and let me know what you get. Note that this assumes your excel file is stored in a folder called ""data"" in your working directory. Use 
getwd()
 and 
setwd()
 to get/set the working directory (or use Projects in RStudio IDE). 


library(h2o)        # Professional grade ML pkg
library(tidyquant)  # Loads tidyverse and several other pkgs 
library(readxl)     # Super simple excel reader
library(lime)       # Explain complex black-box ML models
library(recipes)    # Preprocessing for machine learning

hr_data_raw_tbl <- read_excel(path = ""data/WA_Fn-UseC_-HR-Employee-Attrition.xlsx"")

hr_data_organized_tbl <- hr_data_raw_tbl %>%
  mutate_if(is.character, as.factor) %>%
  select(Attrition, everything())

recipe_obj <- hr_data_organized_tbl %>%
  recipe(formula = Attrition ~ .) %>%
  step_rm(EmployeeNumber) %>%
  step_zv(all_predictors()) %>%
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  prep(data = hr_data_organized_tbl)

hr_data_bake_tbl <- bake(recipe_obj, newdata = hr_data_organized_tbl) 

h2o.init()

hr_data_bake_h2o <- as.h2o(hr_data_bake_tbl)

hr_data_split <- h2o.splitFrame(hr_data_bake_h2o, ratios = c(0.7, 0.15), seed = 1234)

train_h2o <- h2o.assign(hr_data_split[[1]], ""train"" ) # 70%
valid_h2o <- h2o.assign(hr_data_split[[2]], ""valid"" ) # 15%
test_h2o  <- h2o.assign(hr_data_split[[3]], ""test"" )  # 15%

y <- ""Attrition""
x <- setdiff(names(train_h2o), y)

automl_models_h2o <- h2o.automl(
  x = x, 
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 15
)

automl_leader <- automl_models_h2o@leader

explainer <- lime::lime(
  as.data.frame(train_h2o[,-1]), 
  model          = automl_leader, 
  bin_continuous = FALSE
)

explanation <- lime::explain(
  x              = as.data.frame(test_h2o[1:10,-1]), 
  explainer      = explainer, 
  n_labels       = 1, 
  n_features     = 4,
  n_permutations = 500,
  kernel_width   = 1
)

explanation",2018-01-03T00:03:11,Matt Dancho,https://stackoverflow.com/users/6713793/matt-dancho,"7,278",48064171
48067686,48067686,2,"thanks for pointing this out! The offset parameter is actually not supported for H2O's distributed random forest. The parameters will be remove in a future release. A jira ticket for the issue can be found here:
https://0xdata.atlassian.net/browse/PUBDEV-5191",2018-01-02T20:51:42,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",48059291
48074018,48074018,0,"UPDATE AFTER YOUR COMMENT: The first column is the answer that your model is choosing. The remaining 205 columns are the prediction confidences for each of the 205 categories. (It implies whatever you are trying to predict is a factor (aka enum) column with 205 levels.) Those 205 columns should be summing to 1.0.


The column names should be a good clue: the first column is ""predict"", but the others are the labels of each of your 205 categories.




(Old answer, based on assuming it was 206 rows, 1 column!)


If predict is giving you a single column of output you have done a 
regression
, not a classification.




This sort of makes sense as the model's output is categorical variable with values 0 and 1 as possible values.




H2O has seen those 0s and 1s and assumed they are numbers, not categories. To do a classification you simply need to change that column to be an enum (H2O's internal term for it), aka factor (the R/Python H2O API term for it). (Do this step immediately after loading your data into H2O, and before splitting it or making any models.)


E.g. if 
data
 is your H2O Frame, and 
answer
 is the name of your column with the 0 and 1 catgeories in it, you would do:


data[""answer""] = data[""answer""].asfactor()



If any of your other columns look numeric but should actually be treated as factors, you can do multiple columns at once like this:


factorsList = [""cat1"", ""cat2"", ""answer""]
data[factorsList] = data[factorsList].asfactor()



You can also set the column types at the time you 
import the data with the col_types argument
.",2018-01-03T08:51:23,,,,48057200
49963920,49963920,1,"Though it's too late, may be helpful for someone else.
I had the same problem and solved it by installing 'h2o' using pip command:


pip install h2o



or if you are in IPython environment:


!pip install h2o",2018-04-22T08:19:27,Mohammad,https://stackoverflow.com/users/3222996/mohammad,118,48055082
61489365,61489365,1,"I had a similar issue on macOS, tried to install using 
conda install -c anaconda h2o
 as advised in 
anaconda documentation
 However, it did not reflect in my JupyterLab.
I finally resolved the issue by using 
!pip install h2o",2020-04-28T20:25:02,Path2Perfection,https://stackoverflow.com/users/13172138/path2perfection,13,48055082
48058547,48058547,0,"The 
recommended way
 to run python 3.6 on Ubuntu 16.04 is to use the PPA at 
https://launchpad.net/~jonathonf/+archive/ubuntu/python-3.6
 (and remember you then need to run it with 
python3.6
).


For 16.10 and 17.04 you don't need the ppa and can just do 
sudo apt-get install python3.6


Alternatively, upgrade your system to Ubuntu 17.10, and then python 3.6 will be the system python.  (17.10 is not a long-term support release, so plan to then upgrade to 18.04 LTS when it comes out in April.)",2018-01-02T09:37:38,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,48044253
50165198,50165198,0,"Finally, I figure this out:


# if you don't have virtualenv installed:
sudo apt-get install virtualenv

virtualenv -p python3.6 py_36_env
# Then activate the environment:
source ~/py_36_env/bin/activate



Once in the environment, then following the instructions for your specific system:  
https://github.com/h2oai/h2o4gpu",2018-05-03T23:43:19,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,48044253
48030879,48030879,1,"Thanks for bug report! It should already be fixed in the master branch of Sparkling Water and it will be part of the next release (ETA is next week).


Thanks,
Navdeep",2017-12-30T04:15:27,Navdeep Gill,https://stackoverflow.com/users/5244810/navdeep-gill,101,48020172
47992227,47992227,1,"Not just AutoML, but H2O generally, will only let you predict a single thing.


Without more information about what those 6 outputs represent, and their relationship to each other, I can think of 3 approaches.


Approach 1:
 6 different models, as you suggest.


Approach 2:
 Train an auto-encoder to compress 6 dimensions to 1 dimension. Then train your model to predict that single value. Then expand it back out. (E.g. by a lookup table on the training data, e.g. if your model predicts 1.123, and you have [1,2,3,4,5,6] was represented by 1.122, and [3.14,0,0,3.14,0,0] was represented by 1.125, you could choose [1,2,3,4,5,6], or a weighted average of those 2 closest matches.)  (Other dimension-reduction approaches, such as PCA, are the same idea.)


Approach 3:
 If the possible combinations of your 6 floats is a (relatively small) finite set, you could have an explicit lookup table, to N categories. 


I assume each are continuous variables, which is why they are float, so I expect approach 3 will be inferior to approach 2. If there is very little correlation/relationship between the 6 outputs, approach 1 is going to be best.",2017-12-27T12:29:12,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47984428
47992561,47992561,2,"The main idea of stacked ensemble (and the thing that differentiates it from other types of ensemble, such as random forest, GBMs, 
simple averaging of confidences
) is that it uses another machine learning model to determine how to weight the base learners. (This other model is the meta-learner.)


For your second question, you currently cannot specify any parameters, but there is 
a ticket for it
, so there is a fair chance it will be available in the next few months.


In the meantime, I would say paying attention to over-fitting in the base models, is more important than regularization in the meta-learner.",2017-12-27T12:53:57,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47983519
49410697,49410697,0,"I was wrong; the deployments can be found in 
steam/var/master/model


The files and directories that are located in 
/tmp
 are created by jetty.",2018-03-21T15:42:22,mtricht,https://stackoverflow.com/users/4193448/mtricht,452,47943530
47943291,47943291,2,"For pysparkling, you need to first create a PyPi library for 
h2o_pysparkling_2.1
 since you are using a Spark 2.1 cluster. The library you attached, 
pysparkling
 is something different. Also, you do not need to attach all those other libraries as the 
h2o_pysparkling_2.1
 package will already import the other necessary libraries.


Once you do that you can run:


from pysparkling import *

h2oConf = H2OConf(spark)
h2oConf.set(""spark.ui.enabled"", False)

h2oContext = H2OContext.getOrCreate(spark, h2oConf)",2017-12-22T14:43:52,,,,47942490
47938827,47938827,1,"d
 is 1 column, 6 rows.


d[,1]
 (in R, and in the H2O R API) selects column 1. 
d[1]
 is another way to write that.


d[1,]
 selects row 1.


d[1,1]
 selects the element that is in row 1, cell 1. 
d[6,1]
 selects the element in row 6, cell 1.


So, 
d.hex[1,1] == d.hex[6,1]
 returns TRUE.


Where it seems the H2O R API differs from normal R, is in some of the row/column queries, especially with errors: 
d[6]
 gives an error, but 
d.hex[6]
 returns the first row; 
d[,6]
 gives an error, but 
d.hex[,6]
 returns a 0x0 data frame!


The moral of the story: when dealing with individual elements, explicitly specify both row and column.",2017-12-22T09:16:37,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47927169
47927763,47927763,0,"you can get the column types for a dataframe using 
h2o.getTypes()


in your case 
h2o.getTypes(d.hex)


H2O requires that each column only contains one type, so if you are comparing row 1 and row 6 in the same column it will have the same type. If you try to put multiple types in a single column H2OFrame it will assign one of them to NA.",2017-12-21T15:10:36,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47927169
47938943,47938943,2,"Use ipython from the commandline, for 
h2o.demo()
.


If you want to stick with Juypter notebooks, there are a whole bunch of demos in that form here:  
https://github.com/h2oai/h2o-3/tree/master/h2o-py/demos",2017-12-22T09:25:02,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47925196
47895493,47895493,2,"The main benefit of using Sparkling Water over regular H2O is that it fits nicely into an existing Spark pipeline.  If you are not already using Spark, then it's best just to use the regular H2O library.  H2O is already distributed, so adding Spark to the equation does not provide any additional value in terms of distributed computing.  


H2O has a lot of the same components that Spark does, such as distributed data frames and shared, in-memory computation.  So yes, H2O is capable of managing distributed processing over a multi-core or multi-node cluster of computers.  That's exactly what it was designed to do.",2017-12-19T21:32:11,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47894205
47835702,47835702,0,"If you look at the top of the notebook you will see the below PATH setting which is set to hardcoded path:


PATH = os.path.expanduser(""~/h2o-3/"")



First download the dataset from the direct links below and set the proper path:




Train Data (train.csv.gz)
 


Test Data(test.csv.gz)




Now change the PATH to the location where datasets are available:


 PATH = ""/your_pyhsical_path/""



Also make sure test_df and train_df point to correct dataset above. 


Note: Deep Water project is no longer in active development so there is no further development from H2O, it is available as it is.",2017-12-15T15:48:28,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,47829169
47856079,47856079,1,"Use this function to prepare RowData object needed for H2O:


def rowToRowData(df: DataFrame, row: Row): RowData = {
  val rowAsMap = row.getValuesMap[Any](df.schema.fieldNames)
  val rowData = rowAsMap.foldLeft(new RowData()) { case (rd, (k,v)) => 
    if (v != null) { rd.put(k, v.toString) }
    rd
  }
  rowData
}",2017-12-17T14:27:47,Dmitry,https://stackoverflow.com/users/217079/dmitry,"2,993",47828510
48464483,48464483,0,"I have a complete answer here: 
https://stackoverflow.com/a/47898040/9120484

You can call map on df directly instead of on rdd.",2018-01-26T15:32:03,jliu3230,https://stackoverflow.com/users/9120484/jliu3230,56,47828510
47897313,47897313,1,"Here is an example of how to use a custom fold column (created from a list).  This is a modified version of the 
example Python code
 in the Stacked Ensemble page in the H2O User Guide.


import h2o
from h2o.estimators.random_forest import H2ORandomForestEstimator
from h2o.estimators.gbm import H2OGradientBoostingEstimator
from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator
from h2o.grid.grid_search import H2OGridSearch
from __future__ import print_function
h2o.init()

# Import a sample binary outcome training set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()

# Add a fold column, generate from a list
# The list has 10 unique values, so there will be 10 folds
fold_list = list(range(10)) * 1000
train['fold_id'] = h2o.H2OFrame(fold_list)


# Train and cross-validate a GBM
my_gbm = H2OGradientBoostingEstimator(distribution=""bernoulli"",
                                      ntrees=10,
                                      keep_cross_validation_predictions=True,
                                      seed=1)
my_gbm.train(x=x, y=y, training_frame=train, fold_column=""fold_id"")

# Train and cross-validate a RF
my_rf = H2ORandomForestEstimator(ntrees=50,
                                 keep_cross_validation_predictions=True,
                                 seed=1)
my_rf.train(x=x, y=y, training_frame=train, fold_column=""fold_id"")

# Train a stacked ensemble using the GBM and RF above
ensemble = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])
ensemble.train(x=x, y=y, training_frame=train)



To answer your second question about how to view the cross-validated predictions in a model.  They are stored in two places, however, the method that you probably want to use is: 
.cross_validation_holdout_predictions()
 This method returns a single H2OFrame of the cross-validated predictions, in the original order of the training observations:


In [11]: my_gbm.cross_validation_holdout_predictions()
Out[11]:
  predict        p0        p1
---------  --------  --------
        1  0.323155  0.676845
        1  0.248131  0.751869
        1  0.288241  0.711759
        1  0.407768  0.592232
        1  0.507294  0.492706
        0  0.6417    0.3583
        1  0.253329  0.746671
        1  0.289916  0.710084
        1  0.524328  0.475672
        1  0.252006  0.747994

[10000 rows x 3 columns]



The second method, 
.cross_validation_predictions()
 is a list which stores the predictions from each fold in an H2OFrame that has the same number of rows as the original training frame, but the rows that are not active in that fold have a value of zero.  This is not usually the format that people find most useful, so I'd recommend using the other method instead.


In [13]: type(my_gbm.cross_validation_predictions())
Out[13]: list

In [14]: len(my_gbm.cross_validation_predictions())
Out[14]: 10

In [15]: my_gbm.cross_validation_predictions()[0]
Out[15]:
  predict        p0        p1
---------  --------  --------
        1  0.323155  0.676845
        0  0         0
        0  0         0
        0  0         0
        0  0         0
        0  0         0
        0  0         0
        0  0         0
        0  0         0
        0  0         0

[10000 rows x 3 columns]",2017-12-20T00:47:41,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47817730
47809126,47809126,2,"The key parameter is 
ntrees
 (
epochs
 for a deep learning model). I will quote my own book (Practical Machine Learning with H2O, p.103):




When specifying epochs, or the number of trees, specify the total amount of
  training you want if you had started from scratch, not how many additional epochs or trees you want.




So, in your case, if your original model was made with 50 trees, your new model will effectively do nothing more than duplicating the existing model.  But if your original model was made with 
ntrees = 20
 and your new model uses that as a checkpoint but with 
ntrees = 50
 then it will add 30 more trees to the model.


Some parameters must stay the same, but some can be altered. E.g. you might lower the learning rate.",2017-12-14T08:42:46,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47784467
47785053,47785053,1,"You have an extra 
list()
 wrapped around 
glm_grid@model_ids
 that you don't need here and that's probably the source of the error.  The 
glm_grid@model_ids
 object is already a list.  Do this instead:


ensemble <- h2o.stackedEnsemble(x = predictors,
                                y = response,
                                training_frame = train,
                                model_id = ""ensemble"",
                                base_models = glm_grid@model_ids) 



See the R example 
here
 for more information.",2017-12-13T03:29:04,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47775759
47785027,47785027,0,"There's currently no way to set a ""description"" for a model (though it's a good idea, so I've added a 
JIRA ticket
 for this), but like Lauren said, if you can summarize your model in a string, you can set that as the 
model_id
.",2017-12-13T03:24:41,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47775255
47783765,47783765,1,"Multiclass support for Stacked Ensemble was only released very recently (in H2O 3.16.0.1), so you'll need to upgrade your H2O package for this to work.  


You can use 
update.packages(""h2o"")
 to upgrade to the latest CRAN version.",2017-12-13T00:30:48,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47773965
47775111,47775111,1,"Have you tried


grid_search_gbm.model_ids[:3]



it should give you the same model ids as 


grid_search_gbm.sorted_metric_table()['model_ids'][:3]",2017-12-12T14:34:11,Dan,https://stackoverflow.com/users/1011724/dan,45.7k,47773338
47784930,47784930,1,"If this is creating a bottleneck, you should use a 
MOJO (or POJO) model
 for row-wise scoring instead of a model loaded into memory in the H2O cluster.  This is what the MOJO/POJOs model format is designed for -- fast scoring without the need to convert between R data.frame and H2OFrame and also does not require running an H2O cluster.  You can skip R altogether here.


Alternatively, if your pipeline requires R, you can still use the MOJO/POJO model from R via the 
h2o.predict_json()
 function; it just requires you to convert your 1-row data.frame to a JSON string.  That might alleviate the bottleneck somewhat, though the straight Java with MOJO/POJO model scoring method (above) will be the fastest.


Here's an example of what this looks like using a GBM MOJO file:


library(h2o)

model_path <- ""~/GBM_model_python_1473313897851_6.zip""
json <- '{""V1"":1, ""V2"":3.0, ""V3"":0}'
pred <- h2o.predict_json(model = model_path, json = json)



Here's how to construct the JSON string from a 1-row data.frame:


df <- data.frame(V1 = 1, V2 = 3.0, V3 = 0)
dfstr <- sapply(1:ncol(df), function(i) paste(paste0('\""', names(df)[i], '\""'), df[1,i], sep = ':'))
json <- paste0('{', paste0(dfstr, collapse = ','), '}')",2017-12-13T03:09:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47759418
47760502,47760502,2,"I believe the problem is due to your python environment. When you install Anaconda, you need to use anaconda pip, to ensure that the installed packages are available in conda. 


The short answer is you can install the lastest stable version of H2O (3.16.0.2 as of today) using conda via 
h2oai
 channel instead of 
anaconda
 channel (h2o maintains it's own channel):


conda install -c h2oai h2o 



this should solve your issue. 


But more generally, the packages will appear in conda if you use anaconda pip. You can check which pip is being used by doing 


which pip


and making sure that the path to the pip is within your anaconda distribution; something like 
/home/<userdir>/anaconda/bin/pip
 instead of 
/usr/bin/pip
 


Same is true also for Python. Try checking if starting Python in terminal points to anaconda Python by doing 
which python
. If that's not the case, than you would need to add the conda installation of Python to your PATH variable. Please refer to conda docs for instructions 
https://conda.io/docs/user-guide/install/index.html


It would have been helpful if you had included information regarding your operating system in the question.",2017-12-11T20:00:13,karhayrap,https://stackoverflow.com/users/8502874/karhayrap,346,47759165
47741326,47741326,1,"You will need to convert them (a similar situation for .rdata files for R users). (It would be nice if binary files like that were supported, so you could try a feature request.)


You don't strictly need to double your storage space: you could load each npy file into the Python client, then use:


d = h2o.H2OFrame(my_npy)



(Last time I checked the source, this will actually save to a temporary csv file, then import that file, then delete the temporary file.)


Whether that step adds any significant time to your overall model training depends on the size of the data, if a multi-node cluster, and if your client is on the cluster, or other side of the world. But, for non-trivial models, the training time is always at least an order of magnitude more than loading data, so not worth too much effort trying to speed it up.",2017-12-10T17:12:29,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47722933
47723124,47723124,0,"When you start H2O cluster on Hadoop as below:


$ hadoop jar h2odriver.jar -nodes 3 -mapperXmx 10g -output /user/test



You will get an output as below just after the command is executed:


Determining driver host interface for mapper->driver callback...
    [Possible callback IP address: x.x.x.217]
    [Possible callback IP address: 127.0.0.1]
Using mapper->driver callback IP address and port: x.x.x.217:39562

(You can override these with -driverif and -driverport/-driverportrange.)



As you can see the callback IP address is selected by the hadoop runtime. So in most of the cases the IP address and the port is select by the Hadoop run time to find best available, 


You can also see the option of using -driverif x.x.x.x -driverport NNNNN along with hadoop command however I am not sure if this is really the good option. I haven't tested it besides the node ip which I am launching the cluster but it does work from the IP where the command it launched. 


Based on my experience, the most popular way to start H2O cluster on Hadoop is to let the Hadoop decide the cluster, they just need to parse the output of the link as below:


Open H2O Flow in your web browser: x.x.x.x:54321



Parse the above line to get the IP address/port of the driver to connect from R/Python API.",2017-12-08T22:33:30,,,,47722047
47715642,47715642,1,"In general, trying to interact directly with the H2O REST API isn't easy.  The vast majority of people use a pre-made API client like Python or R.


But if you really want to do this, I would debug it by comparing with something that's working.  Like the R client for H2O.


Write an R program that does this:


h2o.init()
h2o.startLogging()
h2o.importFile(""/path/to/data.csv"")



The startLogging() call will produce a detailed log file with all the REST API requests and responses.  Look at that and try to mimic it.


You can also refer to the autogenerated REST API documentation (
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/rest-api-reference.html
), but I would caution that if you tried to write a working client just based on the docs it would be hard.


Looking at a logged conversation from an already working client is by far your best bet.",2017-12-08T13:45:53,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",47714901
47749267,47749267,0,"library(h2o)


h2o.init() 
  h2o.startLogging()
  h2o.importFile(""
http://localhost:8082/datasets/tables/csv/vPrzC5TOQr6JTvnAYrU5AKyz8SP4ao8p.csv
"")




Time:     2017-12-11 11:55:09.237


GET       
http://localhost:54321/3/Cloud?skip_ticks=true
 postBody: 


curlError:         FALSE curlErrorMessage:   httpStatusCode:    200
  httpStatusMessage: OK millis:            7


{""__meta"":{""schema_version"":3,""schema_name"":""CloudV3"",""schema_type"":""Iced""},""_exclude_fields"":"""",""skip_ticks"":true,""version"":""3.16.0.2"",""branch_name"":""rel-wheeler"",""build_number"":""2"",""build_age"":""10 days"",""build_too_old"":false,""node_idx"":0,""cloud_name"":""H2O_started_from_R_vasiliy_gey658"",""cloud_size"":1,""cloud_uptime_millis"":306486,""cloud_healthy"":true,""bad_nodes"":0,""consensus"":true,""locked"":true,""is_client"":false,""nodes"":[{""__meta"":{""schema_version"":3,""schema_name"":""NodeV3"",""schema_type"":""Iced""},""h2o"":""localhost/127.0.0.1:54321"",""ip_port"":""127.0.0.1:54321"",""healthy"":true,""last_ping"":1512982506643,""pid"":97891,""num_cpus"":4,""cpus_allowed"":4,""nthreads"":4,""sys_load"":2.0917969,""my_cpu_pct"":-1,""sys_cpu_pct"":-1,""mem_value_size"":17408,""pojo_mem"":12224512,""free_mem"":1896688640,""max_mem"":1908930560,""swap_mem"":0,""num_keys"":56,""free_disk"":0,""max_disk"":0,""rpcs_active"":0,""fjthrds"":[-1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,0,0,0,0,0,0,0],""fjqueue"":[-1,0,0,0,0,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,0,-1,0,0,0,0,0,0,0,0],""tcps_active"":0,""open_fds"":-1,""gflops"":4.598999977111816,""mem_bw"":6.423728128E9}],""internal_security_enabled"":false}




Time:     2017-12-11 11:55:09.251


GET


http://localhost:54321/3/ImportFiles?path=http%3A%2F%2Flocalhost%3A8082%2Fdatasets%2Ftables%2Fcsv%2FvPrzC5TOQr6JTvnAYrU5AKyz8SP4ao8p.csv&pattern=

  postBody: 


curlError:         FALSE curlErrorMessage:   httpStatusCode:    200
  httpStatusMessage: OK millis:            6


{""__meta"":{""schema_version"":3,""schema_name"":""ImportFilesV3"",""schema_type"":""ImportFiles""},""_exclude_fields"":"""",""path"":""
http://localhost:8082/datasets/tables/csv/vPrzC5TOQr6JTvnAYrU5AKyz8SP4ao8p.csv
"",""pattern"":"""",""files"":[],""destination_frames"":[],""fails"":[""
http://localhost:8082/datasets/tables/csv/vPrzC5TOQr6JTvnAYrU5AKyz8SP4ao8p.csv
""],""dels"":[]}",2017-12-11T08:57:31,Vasiliy Nerozin,https://stackoverflow.com/users/7849530/vasiliy-nerozin,21,47714901
52252952,52252952,0,This is my import information.,2018-09-10T07:25:11,liyuhui,https://stackoverflow.com/users/7124383/liyuhui,"1,250",47714901
47801127,47801127,1,"Ended up temporarily capturing the warning output from stderr. Here is the relevant snippet:


import contextlib
import StringIO


@contextlib.contextmanager
def stderr_redirect(where):
    """"""
    Temporarily redirect stdout to a specified python object
    see https://stackoverflow.com/a/14197079
    """"""
    sys.stderr = where
    try:
        yield where
    finally:
        sys.stderr = sys.__stderr__


# make prediction on data
with stderr_redirect(StringIO.StringIO()) as new_stderr:
    preds = est.predict(frame_in)

print 'Prediction complete'
new_stderr.seek(0)
# capture any warning output
preds_stderr = new_stderr.read()



Then used regex to filter to only output lines that contained the column names and list of unseen values, then another regex to filter to get just the list (which I then remove whitespace and 
.split(',')
 to get a python string 
list
 of values). Can also use regex to get the column name from same line and pair them in a list of tuples.",2017-12-13T19:53:22,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",47702323
47807826,47807826,0,"You might consider H2O's GLRM (Generalized Low Rank Model).  It can impute missing values.


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glrm.html",2017-12-14T07:15:32,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,47702323
47702345,47702345,3,"for this scenario you might just want to use the h2o 
ifelse()
 method


(preds['1_bad'] < .0005).ifelse('good','bad')



or if you create a new column that consists of your thresholds and append it to your original frame you could do 


(preds['1_bad'] < preds['my_thresholds']).ifelse('good','bad')",2017-12-07T19:25:07,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47702022
47703614,47703614,1,"When you save a model by main model ID which has CV configuration,  the saved model does have all the cross validated models into it. If you save individual cross validated models on disk then they will all be considered as individual models and you will not see them all together. 


Here is an example:


Lets build GBM model with 5 folds:


prostate_df  = h2o.importFile(""https://raw.githubusercontent.com/Avkash/mldl/master/data/prostate.csv"")
response = ""CAPSULE""
features = setdiff(h2o.colnames(prostate_df), response)
prostate_gbm_cv5_model = h2o.gbm(x = features, y = response, training_frame = prostate_df, nfolds = 5)



You can get all the models from this object:


h2o.cross_validation_models(prostate_gbm_cv5_model)



You can access individual CV models as below:


h2o.cross_validation_models(prostate_gbm_cv5_model][[1]]
h2o.cross_validation_models(prostate_gbm_cv5_model)[[1]]@model_id



You will get total cross fold models count here:


length(h2o.cross_validation_models(prostate_gbm_cv5_model))



Lets save model to disk:


h2o.saveModel(object = prostate_gbm_cv5_model, path = ""/Users/avkashchauhan/Downloads"")



Lets load model from the disk:


model_from_disk = h2o.loadModel(""/Users/avkashchauhan/Downloads/GBM_model_R_1512067532473_2966"")



You will get all the CV models here:


h2o.cross_validation_models(model_from_disk)



Get CV models count:


length(h2o.cross_validation_models(model_from_disk))



Access CV model individually:


h2o.cross_validation_models(model_from_disk)[[1]]
h2o.cross_validation_models(model_from_disk)[[1]]@model_id",2017-12-07T20:54:38,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,47696590
47656801,47656801,4,"You can get a list of all models Id using the following:


> aml@leaderboard 



Note the output will be something as below:


                                               model_id      auc  logloss
1    DeepLearning_grid_0_AutoML_20171205_070022_model_1 0.808806 0.536941
2             GLM_grid_0_AutoML_20171205_070022_model_0 0.808672 0.524783
3 StackedEnsemble_BestOfFamily_0_AutoML_20171205_070022 0.797148 0.541090
4    DeepLearning_grid_0_AutoML_20171205_070022_model_2 0.793247 0.654405
5    StackedEnsemble_AllModels_0_AutoML_20171205_070022 0.788943 0.545078
6                 DeepLearning_0_AutoML_20171205_070022 0.783562 0.570281



After that you can use h2o.getModel() API to get any of the model as below:


> aml6 = h2o.getModel(""DeepLearning_0_AutoML_20171205_070022"")
> aml6



The above will give you the access to model = 6 from the AML leaderboard. Any of H2O Model API will work once you have access to model using the model_id from getModel() API.",2017-12-05T15:08:38,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,47656525
47656824,47656824,3,"To get any model you can do 
m <- h2o.getModel(model_id)
. The 
model_id
 can be any model id from the leaderboard. 


To see the list of non-default parameters, you can do 
h2o.getModel(model_id)@parameters
 or 
h2o.getModel(model_id)@allparameters
 to see all parameters, including default values. 


Hope this helps.


-Navdeep",2017-12-05T15:09:53,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47656525
72113388,72113388,-1,I had the same problem and solved it by changing the port in the h2o.init(port='XXXXX'),2022-05-04T12:58:37,Quentin Moreau,https://stackoverflow.com/users/13221294/quentin-moreau,39,47644657
47685623,47685623,5,"Your understanding is correct. H2O is currently developing Python 
datatable
 package, with the goal to make it as close to R's 
data.table
 as possible, both in syntax and in speed. The package will be released open source once it has a certain minimal number of features. Currently there is no set date for the release, but we hope to do it before the end of March.




UPDATE
: 
datatable
 is now publicly open.",2017-12-07T00:19:40,,,,47639493
47647429,47647429,3,"How does early stopping work here exactly?




Your assumption is correct. Early stopping will be used for each of the CV models, and then for the final model.




If I remove the validation_set here, ...




You are not specifying a validation data set in your example. Instead you are requesting cross-validation, by setting 
nfolds
.


If you remove 
nfolds
 and don't specify 
validation_frame
, it will use the score on the 
training
 data set to evaluate when early stopping should stop. As you are using GBM, that effectively means it will not stop early: GBM will always get better after adding each additional tree.


So, yes, always specify either 
validation_frame
, or 
nfolds
.


UPDATE BASED ON CODE EDIT


gbm_no_val_frame
: for each of the 5-folds, 1/5th of the data is used as the validation frame. The 
final model
 is built using all the data. It will only indirectly use early stopping: it will ignore the value of 
ntrees
 that you give, and instead use the average number of trees that the 5 cv models ended up using.  (Source: the top of p.102 of my book, but it is also in the GBM FAQ.)


As for your second question, my reading of 
the FAQ
 suggests that the above is still how early stopping works, and that the validation set is only used to give you additional statistics.


(For GBM I think this is fine; for deep learning, where progress is stochastic and can be a lot noisier, I find the early stopping point of each fold can be quite different, and less useful to decide early stopping of the final model; so I generally prefer not to use 
nfolds
, and just use a 
validation_frame
)",2017-12-05T06:32:37,,,,47625766
48216998,48216998,8,"AFAIS, the more powerful a machine learning method, the more complex to explain what's going on beneath it.


The advantages of 
GBM
 method (as you mentioned already) also bring in difficulties to understand the model. This is especailly true for numeric varialbes when a 
GBM
 model may utilise value ranges differently that some may have positive impacts whereas others have negative effects.


For 
GLM
, when there is no interaction specified, a numeric variable would be monotonic, hence you can have positive or negative impact examed.


Now that a total view is difficult, is there any method we can analyse the model? There are 2 methods we can start with:


Partial Dependence Plot


h2o
 provides 
h2o.partialplot
 that gives the partial (i.e. marginal) effect for each variable, which can be seen as the effect:


library(h2o)
h2o.init()
prostate.path <- system.file(""extdata"", ""prostate.csv"", package=""h2o"")
prostate.hex <- h2o.uploadFile(path = prostate.path, destination_frame = ""prostate.hex"")
prostate.hex[, ""CAPSULE""] <- as.factor(prostate.hex[, ""CAPSULE""] )
prostate.hex[, ""RACE""] <- as.factor(prostate.hex[,""RACE""] )
prostate.gbm <- h2o.gbm(x = c(""AGE"",""RACE""),
                       y = ""CAPSULE"",
                       training_frame = prostate.hex,
                       ntrees = 10,
                       max_depth = 5,
                       learn_rate = 0.1)
h2o.partialPlot(object = prostate.gbm, data = prostate.hex, cols = ""AGE"")





Individual Analyser


LIME
 package [
https://github.com/thomasp85/lime]
 provides capability to check variables contribution for each of observations.  Luckily, this r package supports 
h2o
 already.",2018-01-11T22:43:14,Sixiang.Hu,https://stackoverflow.com/users/5645311/sixiang-hu,"1,019",47609200
48373034,48373034,1,"You can try 
h2o.varimp(object)",2018-01-22T00:02:05,David Arenburg,https://stackoverflow.com/users/3001626/david-arenburg,92.2k,47609200
47563989,47563989,1,"Yes, this is definitely not the expected behavior, so it's a bug.  I filed a ticket for this 
here
.  Please use the work-around of putting the fold column name in the 
x
 vector for now.  Thanks for the report!",2017-11-30T00:19:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47563536
50728713,50728713,0,"reposting branden murray's solution: you can convert your json to csv. 


also here are the currently support file formats for driverless as of version 1.1.6 (May 29 2018)


File formats supported:




Plain text formats of columnar data (.csv, .tsv, .txt)


Compressed archives (.zip, .gz)


Excel files


Feather binary files


Python datatable binary directories",2018-06-06T20:07:21,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47544498
47523107,47523107,0,"The frustrating answer is that you cannot, and there are already two bug reports for it:


https://0xdata.atlassian.net/browse/PUBDEV-4516


https://0xdata.atlassian.net/browse/PUBDEV-3699


The simplest workaround is to download all your data, and do it in the R client. But with big data that may not be possible. If you must do it in the H2O cluster you will need a loop:




Copy rows with first unique value in d1.hex into 
tmp


tmp2 = h2o.merge(tmp, d2.hex, all.y = TRUE)




Repeat for each unique value in d1.hex. Then, at the end, do a 
h2o.rbind()
 on all your 
tmp2
 tables.


Or, the classic open source solution: implement the unimplemented code yourself (or beg/pay h2o.ai to implement it).",2017-11-28T02:42:14,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47514577
47492893,47492893,0,"I imagine your data is such that there is only way to learn it.


As a concrete example, if you set max_depth to 18, and another tree to max_depth to 24, but you only have a single entry in 
independent_variables
, then it is most likely only going to make trees of depth 1 or 2 in each case. So the different hyper parameter will make no difference.


If you cannot give the data that reproduces it, it would be interesting to output the summary of a default model (not using a grid, not using any particular parameters). Also, show the column types, and 
nrow(train)
. (If you have the wrong column types it could explain what you see.)",2017-11-26T03:58:21,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47475848
47503014,47503014,1,"The 
balance_classes
 option is not exposed to the user (as of H2O v3.16.0.1) in the AutoML function, however we have a 
ticket open
 to turn on automatic class-balancing when the response is reasonably imbalanced (e.g. <10% minority class).  This should be added soon.",2017-11-27T02:05:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47466620
47445683,47445683,0,"FLOW UI is great for prototyping something very quick with H2O without writing a single like of code. You can ingest the data, build desired model and the evaluate the results. Unfortunately FLOW UI is can not be extended for the reason you asked, and FLOW is limited for that reason. 


For collaborative learning you can write your whole application directly in python or R and it will work as expected.",2017-11-23T00:07:11,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,47445626
47406586,47406586,1,"I'm not sure about Qlik/etc but I've been following the announcements from one particular vendor called Yellowfin. Their latest release seems to integrate h2o capabilities into their reporting/visualizations:


https://www.yellowfinbi.com/blog/2017/11/yellowfin-7-4-enabling-data-science-across-the-enterprise-with-h2o-ai


Hope this helps.",2017-11-21T06:29:51,Martyn,https://stackoverflow.com/users/8977647/martyn,11,47406405
48068118,48068118,0,"POJO (Plain old java object) and MOJO (Model ObJect, Optimized) are H2O-generated models intended to be easily embeddable in any Java environment. As far as I know neither PowerBi nor Qlik do not support export in those models. But 
Apache Spark
 framework can generate POJOs for sure.",2018-01-02T21:31:11,,,,47406405
47371447,47371447,2,"You are correct that 
h2o.jar
 is meant to be the standalone version of H2O which is not meant for connecting to HDFS.


Using the appropriate 
h2odriver.jar
 for your particular hadoop distribution is the way to go.


The correct beginner instructions can be found here:




go to 
http://www.h2o.ai/download/


choose H2O ""Latest Stable Release""


choose tab ""Install on Hadoop""






It says to run the following command:


hadoop jar h2odriver.jar -nodes 1 -mapperXmx 6g -output hdfsOutputDirName



[ Note this is ""hadoop jar"", not ""java -jar"" as written in the question. ]


You should see output like this:


Determining driver host interface for mapper->driver callback...
[Possible callback IP address: 172.16.2.181]
[Possible callback IP address: 127.0.0.1]
...
Waiting for H2O cluster to come up...
H2O node 172.16.2.188:54321 requested flatfile
Sending flatfiles to nodes...
[Sending flatfile to node 172.16.2.188:54321]
H2O node 172.16.2.188:54321 reports H2O cluster size 1
H2O cluster (1 nodes) is up
(Note: Use the -disown option to exit the driver after cluster formation)

Open H2O Flow in your web browser: http://172.16.2.188:54321

(Press Ctrl-C to kill the cluster)
Blocking until the H2O cluster shuts down...



Then point your web browser to the place where it says to ""Open H2O Flow in your web browser"".


(The other addresses in the output are diagnostics, and not for end users.)


In this case, the python connection command would be:


h2o.connect(ip = '172.16.2.188', port = 54321)





I recommend going to Flow in a web browser, start importing a file by typing in ""hdfs://"", and seeing if autocompletion works.  If it does, your HDFS connection is working.",2017-11-18T21:52:20,,,,47371242
47352790,47352790,1,"your exception is thrown from this line of code:

https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/water/init/HostnameGuesser.java#L227


because of this condition:


 if (!allowedIps.contains(addr)) {
          throw new HostnameGuessingException(""IP address not found on this machine"");
        }



addr
 is the driver ip:




17/11/17 10:16:43 INFO InternalH2OBackend: Starting H2O client on the
  Spark Driver (192.168.103.46): -name
  sparkling-water-username_app-20171117101603-0031 -nthreads 40
  -ga_opt_out -quiet -log_level WARN -log_dir /path/to/app/h2ologs/app-20171117101603-0031 -baseport 54321 -client
  
-ip 192.168.103.46
 -flatfile /var/folders/gl/vgw262w9227cwqvzk595rbvjygdzh8/T/1510913803950-0/flatfile.txt




and 
allowedIps
 is calculated with the function 
calcPrioritizedInetAddressList
: 
https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/water/init/HostnameGuesser.java#L161


for some reason, 
addr
 is not in 
allowedIps
.

It's hard to know why from here, so I would recommend you to the run function 
calcPrioritizedInetAddressList
 by yourself, and try to understand the cause (it is private, but you can just copy the code)",2017-11-17T14:21:22,lev,https://stackoverflow.com/users/245024/lev,"4,107",47348556
47340470,47340470,1,"There currently isn't a method to drop duplicate rows but jira tickets have been created for 
Python
 and 
R


If however you have some sort of identifier like an id column with duplicated rows you might be able to use h2o's 
h2o.group_by
 method to help with the removal process.",2017-11-16T22:51:30,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47334892
47334677,47334677,1,"you could use 
stratified_kfold_column(n_folds=3, seed=-1)
 or 
stratified_split(test_frac=0.2, seed=-1)
 which create a column with the splits you can use to subset to split on later. 


see more about these in the 
docs",2017-11-16T16:28:15,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47321547
47312300,47312300,2,"[ Driverless AI is a brand new product, so it's evolving very fast.  This answer is for version 1.0.5 of Driverless AI, but could quickly become out of date. ]


Driverless AI uses (preferably GPU-based) xgboost tree models inside for evaluating variable importance during feature engineering, and for building a final model to make predictions.  But what you can do, after the experiment progress bar shows 100% complete, is download the transformed training and test data as .csv files.  These transformed .csv files include the engineered features as new columns, and can be used as inputs to H2O-3's GLM, for example.


Adding more kinds of models definitely makes sense for the future, though.",2017-11-15T16:15:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",47310212
47275509,47275509,3,"This is not what I would call ""overfitting"".  The reason you are seeing really good cross-validation metrics compared to your test metrics is that you have time-series data and so you can't use k-fold cross-validation to give you an accurate estimate of performance.


Performing k-fold cross-validation on a time-series dataset will give you overly-optimistic performance metrics because you are not respecting the time-series component in your data. Regular k-fold cross-validation will randomly sample from your whole dataset to create a train & validation set. Essentially, your validation strategy is ""cheating"" because you have ""future"" data included in your CV training sets (if that makes any sense).


I can see by your code that you understand that you need to train with ""past"" data and predict on ""future"" data, but if you want to read more about this topic, I'd recommend this 
article
 or this 
article
.


One solution is to simply look at test set performance as way to evaluate your model.  Another option is to use what's called ""rolling"" or ""time-series"" cross-validation, but H2O does not currently support that (though it seems like it might be added soon).  Here's a 
ticket
 for this if you want to keep track of the progress.",2017-11-13T23:58:41,,,,47274555
47238373,47238373,1,"[UPDATE: the answer was written before OP was edited to clarify that the problem emerges only 
after
 the conversion to POJO - see comments]


I bet that your dataset is highly 
imbalanced
, i.e. you have much more 1's in your training set than 0's.


Even if you get a good accuracy during model fit, in such cases accuracy as a metric is meaningless, and you should use precision, recall, and the confusion matrix instead - google ""class imbalance"" for more.


As an example, if 85% of your training labels are 1's, you can have a 85% accuracy ""classifier"" simply (and naively) by classifying 
all
 samples as 1 (which, arguably, is not what exactly you are looking to do).",2017-11-11T13:25:39,,,,47238248
47248102,47248102,5,"According to the deep-water link, it wants you to use 3.13.0. And your error message is saying you are using the 3.13.0.369 R package.


So, I think the problem is that you have 3.15.0.393 already running on this machine. Kill it and try again.


From inside your current R session, 
h2o.shutdown()
 
might
 work. If not, and you using unix, do something like 
ps auxw | grep h2o
 to find its PID and kill it; if using Windows search for h2o in the task manager. Or, cleanest, if you know you have an R (or Python, etc.) client where you started that 3.15.0 version of H2O, go and close that client.",2017-11-12T11:12:07,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47226254
47293646,47293646,2,"you can force the Connection


h2o.init(ip=Cluster_ip, port = Cluster_port, 


strict_version_check = FALSE, 


startH2O = FALSE)",2017-11-14T19:18:59,Puink,https://stackoverflow.com/users/8939886/puink,36,47226254
47230888,47230888,0,"Those are the default hyperparameter values for H2O algorithms which are hardcoded in the Java code and propagated through all the APIs (R, Python, Scala, and Flow).  The only way to change the default values is to set them manually in the client interface (like you are already doing), or you can fork the H2O source code, change them in Java, re-compile H2O and use your forked version with the modified settings.


You might be able to save a flow file with those settings and re-use that for your experiments.  This way you'd only need to change the value for the data file (single change) vs many changes to various hyperparameter values.


Lastly, if you are comfortable with R or Python, you could very easily write a script that has your preferred settings and use that instead.  If you want to use some existing R or Python Deep Learning code, there are some examples 
here
.",2017-11-10T20:48:43,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47222985
47244443,47244443,2,"Darren's response that you can't do this in H2O 
was
 correct until very recently -- H2O just 
removed the requirement
 that the base models had to be trained on the same set of inputs since it's not actually required by the Stacked Ensemble algorithm.  This is only available on the 
nightly releases
 off of master though, so even if you're on the latest stable release, you'd see an error that looks like this (in Flow, R, Python, etc) if you tried to use models that don't use the exact same columns:


Error: water.exceptions.H2OIllegalArgumentException: Base models are inconsistent: they use different column lists.  Found: [x6, x7, x4, x5, x2, x3, x1, x9, x8, x10, response] and: [x10, x16, x15, x18, x17, x12, x11, x14, x13, x19, x9, x8, x20, x21, x28, x27, x26, x25, x24, x23, x22, x6, x7, x4, x5, x2, x3, x1, response].  



The metalearning step in the Stacked Ensemble algorithm combines the 
output
 from the base models, so the number of inputs that went into training the base models doesn't really matter.  Currently, H2O still requires that the inputs are all part of the same original 
training_frame
 -- but you can use a different 
x
 for each base model if you like (the 
x
 argument specifies which of the columns from the 
training_frame
 you want to use in your model).


The way that Stacked Ensemble works in Flow is that it looks for models that are all ""compatible"", in other words -- trained on, the same data frame.  Then you select from this list which ones you want to include in the ensemble.  So as long as you are using the latest development version of H2O, then this is how to do what you want to do in Flow.




Here's an R example of how to ensemble models that are trained on different subsets of the feature space:


library(h2o)
h2o.init()

# Import a sample binary outcome training set into H2O
train <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
y <- ""response""
x <- setdiff(names(train), y)

# For binary classification, response should be a factor
train[,y] <- as.factor(train[,y])
test[,y] <- as.factor(test[,y])

# Train & Cross-validate a GBM using a subset of features
my_gbm <- h2o.gbm(x = x[1:10],
                  y = y,
                  training_frame = train,
                  distribution = ""bernoulli"",
                  nfolds = 5,
                  keep_cross_validation_predictions = TRUE,
                  seed = 1)

# Train & Cross-validate a RF using a subset of features
my_rf <- h2o.randomForest(x = x[3:15],
                          y = y,
                          training_frame = train,
                          nfolds = 5,
                          keep_cross_validation_predictions = TRUE,
                          seed = 1)

# Train a stacked ensemble using the GBM and RF above
ensemble <- h2o.stackedEnsemble(y = y, training_frame = train,
                                base_models = list(my_gbm, my_rf))

# Check out ensemble performance
perf <- h2o.performance(ensemble, newdata = test)
h2o.auc(perf)",2017-11-12T00:59:32,,,,47211420
47221025,47221025,1,"A stacked ensemble won't do this, as it does require identical inputs to each model. But you can set up a looser kind of ensemble... and that can almost, but not quite, be done in Flow.


Basically, you would create your four models. Then you would run predict on each of them. Each predict() will give you a new h2o frame. You would then need to cbind (column-bind) those four predictions together, to give you a new h2o frame with 4 binary columns (*). Then that would be fed into a 5th model, that gives you a combined result.


*: This is the bit I don't think you can do in Flow. You would need to export the data, combine it in another application, then bring it back in.


A better approach would be to be build a single model using all the inputs together. This would be both simpler, and give you more accurate results (as, e.g. interactions between insurance_amount and pat_age could be discovered). But, the (potentially major) downside is you cannot explain the model as four sets of yes/no any more. I.e. it becomes more black-box-like.",2017-11-10T10:48:08,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47211420
47201623,47201623,0,"[Summary]


What you are seeing is how Sparkling Water behaves.




[ Details... ]


Sparkling Water on YARN can run in two different ways:




the default way, where H2O nodes are embedded inside Spark executors and there is a single (Spark) YARN job,


the external H2O cluster way, where the Spark cluster and H2O cluster are separate YARN jobs (running in this mode requires more setup; if you were running in this way, you would know it)




H2O nodes do not support elastic cloud formation behavior.  Which is to say, once an H2O cluster is formed, new nodes may not join the cluster (they are rejected) and existing nodes may not leave the cluster (the cluster becomes unusable).


As a result, YARN preemption must be disabled for the queue where H2O nodes are running.  In the default way, it means the entire Spark job must run with YARN preemption disabled (and Spark dynamicAllocation disabled).  For the external H2O cluster way, it means the H2O cluster must be run in a YARN queue with preemption disabled.


Other pieces of information that might help:




If you are just starting on a new problem with Sparkling Water (or H2O in general), prefer a small number of large memory nodes to a large number of small memory nodes; fewer things can go wrong that way,


To be more specific, if you are trying to run with 36 executors that each have 1 GB of executor memory, that's a really awful configuration; start with 4 executors x 10 GB instead,


In general you don't want to start Sparkling Water with executors less than 5 GB at all, and more memory is better,


If running in the default way, don't set the number of executor cores to be too small; machine learning is hungry for lots of CPU.",2017-11-09T12:16:02,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",47201028
47192160,47192160,3,"To plot the decision boundary of an H2O model you will need to use 
matplotlib
. To use 
matplotlib
 you will need to convert the H2O predictions to numpy array or pandas dataframe before plotting. Here is an example for two dimensional binary classification problem: 


import h2o
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from h2o.estimators.random_forest import H2ORandomForestEstimator

h2o.init()
# import the data into H2O frame
hf = h2o.import_file('data.csv')

# Convert the target into a factor for classification
hf[:,-1] = hf[:,-1].asfactor()

# Split the data into train/test
hf_train, hf_test = hf.split_frame(ratios=[0.75])

# columns used for the training
X_cols = hf_train.col_names[:-1]

# last column is the target
y_col = hf_train.col_names[-1]

# Random Forest classifier
rf_clf = H2ORandomForestEstimator(ntrees=10)
rf_clf.train(X_cols, y_col, training_frame=hf_train, validation_frame=hf_test)
y_pred = rf_clf.predict(test_data=hf_test[:,X_cols])

# Convert to pandas df and create a mesh
df = hf.as_data_frame()
x1_min, x1_max = df.ix[:, 0].min() - .5, df.ix[:, 0].max() + .5
x2_min, x2_max = df.ix[:, 1].min() - .5, df.ix[:, 1].max() + .5
xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), 
                       np.arange(x2_min, x2_max, 0.02))

# predict the mesh values using H2O Random Forest and convert back to pandas df
Z = (rf_clf.predict(h2o.H2OFrame(np.c_[xx1.ravel(), xx2.ravel()]))).as_data_frame()
# reshape back to a 2d grid
zz = Z['p1'].values.reshape(xx1.shape)

# Plot the results
cm_scatt = ListedColormap(['b', 'r'])
fig = plt.figure(figsize=(12, 9))
cm_bright = ListedColormap(['b', 'g'])
# decision boundary
plt.contourf(xx1, xx2, zz, cmap='jet', alpha=.8)

# scatter plot of the full dataset
plt.scatter(df.ix[:, 0], df.ix[:, 1], c=df.ix[:, 2], cmap=cm_scatt,
                   edgecolors='k')
# Annotate with a model score
plt.text(xx1.max(), xx2.min(), round(rf_clf.r2(), 2), horizontalalignment='right', 
         color='w', fontsize=18)

# shutdown H2O cluster
h2o.cluster().shutdown()",2017-11-09T00:48:48,karhayrap,https://stackoverflow.com/users/8502874/karhayrap,346,47158520
47163450,47163450,1,"The documentation for how to use the POJO can be found here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




The following example is taken from the documentation.  You can see that the RowData object contains the name and value for the new data point to predict on.  You can just pass in string values and the EasyPredictModelWrapper will convert them into something the model knows how to use.


String modelClassName = ""your_pojo_model_class_name"";
hex.genmodel.GenModel rawModel;
rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();
EasyPredictModelWrapper model = new EasyPredictModelWrapper(rawModel);

RowData row = new RowData();
row.put(""Year"", ""1987"");
row.put(""Month"", ""10"");
row.put(""DayofMonth"", ""14"");
row.put(""DayOfWeek"", ""3"");
row.put(""CRSDepTime"", ""730"");
row.put(""UniqueCarrier"", ""PS"");
row.put(""Origin"", ""SAN"");
row.put(""Dest"", ""SFO"");

BinomialModelPrediction p = model.predictBinomial(row);",2017-11-07T16:57:44,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",47155492
47142383,47142383,5,"Yes, you will need to re-train the models using the same version of H2O (the version you train a model needs to be the same as the version you load the model with). H2O binary models are not compatible across major versions.  


For binary models, this is the standard practice -- you will have the same situation if you use scikit-learn, for example. 


If you want to use MOJO/POJO models in production, those are not tied to a particular version of H2O since they are just plain Java code and do not require the H2O cluster to be running.",2017-11-06T17:18:35,,,,47140630
67652951,67652951,0,"You can simply reinstall the old version. In anaconda, for example,


conda install -c h2oai h2o=3.14.0.7



Worked for me!",2021-05-22T18:32:22,MNK,https://stackoverflow.com/users/10897106/mnk,664,47140630
47168929,47168929,3,"(code example for main.java at the end)




you have it correctly and it is instantiated in this line 
rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();


the 
key
 is the column header and 
value
 is the actual value, if the H2Oframe doesn’t have column headers then H2O will automatically assign them 
C1
, 
C2
, etc. You can manually write this or use a loop using 
System.out.println(java.util.Arrays.toString(rawModel.getNames()));
 (see code snippet for example of this) 


there is not a method for this currently, but you can get the original values and reconstructed values and then calculate the MSE from that (see code snippet below, the last few lines calculate the MSE using the 
original
 and 
reconstructed
 arrays)




When I created my model I called it 
anomaly_model
 (see the code directly below, 
model_id
 is one of the parameters) and you will see that used in the last code snippet below, so if you use a different name you will need to update that part. 


anomaly_model <- h2o.deeplearning(x = names(train_ecg), training_frame = train_ecg, activation = ""Tanh"",
                              autoencoder = TRUE,hidden = c(50,20,50),sparse = TRUE,l1 = 1e-4,epochs = 100, model_id = 'anomaly_model')



Here is example code for how to create the 
main.java
 file, pass in column names for your keys, and calculate MSE with built in method results.


(Note: I generated random values for the 
row.put(key, values)
 you can put whatever you want there instead)


import java.io.*;
import hex.genmodel.easy.RowData;
import hex.genmodel.easy.EasyPredictModelWrapper;
import hex.genmodel.easy.prediction.*;

public class main {
  private static String modelClassName = ""anomaly_model"";

  public static void main(String[] args) throws Exception {
    hex.genmodel.GenModel rawModel;
    rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();
    EasyPredictModelWrapper model = new EasyPredictModelWrapper(rawModel);

    java.util.Random rng = new java.util.Random();
    RowData row = new RowData();
    for (String colName : rawModel.getNames()) {
      row.put(colName,rng.nextDouble());
    }

    AutoEncoderModelPrediction p = model.predictAutoEncoder(row);
    System.out.println(""original: "" + java.util.Arrays.toString(p.original));
    System.out.println(""reconstructedrowData: "" + p.reconstructedRowData);
    System.out.println(""reconstructed: "" + java.util.Arrays.toString(p.reconstructed));

    double sum = 0;
    for (int i = 0; i<p.original.length; i++) {
      sum += (p.original[i] - p.reconstructed[i])*(p.original[i] - p.reconstructed[i]);
    }
    double mse = sum/p.original.length;
    System.out.println(""MSE: "" + mse);
  }
}



Hope this helps!",2017-11-07T23:09:29,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",47140334
47248224,47248224,1,"The R, Python and JavaScript/CoffeeScript (i.e. Flow) clients all just make REST API calls to the H2O server. If your production workflow allows running the H2O java server in the background, you could load models and call predict on them, from your C# application, by making those same REST API calls.


It is 
well documented
 but it might be easier to do the desired steps in Flow, while watching the network calls being made.


Whether this is better than your own idea to export the model parameters from H2O and import them into a C# native library is open to debate, of course. Running the java server and using API calls is more likely to come out ahead if you are batching predictions.",2017-11-12T11:25:15,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,47140224
47149797,47149797,0,"No, H2O does not currently support this.",2017-11-07T04:05:12,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47140224
47179567,47179567,2,"Are you using Spark 2.1 or Spark 1.6 ? At the very start of the question you are referring to Spark 1.6 but bellow to Spark 2.1. I will assume it's 2.1.


Regarding your problem, you are mixing versions in your pom file. You specified dependency for H2O 3.14.0.7 however you are using Sparkling Water 2.1.1 which is based on H2O 3.10.4.2. Both versions require different versions of JODA library which is also reason why you see the error above.


The solution is to specify just sparkling water dependencies in you pom file. H2O are already bundled inside sparkling water and you are not supposed to specify them explicitly.


The dependencies you should put into your pom file are:




ai.h2o:sparkling-water-core_2.11:2.1.16


ai.h2o:sparkling-water-examples_2.11:2.1.16


no.priv.garshol.duke:duke:1.2




Also it is advised to use latest sparkling water versions, which in case for Spark 2.1.x is Sparkling Water 2.1.16.


We are working on this PR 
https://github.com/h2oai/sparkling-water/pull/352
 which will simplify this a little bit and instead of these 3 dependencies you could just specify one uber dependency as:




ai.h2o:sparkling-water-package_2.11:2.1.16",2017-11-08T12:18:27,,,,47129613
47106939,47106939,1,"This question has already been answered 
here
, but you need to set 
reproducible=TRUE
 when you initialize the 
H2ODeepLearningEstimator
 in Python (or in 
h2o.deeplearning()
 in R).


Even after setting 
reproducible=TRUE
, the H2O Deep Learning results are only reproducible when using a single core; in other words, when 
h2o.init(nthreads = 1)
.  The reasons behind this are outlined 
here
.


Also, per the H2O Deep Learning 
user guide
:




Does each Mapper task work on a separate neural-net model that is combined during reduction, or is each Mapper manipulating a shared object that’s persistent across nodes?


Neither; there’s one model per compute node, so multiple
Mappers/threads share one model, which is why H2O is not reproducible
unless a small dataset is used and force_load_balance=F or
reproducible=T, which effectively rebalances to a single chunk and
leads to only one thread to launch a map(). The current behavior is
simple model averaging; between-node model averaging via “Elastic
Averaging” is currently in progress.",2017-11-04T02:58:45,Community,https://stackoverflow.com/users/-1/community,1,47106887
47101832,47101832,0,"Like Tom commented, the prediction is not ""wrong"". You can infer from this that the threshold H2O has chosen is less than 0.27666.  You probably have 
imbalanced
 training data, otherwise H2O would have not picked a low threshold for classifying a predicted value of 0.27666 as a 1.  Does your training set include fewer examples of the positive class than the negative class?


If you don't like that threshold for whatever reason, then you can manually create your own.  Just make sure you know how to properly evaluate the effect of using different thresholds on the performance of your model, otherwise I'd recommend just using the default threshold.


The name, ""classProbabilities"" is a misnomer.  These are not 
actual
 probabilities, they are predicted values, though people often use the terms interchangeably.  Binary classification algorithms produce ""predicted values"" that look like probabilities when they're between 0 and 1, but unless a 
calibration process is performed
, they are not going to represent the probabilities.  Calibration is not necessarily a straight-forward process and there are many techniques.  Here's some more 
info
 about calibration methods for imbalanced data.  In H2O, you can perform calibration using Platt scaling using the 
calibrate_model
 option.  But this is probably not really necessary to what you're trying to do.


The proper way to use the raw output from a binary classification model is to only look at the predicted value for the positive class (you can simply ignore the predicted value for the negative class).  Then you choose a threshold which suits your needs, or you can use the default threshold in H2O, which is chosen to maximize the F1 score.  Some other software will use a hardcoded threshold of 0.5, but that will be a terrible choice if you don't have an even number of positive and negative examples in your training data.  If you have only a few positive examples in your training data, then the best threshold will be something much lower than 0.5.",2017-11-03T17:56:00,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47098219
47546267,47546267,1,"If RAM is a constraint (must be a very large corpus) then using 
mx.io.CSVIter
 could be a way to go. The CSV can be written in batches and will have a limited memory footprint during training. With vanilla 
mx.io.CSVIter
, will likely need to perform a reshaping to bring to features X batch X seq.length as an initial transformation to the data in the network. 


Another option could be to learn the embeddings within as part of the model, for example with this demo: 
http://dmlc.ml/rstats/2017/10/11/rnn-bucket-mxnet-R.html
 which also provides an example of custom iter with bucketing which also limits the RAM consumption.",2017-11-29T06:18:20,jeremiedb,https://stackoverflow.com/users/8717801/jeremiedb,41,47088983
47200287,47200287,0,"This was a bug and was fixed as part of this JIRA 
https://0xdata.atlassian.net/browse/SW-569
. This bug fix will be included in the next release of Sparkling Water.",2017-11-09T11:07:40,,,,47080618
47086496,47086496,4,"If you see an error that looks like this (key identifier being this statement 
Illegal argument: dir of function: importModel:
)


ERROR: Unexpected HTTP Status code: 412 Precondition Failed (url = http://localhost:54321/99/Models.bin/)

water.exceptions.H2OIllegalArgumentException
[1] ""water.exceptions.H2OIllegalArgumentException: Illegal argument: dir of function: importModel: H2O/H2O-XX/gbm_grid1_m02""



Then that probably means that you used a different version of H2O to train and save the model than you are using to load the H2O model.  This is a problem because 
binary models
 (models saved using the 
h2o.saveModel()
 function) are not compatible between different versions of H2O.


The simple solution is to use the same version of H2O to save and re-load the model.


An alternative solution is to use the 
POJO or MOJO
 type H2O models. This format for models exports the model as plain Java code and is not tied to a particular version of H2O.  It also does not require the H2O cluster to be running when you generate predictions on test data.  This is typically what you'd want to use if you were to take your H2O models to production.",2017-11-03T00:03:57,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47062207
47086394,47086394,0,"At this point, there is no built-in functionality for generating confidence intervals within H2O.  


As an aside:
 It says in the docs that the 
RFInfer
 package only works for regression trees.  So if you happen to be performing binary classification instead of regression and want CIs for the AUC or cross-validated AUC estimate of model performance, then you can use a package I wrote called 
cvAUC
 for your Random Forest predictions or any type of model predictions.",2017-11-02T23:51:21,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",47059131
47059392,47059392,0,"You need to install Thrift as per the 
documentation
 you linked:


The following are required in order to run the scoring package. [..] Apache Thrift (to run the TCP scoring service)
:




Installing Thrift


Thrift is required to run the scoring service in TCP mode, but it is
  not required to run the scoring module. The following steps are
  available on the Thrift documentation site at:
  
https://thrift.apache.org/docs/BuildingFromSource
.




$ sudo apt-get install automake bison flex g++ git libevent-dev \
  libssl-dev libtool make pkg-config libboost-all-dev ant
$ wget https://github.com/apache/thrift/archive/0.10.0.tar.gz
$ tar -xvf 0.10.0.tar.gz
$ cd thrift-0.10.0
$ ./bootstrap.sh
$ ./configure
$ make
$ sudo make install



@EDIT:


Please check if you can run (in the folder where you have those scripts) this:


$ source client_env/bin/activate
$ python -c 'from thrift.transport import TSocket'



If you get the same exception then please run:


pip install -r client_requirements.txt



And try running the script again.",2017-11-01T16:26:31,,,,47049458
47202121,47202121,2,"H2O stores data in a columnar compressed store, and is optimized to work well with datasets that have a huge number (billions+) of rows and a large number (thousands+) of columns.


Each column is stored in a bunch of what H2O calls chunks.  A chunk is a group of contiguous rows.  A chunk may be sparse, so if a chunk contains 10,000 rows and they are all missing, the amount of memory needed by that chunk can be really small.  But the chunk still needs to be there.


In practice, what that means is that H2O stores rows sparsely but does not store columns sparsely.  So it won't store things as efficiently as a pure sparse matrix package for wide data.


In your specific case, 800,000 columns is pushing H2O's limits.


One thing some people don't know about H2O is that it handles categorical columns  efficiently.  So if you are getting column explosion by manually 1-hot-encoding your data, you don't need to do that with H2O.  Another data representation would be more efficient.",2017-11-09T12:40:01,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",47041404
47239891,47239891,0,"The unknown categorical level is treated as an NA for that column.


Without knowing the details of your data (including the cost implications of false positives and false negatives), I wouldn't say that you need to threshold rows that have NAs any differently than for rows that do not.  (The NA is already handled quite well by DRF.)


Note the built-in threshold is max-F1 (not 0.5).  So if you are changing the threshold for rows with unknown values, it's relative to max-F1 (not 0.5).  Using your own threshold is certainly a valid approach.


If you want to visualize your trees to more easily see how the NAs behave, you can do so following the instructions here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo




There are also other strategies for dealing with it, like target-encoding your categorical input column and treating an NA as the average target value.  (This effectively turns a categorical variable into a numeric one, but requires you to preprocess the data.)",2017-11-11T16:00:04,,,,47025680
47023930,47023930,2,"If the H2O cluster is still running, then your models are all still there (assuming they finished training successfully).  There are a number of ways that you can check if the H2O Java cluster is still running.  In R, you can check the output of these functions:


h2o.clusterStatus()
h2o.clusterInfo()



At the command line (look for a Java process):


ps aux | grep java



If you started H2O from R, then you should see a line that looks something like this:


yourusername     26215   0.0  2.7  8353760 454128   ??  S     9:41PM  21:25.33 /usr/bin/java -ea -cp /Library/Frameworks/R.framework/Versions/3.3/Resources/library/h2o/java/h2o.jar water.H2OApp -name H2O_started_from_R_me_iqv833 -ip localhost -port 54321 -ice_root /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T//Rtmp6XG99X



H2O models do not live in the R environment, they live in the H2O cluster (a Java process).  It sounds like what's happening is that the R object representing your model (which is actually just a pointer to the model in the H2O cluster) is having issues finding the model since your cluster disconnected.  I don't know exactly what's going on because you haven't posted the errors you're receiving when you try to use 
h2o.predict()
 or 
h2o.performance()
.


To get the model back, you can use the 
h2o.getModel()
 function.  You will need to know the ID of your model.  If your model object (that's not working properly) is still accessible, then you can see the model ID easily that way: 
model@model_id
  You can also head over to H2O Flow in the browser (by typing: 
http://127.0.0.1:54321
 if you started H2O with the defaults) and view all the models by ID that way.


Once you know the model ID, then refresh the model by doing:


model <- h2o.getModel(""model_id"")



This should re-establish the connection to your model and the 
h2o.predict()
 and 
h2o.performance()
 functions should work again.",2017-10-30T20:49:46,,,,46977685
46972127,46972127,37,"import h2o
import pandas as pd

df = pd.DataFrame({'col1': [1,1,2], 'col2': ['CÃ©sar ChÃ¡vez Day', 'CÃ©sar ChÃ¡vez Day', 'CÃ©sar ChÃ¡vez Day']})
hf = h2o.H2OFrame(df)



Since the problem that you are facing is due to the high number of NANs in the dataset, this should be handled first. There are two ways to do so.




Replace 
NAN
 with a single, obviously out-of-range value. 
Ex. If a feature varies between 0-1 replace all 
NAN
 with -1 for that feature.


Use the class 
Imputer
 to handle NAN values. This will replace 
NAN
 with either of mean, median or mode of that feature.",2017-10-27T09:45:36,,,,46971969
47023695,47023695,7,"If there are large number of missing values in your data and you want to increase the efficiency of conversion, I would recommend explicitly specifying the column types and 
NA
 strings instead of letting H2O interpret it. You can pass a list of strings to be interpreted as 
NA
s and a dictionary specifying column types to 
H2OFrame()
 method. 


It will also allow you to create custom labels for the sensors that are not present, instead of having a generic ""not available"" (impute NaN values with a custom string in pandas).   


import h2o    

col_dtypes = {'col1_name':col1_type, 'col2_name':col2_type}
na_list = ['NA', 'none', 'nan', 'etc']

hf = h2o.H2OFrame(df, column_types=col_dtypes, na_strings=na_list)



For more information - 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/_modules/h2o/frame.html#H2OFrame


Edit: @ErinLeDell 's suggestion to use 
h2o.import_file()
 directly with specifying column dtypes and NA string will give you the largest speed-up.",2017-10-30T20:31:57,,,,46971969
46959079,46959079,2,"When you start H2O with 
h2o.init()
 from R, the stdout and stderr files should be saved to a temporary directory (see R's 
tempdir()
 to see the path).  This temporary directory should be removed when the R session exits.  It seems as though this is not working with RStudio, however it works if you are using R from the command line.  I'm not sure if this is a setting that can be changed in RStudio or if this is an RStudio bug.


But you can take more control yourself.  You can start H2O by hand using java on the command line and then connect from R using 
h2o.init()
.


java -Xmx5g -jar h2o.jar



In this example, I started H2O with 5 GB of Java heap memory, but you should increase that if your data is larger.  Then connecting in R will look like this:


> h2o.init()
 Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         16 hours 34 minutes 
    H2O cluster version:        3.15.0.99999 
    H2O cluster version age:    17 hours and 25 minutes  
    H2O cluster name:           H2O_started_from_R_me_exn817 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   4.43 GB 
    H2O cluster total cores:    8 
    H2O cluster allowed cores:  8 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.3.2 (2016-10-31) 



So if you want to redirect both stdout and stderr to devnull you simply add the redirect command to the end of the java command to start the H2O cluster and connect to H2O from R again.  To redirect both stderr and stdout, you append 
> /dev/null 2>&1
 like this:


java -Xmx5g -jar h2o.jar > /dev/null 2>&1 &",2017-10-26T16:12:12,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46956051
52121426,52121426,0,"Encountered this in a spark shell running H2O. The shell had 50 executors connected and this caused the 
/tmp
 directories on those nodes to eventually cause storage issues. 


When 
h2o.init()
 is called it creates jvm's. The logging from h2o is handled by these jvm's. But when the shell is shutdown those jvm's persist and just log heartbeat errors in 
/tmp
 in perpetuity. You will need to find the jvm's associated with h2o and shut them down. I believe in my case the specific process names where 
water.H2OApp",2018-08-31T19:05:29,Grr,https://stackoverflow.com/users/5061557/grr,16.1k,46956051
72425119,72425119,0,"I found it easier to take care of the problem by removing those files after running every model.


unlink(list.files(tempdir(), full.names = TRUE), recursive = TRUE)



This helps remove the temporary files when I run the multiple models in a loop.",2022-05-29T15:48:51,Deep,https://stackoverflow.com/users/13605220/deep,57,46956051
46957302,46957302,1,"In your local system environment you can set the JAVA_HOME as below: 


JAVA_HOME=C:\\PATH_TO_YOUR_JAVA_1.8_INSTALL



After that you can check and confirm that your command line environment shows 64bit Java along with Sys.getenv call shows the 64 bit Java 1.8 as your java environment. 


> Sys.getenv(""JAVA_HOME"")
[1] ""/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home""



If it is not set in R environment then you can set it as below too:


> Sys.setenv(JAVA_HOME= ""/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home"")



Make sure to restart R/Rstudio with clean session so you have updated R with new environment. After that when you will call h2o initialize function it will pickup the right Java to get it started. 


h2o.init()",2017-10-26T14:42:23,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46938002
46937457,46937457,11,"The function you're looking for is called 
h2o.no_progress()
 and it shuts off all progress bars in your session.  If you search the Python module docs for 
""progress""
, you'll find it.",2017-10-25T16:20:34,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46937314
46960523,46960523,0,"Most likely it's a configuration error that is unique to your environment.  Ask for help from your organization's LDAP/AD experts.  It's not going to be easy for anyone externally to help you.


Here are some tricks I recommend for debugging LDAP issues.


First, don't start by debugging this directly in Sparkling Water.  Debug it in pure standalone H2O with no Hadoop or Spark, so you can isolate the problem and it's easy to see what's happening and you don't have to hunt for stdout/stderr/logs.


Second, you can enable the DEBUG jetty log level and get more information about what the ldaploginmodule is doing by adding the following file to the classpath:


jetty-logging.properties


org.eclipse.jetty.util.log.class=org.eclipse.jetty.util.log.StdErrLog
org.eclipse.jetty.LEVEL=DEBUG



So run like this (make sure jetty-logging.properties is in the current directory):


java -cp h2o.jar:. water.H2OApp -ldap_login -login_conf ldap-config-file",2017-10-26T17:35:54,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46924980
49036925,49036925,0,"Two additional notes:




do not use Sparkling Water 1.6  and upgrade 


after upgrade, for LDAP conf you need to modify LoginModlue reference to 
ai.h2o.org.eclipse.jetty.plus.jaas.spi.LdapLoginModule required",2018-02-28T19:12:58,Michal,https://stackoverflow.com/users/5089773/michal,437,46924980
46896837,46896837,0,"There is a problem with this line:


train = h2o.import_file(""(""https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"""")



You have extra "" and (, it should be:


train = h2o.import_file(""https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"")



Then you'll see that 
train
 and also 
print(train)
 give output:


In [6]: train
Out[6]:   sepal_len    sepal_wid    petal_len    petal_wid  class
-----------  -----------  -----------  -----------  -----------
        5.1          3.5          1.4          0.2  Iris-setosa
        4.9          3            1.4          0.2  Iris-setosa
        4.7          3.2          1.3          0.2  Iris-setosa
        4.6          3.1          1.5          0.2  Iris-setosa
        5            3.6          1.4          0.2  Iris-setosa
        5.4          3.9          1.7          0.4  Iris-setosa
        4.6          3.4          1.4          0.3  Iris-setosa
        5            3.4          1.5          0.2  Iris-setosa
        4.4          2.9          1.4          0.2  Iris-setosa
        4.9          3.1          1.5          0.1  Iris-setosa

[150 rows x 5 columns]


In [7]: train.nrow
Out[7]: 150

In [8]: print(train)
  sepal_len    sepal_wid    petal_len    petal_wid  class
-----------  -----------  -----------  -----------  -----------
        5.1          3.5          1.4          0.2  Iris-setosa
        4.9          3            1.4          0.2  Iris-setosa
        4.7          3.2          1.3          0.2  Iris-setosa
        4.6          3.1          1.5          0.2  Iris-setosa
        5            3.6          1.4          0.2  Iris-setosa
        5.4          3.9          1.7          0.4  Iris-setosa
        4.6          3.4          1.4          0.3  Iris-setosa
        5            3.4          1.5          0.2  Iris-setosa
        4.4          2.9          1.4          0.2  Iris-setosa
        4.9          3.1          1.5          0.1  Iris-setosa

[150 rows x 5 columns]",2017-10-23T19:13:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46891829
46853942,46853942,1,"I don't know of a way to change the frame id from Flow once the data has been parsed.  If you want to change it when you're uploading, then you do that here (see ID field):




Though that is not helpful if you're talking about renaming frames that were created in the modeling process.  An alternative is to open up R or Python, connect to your H2O cluster, and change it from there using the 
h2o.assign()
 function (same function name in R/Py).",2017-10-20T17:00:42,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46853591
46852390,46852390,1,"Based on your problem you need to setup H2O cluster to run with more memory to fit your 10000 tree random forest. Looks like the H2O cluster (Java process) is created with 8GB memory however based on your 10000 tree setting it needs more memory then given 8GB. 


max_mem_size 7624.720384 MB (Configured)
heapUsedGC - 7626.295912 MB (Required)



Looks like you are using H2O in R so you can pass max_mem_size=12G (means H2O cluster will start with 12GB memory) in your h2o.init() function as below which should fit your random forest requirement:


h2o.init(max_mem_size=""12G"")



You can also check your H2O cluster details with the command below:


> h2o.clusterInfo()
R is connected to the H2O cluster: 
    H2O cluster uptime:         19 seconds 80 milliseconds 
    H2O cluster version:        3.14.0.3 
    H2O cluster version age:    27 days  
    H2O cluster name:           H2O_started_from_R_avkashchauhan_hwc594 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   10.65 GB <=== This is the max memory size
    H2O cluster total cores:    8 
    H2O cluster allowed cores:  8 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.4.1 (2017-06-30)",2017-10-20T15:26:55,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46852111
47898040,47898040,2,"I just posted a 
solution
 that actually uses DataFrame/Dataset. The post used a Star Wars dataset to build a model in R and then scored MOJO on the test set in Spark. I'll paste the only relevant part here:


Scoring with Spark (and Scala)


You could either use spark-submit or spark-shell. If you use spark-submit, h2o-genmodel.jar needs to be put under lib folder of the root directory of your spark application so it could be added as a dependency during compilation. The following code assumes you're running spark-shell. In order to use h2o-genmodel.jar, you need to append the jar file when launching spark-shell by providing a --jar flag. For example:


/usr/lib/spark/bin/spark-shell \
--conf spark.serializer=""org.apache.spark.serializer.KryoSerializer"" \
--conf spark.driver.memory=""3g"" \
--conf spark.executor.memory=""10g"" \
--conf spark.executor.instances=10 \
--conf spark.executor.cores=4 \
--jars /path/to/h2o-genmodel.jar



Now in the Spark shell, import the dependencies


import _root_.hex.genmodel.easy.{EasyPredictModelWrapper, RowData}
import _root_.hex.genmodel.MojoModel



Using DataFrame


val modelPath = ""/path/to/zip/file""
val dataPath = ""/path/to/test/data""

// Import data
val dfStarWars = spark.read.option(""header"", ""true"").csv(dataPath)
// Import MOJO model
val mojo = MojoModel.load(modelPath)
val easyModel = new EasyPredictModelWrapper(mojo)

// score
val dfScore = dfStarWars.map {
  x =>
    val r = new RowData
    r.put(""height"", x.getAs[String](1))
    r.put(""mass"", x.getAs[String](2))
    val score = easyModel.predictBinomial(r).classProbabilities
    (x.getAs[String](0), score(1))
}.toDF(""name"", ""isHumanScore"")



The variable score is a list of two scores for level 0 and 1. score(1) is the score for level 1, which is ""human"". By default the map function returns a DataFrame with unspecified column names ""_1"", ""_2"", etc. You can rename the columns by calling toDF.


Using Dataset


To use the Dataset API we just need to create two case classes, one for the input data, and one for the output.


case class StarWars (
  name: String,
  height: String,
  mass: String,
  is_human: String
)

case class Score (
  name: String,
  isHumanScore: Double
)


// Dataset
val dtStarWars = dfStarWars.as[StarWars]
val dtScore = dtStarWars.map {
  x =>
    val r = new RowData
    r.put(""height"", x.height)
    r.put(""mass"", x.mass)
    val score = easyModel.predictBinomial(r).classProbabilities
    Score(x.name, score(1))
}



With Dataset you can get the value of a column by calling x.columnName directly. Just notice that the types of the column values have to be String, so you might need to manually cast them if they are of other types defined in the case class.",2017-12-20T02:42:25,,,,46849368
46853122,46853122,1,"If you want to perform scoring with POJO or MOJO in spark you should be using RowData which is provided within h2o-genmodel.jar class as row by row input data to call easyPredict method to generate scores. 


Your solution will be to read the parquet file from HDFS and then for each row, convert that to RowData object by filling each entry and then pass that to your POJO scoring function. Remember POJO and MOJO they both use exact same scoring function to score and the only difference is on how the POJO Class is used vs MOJO resources zip package is used. As MOJO are backward compatible and could work with any newer h2o-genmodel.jar it is best if you use MOJO instead of POJO.


Following is the full Scala code you can use on Spark to load a MOJO model and then do the scoring:


import _root_.hex.genmodel.GenModel
import _root_.hex.genmodel.easy.{EasyPredictModelWrapper, RowData}
import _root_.hex.genmodel.easy.prediction
import _root_.hex.genmodel.MojoModel
import _root_.hex.genmodel.easy.RowData

// Load Mojo
val mojo = MojoModel.load(""/Users/avkashchauhan/learn/customers/mojo_bin/gbm_model.zip"")
val easyModel = new EasyPredictModelWrapper(mojo)

// Get Mojo Details
var features = mojo.getNames.toBuffer

// Creating the row
val r = new RowData
r.put(""AGE"", ""68"")
r.put(""RACE"", ""2"")
r.put(""DCAPS"", ""2"")
r.put(""VOL"", ""0"")
r.put(""GLEASON"", ""6"")

// Performing the Prediction
val prediction = easyModel.predictBinomial(r).classProbabilities 



Here
 is an example of reading parquet files in Spark and then saving as CSV. You can use the same code to read the parquet from HDFS and then pass the each row as RowData to above example. 


Here
 is detailed example of using MOJO model in spark and perform scoring using RowData.",2017-10-20T16:09:55,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46849368
46819604,46819604,1,"There is no support for converting between H2O and Spark frames natively in either the 
h2o
 or the 
SparkR
 packages.  You would have to use 
rsparkling
 (which depends on 
sparklyr
) or do a conversion from Spark DataFrame -> R data.frame -> H2O Frame.


You mentioned Hadoop and HIVE... just to clarify, neither of those are requirements for using 
rsparkling::as_h2o_frame()
.",2017-10-18T21:32:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46815427
54135983,54135983,0,"Since none of the above worked for me, the solution was: 




Saving spark dataframe on a csv (folder csv)


Using apply function to open each csv file using the package Rio Import 


tmp<- lapply(list.files(""data/csvfolder.csv""), function(x){rio::import(paste0(""data/csvfolder.csv/"", x))})
df00<- do.call(""rbind"", tmp)


Use the ""df00"" as a dataframe to use as you wish,, 




Hope that works for you guys! Collect and as.data.frame are too weak depending on the type of data being used.


Chers",2019-01-10T19:50:25,Joni Hoppen,https://stackoverflow.com/users/1972777/joni-hoppen,688,46815427
46818677,46818677,0,"This is the script you can use the launch the H2O cluster on a different port:


## Importing Libraries
from pysparkling import *
import h2o

## Setting H2O Conf Object
h2oConf = H2OConf(sc)
h2oConf

## Setting H2O Conf for different port
h2oConf.set_client_port_base(54300)
h2oConf.set_node_base_port(54300)

## Gett H2O Conf Object to see the configuration
h2oConf

## Launching H2O Cluster
hc = H2OContext.getOrCreate(spark, h2oConf)

## Getting H2O Cluster status
h2o.cluster_status()



I have also written a 
blog
 post to explain it in details.",2017-10-18T20:26:42,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46814953
46820538,46820538,0,"I downloaded your 160MB file locally to experiment and found your data is badly formatted. 


The above error you see only because the last column in your dataset is UUID so H2O make sure to set to column type as UUID however 206000 rows after the last columns shows numeric values which cause H2O to panic while setting numeric value as UUID. 


I was able to load up to 206000 rows in H2O without any problem however 207000 rows gave me error so you can experiment which rows are bad formatted. You can run the following command to get all the rows from 206000 to 207000, and when loading these 1000 rows you will see the same problem. 


$ sed -n '206000,207000p' < consumer_complaints.csv > consumer_complaints_bad.csv



If you can not fix your data with bad formatting at row level, you can save all the columns as string. This way H2O will ingest all the data as string and then later you can analyze the data, clean it properly then change to type properly as enum, or int or UUID. Not a good option to try because your data is already bad formatted but this way you could load all the data into H2O.",2017-10-18T23:08:06,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46799076
46787640,46787640,4,"H2O-3 stores data completely in-memory in a distributed column-compressed distributed key-value store.


No swapping to disk is supported.


Since you are alluding to 
mapperXmx
, I assume you are talking about running H2O in a YARN environment.  In that case, the total YARN container size allocated per node is:


mapreduce.map.memory.mb = mapperXmx * (1 + extramempercent/100)




extramempercent
 is another (rarely used) command-line parameter to h2odriver.jar.  Note the default 
extramempercent
 is 10 (percent).


mapperXmx
 is the size of the Java heap, and the extra memory referred to above is for additional overhead of the JVM implementation itself (e.g. the C/C++ heap).


YARN is extremely picky about this, and if your container tries to use even one byte over its allocation (mapreduce.map.memory.mb), YARN will immediately terminate the container.  (And for H2O-3, since it's an in-memory processing engine, the loss of one container terminates the entire job.)


You can set 
mapperXmx
 and 
extramempercent
 to as large a value as YARN has space to start containers.",2017-10-17T10:09:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46787105
46734964,46734964,2,"Right now H2O bundles only GPU-enabled and minimal (no GPU, no OMP) version of XGBoost. However, there is an experimental change in branch 
mm/xgb_upgrade
 which contains OMP-enabled version of XGBoost (instead of minimal version): 
https://github.com/h2oai/h2o-3/tree/mm/xgb_upgrade",2017-10-13T17:16:24,Michal,https://stackoverflow.com/users/5089773/michal,437,46727500
46773695,46773695,0,Building the mm/xgb_upgrade works. Which jira ticket is referring to this issue?,2017-10-16T15:21:32,nima,https://stackoverflow.com/users/7885172/nima,21,46727500
46714119,46714119,1,"I'll address the two questions at the end for now and update my answer if you can provide a public dataset that replicates the NA in the leaderboard problem.






what XRT_xxx models represent? 






XRT = A Random Forest that uses Extremely Randomized Trees (aka 
ExtraTrees
).  This is achieved by setting 
histogram_type = ""Random""
.






if there is any way to specify n-folds cross validation.






Right now you can use the 
fold_column
 to specify custom folds, so you could can change the number of folds this way.  This should be a column of integers or factors that specify the fold, so the simplest way to create this is something like (R example):  


# train should be your training_frame; we will use iris as an example
data(""iris"")
train <- as.h2o(iris)

# add a fold column that uses 10 folds
train[,""fold""] <- as.h2o(rep_len(1:10, nrow(train)))



Then set 
fold_column = ""fold""
 in 
h2o.automl()
.


In the next release, we will expose the 
nfolds
 argument directly to make this easier (follow progress on this task 
here
).",2017-10-12T16:01:05,,,,46713688
46718742,46718742,0,"Did you try to lower the min_split_improvement parameter? The default of 1e-5 is already microscopic but relevant when having a million lines.
I guess all trees after the 64th (in your example) will be trivial?",2017-10-12T20:55:10,Andreas Holzhammer,https://stackoverflow.com/users/6603785/andreas-holzhammer,51,46713293
46713654,46713654,0,"If the 0.1 learning rate isn't working for you, I'd recommend decreasing the learning rate so something like 0.01 or 0.001. Although you state that the training error stops decreasing after tree 64, I'd still recommend trying to add more trees, at least 1000-5000, especially if you try out a slower learning rate.",2017-10-12T15:37:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46713293
46727758,46727758,0,"Are you able to run other YARN jobs?  (Like the pi example.)


The application id reveals that your Hadoop cluster that was started on Thu Oct 12 2017 07:36:36 UTC (ie yesterday) and this is the first (and second) job that cluster ever tried to run.


Also, the size of the nodes in the cluster are really really tiny.


All of this looks to me like you are trying to be your own Hadoop administrator and didn't get it to work yet.  :)


Keep trying, and when your cluster is configured properly, H2O will run.",2017-10-13T10:25:40,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46702563
46716635,46716635,0,"Based on the partial logs you provided, the following line helps to understand a little: 


2017-10-12 07:45:02,172 FATAL [IPC Server handler 1 on 39365] 
 org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: 
  attempt_1507726330188_0001_m_000002_0 - exited : 
    java.lang.RuntimeException: java.lang.ClassNotFoundException: Class water.hadoop.h2omapper not found



It is clear the task id #2 instance #0 (or first instance) failed due to missing class. So if task #2 shows error, means the other task #1 is already running. Which also means the job has been start or it is in running state. So the problem happened during the job execution stage. It means the DataNode where this particular task was being executed, is not able to find the H2O Driver library. So it is possible the node or the file system on the node is not available due to some reason. If you study your detailed log you will be able to see why this could happen. 


[Additional Details]


Either due to permission or file system issue h2odriver.jar is not accessible for any of the mapper and that is the reason your job is not started. You should make sure to fix the Hadoop permissions and accessibility properly so you can launch any ""hadoop"" command without root and need to super user alias.",2017-10-12T18:33:46,,,,46702563
46614146,46614146,15,"You should install and set the SPARK_HOME variable, in unix terminal run the following code to set the variable:


export SPARK_HOME=""/path/to/spark""



To maintain this config you should append this to the end of your .bashrc.


See this for installation 
https://www.tutorialspoint.com/apache_spark/apache_spark_installation.htm",2017-10-06T21:27:05,,,,46613651
59346656,59346656,11,"While using Jupyter Notebook with Anaconda, the function called to do this 
findspark.py
 does the following:


def find():
    spark_home = os.environ.get('SPARK_HOME', None)

    if not spark_home:
        for path in [
            '/usr/local/opt/apache-spark/libexec', # OS X Homebrew
            '/usr/lib/spark/' # AWS Amazon EMR
            # Any other common places to look?
        ]:
            if os.path.exists(path):
                spark_home = path
                break

    if not spark_home:
        raise ValueError(""Couldn't find Spark, make sure SPARK_HOME env is set""
                         "" or Spark is in an expected location (e.g. from homebrew installation)."")

    return spark_home



So we're going to follow the next procedure. 


1. Specify SPARK_HOME and JAVA_HOME


As we have seen in the above function, for Windows we need to specifiy the locations. The next function is a slightly modified version from these 
answer
. It is modified because 
it is also necessary to specify a JAVA_HOME
, which is the directory where you have installed it. Also, I have created a spark directory where I moved the dowloaded version of Spark that I'm using, for this procedure you could check out these 
link
.


import os 
import sys

def configure_spark(spark_home=None, pyspark_python=None):
    spark_home = spark_home or ""/path/to/default/spark/home""
    os.environ['SPARK_HOME'] = spark_home
    os.environ['JAVA_HOME'] = 'C:\Program Files\Java\jre1.8.0_231'

    # Add the PySpark directories to the Python path:
    sys.path.insert(1, os.path.join(spark_home, 'python'))
    sys.path.insert(1, os.path.join(spark_home, 'python', 'pyspark'))
    sys.path.insert(1, os.path.join(spark_home, 'python', 'build'))

    # If PySpark isn't specified, use currently running Python binary:
    pyspark_python = pyspark_python or sys.executable
    os.environ['PYSPARK_PYTHON'] = pyspark_python

configure_spark('C:\spark\spark-2.4.4-bin-hadoop2.6')



2. Configure SparkContext


When working locally
, you should configurate SparkContext in the next way: (these 
link
 was useful)


import findspark
from pyspark.conf import SparkConf
from pyspark.context import SparkContext

# Find Spark Locally
location = findspark.find()
findspark.init(location, edit_rc=True)

# Start a SparkContext 
configure = SparkConf().set('spark.driver.host','127.0.0.1')
sc = pyspark.SparkContext(master = 'local', appName='desiredName', conf=configure)



This procedure has worked out nice for me, Thanks!.",2019-12-15T18:02:29,Miguel Trejo,https://stackoverflow.com/users/12483346/miguel-trejo,"6,619",46613651
46614149,46614149,4,"You will have to download the spark runtime on the machine where you want to use Sparkling Water. It could be either a local download or a clustered spark i.e. on Hadoop.


The SPARK_HOME variable is the directory/folder where sparkling water will find the spark run time. 


In the following setting SPARK_HOME, I have Spark 2.1 downloaded on local machine and the path set is the unzipped spark 2.1 as below:


SPARK_HOME=/Users/avkashchauhan/tools/spark-2.1.0-bin-hadoop2.6

$ pwd
 /Users/avkashchauhan/tools/sw2/sparkling-water-2.1.14



Now when I launch the sparkling-shell as below it works fine:


~/tools/sw2/sparkling-water-2.1.14 $ bin/sparkling-shell                                                                                                                                                                                        

-----
  Spark master (MASTER)     : local[*]
  Spark home   (SPARK_HOME) : /Users/avkashchauhan/tools/spark-2.1.0-bin-hadoop2.6
  H2O build version         : 3.14.0.2 (weierstrass)
  Spark build version       : 2.1.1
  Scala version             : 2.11
----",2017-10-06T21:27:23,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46613651
46591055,46591055,0,"This is a regression which we have encountered very recently, and a JIRA is filed as below:


https://0xdata.atlassian.net/browse/PUBDEV-4930


We are actively working on to fix this issue in next H2O release. I will updated here as soon as we have a fix ready and available.",2017-10-05T16:55:52,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46583393
46570029,46570029,0,"The problem is that your are using the bleeding edge version of the code (and an older build too) when we were working on an enterprise function to support encrypted data using importFile function so it is possible you have are hitting that problem. We have finished developing this feature now. So you just need to update H2O to the latest release version on your backend and R API as well. 


The latest STABLE release 3.14.0.3 can be downloaded from here and please make sure you install latest H2O R Package as well:


https://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/3/index.html


The latest bleeding is does not have this issue as well so you can try that as well.


http://h2o-release.s3.amazonaws.com/h2o/master/4052/index.html


[H2O 3.14.0.3 File Import Example]


> h2o.init()
Reading in config file: ./.h2oconfig

H2O is not running yet, starting it now...
java version ""1.8.0_101""
Java(TM) SE Runtime Environment (build 1.8.0_101-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)

Starting H2O JVM and connecting: .. Connection successful!

R is connected to the H2O cluster: 
H2O cluster uptime:         1 seconds 944 milliseconds 
H2O cluster version:        3.14.0.3 
H2O cluster version age:    12 days  
H2O cluster name:           H2O_started_from_R_avkashchauhan_hwc594 
H2O cluster total nodes:    1 
H2O cluster total memory:   3.56 GB 
H2O cluster total cores:    8 
H2O cluster allowed cores:  8 
H2O cluster healthy:        TRUE 
H2O Connection ip:          localhost 
H2O Connection port:        54321 
H2O Connection proxy:       NA 
H2O Internal Security:      FALSE 
H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
R Version:                  R version 3.4.1 (2017-06-30) 

> df = h2o.importFile('https://raw.githubusercontent.com/h2oai/sparkling-water/master/examples/smalldata/prostate.csv')
  |========================================================| 100%
> df
  ID CAPSULE AGE RACE DPROS DCAPS  PSA  VOL GLEASON
    1  1       0  65    1     2     1  1.4  0.0       6
    2  2       0  72    1     3     2  6.7  0.0       7
    3  3       0  70    1     1     2  4.9  0.0       6
    4  4       0  76    2     2     1 51.2 20.0       7
    5  5       0  69    1     1     1 12.3 55.9       6
    6  6       1  71    1     3     2  3.3  0.0       8

    [380 rows x 9 columns]",2017-10-04T16:42:55,,,,46569298
46569476,46569476,1,"You really to need to pass the current linux user uid/pid with the -p parameter of ""nvidia-docker run"" command. This is how u can do it. 


If you run id command on a Ubuntu machine you will see the following udi/gid for the logged user name ""ubuntu"":


$ id
uid=1000(ubuntu) gid=1000(ubuntu)



You will be using this info with the -p parameter with ""nvidia-docker run"" command as below:


nvidia-docker run -u 1000:1000



What you can do it run the following command to get help on nvidia-docker:


nvidia-docker run --help",2017-10-04T16:09:36,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46558913
46972477,46972477,0,"It looks like you are using the wrong quote.  Your example has an apostrophe (') and it should be a backquote (`).


Backquote (correct):


$ echo `id -g`
20



Apostrophe (incorrect):


$ echo 'id -g'
id -g





Also note that the instructions now refer to an AMI-based startup (so you shouldn't have to type this stuff in yourself anymore).",2017-10-27T10:03:04,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46558913
46555914,46555914,1,"Thanks for the report, the current implementation is restricted by JVM's maximum length of an array. This model seems to be too large and it exceeds the JVM's limits.


We will have to fix it in H2O.",2017-10-04T02:01:15,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,46553482
46712619,46712619,1,"Given that you are exceeding the max array size for a model, as a workaround, you could trim it back a bit. I'm assuming the vocabulary is ordered by frequency, in the glove file. In other words, I am assuming the most frequent words come first, and that the ones at the end are generally obscure and less useful.


E.g. this code would just use the first 50% of the words.


h2o.init()
glove <- h2o.importFile(""glove.840B.300d.csv"",header = F)
parts <- h2o.split(glove, [0.5])
modelCommon <- h2o.word2vec(pre_trained = parts[[1]],vec_size = 300)



Depending on what you were going to do next, you could make a 2nd model for the second half of the data:


modelObscure <- h2o.word2vec(pre_trained = parts[[2]],vec_size = 300)",2017-10-12T14:48:02,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,46553482
46544813,46544813,0,"This issue is resolved. 


I was under the false impression that you had to download the cluster and the python package separately. In fact its much easier just to let the python package start the cluster. 


All I had to do was uninstall everything, and simply use pip to install the latest h2o.


Similar to this answer here but in reverse:


OSError: Version mismatch while installing h2o?",2017-10-03T12:39:21,Woody Pride,https://stackoverflow.com/users/2484720/woody-pride,13.9k,46537165
46535310,46535310,2,Turns out I overlooked the requirements of H2O. Java 9 SDK is not supported. Downgrading to version 8 fixed my problem.,2017-10-02T23:57:42,Sasquatch Man,https://stackoverflow.com/users/8687359/sasquatch-man,73,46535110
46529944,46529944,1,"xgboost implementation on H2O is multithreaded and like all other algorithms supported into H2O however it is platform dependent which is described into 
H2O documentation
 properly. 


So if you try it on Linux, and have all supported libraries available then you will take advantage of distributed xgboost otherwise like OSX, you might get a single CPU fall back runtime. So it's all depend on which lib is loaded from your OS.


When H2O starts in the log you will see the following:


10-02 09:25:34.579 10.0.0.46:54321       54229  main      INFO: Registered 3 core extensions in: 57ms
10-02 09:25:34.580 10.0.0.46:54321       54229  main      INFO: Registered H2O core extensions: [Watchdog, XGBoost, KrbStandalone]
10-02 09:25:34.791 10.0.0.46:54321       54229  main      INFO: Registered: 161 REST APIs in: 211ms
10-02 09:25:34.791 10.0.0.46:54321       54229  main      INFO: Registered REST API extensions: [XGBoost, Algos, AutoML, Core V3, Core V4]



Then you will see if CPU/GPU is included as below:


10-02 09:23:49.952 10.0.0.46:54321       54143  FJ-1-5    INFO: No GPU (gpu_id: 0) found. Using CPU backend.



If you could run objdump or ldd command to see the libs loaded with H2O, you will have better idea what is missed which cause your xgboost runtime to be single CPU.",2017-10-02T16:43:51,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46523998
46492688,46492688,2,"The error you reported says:




Only Java 1.6-1.8 supported, version is 9




Seems like you have Java 9 installed, which is not yet supported by H2O.  Use a compatible version of Java and that will fix the error.


If you can't or don't want to uninstall Java 9, then you'll need to tell H2O which Java you'd like to use by setting the 
JAVA_HOME
 environment variable.  First, get the location of Java 1.8 by executing the following in a shell: 


/usr/libexec/java_home -v 1.8



On my mac, it shows me this: 


/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home



You can check if R can see your 
JAVA_HOME
 variable by running the following command: 
Sys.getenv(""JAVA_HOME"")
.  


If that's blank (and possibly will be if you're using RStudio), then will have to do a bit more work to get R to see the 
JAVA_HOME
 variable.  You can edit the 
~/.Renviron
 file to add 
JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home
 or whatever that location is on your machine. Then restart RStudio and it should work.",2017-09-29T15:56:12,,,,46490290
46504401,46504401,1,"I followed the discussion 
in this thread
 to get a solution to the problem, though it won't be that convenient for some people.


The default 
java
 is 1.8.x, hence once that 
h2o
 can use, but calling 
h2o
 from 
R
 results in the version 9 
java
 getting called.


The (rather patchy) solution for now is to start the 
h2o
 server from the terminal like this


cd h2o-3.14.0.3   #navigate to wherever you have the h2o installation
java -jar h2o.jar



with that running fine, I then link it from 
R
 without starting an 
h2o
 instance:


h2o.init(startH2O = FALSE) 



This works fine if you're ok with starting 
h2o
 from the terminal (might be the only way if you're working on a cluster), but might be annoying if you want to start it from 
RStudio
 right away.",2017-09-30T15:51:41,,,,46490290
46495212,46495212,1,"I don't know of any formal benchmarks. Deepwater uses TensorFlow and MXNet as deep learning engines, and there are benchmarks for those. In general you'll see significant speed-ups when convolution is involved. 


The newer Nvidia cards are faster than old ones (no surprise there), and in particular they have more internal RAM, which determines how large mini-batches you can use for different problems, and how large problems you can work onsome . For example 1080 Ti has 11 GB of RAM while the older 1080 has 8 GB. 


Titan X has 12 GB of RAM. It will give you significant speed-ups. However, it's more expensive than 1080 Ti, which is a much better value with almost as much memory.


Szilard Pafka has done benchmarks with different GPU cards. See 
https://github.com/szilard/benchm-dl",2017-09-29T18:46:26,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46479218
46549652,46549652,0,"If you want to use H2O 
word2vec
 algorithm you can use Sparkling Water samples 
here
 which are writing in Scala/Java, very easy to make them work on your Scala code.  


I don't have much experience with 
SMILE
 library however looking their code you can find some of the Java samples in their test code 
here
 into nlp section. You can try them to use with Scala as well. 


I hope you know what you want to do because they way you describe your question is not exactly clear. What you really need is to ask a very specific question after writing some code first. This will help you to understand exactly where you are stuck and what is needed to unblock you.",2017-10-03T16:51:14,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46454196
46430246,46430246,3,"There is a tool to create visualizations for H2O-3 MOJO models.  See the full documentation here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#viewing-a-mojo






Use R to create and download a MOJO:


library(h2o)
h2o.init()
df <- h2o.importFile(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"")
model <- h2o.gbm(model_id = ""model"",
                training_frame = df,
                x = c(""Year"", ""Month"", ""DayofMonth"", ""DayOfWeek"", ""UniqueCarrier""),
                y = ""IsDepDelayed"",
                max_depth = 3,
                ntrees = 5)
h2o.download_mojo(model, getwd(), FALSE)



Run the PrintMojo tool (packaged inside h2o.jar) on the command line to make a .png file.  You need to download the latest stable H2O-3 release from 
http://www.h2o.ai/download/
 and run the PrintMojo tool from the command line.


# (For MacOS: brew install graphviz)
java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i model.zip -o model.gv
dot -Tpng model.gv -o model.png
open model.png",2017-09-26T15:17:20,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46426143
53975556,53975556,1,"New Tree API was added in H2O in 3.22.0.1. It lets you fetch trees into R/Python objects from any tree-based model in H2O (for details see 
here
):


tree <- h2o.getModelTree(model = airlines.model, tree_number = 1, tree_class = ""NO"")



Having a tree representation from h2o in R plotting a tree explained here: 
Finally, You Can Plot H2O Decision Trees in R",2018-12-30T05:47:47,,,,46426143
46429196,46429196,0,"You can export the model as POJO with 
h2o.download_pojo()
 and then look at the full details of each tree in the file.",2017-09-26T14:28:48,Jo-fai Chow,https://stackoverflow.com/users/3283131/jo-fai-chow,1,46426143
46417630,46417630,3,"To see if the cluster is up you can use


h2o.clusterIsUp()
# TRUE



and to see the connection info you can use


h2o.getConnection()

IP Address: localhost 
Port      : 54321 
Session ID: _sid_b51e 
Key Count : 0



Then you can use some of the internal 
h2o
 functions to get all the meta about the connection


res <- h2o:::.h2o.fromJSON(
         jsonlite::fromJSON(
           h2o:::.h2o.doSafeGET(
             urlSuffix = h2o:::.h2o.__CLOUD
           ), 
           implifyDataFrame = FALSE
         )
       )

str(res)
List of 19
 $ __meta                   :List of 3
  ..$ schema_version: int 3
  ..$ schema_name   : chr ""CloudV3""
  ..$ schema_type   : chr ""Iced""
 $ _exclude_fields          : chr """"
 $ skip_ticks               : logi TRUE
 $ version                  : chr ""3.10.4.6""
 $ branch_name              : chr ""rel-ueno""
 $ build_number             : chr ""6""
 $ build_age                : chr ""4 months and 30 days""
 $ build_too_old            : logi TRUE
 $ node_idx                 : int 0
 $ cloud_name               : chr ""H2O_started_from_R_david_tos519""
 $ cloud_size               : int 1
 $ cloud_uptime_millis      : int 772951
 $ cloud_healthy            : logi TRUE
 $ bad_nodes                : int 0
 $ consensus                : logi TRUE
 $ locked                   : logi TRUE
 $ is_client                : logi FALSE
 $ nodes                    :List of 1
  ..$ :List of 27
  .. ..$ __meta        :List of 3
  .. .. ..$ schema_version: int 3
  .. .. ..$ schema_name   : chr ""NodeV3""
  .. .. ..$ schema_type   : chr ""Iced""
... etc",2017-09-26T04:02:00,,,,46417508
46417637,46417637,2,"OK, 
h2o.clusterStatus()
 is providing the connection attributes 


                           h2o healthy    last_ping
1 localhost/127.0.0.1:54321    TRUE 1.506398e+12
  num_cpus  sys_load mem_value_size  free_mem
1        4 0.2445616           5120 783876096
   pojo_mem swap_mem    free_disk     max_disk
1 170846208        0 310012542976 510426873856
   pid num_keys tcps_active open_fds rpcs_active
1 7084       20           0       -1           0",2017-09-26T04:02:54,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46417508
46414097,46414097,0,"The UI has not been updated to handle MOJOs yet and there seems to be a bug. You're welcome to contribute: 
https://github.com/h2oai/steam/blob/master/CONTRIBUTING.md",2017-09-25T21:00:00,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46412745
46416562,46416562,0,"My solution is very hacky, but works for my 
particular
 case (ie. I have a 
DRF
, 
binomial
 model in h2o steam that is not being recognized as a binary model (how I know this is shown in this answer)). 


Solution:

In my original post, there was a variable 
outputDomain
 that was 
undefined
. Looking at the source code, that variable is set to (what is 
supposed
 to be) the domain labels of the output response for the model, 
here
. I changed this line from 
outputDomain = domains[i1];
 to 
outputDomain = domains[i1-1];
. My output after clicking the predict button looks like:




From the official linux download for 
h2o steam
, you can access the prediction service 
predict.js
 file by opening 
steam-1.1.6-linux-amd64/var/master/assets/ROOT.war/extra/predict.js
, then saving changes and relaunching the jetty server 
$ java -Xmx6g -jar var/master/assets/jetty-runner.jar var/master/assets/ROOT.war
.


Causes?
: 
I suspect the problem has something to do with that fact that the global variable 
isBinaryPrediction
 in predict.js seems to remain 
false
 for my model. The reason that 
isBinaryPrediction
 is false seems to be because in the function 
showInputParameters()
, 
data.m
 has no field _problem_type. Using 
console.dir(data, {depth: null})
 in the inspector console to see the fields of 
data.m
, I see that the expectedd field 
data.m._problem_type
 does not exist and so returns undefined, thus 
isBinaryPrediction
 is never set true (
here
). 




Why this is happening, I do not know. I have only used DRF models in steam so far and this may be a problem with that model, but I have not tested. If anyone knows why this may be happening, please let me know.",2017-09-26T01:43:40,,,,46412745
46394550,46394550,3,"You need to change the way you are loading the MOJO zip file in your project, instead you need to load MOJO file as stream from resource. You can follow this 
example
 where you can see how to MOJO is placed into resource folder and then addMOJOsFromJARResource is called to include MOJO.


Project: 
https://github.com/h2oai/h2o-tutorials/tree/f67765bc6c68c2058d4b2786d1bbc627d3b70539/tutorials/hive_udf_template/hive_udf_mojo_template




MOJO zip is stored at src/main/resources/model


You would need to reference h2o-genmodel classes as below to 




```


 import hex.genmodel.MojoReaderBackendFactory;
 import static hex.genmodel.MojoReaderBackendFactory.CachingStrategy;
 import hex.genmodel.MojoReaderBackend;
 import hex.genmodel.ModelMojoReader;





Here is the function which includes all MOJO.zip (yes you can add multiple MOJO) into your project




```


  public void addMOJOsFromJARResource() {
      try {
        String[] mojo_names = this.getMOJONames();
        for (int i = 0; i < mojo_names.length; i++) {
            MojoReaderBackend reader =
                MojoReaderBackendFactory.createReaderBackend(
                  getClass().getResourceAsStream(
                     ""/models/""+mojo_names[i]), 
                      MojoReaderBackendFactory.CachingStrategy.MEMORY);
            MojoModel model = ModelMojoReader.readFrom(reader);
            this.addModel(model);
        }
       } catch (Exception e) {
         e.printStackTrace();
        throw new RuntimeException();
        }
    }



```
This will work.",2017-09-24T20:29:58,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46392819
46392517,46392517,10,"Based on the error message and the troubleshooting we carried out in the comments, it seems that you are using a version of Java (Java 1.9) which is too new for your version of H2O.


Your 2 options seem to be:




Verify that your version of H2O is up to date. If not, update it.


Download a compatible version of Java, i.e. 
Java 1.8
 (you can just use it for this 1 task rather than for everything, if you prefer)




Note that on the main documentation page of H2O v3 it says:




Java 7 or later. Note: Java 9 is not yet released and is not currently
  supported.




But at the same time they usually have several Beta and Alpha development branches going, so you might find one of those that works with Java 9.",2017-09-24T16:54:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46392394
46397353,46397353,6,"So if anyone else is facing the same issue. 


My recommendation (after spending about over 10 hours trying to figure this out (worth mentioning)) is check your version of java.


If it's higher than 8 then either keep it remove it. 


I removed it because I didn't want to deal with setting the JAVA Home function in R and to reduce work. 


Make sure you install Java 7 or 8 but a 64 bit version. 
h2o
 doesn't work if you have 32 bit.


Then voila! Just go ahead and type 
install.package('h2o')
 in your rstudio.


I wanted to be extra careful in my final attempt of this so unloaded and uninstalled the library because I had installed it before and then installed it again and then loaded it using 
library(h2o)
 and then 
h20.init()
 worked just fine.",2017-09-25T03:53:11,sm925,https://stackoverflow.com/users/5269047/sm925,"2,678",46392394
46374948,46374948,0,I believe for POJOs there's no way to change it as it's hardcoded. Don't know the answer for MOJOs.,2017-09-23T00:52:34,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46374929
46373619,46373619,0,"The prediction service uses the same format as the model was trained on. If the model used timestamps as input, the service will too. You need to add your own preprocessing to convert, e.g., 2016-12-21 to a timestamp before calling the prediction service.",2017-09-22T21:43:34,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46373561
46372556,46372556,0,"As I explained in this other question 
Using MOJOS in H2O Steam Prediction Service Builder
  this is because the UI has not been updated to handle MOJOs, it currently only handles POJOs. 


You can use command line (or other tools) to send data to and get predictions from the prediction service. How to do this is explained here: 
https://github.com/h2oai/steam/tree/master/prediction-service-builder",2017-09-22T20:12:42,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46372293
46375256,46375256,1,"[ If using H2O is ""mandatory"" for you, are you perhaps using it in a course?  If so, I'm curious where that is... ]


H2O-3 is written in Java, and has an internal word2vec implementation written from scratch in Java.  You wouldn't actually use the referenced C++ implementation inside of H2O-3.


Here is a pointer to the relevant word2vec documentation for H2O-3:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/word2vec.html",2017-09-23T01:54:19,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46369378
56957198,56957198,0,"You have to generate the previous model as csv, import the csv as a frame and construct the w2oModel and specify the data frame as pretrained parameter.",2019-07-09T16:44:02,Gustavo Orair,https://stackoverflow.com/users/1008690/gustavo-orair,106,46369378
46444337,46444337,1,"Just make sure jetty HTTP server is running locally by executing the following in your shell:

java -jar var/master/assets/jetty-runner.jar var/master/assets/ROOT.war",2017-09-27T09:32:25,Anton Berlinsky,https://stackoverflow.com/users/1191905/anton-berlinsky,615,46355861
46371906,46371906,0,"Looking 
here
, it seems like I would need to ""override"" some kind of default browser restriction for accessing localhost:8080 (which is what I assume 
steam
 is trying to do to launch the service builder (I don't know much about networking related stuff)). I got around this by launching 
steam
 with the command:


$ ./steam serve master --prediction-service-host=localhost --prediction-service-port-range=12345:22345



where the ports are some arbitrary range between (1025, 65535) which I got by word-searching the a page of the 
steam
 source 
code
 (line 182 as of the date of this posting).


Doing this lets me deploy the models through the 
steam
 dialog without any error messages. Again, I don't know much about networking related stuff, so if anyone has a better way to solve this problem (ie. allow access of localhost:8080) please post or comment. Thanks.",2017-09-22T19:25:47,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",46355861
46355344,46355344,0,"I'm guessing you started it with Gradle. In that case you can do 
GRADLE_OPTS=-Xmx4g ./gradlew jettyrunwar
 to start it with 4 GB of memory.",2017-09-22T01:02:50,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46355251
46353786,46353786,1,"Unfortunately, the UI has not been updated for mojo functionality yet. You can however use the command line to build war files with mojos.


Run this from your command line:


curl -X POST --form mojo=drf_denials_v4.zip --form jar=h2o-genmodel.jar localhost:55000/makewar > example.war


Then run the war file in the normal way.


For more information see: 
https://github.com/h2oai/steam/tree/master/prediction-service-builder",2017-09-21T22:01:30,Magnus,https://stackoverflow.com/users/7816546/magnus,246,46353578
46334147,46334147,1,"What you are really looking is to ""how to put H2O models in production?"" You really need to understand few key things about H2O models and how to use them in a production system, starting from 
here
.


H2O have 3 types of models where Binary (Type:1) must need H2O to perform prediction. The H2O uses RESTful interface so you can use a very simple front end to send your prediction data over RESTful interface to H2O running server and get the prediction back. This all can be done just by using simple JavaScript code.


Other 2 types, POJO (Type:2) and MOJO(type:3) does not need H2O, instead you just need Java runtime i.e. Java App, Java WebServer, Jetty embedded webserver, to perform the prediction. You can learn POJO in production 
here
 and MOJO in production 
here
. 


We also have a full Web Application sample ""
Consumer Loan Application
"" already built for users to learn how to build a full WebApp using POJO or MOJO. You can clone the following github repo to just compile and run it. Once you got it understood, just use your own POJO/MOJO model to create the Web Front end.


https://github.com/h2oai/app-consumer-loan


There is another way to quickly create a WebApp for your H2O POJO and MOJO models and the option is to use H2O 
Steam
 product and within this product there is ""
Steam Prediction Service Builder
"". Please visit the Steam Prediction service builder documentation to use your POJO or MOJO to build a WebApp interface to generate prediction in few minutes. 


So you can see there are several ways you can try to  build the WebApp you are looking for.",2017-09-21T01:48:47,,,,46333680
46359347,46359347,0,"The best way to see inside a model is to export the pojo, and look at the java source code. You should see how it is processing enums.


But, if I understand the rest of your question correctly, it should be fine. As long as the training data contains all possible values of a category it will work as you expect. If a categorical value not see in training is presented in production it will be treated as an NA.",2017-09-22T07:40:08,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,46328579
46333631,46333631,1,"Yes, when using apply with H2OFrame, you can not pass a function instead only lambda is accept. For example if you try passing tryit function you will get the following error showing the limitation: 


H2OValueError: Argument `fun` (= <function tryit at 0x108d66410>) does not satisfy the condition fun.__name__ == ""<lambda>""



As you already know Sparkling Water is another option to perform all the data munging first in spark and then push you data into H2O for ML.


If you want to stick with H2O as it is, then your options are to just loop through the dataframe to process elements your way. The following option could be little time consuming depending on your data however it does not ask you to move your environment. 




Create a new H2O frame by selecting your ""ip"" column only and add location, city, and other empty columns to it with NA. 


Loop through all the ip values and based on ""ip"", find location/city and add location, city and other column values to the existing columns


Finally 
cbind
 the new h2oFrame with original H2OFrame


Check ""ip"" and ""ip0"" columns for proper merge with 100% match and then remove one of the duplicate ""ip0"" column.


Remove the other extra H2OFrame to save memory",2017-09-21T00:32:43,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46317073
46359788,46359788,1,"If your ip --> city algorithm is a lookup table, you could create that as a data frame, then use 
h2o.merge
. For an example, 
this video
 (starting at around the 59min mark) shows how to merge weather data into the airlines data.


For ip addresses I imagine you might want to first truncate to the first two or three parts.


If you don't have a lookup table, it becomes interesting as to whether it is quicker to turn a complex algorithm into that lookup tree and do the 
h2o.merge
, or stick with downloading your huge data in batches, running locally in client, uploading a batch of answers, and doing 
h2o.cbind
 at the end.


BTW, the cool and trendy approach would be to sample 1 million of your ip addresses, lookup the correct answer on the client to make a training data set, then use h2o to build a machine learning model. You can then use 
h2o.predict()
 to create the new city column in your real data. (You will want to at least split ip address into 4 columns first, though.)  (My hunch is a deep random forest would work best... but I would definitely experiment a bit.)",2017-09-22T08:04:32,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,46317073
46303042,46303042,1,"When using H2O-3 with cross validation, you can tell the training algorithm which fold number an observation belongs to with the 
fold_column
 parameter.  See:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/fold_column.html




The code example below (copied from the link above) shows folds being assigned randomly.  But you could alternately write a piece of code to assign them specifically yourself.


library(h2o)
h2o.init()

# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars <- h2o.importFile(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# convert response column to a factor
cars[""economy_20mpg""] <- as.factor(cars[""economy_20mpg""])

# set the predictor names and the response column name
predictors <- c(""displacement"",""power"",""weight"",""acceleration"",""year"")
response <- ""economy_20mpg""

# create a fold column with 5 folds
# randomly assign fold numbers 0 through 4 for each row in the column
fold_numbers <- h2o.kfold_column(cars, nfolds=5)

# rename the column ""fold_numbers""
names(fold_numbers) <- ""fold_numbers""

# print the fold_assignment column
print(fold_numbers)

# append the fold_numbers column to the cars dataset
cars <- h2o.cbind(cars,fold_numbers)

# try using the fold_column parameter:
cars_gbm <- h2o.gbm(x = predictors, y = response, training_frame = cars,
                    fold_column=""fold_numbers"", seed = 1234)

# print the auc for your model
print(h2o.auc(cars_gbm, xval = TRUE))",2017-09-19T14:26:13,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46296441
46259618,46259618,3,"I would like to access raw predictions during cross-validation, so I can calculate performance on my own.




If you want to calculate a custom metric on the cross-validated predictions, then set 
keep_cross_validation_predictions = True
 and you can access the raw predicted values using the 
.cross_validation_holdout_predictions()
 method like you have above.




Can I take new predictions made on the same data set and use it to calculate performance?




It sounds like you're asking if you can use only training data to estimate model performance?  Yes, using cross-validation.  If you set 
nfolds > 1
, H2O will do cross-validation and compute a handful of cross-validated performance metrics for you.  Also, if you tell H2O to save the cross-validated predictions, you can compute ""cross-validated metrics"" of your own.",2017-09-17T00:21:45,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46253317
47251303,47251303,1,"I tried myself to detect anomaly on Time-Series data. To learn the concept I was using this 
blog
. The explanations in this blog worked fine for me. 


I hope to contribute with some visual representation of what is happening when we detect anomaly. 
In the example, Deep Learning model was fit on this ECG dataset. The data looks physically like this:


Data we fit our Deep Learning Model


After that we provide test dataset (containing anomaly) that will look like this:

Data we test our Deep Learning Model on


Anomaly detection itself is possible when 'Artificial Intelligence' sees the difference using Metric MSE or Mean Square Error


This is what AI 'see' on Test dataset


The generated MSE can be obtained as in example


MSE output",2017-11-12T16:44:26,vlad1490,https://stackoverflow.com/users/5499595/vlad1490,365,46243483
46244232,46244232,0,"Enabling autoencoder (as TRUE) becomes a clustering problem so there is no need to set response (y).


Also when autoencoder is set to TRUE you still need to set x. The problem you see above with autoencoder is TRUE that you dont have predictors (x) set. Once you set the x your problem will go away. 


Here is I did run a quick anomaly detection test (learn more in this 
blog
) with H2O 3.14.0.2 on R:


  > library(h2o)
  > h2o.init()
  Reading in config file: ./.h2oconfig

  H2O is not running yet, starting it now...

  Note:  In case of errors look at the following log files:
      /var/folders/x7/331tvwcd6p17jj9zdmhnkpyc0000gn/T//Rtmp7RuYKp/h2o_avkashchauhan_started_from_r.out
      /var/folders/x7/331tvwcd6p17jj9zdmhnkpyc0000gn/T//Rtmp7RuYKp/h2o_avkashchauhan_started_from_r.err

  java version ""1.8.0_101""
  Java(TM) SE Runtime Environment (build 1.8.0_101-b13)
  Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)

  Starting H2O JVM and connecting: .. Connection successful!

  R is connected to the H2O cluster: 
      H2O cluster uptime:         1 seconds 948 milliseconds 
      H2O cluster version:        3.14.0.2 
      H2O cluster version age:    24 days  
      H2O cluster name:           H2O_started_from_R_avkashchauhan_alj381 
      H2O cluster total nodes:    1 
      H2O cluster total memory:   3.56 GB 
      H2O cluster total cores:    8 
      H2O cluster allowed cores:  8 
      H2O cluster healthy:        TRUE 
      H2O Connection ip:          localhost 
      H2O Connection port:        54321 
      H2O Connection proxy:       NA 
      H2O Internal Security:      FALSE 
      H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
      R Version:                  R version 3.4.0 (2017-04-21) 

  > mtcar = h2o.importFile('https://raw.githubusercontent.com/woobe/H2O_London_Workshop/master/data/auto_design.csv')
    |==================================================================================================================================| 100%
  > mtcar$gear = as.factor(mtcar$gear)
  > mtcar$carb = as.factor(mtcar$carb)
  > mtcar$cyl = as.factor(mtcar$cyl)
  > mtcar$vs = as.factor(mtcar$vs)
  > mtcar$am = as.factor(mtcar$am)
  > mtcar.dl = h2o.deeplearning(x = 2:12, training_frame = mtcar, autoencoder = TRUE, hidden = c(1,1,1), epochs = 100,seed=1)
    |==================================================================================================================================| 100%
  > errors <- h2o.anomaly(mtcar.dl, mtcar, per_feature = TRUE)
  > print(errors)
    reconstr_carb.1.SE reconstr_carb.2.SE reconstr_carb.3.SE reconstr_carb.4.SE reconstr_carb.6.SE reconstr_carb.8.SE
  1                  0                  0                  0                  1                  0                  0
  2                  0                  0                  0                  1                  0                  0
  3                  1                  0                  0                  0                  0                  0
  4                  1                  0                  0                  0                  0                  0
  5                  0                  1                  0                  0                  0                  0
  6                  1                  0                  0                  0                  0                  0
    reconstr_carb.missing(NA).SE reconstr_cyl.4.SE reconstr_cyl.6.SE reconstr_cyl.8.SE reconstr_cyl.10.SE reconstr_cyl.missing(NA).SE
  1                            0                 0                 1                 0                  0                           0
  2                            0                 0                 1                 0                  0                           0
  3                            0                 1                 0                 0                  0                           0
  4                            0                 0                 1                 0                  0                           0
  5                            0                 0                 0                 1                  0                           0
  6                            0                 0                 1                 0                  0                           0
    reconstr_gear.3.SE reconstr_gear.4.SE reconstr_gear.5.SE reconstr_gear.missing(NA).SE reconstr_vs.0.SE reconstr_vs.1.SE
  1                  0                  1                  0                            0                1                0
  2                  0                  1                  0                            0                1                0
  3                  0                  1                  0                            0                0                1
  4                  1                  0                  0                            0                0                1
  5                  1                  0                  0                            0                1                0
  6                  1                  0                  0                            0                0                1
    reconstr_vs.missing(NA).SE reconstr_am.0.SE reconstr_am.1.SE reconstr_am.missing(NA).SE reconstr_mpg.SE reconstr_disp.SE reconstr_hp.SE
  1                          0                0                1                          0    8.705556e-05     0.0196626269   0.0035177471
  2                          0                0                1                          0    8.705556e-05     0.0196626269   0.0035177471
  3                          0                0                1                          0    2.684331e-04     0.0411916382   0.0045768080
  4                          0                1                0                          0    1.307597e-05     0.0004837585   0.0035177471
  5                          0                1                0                          0    1.779785e-03     0.0102131519   0.0007516691
  6                          0                1                0                          0    2.576469e-03     0.0038200199   0.0038147898
    reconstr_drat.SE reconstr_wt.SE reconstr_qsec.SE
  1      0.002147682    0.002080628      0.003914459
  2      0.002147682    0.002054817      0.003843678
  3      0.002153499    0.002111200      0.003646228
  4      0.002244072    0.002020654      0.003545225
  5      0.002235761    0.001998203      0.003843678
  6      0.002282261    0.001996213      0.003451600

  [32 rows x 28 columns]



You can also do the GLRM on the same dataset as below, you must need to set k and there is no need to pass x with GLRM however the dataset must not have constant columns. Thats why I am using filtered dataset with GLRM as in Deep Learning. 


> mtcar_glrm = mtcar[2:12]
> mtcar.glrm = h2o.glrm(training_frame = mtcar_glrm,seed=1, k = 5)",2017-09-15T16:44:42,,,,46243483
46237446,46237446,1,"Yes, the GBM MOJO with the Easy Wrapper (i.e. what is shown in the question) is thread-safe.


Here is an example showing a GBM MOJO model being initialized in a static block as part of a java servlet deployment:




https://github.com/h2oai/app-mojo-servlet/blob/master/src/main/java/ai/h2o/PredictServlet.java",2017-09-15T10:29:07,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46235467
58550875,58550875,0,"I had a similar problem, what worked for me was having 
enable_assertions = False
 in 
h2o.init()
.


h2o.init(..., enable_assertions = False)",2019-10-25T00:56:24,kangaroo_cliff,https://stackoverflow.com/users/3651529/kangaroo-cliff,"6,222",46220893
46221325,46221325,0,"What you are saying above is little hard to understand 




You can use R script with H2O to build a model. 


H2O generates 3 kinds of models - Binary, POJO and MOJO


Once a model is build with H2O, using R or Python script you have opportunity to export models in either of all of above types


The binary model needs exact same version of H2O running to do the scoring 


Other 2 models POJO and MOJO models needs Java run time to score, however you don't need to H2O with POJO and MOJO. 


POJO and MOJO scoring is explained 
here
 and 
here
 respectively.




Based on above your first sentence is not clear and first point needs more clarity what you really doing and what do you want. Looks like you are mixing multiple independent things together which is hard to understand.


About your second point, yes H2O can export models as POJO or MOJO. If you have a R script which can run with H2O to generate model then you sure can use R script to generate POJO from H2O.",2017-09-14T14:07:40,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46220306
46221684,46221684,0,"If you want to score on new data in batch from inside R, it would be easier to save your model with h2o.saveModel() and load it back with h2o.loadModel().


And then make predictions with h2o.predict().",2017-09-14T14:24:55,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46220306
46206613,46206613,3,"Here are two repos you can look at to see working examples of a POJO deployed in a jetty:




https://github.com/h2oai/app-consumer-loan




And a MOJO deployed in a jetty:




https://github.com/h2oai/app-mojo-servlet




With respect to your specific issue above, you probably need to add a web.xml file to your .war file.  This is the web.xml from the app-mojo-servlet repo:


$ cat src/main/webapp/WEB-INF/web.xml

<web-app xmlns=""http://java.sun.com/xml/ns/j2ee""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://java.sun.com/xml/ns/j2ee
http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd""
         version=""2.4"">
    <servlet>
        <servlet-name>Predict</servlet-name>
        <servlet-class>ai.h2o.PredictServlet</servlet-class>
    </servlet>
    <servlet-mapping>
        <servlet-name>Predict</servlet-name>
        <url-pattern>/predict</url-pattern>
    </servlet-mapping>
</web-app>",2017-09-13T20:49:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46205042
46178996,46178996,2,"The Java POJO and MOJO documentation for H2O-3 is here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




The relevant example at the POJO level is pasted below:


String modelClassName = ""gbm_pojo_test"";
hex.genmodel.GenModel rawModel;
rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();

// By default, unknown categorical levels throw PredictUnknownCategoricalLevelException.
// Optionally configure the wrapper to treat unknown categorical levels as N/A instead
// and strings that cannot be converted to numbers also to N/As:
EasyPredictModelWrapper model = new EasyPredictModelWrapper(
         new EasyPredictModelWrapper.Config()
             .setModel(rawModel)
             .setConvertUnknownCategoricalLevelsToNa(true)
             .setConvertInvalidNumbersToNa(true)
);





Incidentally, if you use MOJOs instead of POJOs, you won't have to compile any DRF Java model code at all, which can be an issue for large models.  Here is an example project which builds a tree model, exports a MOJO, creates a WAR file, and deploys it in a really simple Java servlet container:




https://github.com/h2oai/app-mojo-servlet",2017-09-12T14:25:02,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46174071
49518749,49518749,0,"I also had this problem when making predictions in R. I needed to use models that were version agnostic (either POJO or MOJO) and not having a h2o cluster running was a bonus.


I figured that if you save your model as a MOJO (this workaround does not work in POJOs), and not feed the variables that are throwing an error when you call the 
h2o.predict_json()
 function, the model will work as intended.


My code which makes predictions (regression) based on input from a .csv file can be summed to this:


dataset <- read.csv(<filepath>)
dataset$error_column <- """"
dataset$prediction <- 0
dataset_good <- dataset[0,]
dataset_error <- dataset[0,]
variables <- c(<variable1>, <variable2>, <...>, <variableN>)

while (length(dataset[,1]>0){

    # make predictions without feeding variables identified as problematic #
    dataset$prediction <- setNames(unlist(h2o.predict_json(model = <model_path>, 
                          json = toJSON(dataset[, setdiff(variables, unlist(strsplit(dataset$error_column, split=""; "")))]))), ""prediction"")

    # save good predictions in one table #
    dataset_good <- rbind(dataset_good, dataset[!is.na(as.numeric(dataset$prediction)),])

    # save errors in another dataset #
    dataset_error <- rbind(dataset_error, dataset[is.na(as.numeric(dataset$prediction)),])

    # identify problematic variable in message #
    dataset_error$error_column <- paste(dataset_error$error_column,
                                  substr(dataset_error$prediction, start = regexpr(""\\("", dataset_error$prediction)+1, 
                                                                   stop = regexpr("","", dataset_error$prediction)-1 ), sep = ""; "")

    # rerun rows that generated errors #
    dataset <- dataset_error
}



Don't forget you need to have the h2o-genmodel as well as the MOJO.",2018-03-27T17:10:53,,,,46174071
46351059,46351059,5,"Calibration is a post-processing step run after the model finishes. Therefore it doesn't affect the leaderboard and and it has no effect on the training metrics either.  It adds 2 more columns to the scored frame (with calibrated predictions).


This article
 provides guidance how to construct a calibration frame:




Split dataset into test and train


Split the train set into model training and calibration.




It also says:

The most important step is to create a separate dataset to perform calibration with.


I think the calibration frame should be used only for calibration, and hence distinct from the validation frame.  The conservative answer is that they should be separate -- when you use a validation frame for early stopping or any internal model tuning (e.g. lambda search in H2O GLM), that validation frame becomes an extension of the ""training data"" so it's kind of off-limits at that point. However you could try both versions and directly observe what the effect is, then make a decision.  Here's some additional guidance from the article:


""How much data to use for calibration will depend on the amount of data you have available. The calibration model will generally only be fitting a small number of parameters (so you do not need a huge volume of data). I would aim for around 10% of your training data, but at a minimum of at least 50 examples.""",2017-09-21T18:39:25,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46172137
46204997,46204997,1,"This is not a direct answer to your question because product roadmap is not really something we can comment on. However, if you are worried about dying ReLU problem in H2O, why don't you use 
ExpRectifier
, which stands for 
exponential linear unit (RLU)
, which does not suffer dying ReLU problem. As a matter of fact, 
this paper
 proves that ELU outperforms all ReLU variants. The only drawback is it is more computational heavy as it involves exponent in calculation.",2017-09-13T18:59:17,Lan,https://stackoverflow.com/users/1518628/lan,"6,620",46167613
46162199,46162199,0,"When you ingest data using h2o.importFile and h2o.import_sql_table, both the objects are H2OFrame as shown in the code snippet below:


> payment = h2o.import_sql_table(connection_url = ""jdbc:postgresql://localhost:5432/dvdrentaldb?&useSSL=false"", table= ""payment"", username = ""avkash"", password = ""avkash"")

|====================================================| 100%

> class(payment)
  [1] ""H2OFrame""

> a1 = h2o.importFile(""/Users/avkashchauhan/src/github.com/h2oai/h2o-3/smalldata/junit/cars.csv"")
  |=======================================| 100%
> class(a1)
  [1] ""H2OFrame""



If you want to show the histogram on a frame from h2o.import_sql_table, you can do the same as below:


> h2o.hist(payment$staff_id)





So they both are H2OFrame and all the functions on H2OFrame are applied as any other H2OFrame. 


Please use h2o.importFile instead of h2o.parseSetup/h2o.parseRaw which are designed to perform 2 step parsing on an existing H2OFrame instead of a data source i.e. file location on disk, or HDFS or web location.


If you will use h2o.importFile and h2o.import_sql_table you will get H2OFrame all the functions will be same between these two.",2017-09-11T18:29:56,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46160751
46160077,46160077,1,"You are passing response as list ['count.value'] and that is the problem. You just need to pass response as 'count.value', thats all, like as below:


response1 = 'count.value'",2017-09-11T16:13:58,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46153863
46125082,46125082,2,"You can a list of all predictors and categorical from POJO and MOJO. When you get categorical from predictors if the results are ""null"" then they are considered numbers otherwise enum.


You can use Java code from the following article:


https://aichamp.wordpress.com/2017/08/30/getting-all-categorical-for-predictors-in-h2o-pojo-and-mojo-models/


FYI: There is still an open bug on this issue with 
POJO
 so use MOJO instead.",2017-09-08T22:03:49,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,46124347
46125952,46125952,1,"I assume by ""each iteration of the grid search"", you mean each model in the grid search.  So you're asking how to find model training times in a grid search.  If so, here's how to do that.  


H2O stores the model start time in the model (as milliseconds since unix epoch time).  You can use that to determine the time between models -- this can be used to deduce the training time for any model (except the last one).  


In R, the model start time is stored at 
my_model@model$start_time
.
Here is an example using the iris dataset and a GBM grid:


library(h2o)
h2o.init()

# Load iris dataset 
data(""iris"")
train <- as.h2o(iris)


# GBM hyperparamters 
gbm_params <- list(learn_rate = seq(0.01, 0.1, 0.01),
                    max_depth = seq(2, 10, 1),
                    sample_rate = seq(0.5, 1.0, 0.1),
                    col_sample_rate = seq(0.1, 1.0, 0.1)) 
search_criteria <- list(strategy = ""RandomDiscrete"", max_models = 5)

# Train and cross-validate a grid of GBMs 
gbm_grid <- h2o.grid(""gbm"", x = 1:4, y = 5,
                      training_frame = train,
                      nfolds = 3,
                      ntrees = 100,
                      seed = 1,
                      hyper_params = gbm_params,
                      search_criteria = search_criteria)

# Model Start times (milliseconds since unix epoch) 
start_times <- sort(sapply(gbm_grid@model_ids, function(m) h2o.getModel(m)@model$start_time))

# Model training times (milliseconds) 
train_time_ms <- start_times[2:length(start_times)] - start_times[1:(length(start_times)-1)] 
print(train_time_ms)
# 758 662 532 469",2017-09-09T00:02:24,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46120544
46117435,46117435,1,"> class(h2odf)
[1] ""H2OFrame""

> h2odf
  A  B C D
1 1 NA 2 0
2 2  1 2 0
3 3 NA 2 0
4 4  3 2 0

[4 rows x 4 columns] 

> h2odf[!is.na(as.numeric(as.character(h2odf$B))),]
  A B C D
1 2 1 2 0
2 4 3 2 0

[2 rows x 4 columns]",2017-09-08T13:17:12,,,,46117348
46112580,46112580,0,"The root cause was insufficient memory allocation for 
sparklyr
, the default 1 GB of memory was not enough for H2O client which was executed in the same JVM. These lines of code saved the day:


config$`sparklyr.shell.driver-memory` <- ""6g""
config$`sparklyr.shell.executor-memory` <- ""6g""",2017-09-08T08:59:37,Igor Melnichenko,https://stackoverflow.com/users/3652569/igor-melnichenko,145,46102269
46113255,46113255,5,"Just a hunch, but try running R in the en_US locale.


If that fixes it, I imagine what is happening is that either 
aml@leaderboard
 or 
h2o.getFrame(""leaderboard"")
 is choking on the comma in the floating point numbers, and that is where the NaN is coming from. I.e. display bug, not an data bug.


(If that does fix it, it might also be useful to know what happens if you run both H2O and R in the same pl_PL.UTF-8 locale.)",2017-09-08T09:34:42,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,46095531
47122257,47122257,0,"I have met the same problem and I have solved that from aligning h2o and sparkling-water versions.




https://github.com/h2oai/rsparkling
 shows a version matching table. Since your h2o is 3.14.0.2, the backend spark should be 2.2.0.


https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.2/2/index.html
 have three lines below the download link which indicates the specified version which sparkling water is built on. For example, Sparkling water 2.2.2 matches H2O 3.14.0.7. Here is the key problem: if you use H2O 3.14.0.6 with Sparkling water 2.2.2, or H2O 3.14.0.7 with Sparkling water 2.2.1, your error will be raised.


carefully read these information and select your download solution (choose exactly matched version between sparkling water and H2O, and Spark). 




Here is a solution:


Cluster/local Spark version: 2.2
R: 3.4.2
RStudio: 1.0.153
Sparklyr: 0.6.2
h2o: 3.14.0.2

sparkling water 2.2.0
, download from 
https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.2/0/index.html


## sparkling water 2.2.0
options(rsparkling.sparklingwater.version = ""2.2.0"")
options(rsparkling.sparklingwater.location = ""/opt/sparkling-water-2.2.0"")
library(rsparkling) 

## spark version 2.2.0
sc <- spark_connect(master = ""local"", version = ""2.2.0"")

## connect succeed!
h2o_context(sc)",2017-11-05T13:42:47,Hawk Ista,https://stackoverflow.com/users/5353665/hawk-ista,81,46093109
50331878,50331878,0,"Maybe you don't have correctly install all the dependancies for spark, h2o and Rstudio. I have this issue, and by following the doc I notice that I have not all the package.


This is how I fix the issue for me, following the doc 
here


Make sure you have devtools installed, in Rstudio run this command: 
install.packages('devtools')
.


Then:


library(devtools)
devtools::install_github(""h2oai/rsparkling"", ref = ""master"")



Hope this could hepl you.",2018-05-14T13:44:08,french_dev,https://stackoverflow.com/users/3632340/french-dev,"2,177",46093109
46084765,46084765,4,"The R install package is embedded in the zip download file.


This will work, assuming all the dependencies have also been downloaded and installed.


(Of course, substitute the specific version that you want.)


wget https://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/2/h2o-3.14.0.2.zip
unzip h2o-3.14.0.2.zip 
cd h2o-3.14.0.2
cd R
R CMD INSTALL h2o_3.14.0.2.tar.gz",2017-09-06T21:41:29,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46084545
48065056,48065056,0,"You have to have 
h2o.jar
 already downloaded. 


Then set environment variable like so:


Sys.setenv(H2O_JAR_PATH=""_your_h2o_installation_path_/h2o.jar"").",2018-01-02T17:07:52,Milo,https://stackoverflow.com/users/3780040/milo,"3,443",46084545
53768183,53768183,0,"This worked for me.


First download the h2o package archive and get the Jar file then set up H2O_JAR_PATH using this command


Sys.setenv(H2O_JAR_PATH=""/home/hadoop/R/h2o.jar"")



Finally, 


install.packages(""~/R/h2o_3.20.0.8.tar.gz"", repos = NULL, type = ""source"")
library(h2o)",2018-12-13T18:37:30,Arun Kumar,https://stackoverflow.com/users/6945220/arun-kumar,11,46084545
46083205,46083205,0,"To officially answer this question, as Branden said above, this is a bug (and can be avoided by not setting the 
verbose
 option).  The bug is being tracked in the H2O-3 JIRA 
here
 and there is already a pull request with a fix 
here
.",2017-09-06T19:44:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",46080528
46057980,46057980,1,"Two things to keep in mind here.




Your data needs to be large enough to take advantage of data parallelism. In particular, the number of chunks per column needs to be large enough for all the cores to have work to do.  See this answer for more details:  
H2O not working on parallel


H2O-3 assumes your nodes are symmetric.  It doesn't try to load balance work across the cluster based on capability of the nodes.  Faster nodes will finish their work first and wait idle for the slower nodes to catch up.  (You can see this same effect if you have two symmetric nodes but one of them is busy running another process.)




Asymmetry is a bigger problem for memory (where smaller nodes can run out of memory and fail entirely) than it is for CPU (where some nodes are just waiting around).  So always make sure to start each H2O node with the same value of 
-Xmx
.


You can limit the number of cores H2O uses with the 
-nthreads
 option.  So you can try giving each of your two nodes 
-nthreads 4
 and see if they behave more symmetrically with each using roughly four cores.  In the case you describe, that would mean the smaller machine is roughly 100% utilized and the larger machine is roughly 25% utilized.  (But since the two machines probably have different chips, the cores are probably not identical and won't balance perfectly, which is OK.)


[I'm ignoring the virtualization aspect completely, but CPU shares could also come into the picture depending on the configuration of your hypervisor.]",2017-09-05T14:54:12,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",46056853
45979389,45979389,2,"The cited article from 2014 is many years out of date, and refers to H2O-2.  The within-H2O user-mode swap-to-disk concept was experimental at that time.


But this has never been supported in H2O-3 (which became the main H2O code base around early 2015) because the performance was bad, as the cited StackOverflow post explains.",2017-08-31T10:36:46,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45976338
45977094,45977094,1,"If this is in any way commercial, buy more RAM, or pay a few dollars to rent a few hours on a cloud server.


This is because the extra time and effort to do machine learning on a machine that is too small is just not worth it.


If it is a learning project, with no budget at all: cut the data set into 8 equal-sized parts (*), and just use the first part to make and tune your models. (If the data is not randomly ordered, cut it in 32 equal parts, and then concatenate parts 1, 9, 17 and 25; or something like that.)


If you really, really, really, must build a model using the whole data set, then still do the above. But then save the model, then move to the 2nd of your 8 data sets. You will already have tuned hyperparameters by this point, so you are just generating a model, and it will be quick. Repeat for parts 3 to 8. Now you have 8 models, and can use them in an ensemble.


*: I chose 8, which gives you a 0.5GB data set, which is a quarter of available memory. For the early experiments I'd actually recommend going even smaller, e.g. 50MB, as it will make the iterations so much quicker.


A couple more thoughts:




H2O compresses data in-memory. So if the 4GB was the uncompressed data size, you might get by with a smaller memory. (However, remember that the recommendation is for memory that is 3-4x the size of your data.)


If you have some friends with similar small-memory computers, you could network them together. 4 to 8 computers might be enough to load your data. It might work well, it might be horribly slow, it depends on the algorithm (and how fast your network is).",2017-08-31T08:44:29,,,,45976338
46002429,46002429,1,"I don't think H2O supports what you are describing.


BUT, if what you are after is to get the performance against the number of trees used, that can be done at model building time. 


library(h2o)
h2o.init()

iris <- as.h2o(iris)
parts <- h2o.splitFrame(iris,c(0.8,0.1))
train <- parts[[1]]
valid <- parts[[2]]
test <- parts[[3]]
m <- h2o.gbm(1:4, 5, train,
             validation_frame = valid,
             ntrees = 100, #Max desired
             score_tree_interval = 1)

h2o.scoreHistory(m)
plot(m)



The score history will show the evaluation after adding each new tree. 
plot(m)
 will show a chart of this. Looks like 20 is plenty for iris!


BTW, if your 
real
 purpose was to find out the optimum number of trees to use, then switch early stopping on, and it will do that automatically for you. (Just make sure you are using both validation and test data frames.)",2017-09-01T14:26:50,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45953884
59155852,59155852,0,"As of 
3.20.0.6
 H2O 
does support
 this. The method you are looking for is 

staged_predict_proba
. For classification models it produces predicted class probabilities after each iteration (tree), for every observation in your testing frame. For regression models (i.e. when response is numerical), although not really documented, it produces the actual prediction for every observation in your testing frame.


From these predictions it is also easy to compute various performance metrics (AUC, r2 etc), assuming that's what you're after.


Python API:


staged_predict_proba = model.staged_predict_proba(test)



R API:


staged_predict_proba <- h2o.staged_predict_proba(model, prostate.test)",2019-12-03T11:15:15,,,,45953884
45949460,45949460,1,"H2O's glm with lambda search and cross-validation should always pick the best lambda based on cross-validation and use that in the returned (main) model. The early stopping option should have no effect on selected lambda. Its purpose is to skip computation of models for lambdas > best since they are not needed for the main model (we still compute models for lambdas < best since that allows to use warm starting and take full advantage of strong rules).


I think the behavior with early_stopping set to false should compute models for all lambdas in case user wants to see them / do custom model selection.",2017-08-29T22:57:23,Tomas,https://stackoverflow.com/users/7772311/tomas,19,45948642
45928270,45928270,4,"Short answer: you've found a bug and we've opened a ticket 
here
.  The early stopping flag is not being honored when 
nfolds
 > 0.  In the meantime, if you don't set 
nfolds
, you should get 100 lambdas.",2017-08-28T22:38:50,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45890985
45903390,45903390,1,"What is happening is it learns from the cross-validation models, to optimize the parameters used for the final run. (BTW, you are using 
nfolds=2
 which is fairly unusual for a small data set: learn on just 75 records, then test on the other 75. So you are going to have a lot of noise in what it learns from CV.)


Following on from your code:


tail(mod@allparameters$lambda)
mod@model$lambda_best



I'm using 3.14.0.1, so here is what I get:


[1] 0.002129615 0.001940426 0.001768044 0.001610975 0.001467861 0.001337460



and:


[1] 0.001610975



Then if we go look at the same for the 2 CV models:


lapply(mod@model$cross_validation_models, function(m_cv){
  m <- h2o.getModel(m_cv$name)
  list( tail(m@allparameters$lambda), m@model$lambda_best )
  })



I get:


[[1]]
[[1]][[1]]
[1] 0.0002283516 0.0002080655 0.0001895815 0.0001727396 0.0001573939 0.0001434115

[[1]][[2]]
[1] 0.002337249


[[2]]
[[2]][[1]]
[1] 0.0002283516 0.0002080655 0.0001895815 0.0001727396 0.0001573939 0.0001434115

[[2]][[2]]
[1] 0.00133746



I.e. it seems the lowest best lambda found in the CV models was 0.00133, so it has used that as early stopping for the final model.


BTW, if you poke around in those cv models you will see they both tried 100 values for lambda. It is only the final model that does the extra optimization.


(I'm thinking of it as a time optimization, but reading p.26/27 of the Generalized Linear Models booklet (free download from 
https://www.h2o.ai/resources/
), I think it is mainly about using the cv data to avoid over-fitting.)


You 
can
 explicitly specify a set of lambda values to try. BUT, the cross-validation learning will still take priority for the final model. E.g. in the following the final model only tried the first 4 of the 6 lambda values I suggested, because both CV models liked 0.001 best.


mx = h2o.glm(y = ""Sepal.Length"", x = setdiff(colnames(iris), ""Sepal.Length""), 
            training_frame = iris.hex, nfolds = 2, seed = 100,
            lambda = c(1.0, 0.1, 0.01, 0.001, 0.0001, 0), lambda_search = T,
            family = ""gamma"")

tail(mx@allparameters$lambda)
mx@model$lambda_best

lapply(mx@model$cross_validation_models, function(m_cv){
  m <- h2o.getModel(m_cv$name)
  list( tail(m@allparameters$lambda), m@model$lambda_best )
})",2017-08-27T09:09:25,,,,45890985
45885822,45885822,2,"The 
h2o.importFile()
 function does not provide a way of skipping rows upon import.  You have a few options:




Import using 
h2o.importFile()
 and then subset the frame to the rows you want.  Here are 
some examples
 of how to slice rows in an H2OFrame.


Import using a different package that will allow you to skip rows and then use 
as.h2o()
 to convert the data from a data.frame to an H2OFrame.  As noted in the comments above, the 
as.h2o()
 function can be slow for big datasets, however, you can speed it up by installing the 
data.table
 package and setting 
options(""h2o.use.data.table"" = TRUE)
.




I'd recommend the first option, but you could try both and see what's faster for your dataset.",2017-08-25T16:30:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45883791
45851303,45851303,0,"Found the problem. In the docs mentioned in original post, it is specified that the dates should be 
yyyy-mm-dd
. I was inputing the date data into 
h2o
 in the format 
yyyy/mm/dd
. Changing the date info to the 
yyyy-mm-dd
 format seems to have fixed the problem (verifying that the first two dates map correctly to the first two output 
epoch
 time stamps).",2017-08-24T00:51:43,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",45848439
45843574,45843574,0,"Added:


h2o.cluster().shutdown()



and fixed my problem. May be wrong, but I think lack of RAM was my issue, so the shutdown of the previous cluster helped.


Figured out the solution to my own problem but I'll leave this here so I can help the rest of the people that can have the same issue.",2017-08-23T15:15:49,,,,45838312
45837544,45837544,4,"Call the function inside 
tryParam
 with any args or kwargs passed. 


def tryParam(getParam, *args, **kwargs):
    try:
        return getParam(*args, **kwargs)
    except:   
        return None



Then pass the function itself rather than calling it, along with any args or kwargs. 


tryParam(model.aic, valid=True)",2017-08-23T10:45:01,,,,45837493
45837957,45837957,1,"I would try to do this way:


def tryParam(obj, methodName):
    method = getattr(obj, methodName, None)
    if method is not None:
        return method()



Then I can use like:


model = H2ODeepLearningEstimator(...)
model.train()

aic = tryParam(model, 'aic')
mse = tryParam(model, 'mse')
mae = tryParam(model, 'mae')



Repl.it example here",2017-08-23T11:04:58,,,,45837493
45832953,45832953,12,"There are a number of different ways to slice an H2OFrame, row-wise.  The methods are outlined in the H2O User Guide section on 
Slicing Rows
.


Here is an Python example of subsetting an H2OFrame based on a column being set to a particular value using the Iris dataset:


import h2o
h2o.init()

# Load data
path = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv""
df = h2o.import_file(path=path)

# Subset data
mask = df[""class""] == ""Iris-setosa""
newdf = df[mask, :]

# equivalent to both of these, which also work
# newdf = df[df[""class""] == ""Iris-setosa"", :]
# newdf = df[df[""class""] == ""Iris-setosa""]



The 
newdf = df[df[""class""] == ""Iris-setosa""]
 version is almost identical to the format you have above, except H2OFrames do not support referencing a column like this: 
df.class
; you must use: 
df[""class""]
.",2017-08-23T07:12:24,,,,45832671
45821722,45821722,4,"There are two factors at work here.


1) The first is you are using 
as.h2o()
, which is the not-very-efficient ""push"" method (where the client pushes data to the server) of ingesting data.


This is meant for small data and for convenience (which is fine for this case, because you created a dataset with 30,000 rows, which is small data).


If you want H2O to ingest data efficiently, you need to use the ""pull"" method, where H2O pulls data from the data store into H2O's memory.  In R, this would be 
h2o.importFile()
.


2) The second factor is H2O uses chunking of data (contiguous rows in the dataset) to get data parallelism.  The number of chunks per column directly affects the number of threads that work in parallel.  Once a dataset is read in, if it only has 1 chunk per column, then it will only be able to use 1 thread (and hence 1 core).  You can see the number of chunks per column by looking at how the data was parsed in the H2O Flow Web UI.


I ran your program above; see how the Frame Distribution Summary for the resulting H2O Frame shows that the number of chunks per column is 1:




Running the same program again with 3,000,000 rows gives 66 chunks per column:




This is much better because now once you try to do stuff with the data in H2O (like train a model) you will get up to 66 threads running in parallel on a distributed cluster.


[ Note for the bigger case, the data ingestion itself took a few minutes on my laptop and was still slow and single-threaded because it's using the inefficient 
as.h2o()
 ""push"" approach.  If you wrote the dataset out to a csv file, and had H2O parse it with the 
h2o.importFile()
 ""pull"" approach, it would be much faster. ]",2017-08-22T15:28:53,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45819380
45817058,45817058,0,"I can only answer your second question. You should never copy .jars into a Maven project. You need to 
install them to you local repository
 and add the dependency to your pom.xml.
(You can choose what you want as artifact and group. The vendor of the framework would be a good choice)",2017-08-22T12:00:13,Bevor,https://stackoverflow.com/users/319773/bevor,"8,575",45816896
45829433,45829433,0,"You can't use the Maven h2o-genmodel.jar. You have to use the h2o-genmodel.jar that comes from the H2O that you're using. The same goes for deepwater-all.jar. It has to be from the same H2O. deepwater-all.jar contains all the code you need, including the backends. 


Since you used the argument get_genmodel_jar=True you downloaded that at the same time as the mojo. This is the one you must use.",2017-08-23T01:52:01,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45816896
45828181,45828181,2,"You don't need to calculate the distance inside a loop, H2O's distance function can efficiently calculate distances for all the rows. For two data frames with 
n x k
 and 
m x k
 dimensions, you can find the 
n x m
 distance matrix in a following way: 


distance_matrix <- h2o.distance(df1, df2, 'l2')



There is no need to take the square root, since 
h2o.distance()
 function
 allows you to specify what distance measure to use: 
""l1""
 - Absolute distance (L1 norm), 
""l2""
 - Euclidean distance (L2 norm), 
""cosine""
 - Cosine similarity and 
""cosine_sq""
 - Squared Cosine similarity.


Following your example, the code to calculate the Euclidean distance matrix will be:


library(h2o)
h2o.init()
df1 <- as.h2o(matrix(rnorm(7500 * 40), ncol = 40))
df2 <- as.h2o(matrix(rnorm(1250 * 40), ncol = 40))
distance_matrix <- h2o.distance(df1, df2, 'l2')



resulting in a matrix with dimensions 
7500 rows x 1250 columns
.",2017-08-22T22:58:53,karhayrap,https://stackoverflow.com/users/8502874/karhayrap,346,45814469
45808793,45808793,1,"This is a 
known issue
 with H2O's XGBoost implementation and should be fixed soon.  It does not affect other H2O models.",2017-08-22T04:12:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45808473
45828610,45828610,2,"This doesn't exactly answer your question, but I use pip within conda and it works nicely:


$ source activate yourenv
$ which pip





make sure it's the right pip


go to www.h2o.ai/download


choose latest stable release


click ""install in python""


cut and paste the pip command




For example:


$ pip install http://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/2/Python/h2o-3.14.0.2-py2.py3-none-any.whl




Now start python and import h2o.",2017-08-23T00:00:51,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45783640
45786268,45786268,4,"H2O is a client/server architecture.  (See 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html
)


So what you've shown is a very inefficient way to specify an H2O frame in H2O memory.  Every write is going to be turning into a network call.  You almost certainly don't want this.


For your example, since the data isn't large, a reasonable thing to do would be to do the initial assignment to a local data frame (or datatable) and then use push method of as.h2o().


h2o_frame = as.h2o(matrix1)
head(h2o_frame)



This pushes an R data frame from the R client into an H2O frame in H2O server memory.  (And you can do as.data.table() to do the opposite.)




data.table Tips:


For data.table, prefer the in-place := syntax.  This avoids copies.  So, for example:


matrix1[i, 3 := 42]





H2O Tips:


The fastest way to read data into H2O is by ingesting it using the pull method in h2o.importFile().  This is parallel and distributed.


The as.h2o() trick shown above works well for small datasets that easily fit in memory of one host.


If you want to watch the network messages between R and H2O, call h2o.startLogging().",2017-08-20T19:55:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45783048
45784139,45784139,2,"I can't answer your question because I don't know 
h20
. However I can make a guess. 


Your code to fill the 
data.table
  is slow because of the ""copy-on-modify"" semantic. If you update your table by reference you will incredibly speed-up your code.


for(i in 1:1000){ 
  matrix1[i,1]<-3 
}

for(i in 1:1000){ 
  set(matrix1, i, 1L, 3) 
}



With 
set
 my loop takes 3 millisec, while your loop takes 18 sec (6000 times more).


I suppose 
h2o
 to work the same way but with some extra stuff done because this is a special object. Maybe some message passing communication to the H2O cluster?",2017-08-20T16:03:07,,,,45783048
45943695,45943695,2,"It seems as if 
h2o.distance
 calculates the sum of squares, without taking the square root: so take the square root to get the standard result.


distance.h2o <- h2o.distance(df1.h[1,],df2.h[1,],""l2"") 
sqrt(distance.h2o)",2017-08-29T16:06:00,user20650,https://stackoverflow.com/users/2250190/user20650,25.7k,45782023
45749291,45749291,1,"A workaround for this problem is to SET below environment variable before running the Python script:




set PYTHONIOENCODING=UTF-8",2017-08-18T05:43:40,XentneX,https://stackoverflow.com/users/1928229/xentnex,117,45749290
45737424,45737424,2,"col_sample_rate_per_level
 is not supported for xgboost, only GBM and random forest:

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/col_sample_rate_change_per_level.html


Here is the list of what you can use with an xgboost grid: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#xgboost-hyperparameters


(Of course, it ought to be telling you that, and not crashing, so definitely a bug!)",2017-08-17T14:08:41,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45726324
45725738,45725738,1,"AutoML is training H2O models in a sequence, so this advice applies to H2O models in general, not just AutoML -- if your dataset is small enough, adding machines to your H2O cluster will only slow down the training process.  




For a 20MB dataset I am noticing that the cluster is using up a lot of network and hardly touching the CPU.




If you have a 20MB dataset, it's always going to be better to run H2O on a single machine.  The overhead of using multiple machines is only worth it when your training frame won't fit into RAM on a single machine. 
 There is a longer explanation in another Stack Overflow answer I wrote 
here
.




I was wondering if it makes sense for h2o to train 1 model per computer instead of trying to train every model on the entire cluster.




It 
does
 make sense for small data, but H2O was designed to scale to big data (with millions or hundreds of millions of rows), so training several models in parallel is not the design pattern that was used.  To speed up the training process, you can use a single machine with more cores.",2017-08-17T02:33:13,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45725614
45747057,45747057,0,"I don't think we've ever tried running Azure except with a docker image. Are you using Ubuntu 16.04? If so it should work, unless there are differences between that and standard Ubuntu 16.04. It seems like h2o can't communicate with the backends. If you can post the full log from h2o, I could try to see what the problem could be. 


Otherwise I'd say that the easiest way to run it is using the docker image, and that's what I would recommend. Everything has already been installed. The only thing you need to install is docker and nvidia-docker. Instructions: 
https://github.com/h2oai/deepwater#pre-release-docker-image",2017-08-18T01:13:40,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45718219
45706361,45706361,1,"If we check the documentation of 
?h2o.deeplearning




initial_weights  A list of H2OFrame ids to initialize the weight
  matrices of this model with.




Here is an example to set the weights


library(h2o)
h2o.init()
iris.hex <- as.h2o(iris)
iris.dl <- h2o.deeplearning(x = 1:4, y = 5, training_frame = iris.hex,
    hidden=c(10,10),export_weights_and_biases = TRUE
)
w1 <- h2o.weights(iris.dl,1)
w2 <- h2o.weights(iris.dl,2)
w3 <- h2o.weights(iris.dl,3)
b1 <- h2o.biases(iris.dl,1)
b2 <- h2o.biases(iris.dl,2)
b3 <- h2o.biases(iris.dl,3)

dl <- h2o.deeplearning(1:4,5,iris.hex,hidden=c(10,10),initial_weights=c(w1,w2,w3),
    initial_biases=c(b1,b2,b3))

p1 <- h2o.predict(dl, iris.hex)
p1
#  predict    setosa   versicolor    virginica
#1  setosa 0.9967546 0.0032424531 2.946375e-06
#2  setosa 0.9943469 0.0056346023 1.845851e-05
#3  setosa 0.9990881 0.0009072309 4.663780e-06
#4  setosa 0.9990550 0.0009393998 5.593951e-06
#5  setosa 0.9985592 0.0014391955 1.568052e-06
#6  setosa 0.9966511 0.0033477623 1.121636e-06

#[150 rows x 4 columns] 



Regarding the normalization, it will be done by 
h2o
.  Also check 
here",2017-08-16T06:21:26,,,,45705789
45684659,45684659,1,The score function applies the same mapping used to standardize the training data to the test dataset.  This is handled automatically by H2O.,2017-08-14T23:51:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45684592
45684784,45684784,3,"Final EDIT


There are multiple ways of getting lambda (shown below) but here are two concise ways of getting lambda.(Note fully reproducible code is at the bottom)


If you have 
lambda_search = True
, you can look at the model summary table under the 
lambda_search
 column and see what value is set for 
lambda.min
, which is your best lambda


model.summary()['lambda_search']



which will produce a list with a string similar to:


['nlambda = 100, lambda.max = 12.733, lambda.min = 0.05261, lambda.1se = -1.0']



if you don't use lambda search and don't set a lambda value (or do set it) you can also use the summary table


model.summary()['regularization']



output looks like:


['Elastic Net (alpha = 0.5, lambda = 0.01289 )']



Other options:


look at the actual parameters of the model:

best.actual_params['lambda']


best.actual_params['alpha']


where 
best
 was your best model in the grid search results


First EDIT


to get the best model you can do


grid_table = grid.get_grid(sort_by='r2', decreasing=True)
best = grid_table.models[0]



Then you can use:


best.actual_params['lambda']



Fully reproducible example


import h2o
from h2o.estimators.glm import H2OGeneralizedLinearEstimator
h2o.init()

# import the airlines dataset:
# This dataset is used to classify whether a flight will be delayed 'YES' or not ""NO""
# original data can be found at http://www.transtats.bts.gov/
airlines= h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"")

# convert columns to factors
airlines[""Year""]= airlines[""Year""].asfactor()
airlines[""Month""]= airlines[""Month""].asfactor()
airlines[""DayOfWeek""] = airlines[""DayOfWeek""].asfactor()
airlines[""Cancelled""] = airlines[""Cancelled""].asfactor()
airlines['FlightNum'] = airlines['FlightNum'].asfactor()

# set the predictor names and the response column name
predictors = [""Origin"", ""Dest"", ""Year"", ""UniqueCarrier"", ""DayOfWeek"", ""Month"", ""Distance"", ""FlightNum""]
response = ""IsDepDelayed""

# split into train and validation sets
train, valid= airlines.split_frame(ratios = [.8])

# try using the `lambda_` parameter:
# initialize your estimator
airlines_glm = H2OGeneralizedLinearEstimator(family = 'binomial', lambda_ = .0001)

# then train your model
airlines_glm.train(x = predictors, y = response, training_frame = train, validation_frame = valid)

# print the auc for the validation data
print(airlines_glm.auc(valid=True))


# Example of values to grid over for `lambda`
# import Grid Search
from h2o.grid.grid_search import H2OGridSearch

# select the values for lambda_ to grid over
hyper_params = {'lambda': [1, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0]}

# this example uses cartesian grid search because the search space is small
# and we want to see the performance of all models. For a larger search space use
# random grid search instead: {'strategy': ""RandomDiscrete""}
# initialize the glm estimator
airlines_glm_2 = H2OGeneralizedLinearEstimator(family = 'binomial')

# build grid search with previously made GLM and hyperparameters
grid = H2OGridSearch(model = airlines_glm_2, hyper_params = hyper_params,
                     search_criteria = {'strategy': ""Cartesian""})

# train using the grid
grid.train(x = predictors, y = response, training_frame = train, validation_frame = valid)

# sort the grid models by decreasing AUC
grid_table = grid.get_grid(sort_by = 'auc', decreasing = True)
print(grid_table)

best = grid_table.models[0]
print(best.actual_params['lambda'])",2017-08-15T00:08:02,,,,45684402
49566332,49566332,0,"I am not sure why the following does not work 


best = grid_table.models[0]
best.actual_params[""lambda""]
best.actual_params[""alpha""]



It may be an issue with h2o, but if you change the above to the following you should be able to at least access those parameters:


best = grid.models[x]
best.actual_params[""lambda""]
best.actual_params[""alpha""]



Note that I have changed 
0
 to 
x
 because you need to take note of which model performs the best according to your error criteria because the contents within 
grid
 may not be sorted according to your error criteria. This requires you to take a look at 
grid_table
and take note of the model_id and looking at how the models are being stored in 
grid


Then you should be able to at least reference 
lambda
 and 
alpha
. However, when you run a grid search on alpha and you turn the search on for 
lambda
 through the 
lambda_search
 property 
best.actual_params[""lambda""]
 will return the full list of lambdas that were searched over. You could still reference it by considering what Lauren has suggested, but I typically like to see everything in a table and would suggest turning 
lambda_search
 off and adding it to the hyper parameters you search over.


import numpy as np
lambda_search_range = list(np.linspace(0,1,100))
h2o_data = h2o.import_file(""h2o_example.svmlight"")
cols = h2o_data.columns[1:]
hyper_parameters = {""alpha"": [0.0, 0.01, 0.99, 1.0], 
""lambda"": lambda_search_range}
grid = H2OGridSearch(H2OGeneralizedLinearEstimator(family=""gamma"", 
        link=""log"", lambda_search=False, nfolds=2, 
        intercept=True, standardize=False), hyper_params=hyper_parameters)
grid.train(y=""C1"", x=cols, training_frame=h2o_data)
grid_table = grid.get_grid(sort_by=""r2"", decreasing=True)
param_dict = grid_table.get_hyperparams_dict(grid_table.model_ids[0])



param_dict
 should be a dictionary that contains the alpha and lambda values for your best model according to the error criteria you specified.",2018-03-29T23:11:55,,,,45684402
45681480,45681480,3,"It's using the ""leader"" model, which is the #1 model on the leaderboard, ranked by a default metric for the ML task (binary classification, multiclass classification, regression).  The leader model ID is here: 
aml@leader@model_id
.  


The leader model, stored at 
aml@leader
, is just a regular H2O model, so if you want to look at the parameters used, look at 
aml@leader@parameters
 for the parameters that you set, or 
aml@leader@allparameters
 for all the parameter values (including the ones that you did not set manually).


The 
validation_frame
 is used to tune the individual models via early stopping, so the validation error will always be overly-optimistic compared to the test error, which will be a good estimate of the generalization error.  


The third question is out of scope for this post, but I'll answer it anyway.  When you using H2O and start the cluster using 
h2o.init()
 you are running everything locally on your laptop.  If you start an H2O Cluster somewhere else, such as Amazon EC2 or your own remote servers, you can pass the IP address of that server to the 
h2o.init()
 command using the 
ip
 argument to connect to it and the computations will be run on that remote machine.  Either way, the servers are entirely under your control -- there is no ""H2O Cloud"" owned by H2O.ai that does remote processing.",2017-08-14T19:12:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45678743
59588925,59588925,2,"I had the same issue, assume your ""train_h2o"" does not have duplicates, just identify the index of the duplicates in dataframe and remove it. Unfortunately, the h2o Dataframe has limited functionality.


temp_df = train_h2o.as_data_frame()
train_h2o = train_h2o.drop(list(temp_df[temp_df.duplicated()].index), axis=0)",2020-01-04T07:49:29,,,,45672118
64503048,64503048,0,"In case your dataset can contain other duplicate rows that do not come from this H2O bug, the proposed solution will drop also those rows. If you want to make sure that you remove only the additional rows added by H2O, this solution might help you out:


temp_df = train_df_complete.copy()
temp_df['__temp_id__'] = np.arange(len(temp_df))
train_h2o = H2OFrame(temp_df)
train_h2o.drop_duplicates(columns=['__temp_id__'], keep='first')
train_h2o = train_h2o.drop('__temp_id__', axis=1)



What I'm doing here is creating a temporary column that I'll then use as ID in order to drop only the duplicates that have been generated by H2OFrame. Once the duplicates have been remove I drop the temporary column. It might not the most elegant way, but it works.",2020-10-23T15:34:14,,,,45672118
64643960,64643960,0,"I had the same issue with a specific dataset.
Reset index on the base data frame worked for me.


import h2o

train_df_complete = train_df_complete.reset_index()
train_h2o = h2o.H2OFrame(train_df_complete)




I am using h2o 3.30.1.3.",2020-11-02T10:39:47,Utsav Mishra,https://stackoverflow.com/users/14563283/utsav-mishra,1,45672118
45667577,45667577,4,"There is an order in which AutoML builds the models (the GBMs are first in line).  The length of the GBM model building process will depend on how much time you set for 
max_runtime_secs
.  If you plan to run it for 100 hours, then a good portion of that will be spend in the GBM hyperparamter space, so I am not surprised that your first 40 models are GBMs.  In other words, this is expected behavior.  


If you want variety in your models 
as
 they are training, then you can run a single AutoML job for a smaller 
max_runtime_secs
 (say 2 hours), and then run the AutoML process again on that same project (49 more times at 2 hours each -- or some combination that adds up to 100 hours).  If you use the same 
project_name
 when you start an AutoML job, a full new set of models (GBMs, RFs, DNNs, GLMs) should be added to the existing AutoML leaderboard.",2017-08-14T04:40:58,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45665995
45722534,45722534,0,"As Erin said, if you run 
AutoML
 multiple times with the same 
project_name
 the results will accumulate into a single 
leaderboard
 and the hyperparameter searches will accumulate into the same 
grid
 objects.  However, 
AutoML
 will still run through the same sequence of model builds, so it will do a GBM hyperparameter search again before it gets to the 
DL
 model builds.


It feels like your GBM hyperparameter search isn't converging because the 
stopping_tolerance
 is too small for your dataset.  There was a bug in pre-release versions of the bindings which forced the stopping_tolerance to 0.001 instead of letting 
AutoML
 set it higher, if it calculated that that tolerance was too tight for a small dataset.  Which version of H2O-3 are you using? 


A bit about stopping criteria:


The 
stopping_criteria
 such as 
max_models
, 
stopping_rounds
, and 
stopping_tolerance
 apply to the overall 
AutoML
 process as well as to the hyperparameter searches and the individual model builds.  At the beginning of the run 
max_runtime_secs
 is used to compute the end time for the entire process, and then at each stage the remaining overall time is computed and is passed down to the model build or hyperparameter search subtask.


The 
Run Time   558:10:56.131
 that you posted is really weird.  I don't see that sort of output in the 
AutoML.java
 code nor in the Python  or R bindings.  It looks at first glance like this is coming from outside of H2O. . .  Do you have any sense of what the real time was for this run?


We should be able to figure out what's going on if you do the following:




If you're not on the recent release version 3.14.x, please upgrade.


While we're debugging please set the 
seed
 parameter for your AutoML run so that we get repeatable results.


Please post your stopping criteria, your leaderboard output, your User Feedback output, and send your H2O logs to rpeck (at) h2o.ai and support (at) h2o.ai in case we need to delve further.  You can grab the H2O logs from the server or download them using Flow.",2017-08-16T20:33:53,Raymond Peck,https://stackoverflow.com/users/14573842/raymond-peck,11,45665995
45665475,45665475,2,"The model object 
m
 has a lot of information in it.  Use 
dir(m)
 to see all of the available components.  


In some cases, a component of 
m
 is already stored as a data frame, such as the Scoring History:


type(m.scoring_history())
# <class 'pandas.core.frame.DataFrame'>



In other cases, a component will be a list of values, such as Variable Importance:


type(m.varimp())
# <type 'list'>



So, have a look at the output of 
m
, decide what you want, call it with the method names in 
dir(m)
, and then convert to data frame as needed.",2017-08-13T22:36:10,andrew_reece,https://stackoverflow.com/users/2799941/andrew-reece,21.2k,45664403
45680550,45680550,1,"Starting with your 2nd question, Flow has a precision/recall curve (and it is interactive). Flow is always running on port 54321 of each node, i.e. 
http://127.0.0.1:54321
 if you are running h2o locally.


I imagine that there is something interesting with your data or model, and that when you look at the precision/recall curve it will become clear. 


In R if you do 
str(m)
 (where 
m
 is your model) you will see all the model data. 
m@training_metrics@metrics$thresholds_and_metric_scores$recall
 holds the recall numbers for each threshold.


I cannot work out how to look inside the Python object, yet, but your call was correct. On my quick test (the iris dataset with a 2-category enum column added):


m.metric(""recall"")



gave:


[[0.8160852636726422, 1.0]]



And if I want all of the values, it will be something like this:


mDL.metric(""recall"",thresholds=[x/100.0 for x in range(1,100)])



giving:


Could not find exact threshold 0.01; using closest threshold found 0.010396965719556233.
Could not find exact threshold 0.02; using closest threshold found 0.016617060110009896.
...
Could not find exact threshold 0.92; using closest threshold found 0.9469528904679438.
Could not find exact threshold 0.93; using closest threshold found 0.9469528904679438.
Could not find exact threshold 0.94; using closest threshold found 0.9469528904679438.
Could not find exact threshold 0.95; using closest threshold found 0.9469528904679438.
Could not find exact threshold 0.96; using closest threshold found 0.9469528904679438.
Could not find exact threshold 0.97; using closest threshold found 0.9760293572153097.
Could not find exact threshold 0.98; using closest threshold found 0.9787491606489236.
Could not find exact threshold 0.99; using closest threshold found 0.9909817370067531.

[[0.01, 1.0],
 [0.02, 1.0],
 [0.03, 1.0],
 ...
 [0.87, 1.0],
 [0.88, 1.0],
 [0.89, 0.9850746268656716],
 [0.9, 0.9850746268656716],
 [0.91, 0.9850746268656716],
 [0.92, 0.9850746268656716],
 [0.93, 0.9850746268656716],
 [0.94, 0.9850746268656716],
 [0.95, 0.9850746268656716],
 [0.96, 0.9850746268656716],
 [0.97, 0.9701492537313433],
 [0.98, 0.9552238805970149],
 [0.99, 0.8955223880597015]]



(I get such unusual output as it learned my dataset just about perfectly - I suspect that is what has happened with you?) (I foolishly made my binary column a direct function of one of the input columns, with no noise!)",2017-08-14T18:14:42,,,,45655163
45680831,45680831,1,"No, no and maybe.


The maybe is that you could switch from GBM to xgboost, which does have a GPU option (I believe only single-node is supported, and only in Linux currently). xgboost is apparently slightly quicker on small data sets, h2o.gbm slightly quicker on large data sets. If you have a GPU going free, and are using the latest version of H2O, it should be easy to swap 
h2o.gbm
 with 
h2o.xgboost
 (
H2OXGBoostEstimator
 if using Python API) and see for yourself.


I'd be interested to hear the relative timings!


(BTW, the 2nd ""no"" is for GPU use specifically for grids; but all the effort is in the models, not the grid itself, so the 2nd ""no"" could just as well be ""N/A"")",2017-08-14T18:33:06,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45649375
45640783,45640783,4,"You can get some of the individual model metrics for your model based on training and/or validation data. Here is the code snippet:


import h2o
h2o.init(strict_version_check= False , port = 54345)
from h2o.estimators.deeplearning import H2ODeepLearningEstimator
model = H2ODeepLearningEstimator()
rows = [[1,2,3,4,0], [2,1,2,4,1], [2,1,4,2,1], [0,1,2,34,1], [2,3,4,1,0]] * 50
fr = h2o.H2OFrame(rows)
X = fr.col_names[0:4]

## Classification Model
fr[4] = fr[4].asfactor()
model.train(x=X, y=""C5"", training_frame=fr)
print('Model Type:', model.type)
print('logloss', model.logloss(valid = False))
print('Accuracy', model.accuracy(valid = False))
print('AUC', model.auc(valid = False))
print('R2', model.r2(valid = False))
print('RMSE', model.rmse(valid = False))
print('Error', model.error(valid = False))
print('MCC', model.mcc(valid = False))

## Regression Model
fr = h2o.H2OFrame(rows)
model.train(x=X, y=""C5"", training_frame=fr)
print('Model Type:', model.type)
print('R2', model.r2(valid = False))
print('RMSE', model.rmse(valid = False))



Note: As I did not pass validation frame thats why I set valid = False to get training metrics. If you have passed validation metrics then you can set valid = True to get validation metrics as well. 


If you want to see what is inside model object you can look at the json object as below:


model.get_params()",2017-08-11T17:31:09,,,,45634616
45640520,45640520,3,"The model type is stored in 
model.type()
.  


You can see all the methods for a model by typing 
model.
 then the tab key in the IPython terminal.  They are printed alphabetically and that's a good way to find what you're looking for (even if you don't know the exact method name).  You can also search for ""type"" in the 
Python Module documentation
 and you'll find it that way as well.


Example:


import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator
h2o.init()

# Import a sample binary outcome train/test set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()
test[y] = test[y].asfactor() 

# Train a GBM
model = H2OGradientBoostingEstimator(distribution=""bernoulli"", seed=1)
model.train(x=x, y=y, training_frame=train)



Check the model type:


In [3]: model.type
Out[3]: u'classifier'",2017-08-11T17:14:04,,,,45634616
45640350,45640350,1,"h2o.algo gives you the model type.   as for regression or classification, I don't know off the top of my head but it's their somewhere.  Look on flow as its easier to see the parameter names their or do model. and scroll through until you see something that looks like it might have it.",2017-08-11T17:03:47,jack,https://stackoverflow.com/users/8157418/jack,102,45634616
45655258,45655258,0,"(This is on the topic of the question's title so I think it's worth pointing out here.  But it's a bit off topic of the actual question, which is referring to H2O binary models, not POJO and MOJO models.)


For H2O POJO and MOJO models, the method to use is getModelCategory().


See 
http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/hex/genmodel/easy/EasyPredictModelWrapper.html#getModelCategory()",2017-08-12T21:56:03,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45634616
45640149,45640149,1,"When you start h2o inside the docker image, and use -p 54321:54321, h2o will be running at localhost:54321 on the machine where you run docker. You can then connect in the normal way with h2o.init(). When init starts it will look for a running h2o -- which you then have -- and connect to it.",2017-08-11T16:51:25,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45631045
45642638,45642638,0,"Here is what I do to the date 
String
s before I 
row.put(""date_field"", ""<date string>"")
 some 
<date string>
 into a 
RowData
 object (see 
here
) that 
EasyPredictModelWrapper
 can predict on:


/**
     *
     * @param str_date (in MM/dd/yyyy form)
     * @return string representation of timestamp value, either the string value of the str_date timestamp or ""NULL""
     * if can parse str_date to Date object, else returns null
     */
    private String dateString2TimestampString(String str_date) {
        if (str_date.toUpperCase().equals(""NULL"")) {
            return ""NULL"";
        } else {
            try {
                // convert date (MM/DD/YYYY) string to java date
                DateFormat formatter;
                formatter = new SimpleDateFormat(""MM/dd/yyyy"");
                Date date = (Date) formatter.parse(str_date);

                // convert date string to timestamp (since epoch time) (double??)
                double epochTimestamp = (double) date.getTime();
                return new BigDecimal(epochTimestamp).toPlainString();
            } catch (Exception e) {
                System.out.println(""** dateString2TimestampString: could not parse string \"""" + str_date + ""\"" to Date object"");
                System.out.println(e.getClass().getCanonicalName());
                System.err.println(e.getMessage());
                System.exit(1);
                return null;
            }
        }
    } 



Be sure to set the 
convertInvalidNumberToNa
 config (see near the top of 
this
 code) for the wrapper as well so that is nicely handles 
""NULL""
 strings. E.g.:


EasyPredictModelWrapper model = new EasyPredictModelWrapper(
            new EasyPredictModelWrapper.Config()
                .setModel(MojoModel.load(MODEL_CLASS_NAME))
                .setConvertUnknownCategoricalLevelsToNa(true)
                .setConvertInvalidNumbersToNa(true)
        );",2017-08-11T19:37:05,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",45626764
45598669,45598669,1,"The answer depends on what those numbers represent.  


One-hot encoding involves taking a categorical column and expanding that single column into a group of boolean columns.  The assumption here is that among these boolean columns, a training observation can only belong to one of the columns at a time (that's where the ""one"" in one-hot comes from) -- only one column can be ""active"".


If you want to consider 
1,2,3
 it's own category (rather than three categories), then that's fine if that's how you want to represent the data.  In that case, you can leave the data as-is because H2O will automatically one-hot encode categorical columns under the hood, as long as they are encoded as a factor (aka enum) type.  Assuming that your data frame was just those three rows, then there would be three categories: 
1,2,3
, 
1,4
, and 
1,2
.


If the 
1,2,3
 value in 
col2
 means that row 1 is associated with three separate, independent, categories, then you should manually replace 
col2
 with C binary indicator columns, where C is the total number of categories.  Again, if those three rows represented your whole data frame, then you'd replace 
col2
 with four columns.  Your new data frame would look like this:


col1 col2_1 col2_2 col2_3 col2_4  
1    1      1      1      0
2    1      0      0      1
1    1      1      0      0",2017-08-09T18:58:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45565029
45551286,45551286,1,"H2O uses data parallelism to achieve scale and efficiency, and the number of rows here is very small, so the number of parallel threads doing work is probably low.


H2O compares favorably speed-and-scale wise when there are more rows (millions +).


You can see how many threads are working by using the built-in Water Meter (on Linux), or ""top"" or another performance monitoring tool.  And if you open the H2O Flow Web UI, after parsing the data, you can see a detailed Frame Distribution Summary breakdown (see below).


For this example, the dataset I ingested has 43,978 rows and 31 columns.  You can see the number of chunks per column is 1.  This means my data parallelism level is only 1, and only 1 thread will be working.  H2O was designed to be efficient on larger data sets.",2017-08-07T16:06:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45547698
45558364,45558364,1,"There are a few things that I'd consider wrong with the benchmark:  




In H2O, you have 
col_sample_rate_per_tree=0.3
, and in sklearn, you have 
max_features=0.25
.  You should set 
col_sample_rate
 in H2O to the same thing as as 
max_features
 in sklearn.  Using fewer features in sklearn will cause sklearn to train faster.


In sklearn, you have 
min_samples_leaf=3
, but 
min_rows
 (the H2O equivalent) defaults to 1.  These should be set to the same value.  They both default to 1, so you should probably just leave them both at the default value.  Setting 
min_samples_leaf=3
 will force sklearn to stop building the tree sooner (so training will be faster).


Do not set 
stopping_rounds=2
 in H2O.


There are a number of other parameters that have different default values in sklearn vs H2O.


I'd recommend running the benchmark with and without scoring on each iteration to see how that affects performance (referring to 
score_each_iteration
 in H2O and 
oob_score
 in sklearn).


I'm assuming that your data contains only numeric features, but if you use a dataset that contains categorical features, sklearn will require you to one-hot encode those features, which could increase your training time quite a bit, depending on the number of levels for each categorical feature.




That said, it's still possible that sklearn can train faster than H2O on small datasets. H2O is designed with scalability in mind, so you'll start seeing the value of H2O (over other tools) when you use a bit more training data.  There is a nice plot of how H2O Random Forest compares to other tools as training size increases in this 
benchmark
 (screenshot below).  This is only on a single dataset, so it can't be generalized to all situations, but it's a good demonstration of how tools like sklearn start to break down as training size increases (sklearn RF runs out of memory after 1M rows in this particular benchmark).",2017-08-08T02:27:25,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45547698
45611394,45611394,1,"The 6-7 milliseconds vs. ~30 milliseconds difference is probably due to the overhead of making REST API calls.


For making predictions in production environments, where 23ms really matters, I believe it is recommended practice to use the POJO or MOJO. You are using random forest, so should use MOJOs, as they are giving a notable speed improvement according to 
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/howto/MOJO_QuickStart.md


If you are doing tests just to evaluate the speed of H2O, you should also do a comparison on a very large data set, or a more complicated model. E.g. if the difference is then 2.006s vs. 2.030s you can stop worrying about it, and move on to the more important things.",2017-08-10T10:38:58,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45547698
51795230,51795230,0,"I ran into a similar issue.  I had coded up my H2O predict to do one prediction at a time.  The performance was disappointing.  That's because there's a fair amount of overhead to set things up for H2O, including building the H2O dataframe.


To make things reasonable, I batched up several data rows to be predicted on at once, and now I get good performance.


The graph that Dr LeDell posted, clearly shows the various and sometimes large overhead that various platforms encounter.


The OP needs to set up the benchmark to reflect how they really expect to use the model: whether if the overhead is more important (unlikely), or if the time per prediction is more important.",2018-08-10T23:47:30,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,45547698
45548714,45548714,7,"You need to restart your H2O cluster. 


Try 
h2o.cluster().shutdown()
 and then 
h2o.init()
. 


You can also explicitly set the memory allocated to H2O by 
h2o.init(min_mem_size_GB=8)
, which depends upon how much memory your machine has of course.",2017-08-07T13:57:00,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45538140
62464304,62464304,0,"For me below command worked


h2o.shutdown(prompt = FALSE)",2020-06-19T06:09:25,Tokci,https://stackoverflow.com/users/4407260/tokci,"1,280",45538140
45525905,45525905,5,"p0 is the probability (between 0 and 1) that class 0 is chosen.


p1 is the probability (between 0 and 1) that class 1 is chosen.


The thing to keep in mind is that the ""prediction"" is made by applying a threshold to p1.  That threshold point is chosen depending on whether you want to reduce false positives or false negatives.  It's not just 0.5.


The threshold chosen for ""the prediction"" is max-F1.  But you can extract out p1 yourself and threshold it any way you like.",2017-08-05T20:01:32,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45523997
45548566,45548566,1,"Darren Cook asked me to post the first few lines of my training data. Here is is:


   BoxRatio  Thrust  Velocity  OnBalRun  vwapGain  Altitude
0     0.000   0.000     2.186     4.534     0.361         1
1     0.000   0.000     0.561     2.642     0.909         1
2     2.824   2.824     2.199     4.748     1.422         1
3     0.442   0.452     1.702     3.695     1.186         0
4     0.084   0.088     0.612     1.699     0.700         1



The response column is labeled ""Altitude"".  Class 1 is what I want to see from new ""out-of-sample"" data.  ""1"" is good, and it means that ""Altitude"" was reached (true positive).  ""0"" means that ""Altitude"" was not reached (true negative). In the predict table above, ""1"" was predicted with a probability of 0.11505681818181818.  This does not make sense to me.


Charles",2017-08-07T13:49:37,,,,45523997
45558550,45558550,4,"The Stacked Ensemble algorithm in H2O uses GLM as the metalearning algorithm, so you can interpret the magnitude of the coefficients of the GLM metalearner as the ""importance"" of each base learner in making a prediction in the ensemble.  


In the simple 
example
 that's in the Stacked Ensemble documentation, we train a 2-model (GBM, RF) ensemble.  This is how you'd inspect the coefficients of the metalearner GLM in Python:


import h2o
from h2o.estimators.random_forest import H2ORandomForestEstimator
from h2o.estimators.gbm import H2OGradientBoostingEstimator
from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator
h2o.init()

# Import a sample binary outcome train/test set into H2O
train = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv"")
test = h2o.import_file(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")

# Identify predictors and response
x = train.columns
y = ""response""
x.remove(y)

# For binary classification, response should be a factor
train[y] = train[y].asfactor()
test[y] = test[y].asfactor()

# Number of CV folds (to generate level-one data for stacking)
nfolds = 5

# Generate a 2-model ensemble (GBM + RF)

# Train and cross-validate a GBM
my_gbm = H2OGradientBoostingEstimator(distribution=""bernoulli"",
                                      ntrees=10,
                                      max_depth=3,
                                      min_rows=2,
                                      learn_rate=0.2,
                                      nfolds=nfolds,
                                      fold_assignment=""Modulo"",
                                      keep_cross_validation_predictions=True,
                                      seed=1)
my_gbm.train(x=x, y=y, training_frame=train)

# Train and cross-validate a RF
my_rf = H2ORandomForestEstimator(ntrees=50,
                                 nfolds=nfolds,
                                 fold_assignment=""Modulo"",
                                 keep_cross_validation_predictions=True,
                                 seed=1)
my_rf.train(x=x, y=y, training_frame=train)


# Train a stacked ensemble using the GBM and RF above
ensemble = H2OStackedEnsembleEstimator(base_models=[my_gbm.model_id, my_rf.model_id])
ensemble.train(x=x, y=y, training_frame=train)

# Grab the metalearner GLM fit & print normalized coefficients
metafit = h2o.get_model(ensemble.metalearner()['name'])
metafit.coef_norm()



This prints the following:


{u'DRF_model_python_1502159734743_250': 0.6967886117663271,
 u'GBM_model_python_1502159734743_1': 0.48518914691349374,
 u'Intercept': 0.1466358030144971} 



So in this case, the Random Forest's predictions are contributing to the ensemble prediction more than the GBM.


If you evaluate the base models on a test set, you can see that the Random Forest performs slightly better than the GBM, so it makes sense that the ensemble would prefer RF predictions slightly more than GBM (although there is not always a straight-forward 1-1 correspondence between test set performance and metalearner variable importance like this).


my_gbm.model_performance(test).auc()  # 0.7522498803447679
my_rf.model_performance(test).auc() # 0.7698039263004212



There are plans to 
expose the metalearner as an argument
 so that the user can use any of H2O's supervised ML algos as a metalearner in the future, and in that case, you could look at the variable importance of the algorithm to get the same information since all the H2O algorithms compute variable importance.",2017-08-08T02:54:51,,,,45516147
45556196,45556196,1,"This is currently not possible (meaning: there is no option to enable that behavior). You are welcome to request this feature in H2O's jira: 
https://0xdata.atlassian.net/secure/Dashboard.jspa",2017-08-07T21:47:25,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,45512346
45511789,45511789,4,"The 
h2o.automl()
 function has been included in the nightly releases for the past 2 months, so it should be in there if you have correctly installed the package.  I recommend the nightly release over the 3.12 ""preview release"" because 3.12 has some bugs in it with AutoML. 


The nightly release (from last night) can be installed here:


install.packages(""h2o"", type=""source"", repos=""https://h2o-release.s3.amazonaws.com/h2o/master/3978/R"")



Those reading this later, should visit 
this page
 to get the link to the most recent version.


After installation in R, start up the H2O cluster and verify the version.  It should be the same as below:


> h2o.init()
Reading in config file: ./../../.h2oconfig

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T//RtmpV47QKn/h2o_me_started_from_r.out
    /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T//RtmpV47QKn/h2o_me_started_from_r.err

java version ""1.8.0_45""
Java(TM) SE Runtime Environment (build 1.8.0_45-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)

Starting H2O JVM and connecting: .. Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         1 seconds 983 milliseconds 
    H2O cluster version:        3.13.0.3978 
    H2O cluster version age:    10 hours and 6 minutes  
    H2O cluster name:           H2O_started_from_R_me_flj500 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   3.56 GB 
    H2O cluster total cores:    8 
    H2O cluster allowed cores:  8 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.3.2 (2016-10-31) 



AutoML will be included in the next stable release of H2O, 3.14.0.1, to be released in the next week or two.",2017-08-04T16:41:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45510759
45494803,45494803,0,"Are you running this on an Ubuntu 16.04 machine with an Nvidia GPU and all the requirements met from this page 
https://github.com/h2oai/deepwater
 ?


The reason I'm asking is that this is the error you get when you try to run the GPU version on a machine that does not have a GPU.


Deepwater won't work unless the requirements are met. A simple way to do this is to use one of the docker images 


https://github.com/h2oai/deepwater#pre-release-docker-image",2017-08-03T21:29:33,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45493208
50842118,50842118,1,"H2O AutoML has been available since H2O 3.14.0.1.  If it's not available, it means you need to upgrade H2O.",2018-06-13T16:29:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45487655
45610982,45610982,2,"Firstly I would use 
balance_classes
 (set it to true). That will help, a bit, with unbalanced data. (Also look at 
class_sampling_factors
 and 
max_after_balance_size
 if you need to take fine control.)


My hunch would be that your suggestion to use the output of one model to weight a second model is dangerous. It sounds like a bit of the idea of stacked ensemble, but hand-coded and custom code is more likely to have bugs. (But, if you do try it, it would be interesting to see the code and the results.)


To maximize precision I'd go with an ensemble, and put my effort into making 3 or 4 models that have different strengths and weaknesses. E.g. a GBM, a GLM, a deep learning model with all defaults, then a deep learning model using dropout (and more hidden nodes, to compensate).",2017-08-10T10:19:36,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45486923
45496049,45496049,1,"If your Random Forest is slower on a multi-node H2O cluster, it just means that your dataset is not big enough to take advantage of distributed computing.  There is an overhead to communicate between cluster nodes, so if you can train your model successfully on a single node, then using a single node will always be faster.  


Multi-node is designed for when your data is too big to train on a single node.  Only then, will it be worth using multiple nodes.  Otherwise, you are just adding communication overhead for no reason and will see the type of slowdown that you observed.


If your data fits into memory on a single machine (and you can successfully train a model w/o running out of memory), the way to speed up your training is to switch to a machine with more cores.  You can also play around with certain parameter values which affect training speed to see if you can get a speed-up, but that usually comes at a cost in model performance.",2017-08-03T23:24:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45485680
45611203,45611203,1,"As Erin says, often adding more nodes just adds the capability for bigger data sets, not quicker learning. Random forest might be the worst; I get fairly good results with deep learning (e.g. 3x quicker with 4 nodes, 5-6x quicker with 8 nodes).


In your comment on Erin's answer you mention the real problem is you want to speed up hyper-parameter optimization? It is frustrating that 
h2o.grid()
 doesn't support building models in parallel, one on each node, when the data will fit in memory on each node. But you can do that yourself, with a bit of scripting: set up one h2o cluster on each node, do a grid search with a subset of hyper-parameters on each node, have them save the results and models to S3, then bring the results in and combine them at the end.  (If doing a random grid search, you can run exactly the same grid on each cluster, but it might be a good idea to explicitly use a different seed on each.)",2017-08-10T10:29:23,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45485680
45491655,45491655,1,"When you have started the docker image you have to start H2O manually. You do that with


java -jar /opt/h2o.jar &


For more info on this, please see 
https://github.com/h2oai/deepwater#pre-release-docker-image


In the side note: Please post the log, I can't tell what went wrong from this. It's possible that your Nvidia driver is too old.",2017-08-03T18:11:02,,,,45483359
45491572,45491572,0,"We currently don't support the PowerPC architecture. You're getting this error because you try to run Intel x86-64 code and that does not work on ppc64.


Please see 
https://github.com/h2oai/deepwater
 to see what the requirements are for the code, and different ways of using it.",2017-08-03T18:06:08,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45476088
45610449,45610449,0,"Your three lines of svmlight is like a virus! According to 
top
 the java process is as close to 800% CPU (8-core machine) as it can get. After 45m of cpu effort (5-6 mins wall clock) I had to use 
kill -9
 on it to get my machine back.


Even if your type of file is not officially supported, I think the fact that it brings down a machine makes it a serious bug, so I've reported it here: 
https://0xdata.atlassian.net/browse/PUBDEV-4798


BTW, you can find a unit test showing use of smvlight here:

https://github.com/h2oai/h2o-3/blob/30f382efac687be3959a253d975cb48c341c92b4/h2o-r/tests/testdir_misc/runit_parser_type.R",2017-08-10T09:57:59,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45470674
45466609,45466609,1,"Thank you for pointing this out. It will be fixed in the next version of H2O (3.14) coming up next week.


In the meantime please use this code as a workaround to retrieve the model:


model_json = h2o.api(""GET /3/Models/%s"" % model_id)[""models""][0]
m = H2OWord2vecEstimator()
m._resolve_model(model_id, model_json)",2017-08-02T16:46:32,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,45464691
45477132,45477132,0,"This was a bug in 
h2oEnsemble
 v0.2.0 that was introduced when I added support for the extra 
family
 values (gamma, poisson, etc).  I have 
fixed the bug
 and released a 
h2oEnsemble
 v0.2.1; you can find a link to download the new package 
here
, or use the R command below:


install.packages(""https://h2o-release.s3.amazonaws.com/h2o-ensemble/R/h2oEnsemble_0.2.1.tar.gz"", repos = NULL)



On a separate note, your code attempts to include an XGBoost model by using a wrapper, 
""h2o.xgboost.wrapper""
 -- there is no built-in wrapper for XGBoost in the 
h2oEnsemble
 package yet, so that won't work.  I will add the XGBoost wrapper after 
h2o
 3.14.0.1 is released.  That should happen in the next week or two.",2017-08-03T07:05:20,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45463738
45451086,45451086,1,"The 
pred
 object is an H2OFrame.  


> class(pred)
[1] ""H2OFrame""
> head(pred)
  predict        p0        p1
1       1 0.1776320 0.8223680
2       1 0.1959193 0.8040807
3       1 0.2143592 0.7856408
4       1 0.1561238 0.8438762
5       1 0.1461881 0.8538119
6       0 0.2978314 0.7021686



The 
confusionMatrix()
 function is from the 
caret
 package, which does not know what to do with an H2OFrame object -- this is the cause of the error.  The 
caret::confusionMatrix()
 function expects the first argument to be vector in R of class, ""factor"".


If you want to use the 
caret::ConfusionMatrix()
 function, then you just need to convert the 
pred
 object to the right format (which requires bringing it from H2O Cluster memory into R memory and then converting it to a factor).


> confusionMatrix(as.factor(as.data.frame(pred$predict)[,1]), test$Creditability)

Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0  13  10
         1  77 200

               Accuracy : 0.71            
                 95% CI : (0.6551, 0.7607)
    No Information Rate : 0.7             
    P-Value [Acc > NIR] : 0.3793          

                  Kappa : 0.123           
 Mcnemar's Test P-Value : 1.484e-12       

            Sensitivity : 0.14444         
            Specificity : 0.95238         
         Pos Pred Value : 0.56522         
         Neg Pred Value : 0.72202         
             Prevalence : 0.30000         
         Detection Rate : 0.04333         
   Detection Prevalence : 0.07667         
      Balanced Accuracy : 0.54841         

       'Positive' Class : 0               



Alternatively, you can use the 
h2o.confusionMatrix()
 function on the 
deep_model
 object directly.",2017-08-02T03:44:22,,,,45450284
45450912,45450912,0,H2O deals with scaling automatically.  You don't need to do anything.,2017-08-02T03:22:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45448483
45448227,45448227,1,"That is intended -- we wouldn't want to kill an H2O cluster with valuable models on it by accident (if R or Python crashed for some reason).  It makes more sense if you think about R/Python as a gateway to the H2O Cluster.


To shutdown the H2O server from R, type: 
h2o.shutdown()
 or 
h2o.shutdown(prompt = FALSE)
.  You can also kill the associated Java process manually in the terminal if you've already exited R.",2017-08-01T21:50:12,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45446315
45442944,45442944,2,"Variable importance for H2O Deep Learning (or RF or GBM, for that matter) does not have the same interpretation as coefficient magnitude in a GLM (which can be positive or negative), which is what you are describing.  It can be interpreted as ""how important is this variable in predicting the outcome"", and the measure is relative to the other variables in the model.


As mentioned in the 
H2O Deep Learning documentation
, we use a technique called the Gedeon method to calculate this measure.  (RF and GBM use a different method).",2017-08-01T16:19:28,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45442608
45609539,45609539,7,"There appears to be no 
h2o.gc()
 function in the Python API. See ""How can I debug memory issues?"" in 
the FAQ
. You could POST that back-end command (
GarbageCollect
) directly using the REST API if you suspect the problem is the back-end holding on to memory that it no longer should be. Studying the detailed logs, might help confirm if that is the case.


Wrapping up the advice from the comments:




Use 
h2o.remove()
 on H2O frames and models you no longer need, at the end of the loop.


Use 
h2o.removeAll()
 if you do not need to keep anything around, and your loop will be re-loading all the data it needs.


Use 
H2OGridSearch
 rather than your own loops and your own grid code.




I'd also add to be aware that cbind, rbind and any function that modifies an H2O frame will make a copy of the entire frame. Sometimes re-thinking the way you do your data munging steps can reduce the memory requirements.",2017-08-10T09:23:17,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45435739
45427759,45427759,0,"This is a bug with the print-out of the 
str()
 function on H2OFrames (reported 
here
 a few days ago), not an actual bug.  It shows the correct number of rows at the top of the print-out:  


- attr(*, ""nrow"")= int 1000



If you use 
nrow()
 on your frame, you will see the actual number of rows is 1,000:


> nrow(deep_credit)
[1] 1000",2017-08-01T01:52:17,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45427595
45641157,45641157,5,"According to 
?h2o.glm
 the 
interactions=
  parameter takes:




A list of predictor column indices to interact. All
  pairwise combinations will be computed for the list.




You do not want all pairwise combinations, only specific ones.


Unfortunately, the R H2O API does not provide a formula interface.  If it did, then an arbitrary set of interactions would be possible to specify programatically, as in a vanilla R glm.
1


Option 1: Use 
beta_constraints


One solution is to include 
all
 pairwise combinations in the model and then 
suppress
 those you do not want by setting the betas equal to 0.


According to the 
glm docs
, 
beta_constraints=
 serves to:




Specify a dataset to use beta constraints. The selected frame is used
  to constraint the coefficient vector to provide upper and lower
  bounds. The dataset must contain a names column with valid coefficient
  names.




According to the 
H2O Glossary
, the format for 
beta_constraints
 is:




A data.frame or H2OParsedData object with the columns [“names”,
  “lower_bounds”,”upper_bounds”, “beta_given”], where each row
  corresponds to a predictor in the GLM. “names” contains the predictor
  names, “lower_bounds” and “upper_bounds” are the lower and upper
  bounds of beta, and “beta_given” is some supplied starting values for
  beta.




Now we know how to fill out our 
beta_constraints
 data frame 
except
 for how to format the interaction term names.  The 
doc on interactions
 doesn't tell us what to expect. 
 So let's just run an example with interactions through H2O and see what the interactions get named.


library('h2o')
remoteH2O <- h2o.init(ip='xxx.xx.xx.xxx', startH2O=FALSE)

data(mtcars)

df1 <- as.h2o(mtcars, destination_frame = 'demo_mtcars')

target <- 'wt'
predictors <- c('mpg','cyl','hp','disp')

glm1 <- h2o.glm(x = predictors,
                y = target,
                training_frame = 'demo_mtcars',
                model_id = 'demo_glm',
                lambda = 0, # disable regularization, but your use case may vary
                standardize = FALSE, # we want to see the raw parameters, but your use case may vary
                interactions = predictors # create all interactions
                )
print(glm1) # output includes:
# Coefficients: glm coefficients
#        names coefficients
# 1  Intercept     4.336269
# 2    mpg_cyl     0.019558
# 3     mpg_hp     0.000156
# ..



So it looks like the interaction terms are getting named like 
v1_v2
.


So let's name all the interaction terms we want to suppress, using 
setdiff()
 against the terms we want to keep.


library(tidyr)
intx_terms_keep <- # see footnote 1 for explanation
  expand.grid(c('mpg'),c('cyl','hp','disp')) %>%
    unite(intx, Var1, Var2, sep='_') %>% unlist()

intx_terms_suppress <- setdiff( # suppress all interactions minus those we wish to keep
                             combn(predictors,2,FUN=paste,collapse='_'), 
                             intx_terms_keep
                            )
constraints <- data.frame(names=intx_terms_suppress, 
                          lower_bounds=0, 
                          upper_bounds=0, 
                          beta_given=0)

glm2 <- h2o.glm(x = predictors,
                y = target,
                training_frame = 'demo_mtcars',
                model_id = 'demo_glm',
                lambda = 0,
                standardize = FALSE, 
                interactions = predictors, # create all interactions
                beta_constraints = constraints
)
print(glm2) # output includes:
# Coefficients: glm coefficients
#        names coefficients
# 1  Intercept     3.405154
# 2    mpg_cyl    -0.012740
# 3     mpg_hp    -0.000250
# 4   mpg_disp     0.000066
# 5     cyl_hp     0.000000
# 6   cyl_disp     0.000000
# 7    hp_disp     0.000000
# 8        mpg    -0.018981
# 9        cyl     0.168820
# 10      disp     0.004070
# 11        hp     0.000501



As you can see, only the desired interaction terms have non-zero coefficients.  The rest are effectively ignored.  
However,
 since they are still terms in the model, they may count towards degrees of freedom and may affect some of the metrics (i.e., adjusted R-squared).


Option 2: pre-create the interaction terms


As @Darren Cook mentioned, another solution would be to pre-create the interactions as variables in the training dataset.


This approach would ensure that the unwanted interactions do not count towards degrees of freedom and impact your adjusted R-squared.


1
 Alternative, non-H2O solution for vanilla 
glm
 formula interface


In a vanilla R 
glm()
, which allows the formula interface, I would use 
expand.grid
 to create a string of interaction terms and include it in the formula.  


Pass 
expand.grid
 two vectors -- you want to interact all terms in v1 with all terms in v2.


To use your example, you want to interact 
mpg
 with 
cyl
, 
hp
, and 
disp
: 


library(tidyr)
intx_term_string <- 
  expand.grid(c('mpg'),c('cyl','hp','disp')) %>%
    unite(intx, Var1, Var2, sep=':') %>% apply(2, paste, collapse='+')



This gives you a string of interaction terms like 
""mpg:cyl+mpg:hp+mpg:disp""
 that you can paste into a string of other predictors (possibly using paste-collapse) and convert with 
as.formula()
.",2017-08-11T17:54:08,C8H10N4O2,https://stackoverflow.com/users/2573061/c8h10n4o2,18.9k,45426642
45420702,45420702,2,"the two numbers are the threshold and the value for that metric respectively. Once the threshold is determined the 
accuracy
 or 
precision
 metric can be calculated.


if you use 
model.confusion_matrix()
 you can see what threshold was used.


for example in binary classification, the ""threshold"" is the value (between 0 and 1) that determines what the predicted class label is.  If your model predicts a 0.2 for a particular test case, and your threshold is 0.4, the predicted class label will be 0.  If your threshold were 0.15, then the predicted class label would be 1.",2017-07-31T16:12:02,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",45404116
45388619,45388619,2,"Try adding 
gc()
 in your innermost loop. Even better would be to explicitly use 
h2o.rm()
.


So, it would become something like:


for ( k in 1:nrow(par.grid)) {
  hg = h2o.gbm(...stuff...,
             model_id = p(iname, ""_gbm_CV"")
             )
  cv_result[k,1] = h2o.mse(hg, train=TRUE)
  cv_result[k,2] = h2o.mse(hg, valid=TRUE)
  h2o.rm(hg);rm(hg);gc()
}



Theoretically this shouldn't matter, but if R holds on to the reference, then H2O will too.


If you think you might want to investigate any models further, and you have plenty of local disk space, you could do 
h2o.saveModel()
 before your 
h2o.mse()
 calls. (You'll need to specify a filename that somehow summarizes all your parameters, of course...)


UPDATE based on comment:
 If you do not need to keep any models or data, then using 
h2o.removeAll()
 is another way to rapidly reclaim all the memory.  (This approach is also worth considering if any data or models you 
do
 need preserved are quick and easy to re-load.)",2017-07-29T11:14:25,,,,45360398
47202842,47202842,0,"There isn't enough information in this post to give specifics.  But I will say that the presence of Java GC messages is not necessarily a problem, especially at startup.  It's normal to see a flurry of GC messages at the beginning of a Java program's life as the heap expands from nothing to it's steady-state working size.


A sign that Java GC really is becoming a major problem is when you see back-to-back full GC cycles that have a real wall-clock time of seconds or more.",2017-11-09T13:17:05,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45358671
45358061,45358061,1,"Your brackets were misplaced


my_cl$Seg<-ifelse(my_cl$predict==0, 
              '1', 
              ifelse(my_cl$predict==1, '2','0'))",2017-07-27T18:05:17,Patrik_P,https://stackoverflow.com/users/5475592/patrik-p,"3,180",45357217
45340194,45340194,2,"You need to have all host running and sharing same flatfile


For example




You have 3hosts, and create 
flatfile.txt
 for them:


10.0.0.6
10.0.0.7
10.0.0.8



You need to distribute 
flatfile.txt
 around cluster (it is not done for free)


On each host 
10.0.0.{6,7,8}
 you need to run:


java -jar h2o.jar -ip <HOST_IP> -flatfile flatfile.txt





Generally, this is manual process, better way is to use Hadoop/Yarn or Spark (and Sparkling Water).",2017-07-27T02:11:21,Michal,https://stackoverflow.com/users/5089773/michal,437,45340158
45341697,45341697,10,"If you are looking to make predictions on an H2O model in R, then you have three options (which method you choose depends on your use-case):




You can use a 
binary model
 instead of a MOJO (or POJO). For this method, you export the model to disk using 
h2o.saveModel()
 and load it back into the H2O clsuter using 
h2o.loadModel()
 and make predictions using 
predict(model, test)
.  This method requires having an H2O cluster running.


If you's still prefer to export a model to 
MOJO (or POJO)
 format, you can use the 
h2o.mojo_predict_df()
 or 
h2o.mojo_predict_csv()
 function in R to generate predictions on a test set (from an R data.frame or in a CSV file). 


As an alternative to #2, if your data is in JSON format, you can use 
h2o.predict_json()
, but it will only score one row at a time.",2017-07-27T04:53:05,,,,45335697
45337642,45337642,3,"h2o.loadModel
 is meant to be used with 
h2o.saveModel
. If you want to compile and run a MOJO you need to do the following:


first let's say you created a MOJO from a GBM:


library(h2o)
h2o.init(nthreads=-1)
path = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv""
h2o_df = h2o.importFile(path)
h2o_df$RACE = as.factor(h2o_df$RACE)
model = h2o.gbm(y=""CAPSULE"",
        x=c(""AGE"", ""RACE"", ""PSA"", ""GLEASON""),
        training_frame=h2o_df,
        distribution=""bernoulli"",
        ntrees=100,
        max_depth=4,
        learn_rate=0.1)



and then downloaded the MOJO and the resulting h2o-genmodel.jar file to a new experiment folder. Note that the h2o-genmodel.jar file is a library that supports scoring and contains the required readers and interpreters. This file is required when MOJO models are deployed to production.


modelfile = model.download_mojo(path=""~/experiment/"", get_genmodel_jar=True)
print(""Model saved to "" + modelfile)
Model saved to /Users/user/GBM_model_R_1475248925871_74.zip""



Then you would open a new terminal window and change into the experiment directory where you have have the MOJO files .zip and .jar. 


$ cd experiment



Then you would create your main program in the experiment folder by creating a new file called main.java (for example, using ""vim main.java""). Include the following contents. Note that this file is referencing the GBM model created above using R.


import java.io.*;
import hex.genmodel.easy.RowData;
import hex.genmodel.easy.EasyPredictModelWrapper;
import hex.genmodel.easy.prediction.*;
import hex.genmodel.MojoModel;

public class main {
  public static void main(String[] args) throws Exception {
    EasyPredictModelWrapper model = new EasyPredictModelWrapper(MojoModel.load(""GBM_model_R_1475248925871_74.zip""));

    RowData row = new RowData();
    row.put(""AGE"", ""68"");
    row.put(""RACE"", ""2"");
    row.put(""DCAPS"", ""2"");
    row.put(""VOL"", ""0"");
    row.put(""GLEASON"", ""6"");

    BinomialModelPrediction p = model.predictBinomial(row);
    System.out.println(""Has penetrated the prostatic capsule (1=yes; 0=no): "" + p.label);
    System.out.print(""Class probabilities: "");
    for (int i = 0; i < p.classProbabilities.length; i++) {
      if (i > 0) {
    System.out.print("","");
      }
      System.out.print(p.classProbabilities[i]);
    }
    System.out.println("""");
  }
}



Then compile and run in terminal window 2 to get a display of predicted probabilities


$ javac -cp h2o-genmodel.jar -J-Xms2g -J-XX:MaxPermSize=128m main.java
$ java -cp .:h2o-genmodel.jar main",2017-07-26T21:20:37,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",45335697
65610656,65610656,0,"Newer versions of H2O have the ability to import MOJOs via the python API:


# re-import saved MOJO
imported_model = h2o.import_mojo(path)

new_observations = h2o.import_file(path='new_observations.csv')
predictions = imported_model.predict(new_observations)



Caution: MOJO cannot be re-imported into python in older H2O versions, which lack the 
h2o.import_mojo()
 function.


So 
h2o.save_model()
 seems to have lost its role - we can use just 
my_model.save_mojo()
 (notice it's not a 
h2o
 method, but a property of the model object), as these files can be used not just for Java apps deployment, but also in python as well (in fact they still use a python-Java bridge for that internally).",2021-01-07T10:30:27,,,,45335697
45338148,45338148,1,"You need a bigger boat.


The error message is saying ""heapUsedGC=11482667352"", which is higher than MEM_MAX. Instead of giving 
max_mem_size=""12G""
 why not give it more of the 64GB you have? Or build a less ambitious model (fewer hidden nodes, less training data, something like that).


(Obviously, ideally, h2o shouldn't be crashing, and should instead be gracefully aborting  when it gets close to using all the available memory. If you are able to share your data/code with H2O, it might be worth opening a bug report on their JIRA.)


BTW, I've been running h2o 3.10.x.x as the back-end for a web server process for 9 months or so, automatically restarting it at weekends, and haven't had a single crash. Well, I did - after I left it running 3 weeks and it filled up all the memory with more and more data and models. That is why I switched it to restart weekly, and only keep in memory the models I needed.  (This is on an AWS instance, 4GB of memory, by the way; restarts done by cron job and bash commands.)",2017-07-26T22:00:27,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,45333883
45363543,45363543,0,"You can always download the latest stable release from 
https://www.h2o.ai/download
 (there's a link labeled ""latest stable release"").  The latest stable Python package can be downloaded via PyPI and 
Anaconda
; the latest stable R package is available on CRAN.


I agree with Darren that you probably need more memory -- if there is enough memory in your H2O cluster, H2O should not crash.  We usually say that you should have a cluster that's at least 3-4x the size of your training set on disk in order to train a model.  However, if you are building a grid of models, or many models, you will need to increase the memory so that you have enough RAM to store all those models as well.",2017-07-28T01:39:59,,,,45333883
45332668,45332668,0,"I think it's because, since the data is completely random, the max-f1 statistic that H2O uses by default to threshold the final prediction is not producing a useful value.


If you force the threshold to be 0.5, like you see below, you'll get the expected behavior.


Also, if you open H2O Flow and look at the ROC curve for the trained model, it's awful and nearly a straight line (as you would expect).


library(data.table)
library(h2o)

a <- sample(0:1,10000,replace=T)
b <- sample(0:1,10000,replace=T)
c <- sample(1:10,10000,replace=T)
d <- sample(0:1,10000,replace=T)
e <- sample(0:1,10000,replace=T)
f <- sample(0:1,10000,replace=T)
df = data.frame(a, b, c, d, e, f)
dt = as.data.table(df)
dt[1:5000, label := ""A""]
dt[5001:10000, label := ""B""]
dt$label = as.factor(dt$label)
dt

h2o.init()
h2o_dt <- as.h2o(dt)
model = h2o.randomForest(y = ""label"",
                         x = c(""a"", ""b"", ""c"", ""d"", ""e"", ""f""),
                         training_frame = h2o_dt,
                         ntrees = 10,
                         model_id = ""model"")
model
h2o_preds = h2o.predict(model, h2o_dt)
preds = as.data.table(h2o_preds)
preds[, prediction := A > 0.5]
table(preds$prediction)



And the final output is:


FALSE  TRUE 
 5085  4915 



You can rerun it a bunch of times and see the values bounce around randomly but grouped around 5000 each.",2017-07-26T16:28:43,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45330693
45323560,45323560,1,"This appears to be an oddity of how 
str()
 displays H2OFrames, rather than an actual problem. If you look in Flow (localhost:54321) or call 
nrow()
 on the h2o objects, you will see the results you would expect.",2017-07-26T09:57:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45319194
45291343,45291343,1,"The new 
XGBoost integration in H2O
 is the only GPU-capable algorithm in H2O (proper) at this time.  So you can train an XGBoost model on GPUs and score on CPUs, but that's not true for the other 
H2O algorithms
. 


There is also the 
H2O Deep Water
 project, which provides integration between H2O and three third-party deep learning backends (MXNet, Caffe and TensorFlow), all of which are GPU-capable.  So you can train those models using a GPU and score on a CPU as well.  You can download the H2O Deep Water jar file (or R package, or Python module) at the Deep Water link above, and you can find out more info in the 
Deep Water GitHub repo README
.",2017-07-24T22:57:24,,,,45290052
58516354,58516354,0,"Yes, you do the heavy job of training on a GPU, save weights and then, your CPU will only do the matrix multiplication for predictions.


In Keras you can train your model and save Neural Network weights:


model.save_weights('your_model_weights.h5')
model.load_weights('your_model_weights.h5')",2019-10-23T06:00:39,Jeyanth Krishna - Intel,https://stackoverflow.com/users/11759240/jeyanth-krishna-intel,116,45290052
45259546,45259546,4,"p values will only be computed if compute_p_values is set to true, and this will also only work if there is no regularisation, which requires lambda=0


As an example,


library(h2o)
h2o.init()
x<-as.h2o(iris)
xg<-h2o.glm(y=""Sepal.Length"",training_frame=x,compute_p_values=TRUE,lambda=0)
head(xg@model$coefficients_table)



This gives as output:


Coefficients: glm coefficients
               names coefficients std_error   z_value  p_value standardized_coefficients
1          Intercept     2.171266  0.279794  7.760227 0.000000                  6.425687
2 Species.versicolor    -0.723562  0.240169 -3.012721 0.003060                 -0.723562
3  Species.virginica    -1.023498  0.333726 -3.066878 0.002584                 -1.023498
4        Sepal.Width     0.495889  0.086070  5.761466 0.000000                  0.216141
5       Petal.Length     0.829244  0.068528 12.100867 0.000000                  1.463863
6        Petal.Width    -0.315155  0.151196 -2.084418 0.038888                 -0.240223",2017-07-22T21:50:24,Richard,https://stackoverflow.com/users/6718853/richard,"1,121",45258952
55151962,55151962,1,"It's most likely that you got this problem solved, but maybe someone else may benefit.  Use the install in Python Tab on the following website : 
http://h2o-release.s3.amazonaws.com/h2o/rel-tutte/2/index.html
.",2019-03-13T22:14:41,Maxine Bisong,https://stackoverflow.com/users/9655549/maxine-bisong,17,45255460
45225499,45225499,3,"There is a H2OFrame / Pandas DataFrame munging cheatsheet

here
.


The ""EEG Eyestate"" demo was written for both 
H2O
 and 
Scikit-learn
, so that's the closest thing to a side-to-side comparison that I can point you to. 


There are some Python tutorials

here
, which demonstrate basic usage of the supervised H2O algos (and grid search) in Python. 


Taylor Smith created the 
skutil
 module which allows you to use H2O models more easily with sklearn pipelines.",2017-07-20T21:27:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45219053
45220499,45220499,0,"For algorithms and examples in Python for how to use each parameter, go here (the main H2O user documentation) and look at the Algorithms section:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html




For Python specific stuff, go to the docs website and search for 'Python' on the page.  There's a box specifically with Python stuff:




http://docs.h2o.ai




You can use H2O models as elements of an sklearn pipeline.",2017-07-20T16:35:47,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45219053
1393503,1393503,870,"This message means that for some reason the garbage collector is taking an excessive amount of time (by default 98% of all CPU time of the process) and recovers very little memory in each run (by default 2% of the heap).


This effectively means that your program stops doing any progress and is busy running only the garbage collection at all time.


To prevent your application from soaking up CPU time without getting anything done, the JVM throws this 
Error
 so that you have a chance of diagnosing the problem.


The rare cases where I've seen this happen is where some code was creating tons of temporary objects and tons of weakly-referenced objects in an already very memory-constrained environment.


Check out the Java GC tuning guide, which is available for various Java versions and contains sections about this specific problem:




Java 11 tuning guide
 has dedicated sections on excessive GC for different garbage collectors:




for the 
Parallel Collector


for the 
Concurrent Mark Sweep (CMS) Collector


there is no mention of this specific error condition for the Garbage First (G1) collector.




Java 8 tuning guide
 and its 
Excessive GC section


Java 6 tuning guide
 and its 
Excessive GC section
.",2009-09-08T11:39:14,Manuel,https://stackoverflow.com/users/6329250/manuel,691,45217753
1393522,1393522,251,"Quoting from Oracle's article 
""Java SE 6 HotSpot[tm] Virtual Machine Garbage Collection Tuning""
:




Excessive GC Time and OutOfMemoryError


The parallel collector will throw an OutOfMemoryError if too much time is being spent in garbage collection: if more than 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered, an OutOfMemoryError will be thrown. This feature is designed to prevent applications from running for an extended period of time while making little or no progress because the heap is too small. If necessary, this feature can be disabled by adding the option 
-XX:-UseGCOverheadLimit
 to the command line.




EDIT: looks like someone can type faster than me :)",2009-09-08T11:43:16,Community,https://stackoverflow.com/users/-1/community,1,45217753
8498644,8498644,110,"If you are sure there are no 
memory leaks
 in your program, try to:




Increase the heap size, for example 
-Xmx1g
.  


Enable the concurrent low pause collector 
-XX:+UseConcMarkSweepGC
. 


Reuse existing objects when possible to save some memory.




If necessary, the 
limit check
 can be disabled by adding the option 
-XX:-UseGCOverheadLimit
 to the command line.",2011-12-14T01:44:17,Vitalii Fedorenko,https://stackoverflow.com/users/288671/vitalii-fedorenko,114k,45217753
5640498,5640498,58,"It's usually the code. Here's a simple example:


import java.util.*;

public class GarbageCollector {

    public static void main(String... args) {

        System.out.printf(""Testing...%n"");
        List<Double> list = new ArrayList<Double>();
        for (int outer = 0; outer < 10000; outer++) {

            // list = new ArrayList<Double>(10000); // BAD
            // list = new ArrayList<Double>(); // WORSE
            list.clear(); // BETTER

            for (int inner = 0; inner < 10000; inner++) {
                list.add(Math.random());
            }

            if (outer % 1000 == 0) {
                System.out.printf(""Outer loop at %d%n"", outer);
            }

        }
        System.out.printf(""Done.%n"");
    }
}



Using Java 1.6.0_24-b07 on a Windows 7 32 bit.


java -Xloggc:gc.log GarbageCollector



Then look at 
gc.log




Triggered 444 times using BAD method


Triggered 666 times using WORSE method 


Triggered 354 times using BETTER method




Now granted, this is not the best test or the best design but when faced with a situation where you have no choice but implementing such a loop or when dealing with existing code that behaves badly, choosing to reuse objects instead of creating new ones can reduce the number of times the garbage collector gets in the way...",2011-04-12T19:27:01,StackzOfZtuff,https://stackoverflow.com/users/4247268/stackzofztuff,"3,050",45217753
35244518,35244518,40,"Cause for the error according to the 
Java [8] Platform, Standard Edition Troubleshooting Guide
: (emphasis and line breaks added)




[...] ""GC overhead limit exceeded"" indicates that the garbage collector is running all the time and Java program is making very slow progress. 


After a garbage collection, if the 
Java process is spending more than approximately 98% of its time doing garbage collection
 and if it is recovering less than 2% of the heap and has been doing so far the last 5 (compile time constant) consecutive garbage collections, then a 
java.lang.OutOfMemoryError
 is thrown. [...]






Increase the heap size
 if current heap is not enough.


If you still get this error after increasing heap memory, use memory 
profiling tools
 like 
MAT
 ( Memory analyzer tool),  
Visual VM
 etc and fix memory leaks.


Upgrade JDK version to latest version ( 1.8.x) or at least 1.7.x and use G1GC algorithm. . 
The throughput goal for the G1 GC is 90 percent application time and 10 percent garbage collection time


Apart from setting heap memory with -
Xms1g -Xmx2g
 , try


-XX:+UseG1GC -XX:G1HeapRegionSize=n -XX:MaxGCPauseMillis=m  
-XX:ParallelGCThreads=n -XX:ConcGCThreads=n





Have a look at some more related questions regarding G1GC




Java 7 (JDK 7) garbage collection and documentation on G1


Java G1 garbage collection in production


Oracle technetwork article for GC finetuning",2016-02-06T18:06:58,StackzOfZtuff,https://stackoverflow.com/users/4247268/stackzofztuff,"3,050",45217753
23628984,23628984,33,"Just increase the heap size a little by setting this option in


Run → Run Configurations → Arguments → VM arguments


-Xms1024M -Xmx2048M



Xms
 - for minimum limit


Xmx
 - for maximum limit",2014-05-13T10:40:23,randers,https://stackoverflow.com/users/4464702/randers,"5,137",45217753
40771497,40771497,16,"try this


open the 
build.gradle
 file  


  android {
        dexOptions {
           javaMaxHeapSize = ""4g""
        }
   }",2016-11-23T18:09:56,ali ozkara,https://stackoverflow.com/users/4362167/ali-ozkara,"5,599",45217753
27716421,27716421,14,"For me, the following steps worked:




Open the 
eclipse.ini
 file


Change


-Xms40m
-Xmx512m



to


-Xms512m
-Xmx1024m



Restart Eclipse




See here",2014-12-31T05:09:49,Mohd Shakir Zakaria,https://stackoverflow.com/users/520074/mohd-shakir-zakaria,664,45217753
41344611,41344611,13,"The following worked for me. Just add the following snippet:


android {
        compileSdkVersion 25
        buildToolsVersion '25.0.1'

defaultConfig {
        applicationId ""yourpackage""
        minSdkVersion 10
        targetSdkVersion 25
        versionCode 1
        versionName ""1.0""
        multiDexEnabled true
    }
dexOptions {
        javaMaxHeapSize ""4g""
    }
}",2016-12-27T11:47:41,Hoshouns,https://stackoverflow.com/users/1607562/hoshouns,"2,430",45217753
43278151,43278151,9,"increase javaMaxHeapsize in your build.gradle(Module:app) file


dexOptions {
    javaMaxHeapSize ""1g""
}



to (Add this line in gradle)


 dexOptions {
        javaMaxHeapSize ""4g""
    }",2017-04-07T12:27:08,saigopi.me,https://stackoverflow.com/users/5208491/saigopi-me,14.8k,45217753
58048041,58048041,9,"Solved:

Just add


org.gradle.jvmargs=-Xmx1024m

in


gradle.properties

and if it does not exist, create it.",2019-09-22T09:53:06,reza_khalafi,https://stackoverflow.com/users/3319132/reza-khalafi,"6,494",45217753
57172182,57172182,6,"You can also increase memory allocation and heap size by adding this to your 
gradle.properties
 file:


org.gradle.jvmargs=-Xmx2048M -XX\:MaxHeapSize\=32g


It doesn't have to be 2048M and 32g, make it as big as you want.",2019-07-23T21:03:58,John Doe,https://stackoverflow.com/users/11703772/john-doe,"1,131",45217753
58319283,58319283,5,"Java heap size descriptions (xms, xmx, xmn)


-Xms size in bytes

Example : java -Xms32m



Sets the initial size of the Java heap. 
The default size is 2097152 (2MB). 
The values must be a multiple of, and greater than, 1024 bytes (1KB).
(The -server flag increases the default size to 32M.)


-Xmn size in bytes

Example : java -Xmx2m



Sets the initial Java heap size for the Eden generation. 
The default value is 640K. 
(The -server flag increases the default size to 2M.)


-Xmx size in bytes

Example : java -Xmx2048m



Sets the maximum size to which the Java heap can grow. 
The default size is 64M. 
(The -server flag increases the default size to 128M.) 
The maximum heap limit is about 2 GB (2048MB).


Java memory arguments (xms, xmx, xmn) formatting


When setting the Java heap size, you should specify your memory argument using one of the letters “m” or “M” for MB, or “g” or “G” for GB. Your setting won’t work if you specify “MB” or “GB.” Valid arguments look like this:


-Xms64m or -Xms64M
-Xmx1g or -Xmx1G
Can also use 2048MB to specify 2GB
Also, make sure you just use whole numbers when specifying your arguments. Using -Xmx512m is a valid option, but -Xmx0.5g will cause an error.


This reference can be helpful for someone.",2019-10-10T09:09:00,Phoenix,https://stackoverflow.com/users/3269543/phoenix,"1,530",45217753
50858480,50858480,2,"To increase heap size in IntelliJ IDEA follow the following instructions. It worked for me.


For Windows Users,


Go to the location where IDE is installed and search for following.


idea64.exe.vmoptions



Edit the file and add the following.


-Xms512m
-Xmx2024m
-XX:MaxPermSize=700m
-XX:ReservedCodeCacheSize=480m



That is it !!",2018-06-14T13:16:24,Du-Lacoste,https://stackoverflow.com/users/3600553/du-lacoste,12.6k,45217753
48142185,48142185,1,"I'm working in Android Studio and encountered this error when trying to generate a signed APK for release. 
I was able to build and test a debug APK with no problem, but as soon as I wanted to build a release APK, the build process would run for minutes on end and then finally terminate with the ""Error java.lang.OutOfMemoryError: GC overhead limit exceeded"". I increased the heap sizes for both the VM and the Android DEX compiler, but the problem persisted.
Finally, after many hours and mugs of coffee it turned out that the problem was in my app-level 'build.gradle' file - I had the 'minifyEnabled' parameter for the release build type set to 'false', consequently running Proguard stuffs on code that hasn't been through the code-shrinking' process (see 
https://developer.android.com/studio/build/shrink-code.html
). 
I changed the 'minifyEnabled' parameter to 'true' and the release build executed like a dream :)


In short, I had to change my app-level 'build.gradle' file from:
    //...


buildTypes {
    release {
        minifyEnabled false
        proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        signingConfig signingConfigs.sign_config_release
    }
    debug {
        debuggable true
        signingConfig signingConfigs.sign_config_debug
    }
}

//...



to


    //...

buildTypes {
    release {
        minifyEnabled true
        proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        signingConfig signingConfigs.sign_config_release
    }
    debug {
        debuggable true
        signingConfig signingConfigs.sign_config_debug
    }
}

//...",2018-01-07T22:33:42,Alex Ivan Howard,https://stackoverflow.com/users/5320947/alex-ivan-howard,74,45217753
60425510,60425510,1,"you can try to make changes on the server setting by referring to this image and increase the memory size for processing
process changes highlighted in yellow


you can also make changes to java heap by opening cmd-> 
set _java_opts -Xmx2g

2g(2gigabytes) depending upon the complexity of your program


try to use less constant variable and temp variables",2020-02-27T02:40:16,Rahul Jain,https://stackoverflow.com/users/2149194/rahul-jain,410,45217753
69140222,69140222,1,"@Buhb
I reproduced this by this in an normal spring-boot web application within its main method. Here is the code:


public static void main(String[] args) {
    SpringApplication.run(DemoServiceBApplication.class, args);
    LOGGER.info(""hello."");
    int len = 0, oldlen=0;
    Object[] a = new Object[0];
    try {
        for (; ; ) {
            ++len;
            Object[] temp = new Object[oldlen = len];
            temp[0] = a;
            a = temp;
        }
    } catch (Throwable e) {
        LOGGER.info(""error: {}"", e.toString());
    }
}



The sample code that caused an come is also from oracle java8 language specifications.",2021-09-11T05:17:23,spike,https://stackoverflow.com/users/13217255/spike,35,45217753
69866826,69866826,1,"I got this error while working with Oracle web logic server. I am sharing my answer for reference in case someone end up here looking for the solution.


So, if you are trying to up the Oracle web logic server and got this error then you just have to increase the initial and maximum heap size set for running the server.




Go to - > 
C:\Oracle\Middleware\Oracle_Home\user_projects\domains\wl_server\bin


open 
setDomainEnv.cmd


check 
set USER_MEM_ARGS
 value , if its less then


set USER_MEM_ARGS=""-Xms128m – Xmx8192m ${MEM_DEV_ARGS} ${MEM_MAX_PERM_SIZE}""




This means that your intital heap size is set to 128 MB and max heap size is 8GB.
Now , just save the file and restart the server. if it didn't resolve the issue, try increasing the size or look for ways to optimizing the service.


for ref , check this link  : 
https://docs.oracle.com/cd/E49933_01/server.770/es_install/src/tins_postinstall_jvm_heap.html


edit: Check whether you are able to see the updated java args while running the server . just like this 

If its coming as before then replace the shown value from setDoaminEnv.cmd by simple search and replace.",2021-11-06T18:35:38,,,,45217753
36594743,36594743,0,"You need to increase the memory size in Jdeveloper go to 
setDomainEnv.cmd
.


set WLS_HOME=%WL_HOME%\server    
set XMS_SUN_64BIT=**256**
set XMS_SUN_32BIT=**256**
set XMX_SUN_64BIT=**3072**
set XMX_SUN_32BIT=**3072**
set XMS_JROCKIT_64BIT=**256**
set XMS_JROCKIT_32BIT=**256**
set XMX_JROCKIT_64BIT=**1024**
set XMX_JROCKIT_32BIT=**1024**

if ""%JAVA_VENDOR%""==""Sun"" (
    set WLS_MEM_ARGS_64BIT=**-Xms256m -Xmx512m**
    set WLS_MEM_ARGS_32BIT=**-Xms256m -Xmx512m**
) else (
    set WLS_MEM_ARGS_64BIT=**-Xms512m -Xmx512m**
    set WLS_MEM_ARGS_32BIT=**-Xms512m -Xmx512m**
)



and 


set MEM_PERM_SIZE_64BIT=-XX:PermSize=**256m**
set MEM_PERM_SIZE_32BIT=-XX:PermSize=**256m**

if ""%JAVA_USE_64BIT%""==""true"" (
    set MEM_PERM_SIZE=%MEM_PERM_SIZE_64BIT%
) else (
    set MEM_PERM_SIZE=%MEM_PERM_SIZE_32BIT%
)

set MEM_MAX_PERM_SIZE_64BIT=-XX:MaxPermSize=**1024m**
set MEM_MAX_PERM_SIZE_32BIT=-XX:MaxPermSize=**1024m**",2016-04-13T09:52:39,Tunaki,https://stackoverflow.com/users/1743880/tunaki,137k,45217753
44509807,44509807,0,"In Netbeans, it may be helpful to design a max heap size. Go to 
Run
 => 
Set Project Configuration
 => 
Customise
. In the 
Run
 of its popped up window, go to 
VM Option
, fill in 
-Xms2048m -Xmx2048m
. It could solve heap size problem.",2017-06-12T22:45:37,Ravindra babu,https://stackoverflow.com/users/4999394/ravindra-babu,38.8k,45217753
59024964,59024964,0,"I don't know if this is still relevant or not, but just want to share what worked for me.


Update kotlin version to latest available. 
https://blog.jetbrains.com/kotlin/category/releases/


and it's done.",2019-11-25T03:41:41,androidStud,https://stackoverflow.com/users/3489351/androidstud,532,45217753
77143416,77143416,0,"If you are here for the exception that rise in 
TOMCAT
 then this is for you:


It may happen when you work with that tomcat for the long time


Steps:




Navigate to tomcat folder (C:/tomcat)


There will a folder named - ""work"" and then - ""catalina"" then - ""localHost""


Delete that localhost folder


Inside C:/tomcat/webapps there will be files, delete all and rebuild.




Now that heap memory issue would be sorted.",2023-09-20T14:24:35,Ashrik Ahamed,https://stackoverflow.com/users/12836822/ashrik-ahamed,437,45217753
77628368,77628368,0,"For SAP BOBJ BOE SIA CMS 4.1, the xmx parameter is in the registry at location:


HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Apache Software Foundation\Procrun 2.0\SIAserverName\Parameters\Java


Options value, it was 256m, increased it to 2g. No more out of memory errors in the log file, SIA is now stable and CMS.exe starts up okay.",2023-12-08T17:50:27,Roger Perkins,https://stackoverflow.com/users/783470/roger-perkins,376,45217753
54890955,54890955,-6,Rebooting my MacBook fixed this issue for me.,2019-02-26T17:23:05,Thomas,https://stackoverflow.com/users/270847/thomas,"6,110",45217753
45206165,45206165,1,"Set 
fold_assignment
 to ""Stratified"".


.",2017-07-20T05:48:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45206076
45205035,45205035,0,"You can find out how to use Grid Search in Flow 
here
.  (Use CV in your grid search by setting 
nfolds > 1
.)


H2O also supports Random (Grid) Search through the programmatic APIs, but it's not currently supported via Flow, so I created a 
JIRA
 for that.  More info on that at the 
Grid Search
 section of the H2O User Guide.",2017-07-20T04:10:44,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45204330
45204119,45204119,2,"The ""TwoDimTable"" class is used to store lightweight tabular data in a model.  I am agreement with you about using H2OFrames instead of TwoDimTables, but it's a design choice that was made a long time ago (can't change it now).


Since H2OFrames can contain non-numeric data, there is an 
.as_data_frame()
 method to from an H2OFrame or TwoDimTable to a Pandas DataFrame.  So you can chain 
.as_data_frame().as_matrix()
 together to get a matrix (
numpy.ndarray
) if that's what you're looking for.  Here's an example:


import h2o
from h2o.estimators.glrm import H2OGeneralizedLowRankEstimator

h2o.init()

data = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/glrm_test/cancar.csv"")

# Train a GLRM model with recover_svd=True to keep eigenvectors
glrm = H2OGeneralizedLowRankEstimator(k=4,
                                      transform=""NONE"",
                                      loss=""Quadratic"",
                                      regularization_x=""None"",
                                      regularization_y=""None"",
                                      max_iterations=1000,
                                      recover_svd=True)
glrm.train(x=data.names, training_frame=data)

# Get eigenvector TwoDimTable from the model
EV = glrm._model_json[""output""]['eigenvectors']

# Convert to various formats
evdf = EV.as_data_frame() #pandas.core.frame.DataFrame
evmat = evdf.as_matrix()  #numpy.ndarray

# or directly
evmat = EV.as_data_frame().as_matrix()



If you're interested in adding a 
.as_matrix()
 method to the TwoDimTable class, you could submit a pull request on the 
h2o-3 repo
 for that.  I think that would be a useful extension.  There's more info about how to contribute to H2O in our 
contributing guide
.",2017-07-20T02:35:07,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45201792
45258659,45258659,1,"Your intuition is correct.  Using GLRM, you decompose a matrix A = XY and you perform clustering on X.  For a new dataset, ANew, you need to get your new XNew.  To do this, you perform XNew = ANew * inverse(Y).  However, if your dataset contains categorical columns, GLRM will first expand the categorical columns using one hot encoding which will increase the number of columns in your original dataset.  In addition, it will move all categorical columns to the front, then perform one hot encoding.  And then, it will perform GLRM on AOneHot = XY.  Hence, when you try XNew = ANew * inverse(Y), you have the dimension mismatch.  The way to do this is to perform one hot encoding on your categorical columns on ANew and then apply inverse(Y).   Hope this helps.  Wendy",2017-07-22T20:00:58,Wendy Wong,https://stackoverflow.com/users/8351107/wendy-wong,26,45194421
45193530,45193530,5,"Here is an open benchmark you can start with.


https://github.com/szilard/benchm-ml",2017-07-19T14:25:33,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45190787
45192532,45192532,0,"I suppose you are looking for this: 
http://www.wise.io/tech/benchmarking-random-forest-part-1",2017-07-19T13:46:08,Andrey Lukyanenko,https://stackoverflow.com/users/6797250/andrey-lukyanenko,"3,841",45190787
45193454,45193454,2,"There is no supported path in H2O to do this.  (If anyone in the community has a way, I'd be interested to see it.)


They way H2O provides to productionize models is by exporting them as MOJOs or POJOs.




http://docs.h2o.ai/h2o/latest-stable/index.html


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html",2017-07-19T14:22:58,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45182882
45774781,45774781,1,"Everything is included in the docker image. You don't need to do any integrations yourself. You select the backend by setting the 
backend
 parameter to 
tensorflow
, 
mxnet
, or 
caffe
.",2017-08-19T18:02:01,Magnus,https://stackoverflow.com/users/7816546/magnus,246,45174782
45155828,45155828,1,"H2O does not have node.js bindings, but H2O exposes a well documented REST API. From Electron, you can start H2O using the 
child_process
 module, then talk to H2O using the REST API. If you only care about embedding the model in your Electron app, you can self host the model in a java process using node-java (if you are building some kind of a desktop-only application), OR you can have the Electron app talk to a local or remote http server that hosts the model (see 
https://github.com/h2oai/app-consumer-loan
)",2017-07-18T00:59:18,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",45153751
45154577,45154577,4,"If you want to know which feature columns the model used after you have built a model you can do the following in python:


my_training_frame = your_model.actual_params['training_frame']



which will return some frame id


and then you can do


col_used = h2o.get_frame(my_training_frame)
col_used



EDITED
 (after comment was posted)


To get the columns use:

col_used.columns


Also, a quick way to check the version of a saved binary model is to try and load it into h2o, if it loads it is the same version of h2o, if it isn't you will get a warning.


you can also open the saved model file, the first line will list the version of H2O used to create it.


For a model saved as a mojo you can look at the 
model.ini
 file. It will list the version of H2O.",2017-07-17T22:24:45,Laurel,https://stackoverflow.com/users/6083675/laurel,"6,153",45153176
45177389,45177389,1,"I have confirmed that it is a bug with the Python API (the 
max_runtime_secs
 code is working on the backend and also in the R client).  I opened a ticket 
here
 and I'm hopeful that this will be fixed in the next release.",2017-07-18T21:26:26,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45150001
45147752,45147752,0,"Whilst not recommended/supported, you can start h2o with the parameter strict_version_check=False when calling h2o.init()


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/starting-h2o.html",2017-07-17T15:10:52,Richard,https://stackoverflow.com/users/6718853/richard,"1,121",45147066
45143490,45143490,2,"You can save and load models in python directly, although this will require you to have h2o running


https://h2o-release.s3.amazonaws.com/h2o/rel-turing/10/docs-website/h2o-docs/save-and-load-model.html",2017-07-17T11:48:32,Richard,https://stackoverflow.com/users/6718853/richard,"1,121",45137541
45318779,45318779,1,"The skutil project might be helpful for you.  It's an integration of scikit-learn and H2O.


See:


https://github.com/tgsmith61591/skutil",2017-07-26T06:12:31,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45137541
45108173,45108173,2,"There is no maximum dataset size in H2O.  The requirements are defined by how big of a cluster you create.  There is more info about how to tell H2O what the max heap size you'd like 
here
.


If your dataset is 70G, and you have nodes with only 40G RAM, then you will have to use a multi-node cluster.  The general rule of thumb that we tell people is that your H2O cluster should be 3x the size of your data on disk.   It's highly dependent on which algorithm you are using, however.  


70G*3 = 210G, so you might want to try a 5-node cluster.  Or, you could start with fewer nodes, try running your code and increase the size of the cluster as required.",2017-07-14T16:58:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45107028
45094438,45094438,0,"Instead of trying to compile an H2O random forest POJO, you can download and use a MOJO instead in almost exactly the same way without needing the compile step.


See:


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html",2017-07-14T04:07:52,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",45094045
45094060,45094060,0,"H2O binary models (models running in the H2O cluster) will handle unseen categorical levels automatically, however, in when you are generating predictions using the pure Java POJO model method (like in your case), this is a configurable option.  In the 
EasyPredictModelWrapper
, the default behavior is that unknown categorical levels throw 
PredictUnknownCategoricalLevelException
, which is why you are seeing that error.


There is more info about this in the 
EasyPredictModelWrapper Javadocs
.
Here is an example:


The easy prediction API for generated POJO and MOJO models. Use as follows:
1. Instantiate an EasyPredictModelWrapper
2. Create a new row of data
3. Call one of the predict methods


Here is an example:


// Step 1.
modelClassName = ""your_pojo_model_downloaded_from_h2o"";
GenModel rawModel;
rawModel = (GenModel) Class.forName(modelClassName).newInstance();

EasyPredictModelWrapper model = new EasyPredictModelWrapper(
                                    new EasyPredictModelWrapper.Config()
                                        .setModel(rawModel)
                         .setConvertUnknownCategoricalLevelsToNa(true));

// Step 2.
RowData row = new RowData();
row.put(new String(""CategoricalColumnName""), new String(""LevelName""));
row.put(new String(""NumericColumnName1""), new String(""42.0""));
row.put(new String(""NumericColumnName2""), new Double(42.0));

// Step 3.
BinomialModelPrediction p = model.predictBinomial(row);",2017-07-14T03:24:07,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45093030
45098628,45098628,0,"h2o's deeplearning functionality is is missing features that are present in the tensorflow implementation. For example, h2o's deeplearning function does not currently support constitutional neural networks.


See the first slide in the presentation here: 
https://github.com/h2oai/deepwater/blob/master/README.md",2017-07-14T08:49:04,Richard,https://stackoverflow.com/users/6718853/richard,"1,121",45088729
45088244,45088244,4,"The issue is that 
int
 isn't an option you can pass to the h2o 
col_types
 parameter, you need to pass 
numeric
. 


If you pass 
numeric
 for your real and int values,  that should solve your problem - though the integers will be converted to floats. For 
 H2O integers are used so they can be mapped to categorical (using 
.asfactor()
) 


In H2O the following types are allowed


“unknown” - this will force the column to be parsed as all NA


“uuid” - the values in the column must be true UUID or will be parsed as NA


“string” - force the column to be parsed as a string


“numeric” - force the column to be parsed as numeric. H2O will handle the compression of the numeric data in the optimal manner.


“enum” - force the column to be parsed as a categorical column.


“time” - force the column to be parsed as a time column. H2O will attempt to parse the following list of date time formats: (date) “yyyy-MM-dd”, “yyyy MM dd”, “dd-MMM-yy”, “dd MMM yy”, (time) “HH:mm:ss”, “HH:mm:ss:SSS”, “HH:mm:ss:SSSnnnnnn”, “HH.mm.ss” “HH.mm.ss.SSS”, “HH.mm.ss.SSSnnnnnn”. Times can also contain “AM” or “PM”.


you can see more details in the docs: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html?highlight=import_file#h2o.import_file",2017-07-13T18:17:03,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",45085994
45088742,45088742,2,"In H2O, data storage is optimized by H2O, so if you have a column that can be stored with fewer bytes (such as an ""int""), then H2O will store it that way, even if you try to force it to use the ""real"" (or float) type.


For specifying column types, H2O has it's own vocabulary for describing the types (detailed in Lauren's 
response
), but you'll see that when you specify ""numeric"" for that third column, it will end up as an int.


data =[(1,'one', 9),(9,'two',3), (8,'three', 99.0)]
given_types = {'C1': 'int', 'C2': 'string', 'C3': 'numeric'}
frame = h2o.H2OFrame(data, column_types=given_types)
actual_types = frame.types



Results in:


In [39]: actual_types
Out[39]: {u'C1': u'int', u'C2': u'string', u'C3': u'int'}

In [40]: given_types
Out[40]: {'C1': 'int', 'C2': 'string', 'C3': 'numeric'}",2017-07-13T18:45:53,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45085994
60436802,60436802,0,"Just try to use the 
h2o.
import_file
()
 after saving the file to csv with the argument 
col_types
 passed instead of 
h2o.H2OFrame()
. That solved my problem.",2020-02-27T15:40:26,Maximouse,https://stackoverflow.com/users/10742758/maximouse,"4,394",45085994
45065438,45065438,2,"For the 
Super Learner
 algorithm (stacking such that you use the cross-validated predicted values from the base learners as training data for the metalearner), the only requirement is that the base learners must be trained on the same rows -- the columns can be different.  There is a variant of stacking, let's call it 
""Holdout Stacking""
, where you score the base models on a holdout dataset and use those predictions to train the metalearner instead.  In this case, you can use entirely different training frames for the base learners.


The current 
Stacked Ensembles
 implementation in H2O has a restriction that the whole training frame (rows and columns) must be the same for the base learners, but we 
will relax that requirement
 in the future (since it's not really required).


Before we moved Stacked Ensembles in to the Java backend of H2O, I coded a simple reference implementation in Python using only the 
h2o
 Python module.  For the time being, you could probably modify that code fairly easily to get the type of Stacked Ensemble that you're looking for.  It's in a gist 
here
.",2017-07-12T18:48:54,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45061890
46264371,46264371,7,"The 
lime
 package under the hood uses two functions, 
predict_model()
 and 
model_type()
 that you need to setup for any models that are not currently supported. 


For your specific example, here's what you need to do.


Step 1
: Setup a generic 
model_type
 function for models of class 
H2OMultinomialModel
. All you do here is tell 
lime
 what model type you want it to perform such as ""classification"" or ""regression"".


model_type.H2OMultinomialModel <- function(x, ...) {
    # Function tells lime() what model type we are dealing with
    # 'classification', 'regression', 'survival', 'clustering', 'multilabel', etc
    #
    # x is our h2o model

    return(""classification"")

}



Step 2
: Setup a generic 
predict_model
 function for models of class 
H2OMultinomialModel
. The key here is understanding that for lime to work it needs classification probabilities rather than the prediction (this took me a little while to figure out and it has to deal with an 
lime:::output_type(explaination)
 variable).


predict_model.H2OMultinomialModel <- function(x, newdata, type, ...) {
    # Function performs prediction and returns dataframe with Response
    #
    # x is h2o model
    # newdata is data frame
    # type is only setup for data frame

    pred <- h2o.predict(x, as.h2o(newdata))

    # return classification probabilities only
    return(as.data.frame(pred[,-1]))

}



Once you set these functions up properly, you can run your 
lime
 scripts.


# Lime is used to get explain on the train data
explainer <- lime(train_org, model_dl_1, bin_continuous = FALSE, n_bins = 5, n_permutations = 1000)

# Explain new observation
explanation <- explain(test_sample, explainer, n_labels = 1, n_features = 1)",2017-09-17T13:01:01,,,,45059748
52486395,52486395,0,"Unfortunately, 
H2O Xgboost
 is not supported for the time being on Windows as also the 
official documentation
 of 
H2O
 states:




Limitations
 


This section provides a list of XGBoost limitations - some of which
  will be addressed in a future release.


...




XGBoost is not supported on Windows.




...",2018-09-24T19:49:48,Outcast,https://stackoverflow.com/users/9024698/outcast,"5,117",45047445
62964338,62964338,0,"XGBoost
 is not supported on 
Windows
.




The list of limitations include:




XGBoost is not supported on 
Windows
.


The list of supported platforms includes:Linux or OS X






When I met same issue I open my 
COLAB
 account and I try there. It did work for me.",2020-07-18T03:32:13,H.Elci,https://stackoverflow.com/users/13471621/h-elci,226,45047445
45040052,45040052,3,"Yes, these are exposed as learner parameters. For example:


lrn = makeLearner(""classif.h2ogbm"", par.vals = list(seed = 123))",2017-07-11T16:30:41,Lars Kotthoff,https://stackoverflow.com/users/1172002/lars-kotthoff,109k,45029437
45046360,45046360,1,"The ""enum"" type is the type of encoding you'll want to use for categorical features.  If the categorical features are encoded as ""enum"", then the tree-based algorithms like Random Forest and GBM will be able to handle these features in a smart way.  Most other implementations of RFs and GBM force you to do a one-hot expansion of the categorical features (into K dummy columns), but in H2O, the tree-based methods can use these features without any expansion.  The exact whay that the variables are handled can be controlled using the 
categorical_encoding
 argument.


If you have an ordered categorical variable, then it might be okay to encode that as ""int"", however, the effect of doing that on model performance will depend on the data. 


If you were to convert an ""enum"" column to ""numeric"" that would simply encode each category as an integer and you'd lose the notion that those numbers represent categories (so it's not recommended).


You should not use the ""string"" type in H2O unless you are going to exclude that column from the set of predictors.  It would make sense to use a ""string"" column for text, but you'll probably want to parse (e.g. tokenize) that text to generate new numeric or enum features that will be included in the set of predictors.",2017-07-12T00:16:55,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45025667
45024919,45024919,1,"That's the wrong image, the right one is: opsh2oai/h2o3_nae and the
GitHub you have is correct.


H2o3 is 
h2o-3
, and ""H2o3 for POWER8"" is for IBM; the H2OAI is not meant to be public and has been removed.  


We have not enabled GPU on the Nimbix cloud to-date.",2017-07-11T03:35:02,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",45024544
45024759,45024759,1,"It sounds like you are looking for a 
stacking
 learner, which is mlr's method of performing ensembles.


from the docs


 # Regression
  data(BostonHousing, package = ""mlbench"")
  tsk = makeRegrTask(data = BostonHousing, target = ""medv"")
  base = c(""regr.rpart"", ""regr.svm"")
  lrns = lapply(base, makeLearner)
  m = makeStackedLearner(base.learners = lrns,
    predict.type = ""response"", method = ""average"")
  tmp = train(m, tsk)
  res = predict(tmp, tsk)
# Prediction: 506 observations
# predict.type: response
# threshold: 
# time: 0.02
#   id truth response
# 1  1  24.0 27.33742
# 2  2  21.6 22.08853
# 3  3  34.7 33.52007
# 4  4  33.4 32.49923
# 5  5  36.2 32.67973
# 6  6  28.7 22.99323
# ... (506 rows, 3 cols)

performance(res, rmse)
#     rmse 
# 3.138981",2017-07-11T03:13:31,Steve Bronder,https://stackoverflow.com/users/2269255/steve-bronder,936,45021925
45021279,45021279,7,"You're using 
h2o.loadModel
 incorrectly (nothing to do with 
mlr
). See the example usage in 
h2o
's help -- 
h2o.saveModel
 returns the full path you need to give to 
h2o.loadModel
. Full working example:


library(mlr)
library(h2o)
a <- data.frame(y=factor(c(1,1,1,1,1,1,1,1,0,0,1,0)), 
                x1=rep(c(""a"",""b"", ""c""), times=c(6,3,3)))
aTask <- makeClassifTask(data = a, target = ""y"", positive=""1"")
h2oLearner <- makeLearner(""classif.h2o.deeplearning"")
model <- train(h2oLearner, aTask)
# save mlr and h2o model separately:
save(file=""saveh2omodel.rdata"", list=c(""model""))
savedModel = h2o.saveModel(getLearnerModel(model), path=""h2o_model"")

# shutdown h2o and close R and open new session
h2o.shutdown()

library(mlr)
library(h2o)
h2o.init()
h2o.loadModel(savedModel)
load(file=""saveh2omodel.rdata"")
b <- data.frame(x1=rep(c(""a"",""b"", ""c""), times=c(3,5,4)))
pred <- predict(model, newdata=b)",2017-07-10T20:44:23,Lars Kotthoff,https://stackoverflow.com/users/1172002/lars-kotthoff,109k,45012473
45021207,45021207,3,"This bug was fixed in 
this commit
 and will be in the next release. Until then, you can install the Github version:


devtools::install_github(""mlr-org/mlr"")",2017-07-10T20:40:03,Lars Kotthoff,https://stackoverflow.com/users/1172002/lars-kotthoff,109k,45009855
45000212,45000212,2,"It's easy enough to test this 


R code:


library(h2o)
h2o.init()
iris_data<-as.data.frame(iris)
iris_data$Petal.Width<-1
iris_data[iris_data$Species=='setosa','Petal.Width']<-NA
iris_h2o<-as.h2o(iris_data)
h2o.gbm(training_frame=iris_h2o,y='Species')
iris_data$Petal.Width<-as.factor(iris_data$Petal.Width)
iris_h2o<-as.h2o(iris_data)
h2o.gbm(training_frame=iris_h2o,y='Species')



Regardless of if the constant column with missing values is numeric or factor, the same warning is given:


Warning message:
In .h2o.startModelJob(algo, params, h2oRestApiVersion) :
  Dropping constant columns: [Petal.Width].



Therefore the answer to your question appears to be that h2o ignores missing values when determining if a column is constant",2017-07-09T19:29:50,Richard,https://stackoverflow.com/users/6718853/richard,"1,121",44986674
44977136,44977136,2,"To summarize the comments above, the current solution is to add a response column (with fake data if it doesn't exist) to the 
test_data
 frame.  However, this is a bug that should be fixed.  The JIRA is 
here
.",2017-07-07T18:06:16,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44968297
44972691,44972691,0,"The model will be saved relative to where the particular node you are talking to is running.  So, on the local filesystem on the host where the YARN container that the REST API client (like R, Python, or H2O Flow) is talking to is placed.


This is probably not where you want the model to be saved.


You can explicitly specify an ""hdfs://"" path to save the model to, and then find it in hdfs.


[ That ""-output hdfsOutputDirName"" is actually an artifact of inheriting from org.apache.hadoop.util.ToolRunner, and isn't used for anything. ]",2017-07-07T13:58:09,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44966134
45664294,45664294,0,"I had the same error for h2o.deeplearning(). Converting the dependent variable to factor and then feeding the data to h2o.deeplearning() fixed it for me.


dataset$dependent_variable= factor(dataset$dependent_variable,levels = c(0, 1), labels = c(0, 1))",2017-08-13T19:50:14,Nathan Tuggy,https://stackoverflow.com/users/4099598/nathan-tuggy,"2,243",44947850
44972989,44972989,0,"I tried the relatively recent H2O 3.10.4.8, ran your code sample, and the behavior of the two dims looks like the correct behavior to me.


> library(h2o)
> h2o.init()

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /var/folders/tt/g5d7cr8d3fg84jmb5jr9dlrc0000gn/T//RtmpCXcmAu/h2o_tomk_started_from_r.out
    /var/folders/tt/g5d7cr8d3fg84jmb5jr9dlrc0000gn/T//RtmpCXcmAu/h2o_tomk_started_from_r.err

java version ""1.8.0_112""
Java(TM) SE Runtime Environment (build 1.8.0_112-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode)

Starting H2O JVM and connecting: .. Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         2 seconds 605 milliseconds 
    H2O cluster version:        3.10.4.8 
    H2O cluster version age:    1 month and 15 days  
    H2O cluster name:           H2O_started_from_R_tomk_jgy651 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   3.56 GB 
    H2O cluster total cores:    8 
    H2O cluster allowed cores:  2 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    R Version:                  R version 3.3.2 (2016-10-31) 

Note:  As started, H2O is limited to the CRAN default of 2 CPUs.
       Shut down and restart H2O as shown below to use all your CPUs.
           > h2o.shutdown()
           > h2o.init(nthreads = -1)

> nameDF <- c(paste(""O"",letters, sep=""_""),  paste(""T"",letters, sep=""_""),
+ paste(""TR"",letters, sep=""_""))
> DF <- matrix( data=numeric(length(nameDF)*1000000), nrow=1000000)
> colnames(DF) <- nameDF
> DF <- as.data.frame(DF)
> DF$char <- rep(""bla"", 1000000)
> View(DF)
> DFh2o <- as.h2o(DF)
  |=====================================================================================================================| 100%
> dim(DFh2o)
[1] 1000000      79
> dim(DF)
[1] 1000000      79",2017-07-07T14:13:19,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44930886
45013904,45013904,0,"For the case that somebody has the same issue, I post the simple solution to my problem: The machine I was running the code on only had little space left on the disk the h2o objects were saved to. The solution is simple, however h2o doesn't throw an error in its log files so one doesn't see the problem right away.... best regards!",2017-07-10T13:54:12,jovogt,https://stackoverflow.com/users/7429864/jovogt,11,44930886
45002118,45002118,1,"That code in the Python booklet is outdated -- the argument name changed to become compatible with Pandas, but unfortunately it was not made backwards compatible (that's a bug and I opened a ticket to fix that 
here
).  The argument is now 
skipna
.  Here is the correct way to do it:


df5 = h2o.H2OFrame.from_python(np.random.randn(100,4).tolist(), column_names=list(""ABCD""))
df5.apply(lambda x: x.mean(skipna=False))",2017-07-09T23:50:47,,,,44910513
44883603,44883603,1,"You have to replace 
DeepLearning_model_python_1497342069792_59
 with your new name in current file text also, because java use same 
class name
 and 
file name
 together",2017-07-03T10:43:27,sf_,https://stackoverflow.com/users/8119498/sf,"1,196",44883513
44878270,44878270,4,"The typical image which is usually shown in this situation is




Please note that the sweet spot (50 epochs, in the image) depends on the network, the problem and the data. Determining when to stop is an unsolved problem, but early stopping is a popular choice.


Source: My still unpublished, but finished masters thesis. It is not public right now due to bureaucratic reasons of my university.",2017-07-03T05:21:48,Martin Thoma,https://stackoverflow.com/users/562769/martin-thoma,135k,44877161
56285952,56285952,1,"Gradient Descent is an optimization procedure which updates the weights in the neural network in an iterative fashion. If we train the network for a few epochs, it leads to underfitting of the data. This means the neural network cannot capture the underlying trend of the data.
Now, as we increase the number of epochs, it will reach an optimal situation where we will get maximum accuracy on the training set. Beyond this stage, if we keep increasing the number of epochs, it will lead to overfitting of the data. That is the accuracy in the training set increases whereas that of validation set decreases. This means the network does not reflect the reality of the data because it captures the noise in the data as well.


So the answer is we cannot say beforehand the number of epochs to train the neural network so that it performs the best. It is a hypermeter that needs to be tuned. We can only use some heuristics and fix some number of epochs to train the neural network while monitoring the accuracy on training and validation sets.


So in the conclusion, the number of epochs for training the neural network varies from one problem to another because it is highly related to the dataset and the complexity of the network which you are using. It is one of the hyperparameters that needs to be tuned during the training of the neural network.",2019-05-24T04:39:41,varsh,https://stackoverflow.com/users/7162534/varsh,189,44877161
45718739,45718739,1,"Windows is not supported with H2O-3 XGBoost. For reference, here is a list of OS's supported by H2O-3 XGBoost: 


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html#limitations",2017-08-16T16:29:47,David Arenburg,https://stackoverflow.com/users/3001626/david-arenburg,92.2k,44854821
48139570,48139570,0,"At the time I write this (January 2018), this is still a bug for 
xgboost
. See 
this ticket
 for more information.


In the meantime, you can download the model as a 
pojo
 or 
mojo
 file


h2o.download_pojo(model, path = ""/media/somewhere/tmp"")



Loading the model back isn't that easy, unfortunately, but you can pass the new data via 
json
 to the saved 
pojo
 model with the function:


h2o.predict_json()



However, the new data must be provided in 
json
 format.


See 
this question
 for more details",2018-01-07T17:09:24,cd98,https://stackoverflow.com/users/1951065/cd98,"3,532",44848861
44852474,44852474,0,"you could download and take a look at the POJO which lists all the thresholds used for the model 
h2o.download_pojo(model, path=u'', get_jar=True, jar_name=u'')",2017-06-30T18:01:46,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",44843175
44830368,44830368,0,"h2oEnsemble
 v0.1.9 package has not been officially released yet, but it's on the ""h2oEnsemble_v0.1.9"" branch 
here
.  On the README for that branch, the updated table shows that it will be compatible with H2O >=3.10.1.*.


It looks like you are doing a regression problem and attempting to use the 
h2o.naiveBayes.wrapper()
 function?  The error message tells you that can't use Naive Bayes on a regression problem (Naive Bayes is a classification algorithm and does not support regression).


Using the ""h2oEnsemble_v0.1.9"" branch version of 
h2oEnsemble
 and the latest stable release of H2O, 3.10.5.2, I can replicate your error using the code below, but all you need to do to fix it is remove the Naive Bayes model from your base learners:


library(h2oEnsemble)  # Install from h2oEnsemble_v0.1.9 branch
h2o.init()

# Import a sample binary outcome train/test set into R
train <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_train_5k.csv"")
test <- h2o.importFile(""https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv"")
y <- ""response""
x <- setdiff(names(train), y)
family <- ""gaussian""


# Specify the base learner library & the metalearner
learner <- c(""h2o.glm.wrapper"", ""h2o.randomForest.wrapper"", 
             ""h2o.gbm.wrapper"", ""h2o.naiveBayes.wrapper"")
metalearner <- ""h2o.glm.wrapper""

# Train the ensemble 
fit <- h2o.ensemble(x = x, y = y, 
                    training_frame = train, 
                    family = family, 
                    learner = learner, 
                    metalearner = metalearner)",2017-06-29T16:18:07,,,,44829663
44830649,44830649,0,"I cannot reproduce the error, so I assume you are using some older version of H2O.  On the stable release of H2O (which today that is 3.10.5.2), I can execute your code with no errors.


> h2o.confusionMatrix(model,newdata=val_h2o)
Confusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.228804884732884:
        1  2    Error    Rate
1      89  2 0.021978   =2/91
2       0 46 0.000000   =0/46
Totals 89 48 0.014599  =2/137



If you encounter errors in the future, please make sure to try upgrading to the latest stable release of H2O and try again to see if that fixes the bug before reporting the error.  The link to the stable release is always on this 
page
 and also on CRAN.  We release often, so it's good to make sure you are always running the latest version.",2017-06-29T16:34:31,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44829493
44822365,44822365,0,"We're using Spark 1.6.2 and I believe this is a 
known bug
.",2017-06-29T10:16:19,jkeirstead,https://stackoverflow.com/users/694488/jkeirstead,"2,951",44803064
44973305,44973305,0,"There is no explicit column limit in H2O (certainly not at 785, which is not big).  Spark 1.6 is very old now, I recommend moving forward.


See if what you're seeing might be related to this problem:


https://0xdata.atlassian.net/browse/PUBDEV-3808


If so, one workaround that was discovered was to .cache() the dataframe in Spark before passing it to H2O.",2017-07-07T14:28:31,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44803064
44791593,44791593,1,"EDITED

(didn't answer original question the first time, answering it now)
This is how you would convert an numerical column to a column with string values and then replace those values.


import h2o
prostate = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv""
h2o.init()
df = h2o.import_file(prostate)
# creating your example column with all values equal to 23
df['mpg'] = 23
df['mpg'] = df['mpg'].ascharacter()
df[1,'mpg'] # see that it is now a string
df['mpg']=df['mpg'].sub('23',  'please-help-me----23')
df
Out[16]:   ID    CAPSULE    AGE    RACE    DPROS    DCAPS    PSA    VOL    GLEASON  mpg
----  ---------  -----  ------  -------  -------  -----  -----  ---------  --------------------
   1          0     65       1        2        1    1.4    0            6  please-help-me----23
   2          0     72       1        3        2    6.7    0            7  please-help-me----23
   3          0     70       1        1        2    4.9    0            6  please-help-me----23
   4          0     76       2        2        1   51.2   20            7  please-help-me----23
   5          0     69       1        1        1   12.3   55.9          6  please-help-me----23
   6          1     71       1        3        2    3.3    0            8  please-help-me----23
   7          0     68       2        4        2   31.9    0            7  please-help-me----23
   8          0     61       2        4        2   66.7   27.2          7  please-help-me----23
   9          0     69       1        1        1    3.9   24            7  please-help-me----23
  10          0     68       2        1        2   13      0            6  please-help-me----23

[380 rows x 10 columns]



(answering the wrong question below:)
you have to pass a new list of column names (the same length as your original column list).


df.columns = new_column_list


for example I can rename the columns 
ID
 with 
NEW
:


import h2o
prostate = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/prostate/prostate.csv""
h2o.init()
df = h2o.import_file(prostate)
print(df.columns)
columns[0] = 'NEW'
df.columns = columns
print(df.columns)



which will show:


Checking whether there is an H2O instance running at http://localhost:54321. connected.
--------------------------  ------------------------------
H2O cluster uptime:         9 hours 31 mins
H2O cluster version:        3.10.4.8
H2O cluster version age:    1 month and 6 days
H2O cluster name:           H2O_from_python_laurend_tzhifp
H2O cluster total nodes:    1
H2O cluster free memory:    3.276 Gb
H2O cluster total cores:    8
H2O cluster allowed cores:  8
H2O cluster status:         locked, healthy
H2O connection url:         http://localhost:54321
H2O connection proxy:
H2O internal security:      False
Python version:             3.5.1 final
--------------------------  ------------------------------
Parse progress: |████████████████████████████████████████████████████████████████████████████| 100%
['ID', 'CAPSULE', 'AGE', 'RACE', 'DPROS', 'DCAPS', 'PSA', 'VOL', 'GLEASON']
['NEW', 'CAPSULE', 'AGE', 'RACE', 'DPROS', 'DCAPS', 'PSA', 'VOL', 'GLEASON']",2017-06-27T23:41:13,,,,44791101
44754423,44754423,1,"It seems it's not really possible to import sparse matrices of slightly larger size into h2o instance directly through R at the moment. Instead, importing through a SVMLight file is much faster. as discussed here


How to get sparse matrices into H2O?




Edit: in search of converting sparse matrix file to SVMLight format (efficient and fast algorithm)
I tried using laurai2/sparsity package for efficient conversion of sparse matrix to SVMLgith format file. But i couldn't get the package installed due to some Cpp compilation error.
Based on @Dmitriy Selivanov suggestion, i used sparsio package and could easily convert the sparse matrix into SVMLight format and import it quickly to h2o.


## The following works
library(sparsio)
library(h2o)
write_svmlight(x = spmx, file = ""spmx_svmlight.txt"", zero_based = FALSE) #h2o accepts one_based by default

localH2O <- h2o.init(nthreads = -1, max_mem_size = ""16g"")  
spmx.h2o <- h2o.importFile(""spmx_svmlight.txt"", parse = TRUE) 



My dataset size is still fairly small and I'm not sure how well write_svmlight will work on much larger datasets. It took my data about 40 seconds, which is OK.",2017-06-26T06:56:29,,,,44753601
44821848,44821848,0,"This appears to be a bug in the Flow interface, but only in the setupParse command. If you continue through and do the import, the data gets imported correctly.


I've reported the bug, with test data and screenshots (taken in Firefox) here:


https://0xdata.atlassian.net/browse/PUBDEV-4640


So if you have additional information, or the bug is behaving differently for you, it'd be good to add it to that bug report.",2017-06-29T09:53:10,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,44752584
44770720,44770720,-1,"check your csv file in text and binary presentation to find how Cyrillic text is encoded, if it is UTF-8 it should look like this:


&#1055;&#1088;&#1080;&#1074;&#1077;&#1090;


for the word 


Привет",2017-06-27T00:45:49,Smike,https://stackoverflow.com/users/8218079/smike,1,44752584
44771881,44771881,3,"The error refers to a line of the 
StackedEnsembleModel.java code
 that checks that the 
training_frame
 in the base models and the 
training_frame
 in 
h2o.stackedEnsemble()
 have the same checksum. I think the problem is caused because you dynamically created the training frame, rather than defining it explicitly (even though that 
should
 work since it's the same data in the end).  So, rather than setting 
training_frame = h2o.rbind(train, valid, test)
 in the grid and ensemble functions, set the following at the top of your code:


df <- h2o.rbind(train, valid, test)



And then set 
training_frame = df
 in the grid and ensemble functions. 


As a side note, you may get better DL models if you use a validation frame (for early stopping), rather than using all your data for the training frame.  Also, if you want to use all the models in your grid (might lead to better performance, but not always), you can set 
base_models = DLsortedGridEnsemble_logloss@model_ids
 in the 
h2o.stackedEnsemble()
 function.",2017-06-27T03:37:03,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44751866
44772507,44772507,1,"That sounds like a long time to train a Random Forest on a dataset with only 120k x 518 columns.  As Tom said above, it might have to do with the congestion on your Hadoop cluster and possibly that this cluster that is way too big for this task.  You should be able to train a dataset that size on a single machine (no multi-node cluster necessary).  


If possible, try training the model on your laptop for a comparison.  If there is nothing you can do to improve the Hadoop environment, this may be a better option for training.


For your other question about a verbose option -- I don't remember there ever being this option in H2O's Random Forest.  You can view the progress of models as they build in H2O Flow, the GUI.  When you click on a model to view it, there is a ""Refresh"" button that will allow you to check on the progress of the model at it trains.",2017-06-27T04:55:50,,,,44739293
44740478,44740478,0,"Depending on congestion of your network and the busyness level of your hadoop nodes, it may finish faster with fewer nodes.  For example, if 1 of the 20 nodes you requested is totally slammed by some other jobs, then that node may lag, and the work from that node is not rebalanced to other nodes.


A good way to see what is going on is to connect to H2O Flow in a browser and run the WaterMeter.  This will show you CPU activity in your cluster.


You can compare the activity before you start your RF and after you start your RF.


If even before you start your RF the nodes are extremely busy then you may be out of luck and just have to wait.  If even after you start your RF the nodes are not busy at all, then the network communication may be too high and fewer nodes would be better.


You'll also want to to look at the H2O logs and see how the dataset got parsed, datatype-wise, and the speed at which individual trees are built.  And if your response column is a categorical and you're doing multinomial, each tree is really N trees where N is the number of levels in the response column.


[ Unfortunately, the ""it's too slow"" complaint is way too generic to say much more. ]",2017-06-24T20:01:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44739293
44781879,44781879,0,"The difference in size of the models (169M vs 37G) is surprising. Can you please make sure that H2O recognizes all your numeric columns as numeric and not categorical with very high cardinality?


Do you use automatic detection of column types or do you specify it manually?",2017-06-27T13:42:53,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,44738743
44768118,44768118,0,"I have solved the issue.  By putting the following before initializing H2O:


options(java.parameters = ""-Xmx500000m"")",2017-06-26T20:26:17,Raag Agrawal,https://stackoverflow.com/users/7782613/raag-agrawal,146,44738316
44737237,44737237,0,"Rather than compare the results from R's h2o.predict() with your own handwritten code, I recommend you compare with an H2O MOJO, which should match.


See an example here:


http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/overview-summary.html#quickstartmojo


You can run that simple example yourself, and then modify it according to your own model and new row of data to predict on.


Once you can do that, you can look at the code and debug/single-step it in a java environment to see exactly how the prediction gets calculated.


You can find the MOJO prediction code on github here:


https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/easy/EasyPredictModelWrapper.java",2017-06-24T14:06:49,,,,44735518
51985451,51985451,0,"The main cause of the large difference between your observed probabilities and the predictions of h2o is your learning rate. As you have 
learn_rate = 0.001
 the gbm is adjusting the probabilities by a relatively small amount from the overall rate. If you adjust this to 
learn_rate = 1
 you will have something much closer to a decision tree, and h2o's predicted probabilities will come much closer to the rates in each leaf node.


There is a secondary difference which will then become apparent as your probabilities will still not exactly match. This is due to the method of gradient descent (the G in GBM) on the logistic loss function, which is used rather than the number of observations in each leaf node.",2018-08-23T12:05:58,J M Swift,https://stackoverflow.com/users/8640150/j-m-swift,3,44735518
44729936,44729936,1,"If you are letting h2o.init() start the H2O process, then it starts the H2O process with it's output going to a tempdir().


(Look at the R documentation for tempdir().)


Cleaning up after itself was a requirement for getting accepted by CRAN.


If you want H2O to put its output somewhere else, than start H2O on the command line yourself to get more control.  In the simplest case, this would look like the following:


$ java -jar h2o.jar





You can find more information about how to start H2O by doing the following:




http://h2o.ai/download


Choose latest stable version of H2O


Follow the instructions in the ""Download and Run"" tab",2017-06-23T21:06:30,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44729632
44725654,44725654,1,"your scala versions (2.12.1) and the package versions (2.10, 2.11) doesnt match.
And spark is not supported for scala version 2.12. 


scalaVersion := ""2.12.1""
libraryDependencies ++= Seq(
""org.apache.spark"" % ""spark-core_2.10"" % ""1.5.1"",
""ai.h2o""%""sparkling-water-core_2.11""%""2.1.9"")



so your dependency should be something like this (if you are choosing scala version 2.11).


scalaVersion := ""2.11.5""
libraryDependencies ++= Seq(
""org.apache.spark"" % ""spark-core_2.11"" % ""1.5.1"",
""ai.h2o""%""sparkling-water-core_2.11""%""2.1.9"")



And reg the 
java.lang.ClassNotFoundException: com.hw.h20try
 exception make sure you have created a uber jar with the dependency using plugin such as 
sbt-assembly
. 


run a command 
jar -tf h20prova.jar | grep h20try
 to check if the class is actually packaged and available in the jar.",2017-06-23T15:59:18,,,,44725587
44727088,44727088,2,"A common cause for this is that you haven't yet set the environment variables. Please check your installation.


export CUDA_PATH=/usr/local/cuda
export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH


This is described further here: 
https://github.com/h2oai/deepwater#pre-release-downloads",2017-06-23T17:35:36,,,,44720647
45710277,45710277,0,"Please check that you correctly setup the environment variables - but be aware: the snippets in answer 1 and from the deep water page (
https://github.com/h2oai/deepwater#pre-release-downloads
) contain a spelling error in the second line. Correctly it should read as:


export CUDA_PATH=/usr/local/cuda
export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH",2017-08-16T09:48:12,user4556577,https://stackoverflow.com/users/6997380/user4556577,21,44720647
44720354,44720354,1,"There is no 
data
 parameter in the 
h2o.deeplearning
 function.


Try to replace it by the parameter 
training_frame
.


Also, 
validation
 is actually 
validation_frame
 and 
classification
 does not exist.


And 
y
 should be the name of your variable in between double quote and 
x
 a vector containing the name or the indices of the predictors variables.


The documentation:

h2o doc",2017-06-23T11:28:44,,,,44720139
44726226,44726226,0,"The H2O-XGBoost documentation is in the Algorithms section of the H2O User Guide, 
here
.


The hyperparameters for Grid Search are also listed with all the other algorithms in the Grid Search section, 
here
.",2017-06-23T16:35:46,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44717507
56645044,56645044,1,"Have a look at the 
h2o.merge()
 command. 


# Currently, this function only supports `all.x = TRUE`. All other permutations will fail.
library(h2o)
h2o.init()

# Create two simple, two-column R data frames by inputting values, ensuring that both have a common column (in this case, ""fruit"").
left <- data.frame(fruit = c('apple','orange','banana','lemon','strawberry','blueberry'),
                   color = c('red','orange','yellow','yellow','red','blue'))
right <- data.frame(fruit = c('apple','orange','banana','lemon','strawberry','watermelon'),
                    citrus = c(FALSE, TRUE, FALSE, TRUE, FALSE, FALSE))

# Create the H2O data frames from the inputted data.
l.hex <- as.h2o(left)
print(l.hex)
        fruit  color
 1      apple    red
 2     orange orange
 3     banana yellow
 4      lemon yellow
 5 strawberry    red
 6  blueberry   blue

[6 rows x 2 columns]

r.hex <- as.h2o(right)
print(r.hex)
        fruit citrus
 1      apple  FALSE
 2     orange   TRUE
 3     banana  FALSE
 4      lemon   TRUE
 5 strawberry  FALSE
 6 watermelon  FALSE

[6 rows x 2 columns]

# Merge the data frames. The result is a single dataset with three columns.
left.hex <- h2o.merge(l.hex, r.hex, all.x = TRUE)
print(left.hex)
       fruit  color citrus
1  blueberry   blue   <NA>
2      apple    red  FALSE
3     banana yellow  FALSE
4      lemon yellow   TRUE
5     orange orange   TRUE
6 strawberry    red  FALSE

[6 rows x 3 columns]",2019-06-18T08:41:53,Jsimp,https://stackoverflow.com/users/10298545/jsimp,58,44690236
44706271,44706271,2,"You definitely want to minimize calls to 
as.h2o()
 as much as possible since that function actually writes data from R memory to disk and then reads the data into the H2O cluster from disk.  It's meant to be used sparingly.  However, one way to speed up the 
as.h2o()
 call is to use 
data.table
 on the backend.  If you have 
data.table
 installed, you can add the following line to the top of your code and it will use 
data.table::fwrite()
 instead of 
utils::write.csv()
 inside of 
as.h2o()
. 


library(data.table)
options(""h2o.use.data.table"" = TRUE)



Since you want to minimize calls to 
as.h2o()
, it will probably be faster to store a few hundred or thousand rows in an R data.frame and then periodically convert that data.frame to an H2OFrame using 
as.h2o()
 (using 
data.table
 backend), then scan through the rows of the H2OFrame to see which ones are new and then add them to your ""global"" H2OFrame using 
h2o.rbind()
.  


The only way to know for sure which method will be faster is to test both methods on your data and your machine.",2017-06-22T17:50:15,,,,44683514
44682293,44682293,6,"Both missing value handling and variable importances are slightly different between the two methods. Both are treating missing values as information (i.e., they learn from them, and don't just impute with a simple constant). The variable importances are computed from the gains of their respective loss functions during tree construction. H2O uses squared error, and XGBoost uses a more complicated one based on gradient and hessian.


One thing you could check is the variance of the variable importances between different runs with different seeds, to see how stable each method is in terms of variable importances.


PS. If you have categoricals, then you're better off leaving the column as a factor for H2O, no need to do your own encoding. This can lead to a different effective count of columns vs XGBoost's dataset, so for column sampling, things will be different.",2017-06-21T17:09:55,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,44668298
44660576,44660576,2,"Since you did not provide the data directly, I copied your example from above as an R data.frame.


library(h2o)
h2o.init()

# Example data as an R data.frame
df <- data.frame(genes = c(""A"",""B"",""C"",""D"",""E"",""F""),
                 samples = c(""a"",""a"",""a"",""a"",""a"",""a""),
                 y = c(1,1,1,0,0,0),
                 tissue = c(""Muscle"",""Brain"",""Brain"",""Muscle"",""Brain"",""Muscle""))

# Convert R data.frame to H2OFrame
hf <- as.h2o(df)



However, I assume you have this data in a CSV on your computer, so in reality, what you'd do is this:


# Load data from disk directly into H2O cluster
hf <- h2o.importFile(""tissue_samples.csv"")



Now that you have the data in an H2OFrame, there are only a few more steps:


# List of unique tissue types
tissue_types <- as.list(h2o.unique(hf$tissue))

# Create list of frames (one for each tissue type)
frames <- sapply(tissue_types, function(t) hf[(hf[,""tissue""] == t),])

# Set up h2o.glm arguments
x <- c(""genes"", ""samples"")
y <- ""y""

# List of glms (one for each tissue type)
glms <- sapply(frames, function(fr) h2o.glm(x = x, y = y, 
                       family = ""poisson"", training_frame = fr))

# Save the models
model_names <- sapply(glms, function(m) h2o.saveModel(m, path = ""/Users/me/"", force = TRUE))

# Look at model names
print(model_names)
# [1] ""/Users/me/GLM_model_R_1497937770060_222""
# [2] ""/Users/me/GLM_model_R_1497937770060_223""",2017-06-20T18:30:24,,,,44658942
47200416,47200416,0,"This was a bug and is fixed in latest Sparkling Water versions for Spark 2.0, Spark 2.1 and Spark 2.2",2017-11-09T11:14:31,,,,44641158
44669089,44669089,3,"Ok, after some research and try and error, i try to see what are the data contained within the result. From this:


model.model_performance()



It will just show you the model performance right away in console, but if you try to run it as


type(model.model_performance())



you will get the type of the object returned as:


<class 'h2o.model.metrics_base.H2OMultinomialModelMetrics'>



which means that the object itself is a class of metcis and according to 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/metrics.html
, H2OMultinomialModelMetrics is an instance of MetricBase and if we see in 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/metrics.html#h2o.model.metrics_base.MetricsBase
, we found out some of common metrics measurement available.


Further step, if we try to use


dir(model.model_performance())



We will get a list of properties as expected, consisting of 
auc
, 
aic
, 
rmse
, and so on.


If we try to call:


model.model_performance().rmse()



In my case, i get 0.4824827476199047.


The most interesting discovery that i get is that when i try to execute 
auc
 method


model.model_performance().auc()



i got an error saying that 
""AUC""
 key doesn't exists in the dictionary


Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Development\python\lib\site-packages\h2o\model\model_base.py"", line 634, in auc
    for k, v in viewitems(tm): m[k] = None if v is None else v.auc()
  File ""D:\Development\python\lib\site-packages\h2o\model\metrics_base.py"", line 156, in auc
    return self._metric_json['AUC']
KeyError: 'AUC'



and as we can see, it has 
_metric_json
 dictionary. I try to print the 
model.model_performance()._metric_json
 dictionary, and i get the dictionary listing all the metric, you can try to use 
_metric_json.keys()
 to get all the keys and parse it to JSON on your own too.


Edit 1


Even to make life easier, this code show how to even easily convert the class to json string:


json_string = str(model.model_performance()._get_metrics)



Edit 2


The string in edit 1 is not json formatted, better do this way to convert to json and dictionary while striping the classes:


import json

json_string = json.dumps(str(model.model_performance()._get_metrics),ensure_ascii=False)
python_dictionary = json.loads(json_string)",2017-06-21T07:09:38,,,,44628702
44641075,44641075,0,"The H2O python package actually talks to the H2O back-end using a REST API with JSON.  The best way to learn what that looks like is to turn on logging and watch a ""conversation"" between the Python client front-end and the H2O Java back-end.


Turn on logging with this method call:


h2o.start_logging()



and take a look at the output.


Here is a pointer to the REST API reference:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/rest-api-reference.html",2017-06-19T22:46:18,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44628702
44619635,44619635,2,"You are running with 32-bit java, which is limiting the memory that you are able to start H2O with.  One clue is that it won't start with a higher max_mem_size.  Another clue is that it says ""Client VM"".


You want 64-bit java instead.  The 64-bit version will say ""Server VM"".  You can download the Java 8 SE JDK from here:


http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html


Based on what you've described, I recommend setting max_mem_size = '6g' or more, which will work fine on your system once you have the right version of Java installed.",2017-06-18T21:20:00,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44619151
44620211,44620211,1,"train=h2o.importFile(path=normalizePath(""C:\\Users\\All data\\traindt.rds"")



Are you trying to load an 
.rds
 file?  That's an R binary format which is not readable by 
h2o.importFile()
, so that won't work.  You will need to store your training data in a cross-platform storage format (e.g. CSV, SMVLight, etc) if you want to read it into H2O directly.  If you don't have a copy in another format, then just save one from R:


# loads a `train` data.frame for example
load(""C:\\Users\\All data\\traindt.rds"")

# save as CSV
write.csv(train, ""C:\\Users\\All data\\traindt.csv"")

# import from CSV into H2O cluster directly
train = h2o.importFile(path = normalizePath(""C:\\Users\\All data\\traindt.csv""))



Another option is to load it into R from the 
.rds
 file and use the 
as.h2o()
 function:


# loads a `train` data.frame for example
load(""C:\\Users\\All data\\traindt.rds"")

# send to H2O cluster
hf <- as.h2o(train)",2017-06-18T22:40:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44619151
44589032,44589032,15,"conda packages arn't language specific, in this case 
conda install h2o
 installs the java package. You need to do 
conda install h2o-py
 


No idea why this worked on my old computer without the 
-py
.",2017-06-16T12:15:18,mlanier,https://stackoverflow.com/users/6014437/mlanier,197,44577923
52077303,52077303,5,"If anyone still struggling with this issue, according to 
docs
:




H2O has tabulate>=0.75 as a dependency; however, there is no tabulate available in the default channels for Python 3.6. This is available in the conda-forge channel. As a result, Python 3.6 users must add the conda-forge channel in order to load the latest version of H2O.




Thus, you have to follow the following steps:


conda config --append channels conda-forge

This, will append the conda-forge channel to your available repositories.

Then:


conda install -c h2oai h2o

to install the needed packages.",2018-08-29T12:18:00,Yannis,https://stackoverflow.com/users/4371239/yannis,711,44577923
54781091,54781091,5,"For python 3.7, the h2o library is not supporting as on Feb-2019.
So, I have created a new environment with 3.6 version and installed h2o using,


conda install -c h2oai h2o -n <myenvname>",2019-02-20T07:37:26,Siddaram H,https://stackoverflow.com/users/2516225/siddaram-h,"1,176",44577923
47178181,47178181,4,"I had the same problem with 
conda install
, but everything worked fine with:


pip install h2o",2017-11-08T11:09:47,Martin Evans,https://stackoverflow.com/users/4985733/martin-evans,46.7k,44577923
64073374,64073374,1,"Suppose you are running on the Windows system, here is the way I resolved this issue:




Open your Anaconda Prompt.




Enter
 
conda create -n py36 python=3.6 anaconda
 to create a channel with python 3.6. 

(which is often a neglected part, since up-to-date version is 3.83 while h2o module is only supported in 2.7,3.5,3.6)




Enter
 
activate py36
 on the same screen to initiate a new channel named 
py36
.




Enter
 
config --append channels conda-forge
 in order to load the latest version of h2o.




Enter
 
conda install -c h2oai h2o
 install the required modules including h20 and tabulate in the channel 
py36
.




Exit the 
anaconda prompt
, click on the anaconda-navigator application icon or type 
anaconda-navigator
 in your anaconda prompt.




Once you are on the main screen of anaconda-navigator, select 
py36
 as the channel to run applications on the upper-left corner.

(You may notice  a bunch of random apps on your anaconda navigator, that's because 
conda forge
 is in your list of channels, you can either remove it by clicking on the delete button).




Select any environment (Jupyter, Spyder, etc) on which you want to run your application, now you should be able to import h2o.


Hope this answer helps you.",2020-09-26T02:44:35,Newcomer,https://stackoverflow.com/users/13949223/newcomer,73,44577923
57426789,57426789,-1,"Please use below command.. I was facing same issue.. but after executing below command issue got resolved.


python -m pip install h2o 


OR if you are using python3 :


python3 -m pip install h2o",2019-08-09T09:04:21,user3709668,https://stackoverflow.com/users/3709668/user3709668,1,44577923
44559442,44559442,3,"The way H2O GBM multinomial classification works is, when you ask for 1 tree as a parameter, it actually builds a tree for each level in the response column underneath the hood.


So 1 tree really means 20,000 trees in your case.


2 trees would really mean 40,000, and so on...


(Note the binomial classification case takes a shortcut and builds only one tree for both classes.)


So... it will probably finish but it could take quite a long time!",2017-06-15T05:44:40,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44558411
44558607,44558607,2,"It's probably not a good idea to train a classifier with 20,000 classes --  most GBM implementations won't even let you do that.  Can you group/cluster the classes into a smaller number of groups so that you can train a model with a smaller number of classes?  If so, then you could perform your training in a two-stage process -- the first model would have 
K
 classes (assuming you clustered your classes into 
K
 groups).  Then you can train secondary models that further classify the observations into your original classes.


This type of two-stage process may make sense if your classes represent groups that naturally clusters into a hierarchy of groups -- such as zip codes or ICD-10 medical diagnostic codes, for example.


If your use-case really demands that you train a 20,000 class GBM (and there's no way around it), then you should get a bigger cluster of machines to use in your H2O cluster (it's unclear how many CPUs you are using currently).  H2O GBM should be able to finish training, assuming it has enough memory and CPUs, but it may take a while.",2017-06-15T04:33:43,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44558411
44560092,44560092,1,"You can solve this one of two ways -- 1. in R first and then move to H2O for modeling or 2. Entirely in H2O using H2O's word2vec implementation.


Use R data.frames and 
text2vec
, then convert the sparse matrix to an H2O frame and do the modeling in H2O.


 # Use same code as above to get to this point, then:

 # Convert dgCMatrix to H2OFrame, cbind the response col
 train <- as.h2o(dtm_train)
 train$y <- as.h2o(dataframe$output)

 # Train any H2O model (e.g GBM)
 mymodel <- h2o.gbm(y = ""y"", training_frame = train,
                   distribution = ""bernoulli"", seed = 1)



Or you can train a word2vec embedding in H2O, apply it to your text to get the equivalent of a sparse matrix.  Then train a H2O machine learning model 
 (GBM).  I will try edit this answer later with a working example using your data, but in the meantime, here is an 
example
 demonstrating the use of H2O's word2vec functionality in R.",2017-06-15T06:25:22,,,,44555015
45575718,45575718,1,"There are several ways how you can export a model.


You can export binary version( serialization) of model, POJO ( Plain Old Java Object) and Mojo ( Model Object Optimised)


You can read more about POJOs and MOJOs here. These 2 are used for putting models into predictions. The good thing about them that they don't need H2O framework to be running.


The methods you can use for exporting are available here 
https://github.com/h2oai/sparkling-water/blob/master/core/src/main/scala/water/support/ModelSerializationSupport.scala


exportH2OModel
 exports binary model and 
exportPOJOModel
 exports POJO. 


The method for exporting MOJO is accidentally missing and will be added in the next Sparkling Water release.",2017-08-08T18:35:56,,,,44551431
44643691,44643691,4,"The default username/password is superuser/superuser. The flags are not honored by steam server command and looks like its a bug. See config.toml file in the folder. 


This breaks the very first developer experience with h2o/steam and is not encouraging.",2017-06-20T04:12:26,Neelesh,https://stackoverflow.com/users/953333/neelesh,76,44551002
46842531,46842531,0,./steam serve master --superuser-name=superuser --superuser-password=superuser works fine,2017-10-20T04:48:24,Kevin Guillen,https://stackoverflow.com/users/8804654/kevin-guillen,1,44551002
44551073,44551073,2,"You can set 
include=FALSE
 in the chunk options. That should prevent any output from printing.


```{r include=FALSE}
h2o.init()
```",2017-06-14T17:23:37,,,,44550808
44552300,44552300,1,"If you want to suppress all R output, you can use the 
sink()
 function.  Here is how that would look with 
h2o.init()
:


> library(h2o)
> sink(""/dev/null"") 
> h2o.init()
java version ""1.8.0_45""
Java(TM) SE Runtime Environment (build 1.8.0_45-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)",2017-06-14T18:39:45,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44550808
44550854,44550854,0,"Your command line is correct.


YARN really did dispatch one of the containers to 192.168.56.101 or that message would not have appeared.",2017-06-14T17:11:08,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44540331
44533746,44533746,0,"In the special case of NAs, you can use the 
impute()
 method to replace all of them with a single value (or alternatively, you can impute the mean, median or mode of a column).  Here is an example:


import h2o

h2o.init()

df = h2o.H2OFrame([[1,2,3],[4,5,6]])
df.insert_missing_values(fraction=0.5, seed=1)



So the frame will look like this:


  C1    C2    C3
----  ----  ----
 nan   nan     3
 nan     5   nan



Now we can impute by value, but we need to pass along a list of values which is the same length as the number of columns (and in your case, all zeros).


df.impute(column=-1, values=[0 for c in range(df.ncol)])



Now the frame looks like this:


  C1    C2    C3
----  ----  ----
   0     0     3
   0     5     0",2017-06-14T00:57:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44533297
53235107,53235107,0,"going to repost Jakub's comment so it is more easily found:


It seems like your H2O cloud is not properly initialized. Please check the readme here github.com/h2oai/rsparkling#spark-connection",2018-11-10T00:58:50,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",44527904
44530143,44530143,5,"No there are not currently feature selection functions in H2O -- my advice would be to use 
Lasso regression
 (in H2O this means use GLM with 
alpha = 1.0
) to do the feature selection, or simply allow whatever machine learning algorithm (e.g. GBM) you are planning to use to use all the features (they'll tend to ignore the bad ones, but it could still degrade performance of the algorithm to have bad features in the training data).


If you'd like, you can make a feature request by filling out a ticket on the 
H2O-3 JIRA
. This seems like a nice feature to have.",2017-06-13T19:37:49,,,,44521080
51791883,51791883,1,"In my opinion, Yes


My way is use automl to train your data.


after training, you can get a lot of model.


use 
h2o.get_model
 method or H2O server page to watch some model you like.


you can get 
VARIABLE IMPORTANCES
 frame.


then pick your features.",2018-08-10T18:04:44,peikuo,https://stackoverflow.com/users/6187135/peikuo,665,44521080
44550936,44550936,1,"GLM models score really fast.  It's fine to put them in series within a single lambda API call.  Model prediction latency won't be bad.  The database table lookups will probably dominate the latency.


What's important for high volume transaction problems is that multiple transactions can occur in parallel, and using AWS lambda endpoints is a good way to let Amazon handle that problem instead of having to invent your own way.",2017-06-14T17:15:56,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44495091
44495063,44495063,0,"Depending on whether your model is a regression, binomial or multinomial model you'll have to use one of 
ModelMetricsRegression.make()
, 
ModelMetricsBinomial.make()
 or 
ModelMetricsMultinomial.make()
. They have slightly different signatures - you can find them in our Java docs.


For the 
trainDataFrame
 you can get them from your 
drf
 model, it's in 
drf._output._training_metrics
 (you might need to cast it to an appropriate type as this one is a generic 
ModelMetrics
). If you use your test dataset as a validation frame you can get the metrics from 
drf._output._validation_metrics
.


@Edit:


DRFModel drf = job.trainModel().get(); // Train the model
Frame pred = drf.score(testDataFrame); //Score the test
ModelMetricsBinomial mm = ModelMetricsBinomial.make(preds.vec(2), trainDataFrame.vec(rfParms._response_column));
double auc = mm.auc();
double rmse = mm.rmse();
double r2 = mm.r2();
// etc.",2017-06-12T08:47:28,,,,44490925
47568875,47568875,0,"I don't know about h2o autoencoder but it seems to me that autoencoder do not work correctly with one-hot encoded variables.  I tried everything. What I didn't try is the 'Categorical variational autoencoder using the Gumbel-Softmax estimator' (
https://github.com/ericjang/gumbel-softmax
).",2017-11-30T08:25:28,MarioZ,https://stackoverflow.com/users/7215349/marioz,318,44441556
44434557,44434557,1,"That is an old tutorial, which was made before distributed Tensorflow was released. At that time this was the easiest way to ""integrate""/""distribute"" it (by simply running TF on each worker node and then averaging the coefficients on the driver node).


Since then we have released 
project DeepWater
 which integrates several DL frameworks (TF, MXNet, Caffee) with H2O. This one doesn't require Spark, all you need to do (if you're running a linux machine) is to download H2O 
from here
 (
H2O with GPU-Enabled Machine Learning
) and run it. If you're running MacOS or Windows you'd have to build both DeepWater and H2O yourself as we don't provide those yet.


As a disclaimer: deepwater currently runs only on a single node, as none of the mentioned frameworks have Java APIs for distribution (for example TF only has Python API for that). I'm working on a distributed version but for now it's not really a #1 priority.",2017-06-08T11:32:55,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44434050
44426923,44426923,5,"Yes, H2O is one of the few machine learning libraries that does not require the user to pre-process or one-hot-encode (aka ""dummy-encode"") the categorical variables.  As long as the column type is ""factor"" (aka ""enum"") in your data frame, then H2O knows what to do automatically.


In particular, H2O allows direct use of categorical variables in tree-based methods like Random Forest or GBM.  Tree based algorithms have the ability to use the categorical data natively and typically this leads to better performance than one-hot encoding.  In GLM or Deep Learning, H2O will one-hot encode the categoricals automatically under the hood -- either way you don't need to do any pre-processing.  If you want more control, you can control the type of automatic encoding using the 
categorical_encoding
 argument.",2017-06-08T04:56:15,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44425647
45085656,45085656,2,"IMHO, being able to handle categorical variables directly in a Tree algorithm is a huge advantage with H2O.


If you do one-hot encoding of a categorical variable you have effectively taken one variable and split them into several variables whose values are mainly 0 (e.g. sparse).  As Erin stated, this makes Trees perform worse.  This is because Trees use ""information gain"" at each split.  Sparse features (from one-hot encoding) have less information gain, hence are less useful than a categorical feature.",2017-07-13T15:51:44,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,44425647
44441006,44441006,1,Thank you for your help. It turns out my error was coming from the fact that my train_csv was empty due to a variable that I hadn't changed above. It is back to working.,2017-06-08T16:24:35,K.Thomas,https://stackoverflow.com/users/7763070/k-thomas,21,44424083
44426281,44426281,0,"The 
h2o.import_file()
 function requires using the full path of the file.  Change your code to use the full path and hopefully that will solve the issue.",2017-06-08T03:47:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44424083
57897911,57897911,0,"I just came across this issue and for me it was the file didn't have read permissions. So I just had to do a 
chmod 777 train.csv
 to give it full privileges. Now you might not want to give it all privileges of 777, I just did it because it was easiest for me.",2019-09-11T23:21:06,alex,https://stackoverflow.com/users/6393275/alex,"2,185",44424083
44404138,44404138,1,"You can set 
strict_version_check = FALSE
 in your 
h2o.init()
 call and that will get you around the error.  Those versions are close enough that it shouldn't lead to any issues (but technically it could).  


Also, that's an older Docker image -- the build number now is 274, so I would also suggest a 
docker pull
, although it's not strictly necessary.  There's more info on the h2oai/deepwater 
README
.


docker pull opsh2oai/h2o-deepwater",2017-06-07T05:23:24,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44400110
44635065,44635065,0,"Right package file is here:


/opt/dist/h2o_3.11.0.234.tar.gz",2017-06-19T15:56:44,filius_arator,https://stackoverflow.com/users/7515482/filius-arator,139,44400110
44379149,44379149,0,"We don't provide H2O+deepwater builds for MacOS. The one you downloaded is built for Linux machines (tested on Ubuntu), it's mentioned 
on the download page
.


If you want to run it on MacOS you'd have to build both 
DeepWater
 and then 
H2O
 yourself.",2017-06-05T23:26:06,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44378128
44379883,44379883,1,"You will need to use the 
H2OKMeansEstimator
 method in Python (or 
h2o.kmeans()
 function in R) -- there is no way to ""import"" your own K-means code into H2O, which I think is what you're asking.  There is more info about H2O's K-means implementation 
here
.


To export an H2O K-means model for use (scoring) in a production environment, you can export the model as a 
POJO or MOJO
 (pure Java code with no dependencies), or you can save a 
binary H2O model
 which will require to have an H2O cluster running at scoring-time.",2017-06-06T01:04:24,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44374389
44371791,44371791,1,"This is an odd combinations of data import artifacts:


This is an epoch time, which is in number of seconds from January 1, 1970.


If you use this code:


numDate <- 1466073000 #notice I removed three zeros
as.POSIXct(numDate, origin=""1970-01-01"")



You get the following output:


""2016-06-16 06:30:00 EDT""



So, it is in miliseconds.
Also, the time is incorrect, by 6 hours. 


Chances are it is giving you Greenwich mean time adjustment for your systems time zone (which if you work in a corporate system could be different than your current time zone depending on where the actual processor is located and how your system is set up)


You have options:


Run the analysis on epoch time
or
Convert using:  


as.POSIXct( 1466073000000/1000, origin=""1970-01-01"")
 


try to coerce h2o to bring it in the way you want.


As long as this time (with your zone adjustment) IS correct there is no reason to change it unless you need to be able to read it correctly. I would change the output after the analysis was run to make it human readable.",2017-06-05T14:57:55,sconfluentus,https://stackoverflow.com/users/6258859/sconfluentus,"4,995",44369393
44379108,44379108,2,"AUC
 is a metric for classification, you're creating a ~regression~ model from what I see therefore you cannot use 
auc
 in 
grid = h2o.getGrid(""mygrid"", sort_by=""auc"", decreasing=TRUE)
. Instead use, as the error message suggests, one of the following metrics: 
r2, mean_per_class_accuracy, max_per_class_error, err, total_rows, rmse, accuracy, err_count, logloss, mse, mean_per_class_error
.",2017-06-05T23:21:26,,,,44361273
44361167,44361167,2,"You do not need to attach Sparkling Water packages (option 
--packages
), but you need to provide pysparkling Python package (it contains all necessary binary dependencies internally).


The best way is to download binary distribution of Sparkling Water from 
http://h2o.ai/download
 and use 
bin/pysparkling
 script or use spark directly:


$SPARK_HOME/bin/pyspark --py-files h2o_pysparkling_2.1-2.1.8.zip",2017-06-05T03:11:50,Michal,https://stackoverflow.com/users/5089773/michal,437,44349062
44349296,44349296,1,"I partially resolved this on my own: after downloading model to POJO, I opened up the file with a text editor based on Darren Cook's suggestion (thank you), and I think I can see all the weights and biases here. 


I'm not certain however b/c I'm unfamiliar with the POJO format.",2017-06-03T23:03:37,ogukku,https://stackoverflow.com/users/6088414/ogukku,53,44348850
44345073,44345073,1,"I resolved this on my own:


1) Checkpoint can only be done if original model: 




used no CV


or used CV but had fold assignment set to Modulo


and of course if other certain parameters are not changed such as nfolds.




2) 
Would still like to know how it would be possible to extract the weights and biases of my model if possible
. Thank you.",2017-06-03T14:39:41,ogukku,https://stackoverflow.com/users/6088414/ogukku,53,44341557
44365614,44365614,2,"The first part would be easily doable using our Python/R APIs - Flow is more for trying out H2O, doing very basic operations - you'd have to prepare your dataset so it has the same column twice or upload the same dataset twice. This should only be a problem if you're running certain algorithms as regression problems and others as classification.


As for the second question - no, rebalancing is only supported for binomial/multinomial problems (we're achieving it via under/over sampling of certain classes).",2017-06-05T09:19:14,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44338639
44317516,44317516,0,"For your specific question you can do:


library(h2o)
h2o.init(strict_version_check = F)
iris_wheader = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv""

iris.hex = h2o.importFile(iris_wheader)

iris_count <- h2o.group_by(data = iris.hex, by = ""class"", nrow('class'),gb.control=list(na.methods=""rm""))



you can see the original frame and the results:


head(iris.hex)

sepal_len sepal_wid petal_len petal_wid       class
1       5.1       3.5       1.4       0.2 Iris-setosa
2       4.9       3.0       1.4       0.2 Iris-setosa
3       4.7       3.2       1.3       0.2 Iris-setosa
4       4.6       3.1       1.5       0.2 Iris-setosa
5       5.0       3.6       1.4       0.2 Iris-setosa
6       5.4       3.9       1.7       0.4 Iris-setosa

iris_count

      class         nrow
1     Iris-setosa   50
2 Iris-versicolor   50
3  Iris-virginica   50



There is documentation being added for a future release, but here are some examples


> library(h2o)
> h2o.init()

# Import the airlines data set and display a summary.
> airlinesURL <- ""https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv""
> airlines.hex <- h2o.importFile(path = airlinesURL, destination_frame = ""airlines.hex"")
> summary(airlines.hex)

# Find number of flights by airport
> originFlights <- h2o.group_by(data = airlines.hex, by = ""Origin"", nrow(""Origin""), gb.control=list(na.methods=""rm""))
> originFlights.R <- as.data.frame(originFlights)
> originFlights.R
Origin nrow_Origin
1      ABE          59
2      ABQ         876
3      ACY          31
...

# Find number of flights per month
> flightsByMonth <- h2o.group_by(data = airlines.hex, by = ""Month"", nrow(""Month""), gb.control=list(na.methods=""rm""))
> flightsByMonth.R <- as.data.frame(flightsByMonth)
> flightsByMonth.R
Month nrow_Month
1     1      41979
2    10       1999

# Find the number of flights in a given month based on the origin
> cols <- c(""Origin"",""Month"")
> flightsByOriginMonth <- h2o.group_by(data=airlines.hex, by=cols,nrow(""NumberOfFlights""), gb.control=list(na.methods=""rm"")
> flightsByOriginMonth.R <- as.data.frame(flightsByOriginMonth)
> flightsByOriginMonth.R
Origin Month nrow_NumberOfFlights
1      ABE     1                   59
2      ABQ     1                  846
3      ABQ    10                   30
4      ACY     1                   31
5      ALB     1                   75
...

# Find months with the highest cancellation ratio
> which(colnames(airlines.hex)==""Cancelled"")
[1] 22
> cancellationsByMonth <- h2o.group_by(data = airlines.hex, by = ""Month"", sum(""Cancelled""), gb.control=list(na.methods=""rm""))
> cancellation_rate <- cancellationsByMonth$sum_Cancelled/flightsByMonth$nrow_Month
> rates_table <- h2o.cbind(flightsByMonth$Month,cancellation_rate)
> rates_table.R <- as.data.frame(rates_table)
> rates_table.R
Month sum_Cancelled
1     1   0.025417471
2    10   0.009504752

# Use group_by with multiple columns. Summarize the destination, arrival delays, and departure delays for an origin
> cols <- c(""Dest"", ""IsArrDelayed"", ""IsDepDelayed"")
> originFlights <- h2o.group_by(data = airlines.hex[c(""Origin"",cols)], by = ""Origin"", sum(cols),gb.control = list(na.methods = ""ignore"", col.names = NULL))
# Note a warning because col.names null
> res <- h2o.cbind(lapply(cols, function(x){h2o.group_by(airlines.hex,by=""Origin"",sum(x))}))[,c(1,2,4,6)]
> res
Origin sum_Dest sum_IsArrDelayed sum_IsDepDelayed
1    ABE     5884               40               30
2    ABQ    84505              545              370
3    ACY     3131                9                7
4    ALB     3646               49               50
5    AMA      317                4                6
6    ANC      100                0                1",2017-06-01T21:41:58,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",44315642
44316192,44316192,3,"Row names (vertical) are the actual labels.


Column names (across) are the predicted labels.",2017-06-01T20:03:54,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44315497
44316282,44316282,1,"You did not make a mistake; the labels are confusing (and causing people to think that the rows and columns were switched).  This was 
fixed recently
 and will be included in the next release of H2O.",2017-06-01T20:10:02,,,,44315497
44286883,44286883,3,"This seems quite wasteful, starting up h2o twice every iteration. If you just want to free up the memory you can use 
h2o.removeAll()
 instead.


As for the cause, 
h2o.shutdown()
 (any H2O shutdown) is not a synchronized operation and some cleanup can still occur after the function returns (for example handling of outstanding requests). You can check using 
h2o.clusterIsUp()
 whether the cluster is actually down before starting it again with 
init
.",2017-05-31T14:01:11,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44281612
44289362,44289362,1,"The cause of the error is that you are not changing the 
grid_id
 parameter in your loop.  My recommendation is to let H2O auto-generate a grid id by leaving it unspecified/NULL.  You can also create different grid ids (one for each dataset) manually, but it's not required.


You can only add new models to an existing grid (by re-using the same grid id) when you use the same training set.  When you put a grid search in a for loop over different datasets and keep the same grid id, it will throw an error because you are trying to append models trained on different datasets to the same grid.",2017-05-31T15:51:38,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44281612
44279924,44279924,0,"You're passing 
H2OBinomialModel
 into 
find_threshold_by_max_metric
, you're supposed to pass 
H2OBinomialMetrics
 instead, for example:


p <- h2o.performance(NNmodel)
h2o.find_threshold_by_max_metric(p, ""F1"")



h2o.performance
 does take some more parameters which you might need to set.


I'm not sure but I thought 
F1
 isn't supported for deeplearning, should that be the case please try one of 
logloss, auc, classification_error, rmse
.",2017-05-31T08:46:40,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44277378
44443797,44443797,0,"perf_oot <- h2o.performance(NNmodel, newdata=oot_data.hex)",2017-06-08T19:10:57,Mary Li,https://stackoverflow.com/users/5240094/mary-li,11,44277378
44271812,44271812,3,"From a terminal window, run the 
nvidia-smi
 tool.  Look at the utilization.  If it's 0%, you're not using the GPUs.


In the example below, you can see Volatile GPU Utilization is 0%, so the GPUs are not being used.


$ nvidia-smi
Tue May 30 13:50:11 2017   
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 370.28                 Driver Version: 370.28                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 0000:02:00.0     Off |                  N/A |
| 27%   30C    P8    10W / 180W |      1MiB /  8113MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1080    Off  | 0000:03:00.0      On |                  N/A |
| 27%   31C    P8     9W / 180W |     38MiB /  8112MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    1      1599    G   /usr/lib/xorg/Xorg                              36MiB |
+-----------------------------------------------------------------------------+



I use the following handy little script to monitor GPU utilization for myself.


$ cat bin/gputop 
#!/bin/bash

watch -d -n 0.5 nvidia-smi",2017-05-30T20:58:59,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",44269267
44271519,44271519,2,"You will need the GPU-enabled version of H2O, available on the H2O 
download page
.  It is not clear from your question if you are using regular H2O or GPU-enabled H2O, however if you are using GPU-enabled H2O and have the proper dependencies, it should see your GPUs.  The current dependency list is:




Ubuntu 16.04


CUDA 8.0


cuDNN 5.1




I have opened a 
JIRA ticket
 to add some metadata in the 
h2o.init()
 printout so that you'll see information about your GPUs there (in a future release).",2017-05-30T20:39:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44269267
44300384,44300384,1,"I think I've figured out 
an
 answer to my question. A self-contained sample code follows. However, I'll still appreciate an answer from the community since I don't know if this is the best/idiomatic way to do it. 


package org.name.company;

import hex.glm.GLMModel;
import water.H2O;
import water.Key;
import water.api.StreamWriter;
import water.api.StreamingSchema;
import water.fvec.Frame;
import water.fvec.NFSFileVec;
import hex.glm.GLMModel.GLMParameters.Family;
import hex.glm.GLMModel.GLMParameters;
import hex.glm.GLM;
import water.util.JCodeGen;

import java.io.*;
import java.util.Map;

public class Launcher
{
    public static void initCloud(){
        String[] args = new String [] {""-name"", ""h2o_test_cloud""};
        H2O.main(args);
        H2O.waitForCloudSize(1, 10 * 1000);
    }

    public static void main( String[] args ) throws Exception {
        // Initialize the cloud
        initCloud();

        // Create a Frame object from CSV
        File f = new File(""/path/to/data.csv"");
        NFSFileVec nfs = NFSFileVec.make(f);
        Key frameKey = Key.make(""frameKey"");
        Frame fr = water.parser.ParseDataset.parse(frameKey, nfs._key);

        // Create a GLM and output coefficients
        Key modelKey = Key.make(""modelKey"");
        try {
            GLMParameters params = new GLMParameters();
            params._train = frameKey;
            params._response_column = fr.names()[1];
            params._intercept = true;
            params._lambda = new double[]{0};
            params._family = Family.gaussian;

            GLMModel model = new GLM(params).trainModel().get();
            Map<String, Double> coefs = model.coefficients();
            for(Map.Entry<String, Double> entry : coefs.entrySet()) {
                System.out.format(""%s: %f\n"", entry.getKey(), entry.getValue());
            }

            String filename = JCodeGen.toJavaId(model._key.toString()) + "".java"";
            StreamingSchema ss = new StreamingSchema(model.new JavaModelStreamWriter(false), filename);
            StreamWriter sw = ss.getStreamWriter();
            OutputStream os = new FileOutputStream(""/base/path/"" + filename);
            sw.writeTo(os);

        } finally {
            if (fr != null) {
                fr.remove();
            }
        }
    }
}",2017-06-01T06:48:25,RDK,https://stackoverflow.com/users/1165786/rdk,943,44268964
46275924,46275924,1,"Would something like this do the trick?


public void saveModel(URI uri, Keyed<Frame> model)
{
    Persist p = H2O.getPM().getPersistForURI(uri);
    OutputStream os = p.create(uri.toString(), true);
    model.writeAll(new AutoBuffer(os, true)).close();
}



Make sure the URI has a proper form otherwise H2O will break on an npe. As for Maven you should be able to get away with the h2o core.


    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-core</artifactId>
        <version>3.14.0.2</version>
    </dependency>",2017-09-18T09:28:23,,,,44268964
44279309,44279309,0,"As mentioned in the comments - this seems to be a bug relating to how we are using Retrofit, please create an issue 
in our JIRA
. You can point to this 
Retrofit issue
 in it. To be sure also please post the JIRA link on H2O-3 gitter channel.",2017-05-31T08:17:22,,,,44259044
44253818,44253818,0,"Yes we had some unused deps in one of our files in version 
3.10.3.x
, the one you're using.


It should be fixed in the newest version, which is 
3.11.0.X
 and which you can get from 
here
.


@Edit:


The above version was built for Linux, though - if you want to run it on windows you'll have to build it yourself according to the instructions 
here for deepwater
 and 
here for h2o
. We don't have nightly builds for Windows just yet.",2017-05-30T05:04:15,,,,44252106
44243431,44243431,1,"Usually, this arises when you installed h2o before spark. Sparkling is not working with the very last version of h2o.

You need to clear 
h2o
 installation and choose the one corresponding to your 
rsparkling
 installation. The table of correspondence is here: 
https://github.com/h2oai/rsparkling/blob/master/README.md

To uninstall library h2o:  


# detach loaded libraries
  detach(""package:rsparkling"", unload = TRUE)
  if (""package:h2o"" %in% search()) {detach(""package:h2o"", unload = TRUE)}
  if (isNamespaceLoaded(""h2o"")) { unloadNamespace(""h2o"") }
# remove h2o from your installation
  remove.packages(""h2o"", lib = .libPaths()[1])



And re-install it from repository with sparkling compatibility:  


# install last h2o for which sparkling is available
  install.packages(""h2o"", type = ""source"",
    repos = ""http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/2/R"")



If needed, install the last spark version:


# spark_available_versions()
spark_install(version = ""2.1.0"", hadoop_version = ""2.7"")



Reload your R session or close/open it and try again to connect to spark:  


sc <- spark_connect(master = ""local"", version = ""2.1.0"")",2017-05-29T13:14:19,,,,44241161
44250887,44250887,2,"Running AutoML in a loop on different datasets should work (as of two days ago via this 
pull request
).  Prior to that, the AutoML 
project_name
 was hardcoded so that every time you ran AutoML, it would try to append new models to the same project. A project is defined by the training set, so this is why you were getting the error.  


Running that same code now should no longer produce an error.  Now a project name is created automatically based on your training set, or you can also define a custom project name using the new 
project_name
 argument of 
h2o.automl()
.",2017-05-29T22:15:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44240487
44237753,44237753,1,"Water Meter is only implemented for Linux systems (by reading 
/proc/stat
 data), it won't work on neither Windows nor MacOS. From what I recall we don't have anyone working on a Windows/Mac version so if you're feel like it then you can contribute, you can check the 
source code here
 and the Linux implementation 
here
. The tricky part is that it has to use open libraries (due to licensing).",2017-05-29T08:20:49,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44237304
44221382,44221382,2,"I can't replicate your error.  I just downloaded the 
h2o_3.10.0.6.tar.gz
 file from the CRAN archive, and was able to install it properly, so it seems like it must be an internet connectivity issue on your end.  Just did this now:


> install.packages(""h2o_3.10.0.6.tar.gz"", repos=NULL, type=""source"")
* installing *source* package ‘h2o’ ...
** package ‘h2o’ successfully unpacked and MD5 sums checked
** R
** demo
** inst
** preparing package for lazy loading
Performing one-time download of h2o.jar from
     http://s3.amazonaws.com/h2o-release/h2o/rel-turing/6/Rjar/h2o.jar
(This could take a few minutes, please be patient...)
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (h2o)



There are a few other ways to re-install an old version of the 
h2o
 R package.  If it is a CRAN release version, you can use the 
versions
 package to install any old version of a CRAN package:


install.packages(""versions"")
install.versions(""h2o"", versions = ""3.10.0.6"")



Any stable release of H2O can be downloaded from it's release page.  The 3.10.0.6 release page is 
here
, and if you click on the ""Install in R"" tab, it will show you the commands to install that version of H2O from R: 


install.packages(""h2o"", type=""source"", repos=(c(""https://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R"")))",2017-05-27T20:34:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44220933
44209609,44209609,1,"The prediction service is using EasyPredictModelWrapper and it can only use what the underlying model uses. Here it's not clear what model you use, but most use numerical float values. In the for loop code snippet you can see that the number has to be float.",2017-05-26T20:21:34,Magnus,https://stackoverflow.com/users/7816546/magnus,246,44205039
44138304,44138304,3,"but I also cannot install TensorFlow backend on machine without GPU




Do you mean you tried and got errors?




Is there any option to built TensorFlow backend for H2O without GPU support?




Yes but depending on your machine it might be easy or a bit hacky. If you're running on a MacOS system then it should work out of the box, just 
follow our instruction
.


If you are on a Linux based system then you'd have to first change one our scripts, to be exact 
this one
. You'd have to do two things:




change 
export TF_NEED_CUDA=1
 to 
export TF_NEED_CUDA=0


change 
export BUILDFLAGS=""--config=cuda --copt=-m64 --linkopt=-m64 --copt=-march=native""
 to 
export BUILDFLAGS=""--copt=-m64 --linkopt=-m64 --copt=-march=native""




You might also remove 
--config=cuda
 under 
echo ""Build pip package""
.


After this you follow the instructions linked above as normal.


This should work, but I haven't tested it myself so should you get errors please raise an issue on DeepWater's Github issue tracker.",2017-05-23T14:54:51,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44137342
44233251,44233251,1,"The best way is to create 3 different R or Python scripts that each create the Frame X_i and then run GridSearch_i on it, you can run all of them in parallel. If you're doing it in one script or interactively, then the grid searches will be sequential.",2017-05-29T00:27:58,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,44124312
44114420,44114420,1,"The 
support article
 is outdated and was just demonstrating something we already incorporated into our API. That sample code is using an outdated 
water.serial.ObjectTreeBinarySerializer
, which doesn't exist anymore.


The most convenient way is to use the 
ModelSerializationSupport
.",2017-05-22T13:39:39,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,44112659
44259769,44259769,0,"To answer the original question (exception) this is indeed a bug in H2O, currently there's no workaround besides building from 
this branch
.


As pointed out this method does not return the metadata, will answer this part in 
this question
.",2017-05-30T10:30:25,,,,44110233
44095000,44095000,4,"H2O frames are not lazy, contrary to Spark's data structures. There is therefore no need for explicit caching/persisting as we load the whole frame into memory anyway. This can be problematic if your dataset is bigger than cluster's memory but we do it in such a way for performance reasons. In spark you'd cache RDDs for machine learning anyway. There are 2 requirements for an H2O frame:




the total cluster memory has to be big enough to hold the whole frame


a single row of the frame has to fully fit on every machine (we do not distribute frames column-wise, only row-wise meaning we take X rows, a chunk, and put them all on a single node)




H2O frames just like RDDs are fully distributed and only parts of the frame are located on each node. Most of our algos take advantage of data locality (i.e. each node only uses rows stored on it for computations) but you can also shuffle data around so every node uses the whole frame.


When converting an RDD into an H2O frame we materialize the whole data in memory. When doing the opposite there's no memory overhead as we're just iterating over an H2O Frame.


H2O frames are less generic than RDDs but thanks to that we can highly compress the data in memory.",2017-05-21T08:59:59,,,,44094810
44233269,44233269,2,"Whenever a node is split based on a column/feature/variable (either numeric or categorical), the reduction in squared error attributed to the split (squared error in one ""mixed"" node before - sum of squared error in two ""purer"" nodes afterwards) is counted towards the absolute variable importance. It gets scaled afterwards such that the largest variable importance is 1.0.",2017-05-29T00:31:20,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,44092152
44092010,44092010,5,"If 
df
 is your H2O Frame then 
df['y'] = df['y'].relevel('ok')
 should set 'ok' to level 0. See 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html#h2o.frame.H2OFrame.relevel",2017-05-21T00:18:08,Branden Murray,https://stackoverflow.com/users/4155196/branden-murray,494,44089162
44165802,44165802,6,"Firstly, as user1808924 noted, there are differences in the algorithms and their default hyperparameters. For example, R's randomForest splits based on the Gini criterion and H2O trees are split based on reduction in Squared Error (even for classification). H2O also uses histograms for splitting and can handle splitting on categorical variables without dummy (or one-hot) encoding (although I don't think that matters here since the Santander dataset is entirely numeric). Other information on H2O's splitting can be found 
here
 (this is in the GBM section but the splitting for both algos is the same). 


If you look at the predictions from your R randomForest model you will see that they are all in increments of 0.02. R's randomForest builds really deep trees, resulting in pure leaf nodes. This means the predicted outcome or an observation is either going to be 0 or 1 in each tree, and since you've set 
ntrees=50
 the predictions will all be in increments of 0.02. The reason you get bad AUC scores is because with AUC it is the order of the predictions that matters, and since all of your predictions are [0.00, 0.02, 0.04, ...] there are a lot of ties. The trees in H2O's random forest aren't quite as deep and therefore aren't as pure, allowing for predictions that have some more granularity to them and that can be better sorted for a better AUC score.",2017-05-24T18:13:58,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44084312
44071777,44071777,2,"The model instance currently cannot be converted to mojo instance without going through MojoWriter.


MojoWriter provides method 


abstract public void writeTo(OutputStream os);



You can use it to write the mojo to a byte array (using a ByteArrayOutputStream) and then use it as a source of the mojo data:


  ByteArrayOutputStream os = new ByteArrayOutputStream();
  model.getMojo().writeTo(os);
  MojoModel mojoModel = MojoModel.load(MojoReaderBackendFactory.createReaderBackend(
          new ByteArrayInputStream(os.toByteArray()), MojoReaderBackendFactory.CachingStrategy.MEMORY));",2017-05-19T13:48:23,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,44056120
46535190,46535190,12,"A naive solution is to use 
plot()
 generic function to plot a H2OMetrics object:


logit_fit <- h2o.glm(colnames(training)[-1],'y',training_frame =
    training.hex,validation_frame=validation.hex,family = 'binomial')
plot(h2o.performance(logit_fit),valid=T),type='roc')



This will give us a plot:




But it is hard to customize, especially to change the line type, since the 
type
 parameter is already taken as 'roc'. Also I have not found a way to plot multiple models' ROC curves together on one plot. I have come up with a method to extract true positive rate and false positive rate from the H2OMetrics object and use ggplot2 to plot the ROC curves on one plot by myself. Here is the example code(uses a lot of tidyverse syntax):


# for example I have 4 H2OModels
list(logit_fit,dt_fit,rf_fit,xgb_fit) %>% 
  # map a function to each element in the list
  map(function(x) x %>% h2o.performance(valid=T) %>% 
        # from all these 'paths' in the object
        .@metrics %>% .$thresholds_and_metric_scores %>% 
        # extracting true positive rate and false positive rate
        .[c('tpr','fpr')] %>% 
        # add (0,0) and (1,1) for the start and end point of ROC curve
        add_row(tpr=0,fpr=0,.before=T) %>% 
        add_row(tpr=0,fpr=0,.before=F)) %>% 
  # add a column of model name for future grouping in ggplot2
  map2(c('Logistic Regression','Decision Tree','Random Forest','Gradient Boosting'),
        function(x,y) x %>% add_column(model=y)) %>% 
  # reduce four data.frame to one
  reduce(rbind) %>% 
  # plot fpr and tpr, map model to color as grouping
  ggplot(aes(fpr,tpr,col=model))+
  geom_line()+
  geom_segment(aes(x=0,y=0,xend = 1, yend = 1),linetype = 2,col='grey')+
  xlab('False Positive Rate')+
  ylab('True Positive Rate')+
  ggtitle('ROC Curve for Four Models')



Then the ROC curve is:",2017-10-02T23:41:56,C8H10N4O2,https://stackoverflow.com/users/2573061/c8h10n4o2,18.9k,44034944
47821853,47821853,2,"you can get the roc curve by passing the model performance metrics to H2O's plot function.


shortened code snippet which assumes you created a model, call it 
glm
, and split your dataset into train and validation sets:


perf <- h2o.performance(glm, newdata = validation)
h2o.plot(perf)



full code snippet below:


h2o.init()

# Run GLM of CAPSULE ~ AGE + RACE + PSA + DCAPS
prostatePath = system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate.hex = h2o.importFile(path = prostatePath, destination_frame = ""prostate.hex"")
glm = h2o.glm(y = ""CAPSULE"", x = c(""AGE"",""RACE"",""PSA"",""DCAPS""), training_frame = prostate.hex, family = ""binomial"", nfolds = 0, alpha = 0.5, lambda_search = FALSE)

perf <- h2o.performance(glm, newdata = prostate.hex)
h2o.plot(perf)



and this will produce the following:",2017-12-14T20:52:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",44034944
44036116,44036116,1,"There is not currently a function in H2O R or Python client to plot the ROC curve directly.  The 
roc method
 in Python returns the data neccessary to plot the ROC curve, but does not plot the curve itself.  ROC curve plotting directly from R and Python seems like a useful thing to add, so I've created a JIRA ticket for it here: 
https://0xdata.atlassian.net/browse/PUBDEV-4449


The reference to the ROC curve in the docs refers to the H2O Flow GUI, which will automatically plot a ROC curve for any binary classification model in your H2O cluster.  All the other items in that list are in fact available directly in R and Python, however. 


If you train a model in R, you can visit the Flow interface (e.g. localhost:54321) and click on a binomial model to see it's ROC curves (training, validation and cross-validated versions). It will look like this:",2017-05-17T23:07:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44034944
61529342,61529342,1,"Building off @Lauren's example, after you run 
model.performance
 you can extract all necessary information for ggplot from 
perf@metrics$thresholds_and_metric_scores
. This code produces the ROC curve, but you can also add 
precision, recall
 to the selected variables for plotting the PR curve.


Here is some example code using the same model as above. 


library(h2o)
library(dplyr)
library(ggplot2)

h2o.init()

# Run GLM of CAPSULE ~ AGE + RACE + PSA + DCAPS
prostatePath <- system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate.hex <- h2o.importFile(
    path = prostatePath, 
    destination_frame = ""prostate.hex""
    )
glm <- h2o.glm(
    y = ""CAPSULE"",
    x = c(""AGE"", ""RACE"", ""PSA"", ""DCAPS""), 
    training_frame = prostate.hex, 
    family = ""binomial"", 
    nfolds = 0, 
    alpha = 0.5, 
    lambda_search = FALSE
)

# Model performance
perf <- h2o.performance(glm, newdata = prostate.hex)

# Extract info for ROC curve
curve_dat <- data.frame(perf@metrics$thresholds_and_metric_scores) %>%
    select(c(tpr, fpr))

# Plot ROC curve
ggplot(curve_dat, aes(x = fpr, y = tpr)) +
    geom_point() +
    geom_line() +
    geom_segment(
        aes(x = 0, y = 0, xend = 1, yend = 1),
        linetype = ""dotted"",
        color = ""grey50""
        ) +
    xlab(""False Positive Rate"") +
    ylab(""True Positive Rate"") +
    ggtitle(""ROC Curve"") +
    theme_bw()



Which produces this plot:


roc_plot",2020-04-30T17:29:43,Daniel Kent,https://stackoverflow.com/users/12155946/daniel-kent,11,44034944
44038023,44038023,1,"As pointed out 
here
 this functionality does work with the latest H2O-3 and DeepWater, you do need to build both from source (or use our docker image) and install the 
tar.gz
 R package.


Older DeepWater versions will not work as we were generating TF models only for certain types of MLP models.",2017-05-18T03:18:52,,,,44034563
44033441,44033441,11,"There is no 
h2o.sample()
 function (maybe there was in a very old version of H2O?).  You can use the 
h2o.splitFrame()
 function to split your frame into pieces.  This also serves as a way to take a random subset of your data frame (without replacement).  The function will actually create two (or more) pieces of your data, so if you want just the 30%, here is an example in R using iris to get a ~30% random sample of the rows:


library(h2o)
h2o.init()

hf <- as.h2o(iris)
ss <- h2o.splitFrame(hf, ratios = c(0.3), seed = 1)
sub_hf <- ss[[1]]   # will contain 30% of the rows



Note that for scalability reasons, 
h2o.splitFrame()
 uses ""approximate splitting"" which means that you won't necessarily get exactly 30% of the rows.  However, the expected value is 30%, and it will closer to the desired percentage when your data is bigger.  The iris is a tiny 150 row dataset, so there is more variance.",2017-05-17T19:38:05,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44033089
44030769,44030769,0,"I just ran the tutorial locally, and everything is working correctly for me. 


I built the example web service using 
sh example-python.sh
 rather than building the service using the web UI at 
http://localhost:55000
.",2017-05-17T16:54:01,brasofilo,https://stackoverflow.com/users/1287812/brasofilo,26k,44028468
44030005,44030005,2,"Currently H2O supports binomial and regression models in its partial dependency implementation. Multinomial models are not yet compatible. 


-Nav",2017-05-17T16:13:36,Navdeep Gill,https://stackoverflow.com/users/5244810/navdeep-gill,101,44019122
44014143,44014143,5,"The 
max_mem_size
 argument in the 
h2o
 R package is functional, so you can use it to start an H2O cluster of whatever size you want -- you don't need to start it from the command line using 
-Xmx
.


What's seems to be happening in your case is that you are connecting to an existing H2O cluster located at 
localhost:54321
 that was limited to ""10G"" (in reality, 9.78 GB).  So when you run 
h2o.init()
 from R, it will just connect to the existing cluster (with a fixed memory), rather than starting a new H2O cluster with the memory that you specified in 
max_mem_size
, and so the memory request gets ignored.


To fix, you should do one of the following:




Kill the existing H2O cluster at 
localhost:54321
 and restart from R with the desired memory requirement, or 


start a cluster from R at different IP/port than the one that's
already running.",2017-05-17T01:42:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",44011357
45086895,45086895,3,"When starting up 
h2o.init()
 want to specify the argument 
min_mem_size=


This forces H2O to use at least that amount of memory.  
max_mem_size=
 prevents H2O from using more than that amount of memory.",2017-07-13T16:57:30,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,44011357
51024734,51024734,2,"if you have 6GB (for example) of available memory you can do this:


library(h2o)
h2o.init(max_mem_size = ""6g"")



example: 
more memory",2018-06-25T13:31:32,Grant Shannon,https://stackoverflow.com/users/6044312/grant-shannon,"5,025",44011357
44014154,44014154,0,"The predictions get re-scaled back to the scale of the original response column.  If the range of your response column includes 0 (or close to 0), it's possible that you will get negative predictions.",2017-05-17T01:43:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43995293
43942433,43942433,0,"Almost certainly what's happening here is server configuration issues.


For starters I recommend:




disable any linux firewall (iptables/iptables6)


disable SElinux




and try again.",2017-05-12T16:26:01,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43936578
43951937,43951937,0,"You are starting on a non-standard port (12345 instead of the default 54321).


Try removing the 
port
 argument to 
h2o.init()
, and it will probably work fine.


(There is, or used to be, a bug in the handling of the port argument, which might be what you are hitting. I believe the workaround was to manually start h2o.jar from the commandline (i.e. outside of R), and then 
h2o.init(port=12345)
 should be able to connect to it.)",2017-05-13T10:18:59,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43936578
43960433,43960433,0,"I can think of one other thing that might be happening...


If you are able to connect to H2O using the web browser but not from within R, then you might have proxy environment variables that need to be unset from within R.


Make sure the environment variables http_proxy and https_proxy are unset within the R session.",2017-05-14T04:39:25,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43936578
43932717,43932717,1,"Answer To First Question: Your original error message sounds like one you can get when things get of sync. E.g. maybe you had two sessions running at once, and removed the model in one session; the other session wouldn't know its variables are now out of date. H2O allows multiple connections, but they have to be co-operative. (Flow - see next paragraph - counts as a second session.)


Unless you can make a reproducible example, shrug and put it down to gremlins, and start a new session. Or, go and look at the data/models in Flow (a web server always running on 127.0.0.1:54321 ), and see if something is no longer there.


For your EDIT question, your model is making a regression model, but you are trying to use logloss, so thought you were doing a classification. This is caused by not having set the target variable to be a factor. Your current 
as.factor()
 line is on the wrong data, in the wrong place. It should go after your 
as.h2o()
 lines:


train_h2o <- as.h2o(training)  #Typo fix
test_h2o <- as.h2o(test)

feature_names <- names(training)[1:(ncol(training)-1)]  #typo fix
y = ""Species"" #The column we want to predict

train_h2o[,y] <- as.factor(train_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])



And then make the model with:


model_dl <- h2o.deeplearning(x = feature_names, y = y, training_frame = train_h2o, stopping_metric = ""logloss"")



Get predictions with:


pred_dl <- predict(model_dl, newdata = test_h2o)  #Typo fix



And compare with correct answer with the prediction using:


cbind(test[, y], as.data.frame(pred_dl$predict))



(BTW, H2O always detects the Iris data set columns as numeric vs. factor perfectly, so the above 
as.factor()
 lines are not needed; your error message must've been on your original data.)


StackOverflow advice: test your reproducible example, in full, and copy and paste in that exact code, with the exact error message that code is giving you. Your code had numerous small typos. E.g. 
train
 in places, 
training
 in others. 
createDataPartition()
 was not given; I assumed 
a = sample(nrow(iris), 0.8*nrow(iris))
. 
test
 has no ""id"" column.


Other H2O advice:




Run 
h2o.removeAll()
 
after
 
h2o.init()
. It was giving you an error message if run before.  (Personally I avoid that function - it is the kind of thing that gets left in a production script by mistake...)


Consider importing your data into h2o earlier, and using 
h2o.splitFrame()
 to split it. I.e. avoid doing things in R that H2O can easily handle.


Avoid having your data in R, at all, if you can. Prefer importFile() over as.h2o().




The thinking beyond both the last points is that H2O will scale beyond the memory of one machine, while R won't. It also is less confusing than trying to keep track of the same thing in two places.",2017-05-12T08:14:24,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43879388
66868684,66868684,0,"I had the same issue but could resolve it quite easily.


My error occured because I read in an h2o-object before initialising the h2o-cluster. So I trained an h2o-model, saved it, shut down the cluster, loaded in the model and then initialized the cluster once again.


Before reading in the h2o-object, you should already initialize the cluster (h2o.init()).",2021-03-30T09:57:12,Arne,https://stackoverflow.com/users/12257751/arne,57,43879388
43899470,43899470,1,"As noted in comments, the column names in the Train and Test datasets need to match exactly or you will get an error message.  Glad that you were able to find the issue.",2017-05-10T17:47:04,PhilC,https://stackoverflow.com/users/4900824/philc,787,43877962
43878849,43878849,2,"Yes, you need to re-run 
java -jar h2o.jar
 after rebooting. Alternatively, you could have your OS start it, by running that command, during the boot process; the instructions for that vary by OS (and are outside the scope of StackOverflow, but are easy to google).",2017-05-09T19:58:26,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43873603
43871649,43871649,3,"The POJO and MOJO Model Javadoc (start here):




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




A list of examples of how to use models:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html




A specific self-contained example:




https://github.com/h2oai/app-consumer-loan




All H2O documentation:




http://docs.h2o.ai",2017-05-09T13:48:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43865336
43869121,43869121,0,"Try the following:


h2o_flow(sc, strict_version_check = TRUE)
, where sc is the spark context you created. 


You can also see the address of flow using 
h2o.clusterInfo()
.",2017-05-09T11:53:58,Jurgen De Jager,https://stackoverflow.com/users/4901542/jurgen-de-jager,55,43862280
43853732,43853732,3,"You need a supported JDBC (Build on JDBC 42 Core) driver to connect from H2O to SQL Server. You can download Microsoft JDBC Driver 4.2 for SQL Server from the link below first:


https://www.microsoft.com/en-us/download/details.aspx?id=54671


After that please follow the article below to first test JDBC driver from R/Python H2O client and then connect to your database:


https://aichamp.wordpress.com/2017/03/20/building-h2o-glm-model-using-postgresql-database-and-jdbc-driver/


Above article is for postgres however you can use it with SQL server using an appropriate driver.",2017-05-08T17:25:34,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43851748
45493131,45493131,1,"For Windows, remember to use 
;
 instead 
:
 for the 
-cp
 argument.


java -Xmx4g -cp sqljdbc42.jar;h2o.jar water.H2OApp -port 3333



water.H2OApp
 is the main class in 
h2o.jar
.


Important Note: SQL Server is not supported so far( August/2017). 
You may use MariaDB to load datasets:


From Windows console:


java -Xmx4G -cp mariadb-java-client-2.1.0.jar;h2o.jar water.H2OApp -port 3333


Note. For Linux, replace "";"" with "":""


From R:


sqlConn <- ""jdbc:mariadb://10.106.7.46:3306/DBName""
userName <- ""dbuser""
userPass <- ""dbpass.""
sql_Query <- ""SELECT * FROM dbname.tablename;""
mydata <- h2o.import_sql_select( sqlConn, sql_Query, userName, userPass )",2017-08-03T19:35:58,,,,43851748
43896748,43896748,1,"GBM models are supported in Steam. Are you using Steam on YARN or using Steam on a local machine?


I just tested this locally using H2O 3.10.4.6 and Steam version 1.1.6. I created GLM and GBM regression models using the same dataframe. I then created a project and selected that dataframe. My “Select Model Category” dropdown included only the Regression option because that dataframe was used only for the two regression models. Both the GLM and GBM models were then available in the Models to Import table.  


Can you verify that the dataframe you’re selecting is the one used to create that GBM model?",2017-05-10T15:23:54,Angela Bartz,https://stackoverflow.com/users/7992665/angela-bartz,11,43850650
43883405,43883405,0,"H2O does not support Reinforcement Learning at this time.  


You may want to check out something like 
OpenAI Gym
, 
Keras-RL
 (Deep Reinforcement Learning for Keras) or a 
Theano-based implementation of Deep Q-learning
.",2017-05-10T04:06:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43848376
43842351,43842351,0,"Without more information (such as the actual data), my guess would be the starting point gap you see is random noise.


To investigate this further I'd suggest first trying different random seeds. I like to do this using h2o.grid, making 
seed
 a hyper-parameter. Just 3 or 4 different values will give you a good feel for how much randomness affects the model.


The second thing I'd try is different train/valid splits. Again, explicitly give a seed to the split function, so that you can get repeatable results. If your data set is fairly small I'd expect this to be the bigger factor.


Putting these two ideas together: (rough code)


for split_seed in [1,1103,4387]:
  split data using seed
  h2o.grid(
    algorithm = ""gbm"",
    grid_id = ""ww"" + split_seed,
    hyper_params = list(
      seed = [77,800,2099]
      ),
    ...(with weights)...
    )
  h2o.grid(
    algorithm = ""gbm"",
    grid_id = ""wo"" + split_seed,
    hyper_params = list(
      seed = [77,800,2099]
      ),
    ...(without weights)...
    )



My guess is that if you overlay the 9 score history charts you get for with weights, and compare them to the 9 score history charts you get for without weights, you'll see a similar amount of blurriness on each.


If you always/never get that starting gap on all 9, depending on with/without weights, then something more interesting is going on, and I hope you can make available enough data and code so others can reproduce it.",2017-05-08T07:46:49,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43840178
43838605,43838605,1,"Yes, H2O guarantee the order. You can safely join input frame with prediction frame.",2017-05-08T01:48:23,Michal,https://stackoverflow.com/users/5089773/michal,437,43793479
43809412,43809412,2,"I think this is the only correct answer right now. There is no way to save the whole environment. I wrote a script to save (
save_all_models()
), load models (
load_models()
, and save frames (
save_all_frames()
) within Python. You can also saved models produced by a given grid search.


The jupiter demo: 
https://github.com/mmagnus/h2o_utils/blob/master/h2o_utils_demo.ipynb


The module: 
https://github.com/mmagnus/h2o_utils/blob/master/h2o_utils.py",2017-05-05T16:07:44,,,,43791092
43795912,43795912,0,"No, currently there is not a way to save all of the objects in the H2O cluster (which is what you're asking).  The H2O cluster contains data frames and models.  It doesn't really make sense to save the data frames since you already have a copy of the data (that you loaded into H2O).  However, you might want to save the models, and you can do that as follows:




Click 
getModels
 in the Flow Assist section, or click on the ""Models"" menu item and then ""List All Models""


A list of all of you models will pop up.  Click on the one that you want to save.


The model information will be expanded and then you will see an ""Export Model"" button.  Click on that to save the model to disk.




You will have to save the models individually.  This may change in the future, but right now, that's how you do it.",2017-05-05T03:13:21,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43791092
43816839,43816839,0,"Do a 
remove.packages(""h2o"")
 and remove all those 
h2o
 directories in your 
.libPaths()
 folder.  The symlink may work, but just to rule that out, I'd remove it.  


Then reinstall 
h2o
 3.10.2.1 using the same method above:


install.packages( ""h2o"", type=""source"", 
   repos=(c(""http://h2o-release.s3.amazonaws.com/h2o/rel-tutte/1/R"")))



If that doesn't work, then download 
h2o
 3.10.2.1 from S3 or 3.10.2.2 from CRAN:




https://s3.amazonaws.com/h2o-release/h2o/rel-tutte/1/R/src/contrib/h2o_3.10.2.1.tar.gz


https://cran.r-project.org/src/contrib/Archive/h2o/h2o_3.10.2.2.tar.gz




Install via:  
R CMD INSTALL h2o_3.10.2.1.tar.gz",2017-05-06T04:49:43,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43785970
43787106,43787106,5,"When you run 
h2o.init()
 (i.e. with no arguments) it will start a ""cluster"", on that same machine. By default it will be given about a quarter of your machine's memory, and can use either all threads or two threads (the latter is if using R and you installed it from CRAN). You will find Flow listening on 
http://127.0.0.1:54321/


If you already have an H2O cluster running on another machine (whether on your LAN or a distant cloud server), give the address to 
h2o.init()
 to have it connect to that instead of starting anything locally.


Run 
help(h2o.init)
 (on Python) or 
?h2o.init
 (on R) to see all the available options.


NOTE: H2O is a client/server architecture, but the server (also called the ""cluster"", even if you only have one machine) is where all the action takes place, and where the data and models are kept, and the client is relatively thin. Responding to one of the comments, if you are comparing H2O running localhost to a library like scikit-learn, there is not much difference (in available compute power). The advantage of H2O is that you can easily and transparently add more machines over a LAN, to increase available memory and (to some extent) compute power; and having clients in languages other than R. The disadvantages are mainly around having to remember the server is where your data is kept; e.g. with large data sets use the functions to load it directly into your server, because keeping a copy in the client is just wasting memory.",2017-05-04T15:27:53,,,,43785580
43795304,43795304,3,"The cause of this is incompatible versions of the H2O backend and client (in this case, the client is the 
h2o
 Python module).  The version of the H2O backend (the Java process running on your cluster) and the Python 
h2o
 module that you are using locally must be the same.


It seems like your server (at 
""http://IP:54321""
) is running an older version of H2O.  Since you already have an H2O cluster running that you're trying to connect to, probably the best solution is to install a different version of the 
h2o
 Python module (instead of the reverse).


If you don't know what version your server is running, then you could look at the logs, or you can try 
h2o.init(ip=IP)
 and it should return a proper ""version mismatch"" error which will tell you both versions.


To download a specific version of the 
h2o
 Python module, you can look in 
Changes.md
 for the release name (e.g. ""Turing"") and then go to the Download page URL.  For example, if I wanted to download 3.10.4.2, I'd search for ""3.10.4.2"" on the Changes.md linked above, see that the release name is ""Ueno"".  With that information, you can construct the URL for the download page for that version, e.g:


http://h2o-release.s3.amazonaws.com/h2o/rel-ueno/2/index.html



Or you can figure out the exact location of the 
.whl
 file as well: 


pip install http://h2o-release.s3.amazonaws.com/h2o/rel-ueno/2/Python/h2o-3.10.4.2-py2.py3-none-any.whl



Writing this response made me realize it's not trivial to find links to older releases, so I added a 
JIRA
 to fix that.",2017-05-05T01:57:24,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43774821
43766783,43766783,1,"An H2O version mismatch is caused when the H2O Java application and the 
h2o
  Python module (or R package) have different version numbers.  If you only use the 
h2o
 Python module, this will not happen.  However, if you launch an H2O cluster from the command line, 
java -jar h2o.jar
, and then connect to it via the 
h2o
 Python module, the version numbers can be in disagreement.


If this happens, the best way to resolve is to kill the existing Java process and start the H2O cluster from inside the 
h2o
 Python module.  Alternatively, you can 
pip uninstall h2o
, visit the 
H2O Downloads page
 and install the matching version of the Python package.",2017-05-03T17:44:40,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43762037
43764060,43764060,0,"This has been resolved. It was a path mixup which I have fixed and now can see the same h2o.
version
 from the cmd and jupyter.",2017-05-03T15:17:35,expectedGains,https://stackoverflow.com/users/7957756/expectedgains,13,43762037
50629102,50629102,0,"Here is another solution: Best way is to match both the versions.
Try to be on the latest. Few things are tricky while matching the versions. When you are upgrading the one that has lower version, make sure you do 
h2o.shutdown()
 to shut the h2o else, the uninstall or install won't happen successfully. 
And then go to 
h2o-ai
 and follow the steps",2018-05-31T16:43:39,Sincole Brans,https://stackoverflow.com/users/1732587/sincole-brans,304,43762037
45053314,45053314,1,"For those who are interested, I found the reason of this error. It is actually really simple.


Using 
makeCluster(12)
 I request 12 threads on my CPU.


Later on in the 
foreach
 call, I make a 
h2o.init
 call in which I request yet another thread. 


Since my machine only has 12 threads, this last call for an additional (12+1) thread can't be correctly processed.


I fixed this by assigning 6 threads to the cluster. This leaves me 6 threads to make six individual calls to 
h2o.init
 (one in each 
foreach
 call). 


This works great.",2017-07-12T09:10:06,wake_wake,https://stackoverflow.com/users/3587303/wake-wake,"1,214",43746769
43743453,43743453,3,"The correct code for this is simply


library(mlr)
h2o.learner = makeLearner(""regr.h2o.deeplearning"")",2017-05-02T16:59:40,Lars Kotthoff,https://stackoverflow.com/users/1172002/lars-kotthoff,109k,43733918
43741077,43741077,2,"The 
makeLearner()
 is not part of H2O. It appears to be part of the 
mlr package
. It also seems that mlr does have h2o support, so it might be as simple as adding a 
library(mlr)
 to the top of your script?  (Making sure that the mlr package has been installed, already, of course.)",2017-05-02T14:54:56,,,,43733918
43750349,43750349,0,"H2O Stacked Ensemble does 
not yet support
 multinomial classification -- only regression and binary classification. This is noted in the 
Stacked Ensemble documentation
.  That's why it's failing.",2017-05-03T03:00:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43720117
43700476,43700476,13,"The binomial classification models in h2o return a probability (
p
) of the prediction being a ""1"" (and they also, redundantly will tell you the probability of it being a ""0"", i.e. 
1-p
).


To use this model you have to decide the 
cutoff
. E.g. you could split it down the middle, if 
p > 0.5
 for ""1"", then it is ""1"", otherwise it is a ""0"". But you could choose other values, and what you are seeing in this report is the model quality at different cutoffs: that is what you are seeing in the ""threshold"" column. The extreme values (remember, based on the 
test
 data you have given it) are these two:


5                max precision  0.941437 1.000000   0
6                   max recall  0.002550 1.000000 397



I.e. if you specify the cutoff as 0.94, it has perfect precision, and if you specify the cutoff as 0.00255 it has perfect recall.


The default confusion matrix it shows is using this line:


3                 max f0point5  0.173215 0.330006 131



(The answer to 
this question
 looks to explain that metric in more detail.)


Personally, I find max accuracy the most intuitive:


4                 max accuracy  0.288168 0.839957  64



I.e. maximum accuracy means the threshold which has the lowest error.


Whichever of these metrics you decide is most suitable, you are still left with having to decide a threshold, for your real-world unseen data. One approach is to use the threshold from the table, based on your test data (so if I think max accuracy is most important, I would use a threshold of 0.288 in my live application.) But I've found that averaging the threshold from the test data and from the train data to give more solid results.


P.S. After resisting for a while, I've come around to being a fan of 
logloss
. I've found models tuned for best logloss (rather than tuning for best recall, best precision, best accuracy, lowest MSE, etc, etc.) tended to be more robust when turned into real-world applications.",2017-04-29T21:05:20,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43699454
44049203,44049203,2,"I like to read it differently. You already have the Confusion Matrix, for some problems you can (of-course!) straightaway calculate accuracy as (True Positives+True Negatives)/Total cases but for rest there is a tendency to go for Balanced Accuracy (depends on the number of predictors your have to counter multi-collinearity and remove biased from different sample size of response cases).


Balanced Accuracy = ((TP/P)+(TN/N))/2
TP True Positive
TN True Negative
P Actual Positive
N Actual Negatives


This gives a true picture wrt to your Specificity and Sensitivity cases as well",2017-05-18T13:31:32,wackyanil,https://stackoverflow.com/users/3256019/wackyanil,21,43699454
43693485,43693485,5,"Use the function 
h2o.confusionMatrix()
 to get the confusion matrix. The easy way is to give it the model, and the data you want analyzed:


h2o.confusionMatrix(model, test)



If you look at 
?h2o.confusionMatrix
 you see it can also accept an 
H2OModelMetrics
 object. You get one of those by calling 
h2o.performance()
:


p = h2o.performance(model, test)
h2o.confusionMatrix(p)



I recommend the second way, as the 
p
 object contains other useful information about how good your model is.


Note: either way you didn't use your predictions. Basically:




h2o.performance
 if you want to analyze the quality of the model.


h2o.predict
 if you want to get the actual predictions.",2017-04-29T08:31:13,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,43692058
43674594,43674594,1,"No, offsets for multinomial GBM is currently not supported, mostly because of the API implications (offset_column would change semantics everywhere in the code), but it wouldn't be hard to implement otherwise.


The only option right now is to use the offset columns as additional predictors.",2017-04-28T07:35:45,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43672318
43688522,43688522,2,"The short answer is this isn't what H2O was designed to do.
So unfortunately the answer today is no.




The longer answer...  (Assuming that the intent of the question is regarding model training in H2O-3.x...)


I can think of at least two ways one might 
want
 to use H2O in this way:  one-pass streaming, and swapping.


Think of one-pass streaming as having a continuous data stream feeding in, and the data constantly being acted on and then thrown away (or passed along).


Think of swapping as the computer science equivalent of swapping, where there is fast storage (memory) and slow storage (disk) and the algorithms are continuously sweeping over the data and faulting (swapping) data from disk to memory.


Swapping just gets worse and worse from a performance perspective the bigger the data gets.  H2O isn't ever tested this way, and you are on your own.  Maybe you can figure out how to enable an unsupported swapping mode from clues/hints in the other referenced stackoverflow question (or the source code), but nobody ever runs that way, and you're on your own.  H2O was architected to be fast for machine learning by holding data in memory.  Machine learning algorithms iteratively sweep over the data again and again.  If every data touch is hitting the disk, it's just not the experience the in-memory H2O-3 platform was designed to provide.


The streaming use case, especially for some algorithms like Deep Learning and DRF, definitely makes more sense for H2O.  H2O algorithms support checkpoints, and you can imagine a scenario where you read some data, train a model, then purge that data and read in new data, and continue training from the checkpoint.  In the deep learning case, you'd be updating the neural network weights with the new data.  In the DRF case, you'd be adding new trees based on the new data.",2017-04-28T20:36:29,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43668371
43668955,43668955,0,"The easy answer is that you probably don't have enough R memory to perform this action, so one solution is to increase the amount of memory in R (if that's an option for you).  It could also mean that you don't have enough memory in your H2O cluster, so you could increase that as well.


The only way to go directly from R memory to the H2O cluster is the 
as.h2o()
 function, so you are definitely using the right command. Under the hood, the 
as.h2o()
 function writes the frame from R memory to disk (stored in a temp file) and then reads it directly into the H2O cluster using H2O's native parallel read functionality.  


We recently added the ability to use 
data.table
's read/write functionality any place that we use base R, so since you have 
data.table
 installed, you should probably be able to get around this bottleneck by adding this to the top of your script: 
options(""h2o.use.data.table""=TRUE)
.  This will force the use of 
data.table
 instead of base R to write to disk for the first half of the 
as.h2o()
 conversion process.  This should work for you since it's doing the exact same thing that your code is doing already where you use 
fwrite
 to write to disk and 
h2o.importFile()
 to read it back in.


Also you don't need the last line with 
h2o.parseRaw()
:


tmp <- as.h2o(mat.agg.dt)
h2o.orig.1 <- h2o.parseRaw(tmp, parse_type=""SVMLight"")



You can just do:


h2o.orig.1 <- as.h2o(mat.agg.dt)



There is a related post that shows how to use 
data.table
 to solve the reverse problem (using 
as.data.frame()
 instead of 
as.h2o()
) 
here
.",2017-04-27T22:32:43,,,,43665020
43666791,43666791,2,"right now Sparkling Water/RSparkling does not support dynamic Spark cluster. SO you just need to disable it:



 config = list(""spark.dynamicAllocation.enabled"" = ""false"")",2017-04-27T19:52:08,Michal,https://stackoverflow.com/users/5089773/michal,437,43662373
60081703,60081703,-1,"For Python users:


conf = H2OConf(spark).set('spark.dynamicAllocation.enabled', False)   # Default of True causes this error:  IllegalArgumentException: 'Unsupported argument: (spark.dynamicAllocation.enabled,true)'
hc = H2OContext.getOrCreate(spark, conf)",2020-02-05T18:08:51,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,43662373
43666546,43666546,1,"Try running


 killall -9 java



before you call the ./gradlew build -x test, there might be some other H2O running already.",2017-04-27T19:37:23,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43652714
43659185,43659185,0,"H2O tries to figure out a suitable network interface to bind to, but some network setups are tricky and it sometimes needs you to specify what you want on the command line.


If you are running H2O standalone (java -jar h2o.jar ...), you can specify the 
-ip a.b.c.d
 command-line option to tell H2O exactly which interface to bind to.


If you are running H2O on Hadoop (hadoop jar h2odriver.jar ...), you can specify the 
-network a.b.c.d/e
 command-line option to specify a range of interface addresses to bind to.  This is because the individual hosts the mapper containers get placed on varies (they are chosen by the YARN resource manager), so you need to provide an appropriate mask that will match for all the possible nodes.


For example, if ifconfig says that your gateway node has ip address 10.2.3.4, then


hadoop jar h2odriver.jar -network 10.2.3.0/24 ...



or 


hadoop jar h2odriver.jar -network 10.2.0.0/16 ...



might be good choices.",2017-04-27T13:23:48,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43640828
43667021,43667021,0,"Solved: 
rrc3.reset_index(inplace=True)
 will do the job!",2017-04-27T20:05:28,Marcin Magnus,https://stackoverflow.com/users/1259266/marcin-magnus,282,43631804
43593039,43593039,1,"The [domains] have a 0-based index for the column they belong to. In the example below, ""7:"" refers to the CAPSULE column: it has a 2-factor domain listed in the d000.txt file.


[columns]
AGE
RACE
DPROS
DCAPS
PSA
VOL
GLEASON
CAPSULE

[domains]
7: 2 d000.txt",2017-04-24T16:12:25,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43592291
43593206,43593206,0,"Interpreting the matrix given by:


CM: Confusion Matrix (vertical: actual; across: predicted):
       0    1   Error       Rate
    0  0  500  1,0000  500 / 500
    1  0  300  0,0000    0 / 300
Totals 0  800  0,6250  500 / 800



We can see that all 800 observations were labelled 
1
, given by the numbers in the 
Totals
 row.


The model being tested predicted 
0
 500 times, and 
1
 300 times given by the rows. That gives you an overall error of 
0.625
 or 62.5%.


This tells us two things:




The data in that dataset were completely unbalanced in favour of class 
1
.


The model did a pretty bad job




Is it possible that the two initial matrices represent the summary of an untrained model, essentially picking classes at random? And the latter two matrices represent the summary of the trained model?",2017-04-24T16:20:41,ImDarrenG,https://stackoverflow.com/users/4697497/imdarreng,"2,345",43591430
43598078,43598078,9,"This is not specific to variable importance, this is just how H2O displays H2O Frames in the R console.  If you want to view the whole frame, you could convert it to an R data.frame and then print it. 


df <- as.data.frame(h2o.varimp(model))
print(df)",2017-04-24T21:33:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43578485
43582163,43582163,0,"(summary) will show all stats with extraction from h2o.varimp. Then save the table of variable importance


mymodel <- summary(model)

write.table(mymodel, file = ""mymodel.txt"", sep = ""\t"", quote = FALSE, row.names = TRUE)",2017-04-24T07:28:19,tylers,https://stackoverflow.com/users/7899037/tylers,1,43578485
43563619,43563619,2,"Once you train a model in H2O, if you simply do: 
print(fit)
 it will show you all the available metrics for that model type.  For multiclass, I'd recommend 
h2o.mean_per_class_error()
.


R code example on the iris dataset:


library(h2o)
h2o.init(nthreads = -1)

data(iris)
fit <- h2o.naiveBayes(x = 1:4, 
                      y = 5, 
                      training_frame = as.h2o(iris), 
                      nfolds = 5)



Once you have the model, we can evaluate model performance using the 
h2o.performance()
 function to view all the metrics:


> h2o.performance(fit, xval = TRUE)
H2OMultinomialMetrics: naivebayes
** Reported on cross-validation data. **
** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **

Cross-Validation Set Metrics: 
=====================

Extract cross-validation frame with `h2o.getFrame(""iris"")`
MSE: (Extract with `h2o.mse`) 0.03582724
RMSE: (Extract with `h2o.rmse`) 0.1892808
Logloss: (Extract with `h2o.logloss`) 0.1321609
Mean Per-Class Error: 0.04666667
Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>,xval = TRUE)`
=======================================================================
Top-3 Hit Ratios: 
  k hit_ratio
1 1  0.953333
2 2  1.000000
3 3  1.000000



Or you can look at a particular metric, like 
mean_per_class_error
:


> h2o.mean_per_class_error(fit, xval = TRUE)
[1] 0.04666667



If you want to view performance on a test set, then you can do the following:


perf <- h2o.performance(fit, test)
h2o.mean_per_class_error(perf)",2017-04-22T19:21:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43556802
43562261,43562261,0,"To load data into Scala as H2O Frame you can do the following:


import org.apache.spark.h2o._
import water.support.SparkContextSupport.addFiles
import org.apache.spark.SparkFiles
import java.io.File

val hc = H2OContext.getOrCreate(sc)

addFiles(sc, ""/Users/avkashchauhan/smalldata/iris/iris.csv"")
val irisData = new H2OFrame(new File(SparkFiles.get(""iris.csv"")))



Once data is loaded you can see the data frame as below:


scala> irisData
res1: water.fvec.H2OFrame =
   Frame key: iris.hex
   cols: 5
   rows: 150
 chunks: 1
   size: 2454



Once you have ingested the data frame you can build model with it. If you are looking for a sample of using H2O library in Scala you can look for this blog for 
full end to end Scala based deep learning sample in H2O
.",2017-04-22T17:22:45,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43556784
44503483,44503483,0,"this is a known behaviour of Sparkling Water internal backend at the moment. To avoid this, the external Sparkling Water backend can be used. More information about this can be found here 
https://github.com/h2oai/sparkling-water/blob/master/doc/backends.md


I'm currently working on this JIRA which should eliminate the behaviour above as well. It's work in progress, this JIRA 
https://0xdata.atlassian.net/browse/SW-369
 can be tracked to get the status of the task.",2017-06-12T15:40:47,,,,43549276
43550679,43550679,13,"You can get the documentation for H2O's Python API (specifically for H2OFrame methods) here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html


If you want to get the types of a dataframe in H2O Python do 
.types


frame = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris.csv"")
frame.types
{u'C3': u'real', u'C2': u'real', u'C1': u'real', u'C5': u'enum', u'C4': u'real'}",2017-04-21T19:36:45,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",43548878
43545980,43545980,-1,"The answer to your first question is as below:


You sure can get to run deep water without GPU, it will be very slow. When you are using FLOW you could disable gpu setting as below (which is TRUE by default)




Also you can set gpu as false in the FLOW cell as below:


""gpu"":false 


However your main problem is that none of the backend (mxnet, tensorflow, caffe) was available to run your code. We did test gpu flag settings with mxnet for sure. Please try to investigate more about the error above.",2017-04-21T15:00:16,,,,43545511
43540398,43540398,1,"The manual 
Deep Learning with H2O
 should be helpful. Autoencoders are explained starting from page 43 with an implementation in bot 
R
 and 
Python
. For Stacking in H2O refer to 
this
 documentation.",2017-04-21T10:31:15,Kevin Katzke,https://stackoverflow.com/users/1280289/kevin-katzke,"3,721",43540038
43555881,43555881,0,"There is an 
example
 of how to create a stacked autoencoder using the 
h2o
 R package and the 
h2o.deeplearning()
 function.


The 
H2O Deep Learning in R Tutorial
 that provides more background on Deep Learning in H2O, including how to use an autoencoder for unsupervised pretraining.  


There are more H2O code tutorials in the 
h2oai/h2o-tutorials
 GitHub repo, or you can often find code examples in the 
tests
 directories of the H2O codebase (I found the stacked autoencoder example by searching for ""stacked autoencoder"" in the 
h2oai/h2o-3
 repository on GitHub, for example).",2017-04-22T06:09:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43540038
43526712,43526712,3,"Make sure that 
class(QCAnalysis_sub_h2o)
 is ""H2OFrame"" and that your 
indep
 vector doesn't contain any columns that are strings.  Also, note that when converting an R data.frame to an H2O Frame using 
as.h2o()
, it preserves the column types, so it won't automatically convert any string columns into factors.  You will need to do that automatically using the 
as.factor()
 function on each column (e.g. 
df[,""mycol""] <- as.factor(df[,""mycol""]
).  You can do this on your R data.frame before you copy over to H2O, or you can fix the columns once they are in the H2O Frame.  


If you read in a CSV file from disk directly into H2O using the 
h2o.importFile()
 command, it will turn any column containing strings into factors by default, so I assume that you probably copied this frame over from R.",2017-04-20T18:01:22,,,,43515721
43533420,43533420,0,"Some sample codes: 


QCAnalysis_sub_h2o <- h2o.importFile(path = normalizePath(""QCAnalysis_sub_h2o.csv""),header=T)



(if not, specify the dataframe with as.data.frame )


x and y should state the columns you want h2o.randomforest to read",2017-04-21T03:23:39,tylers,https://stackoverflow.com/users/7899037/tylers,1,43515721
43539913,43539913,2,"So, I looked at the 
h2o
 source code on github and it does not seem as if there is a 
timeout
 argument (neither in 
R
 nor in the underlying 
java
 code). There is a 
java
 argument called 
session_timeout
 but I don't think this applies to my problem.


So what I did is this:


foreach(i=seq_along(workers),.inorder=FALSE,.multicombine=TRUE) %dopar% {
  library(h2o)
  startCounter=1
  startCounterMax=3
  while(inherits(clusterStatus<-try({
      h2o.init(nthreads=-1)
      capture.output(h2o.clusterStatus())
    },silent=TRUE),""try-error"")&(startCounter<=startCounterMax)) {
    startCounter=startCounter+1
  }
  if (startCounter>startCounterMax) stop(""Failed to start h2o server for "",
                                         startCounterMax,"" successive times"")

  return(clusterStatus)
}



Not very nice but it does the job.",2017-04-21T10:10:29,cryo111,https://stackoverflow.com/users/983028/cryo111,"4,474",43515062
43546870,43546870,0,"If you are trying to form a cluster of several H2O nodes (say cluster of 3 h2o nodes with one node per machine) and you want to wait for a specified time then you can try it in Java code - 
water.H2O.waitForCloudSize(3, 50 * 1000/*ms*/);

I assume there should be the corresponding parameter available in R as well.",2017-04-21T15:43:08,Gaurav Gupta,https://stackoverflow.com/users/5746807/gaurav-gupta,104,43515062
43507562,43507562,2,"Convert your response column from 
int
 to 
enum
 and then it should be recognized as a binary column for classification. If you have a binary column with type 
int
, the algorithms will assume you're doing a regression problem.


To convert your response column to enum, select enum from the drop down menu during the parse step. (In the below example you could switch 
ArrDelay
 to 
enum
 instead of 
Numeric
 for example)



There is functionality in flow so that if the response column is a binary categorical column then the 
balance_classes
 parameter will appear, but if the response column is real/int the 
balance_classes
 button will disappear.",2017-04-19T23:11:30,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",43506620
49124999,49124999,0,"This issue is being investigated at following issues of the Sparkling Water project:




https://github.com/h2oai/sparkling-water/issues/597


https://github.com/h2oai/sparkling-water/issues/182




It seems somehow related to the size of the data. 


This happens when we try to pull a huge spark dataframe to h2o frame.
63m records x 6300 columns.
Although H2O/ Sparkling Water cluster sized properly: (there are 40 executors x 17g of memory each, and each Spark executor has 4 threads/ cores)
So total amount of memory is 680Gb


We never get this error on smaller datasets.",2018-03-06T06:56:23,Tagar,https://stackoverflow.com/users/470583/tagar,14.8k,43502724
44724813,44724813,3,"The fix that worked for me was to set 
both
 the min and max memory sizes when initializing H2O.  For example:


This fails when not specifying either min or max memory size:


localH2O <- h2o.init(ip='localhost', nthreads=-1)

INFO: Java heap totalMemory: 1.92 GB
INFO: Java heap maxMemory: 26.67 GB
INFO: Java version: Java 1.8.0_121 (from Oracle Corporation)
INFO: JVM launch parameters: [-ea]
INFO: OS version: Linux 3.10.0-327.el7.x86_64 (amd64)
INFO: Machine physical memory: 1.476 TB



This fails when specifying only max memory size:


localH2O <- h2o.init(ip='localhost', nthreads=-1,
                     max_mem_size='200G')

INFO: Java availableProcessors: 64
INFO: Java heap totalMemory: 1.92 GB
INFO: Java heap maxMemory: 177.78 GB
INFO: Java version: Java 1.8.0_121 (from Oracle Corporation)
INFO: JVM launch parameters: [-Xmx200G, -ea]
INFO: OS version: Linux 3.10.0-327.el7.x86_64 (amd64)
INFO: Machine physical memory: 1.476 TB



This is successful when specifying 
both
 min and max memory sizes:


localH2O <- h2o.init(ip='localhost', nthreads=-1,
                     min_mem_size='100G', max_mem_size='200G')

INFO: Java availableProcessors: 64
INFO: Java heap totalMemory: 95.83 GB
INFO: Java heap maxMemory: 177.78 GB
INFO: Java version: Java 1.8.0_121 (from Oracle Corporation)
INFO: JVM launch parameters: [-Xms100G, -Xmx200G, -ea]
INFO: OS version: Linux 3.10.0-327.el7.x86_64 (amd64)
INFO: Machine physical memory: 1.476 TB",2017-06-23T15:14:10,BA88,https://stackoverflow.com/users/7733787/ba88,79,43485939
43560940,43560940,2,"The 3.32 GB number in your post is a calculated number based on activity in the H2O job.  So it's hard to validate it directly without knowing what happened in your job.  40 GB per node is quite different from 3.32 GB though, so do the following to sanity check the job...


After your H2O Hadoop job completes, you can take a look at the YARN logs to confirm the container is really getting the amount of memory you expect.


Use the following command (which is printed for you by the h2odriver output after the run completes):


yarn logs -applicationId application_nnn_nnn



For me, the (lightly pruned) output for one of the H2O node containers looks like this:


Container: container_e20_1487032509333_2085_01_000004 on mr-0xd4.0xdata.loc_45454
===================================================================================
LogType:stderr
Log Upload Time:Sat Apr 22 07:58:13 -0700 2017
...

LogType:stdout
Log Upload Time:Sat Apr 22 07:58:13 -0700 2017
LogLength:7517
Log Contents:
POST 0: Entered run
POST 11: After setEmbeddedH2OConfig
04-22 07:57:56.979 172.16.2.184:54323    11976  main      INFO: ----- H2O started  -----
04-22 07:57:57.011 172.16.2.184:54323    11976  main      INFO: Build git branch: rel-turing
04-22 07:57:57.011 172.16.2.184:54323    11976  main      INFO: Build git hash: 34b83da423d26dfbcc0b35c72714b31e80101d49
04-22 07:57:57.011 172.16.2.184:54323    11976  main      INFO: Build git describe: jenkins-rel-turing-8
04-22 07:57:57.011 172.16.2.184:54323    11976  main      INFO: Build project version: 3.10.0.8 (latest version: 3.10.4.5)
04-22 07:57:57.011 172.16.2.184:54323    11976  main      INFO: Build age: 6 months and 11 days
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Built by: 'jenkins'
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Built on: '2016-10-10 13:45:37'
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Java availableProcessors: 32
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Java heap totalMemory: 9.86 GB
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Java heap maxMemory: 9.86 GB
04-22 07:57:57.012 172.16.2.184:54323    11976  main      INFO: Java version: Java 1.7.0_67 (from Oracle Corporation)



Note that the application master container log output looks different, so just find the output for any one of the H2O node containers.


Look for the line ""Java heap maxMemory"".  In my case, I requested '-mapperXmx 10g' on the command line, so this looks good.  9.86 GB is close to '10g' given a little JVM overhead.


If it's not as you expect, you have a Hadoop configuration problem: some Hadoop setting is overriding the amount of memory you are requesting on the command line.",2017-04-22T15:22:35,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43485939
43466852,43466852,0,"If you mean ""data leakage"", that term is commonly associated with the process of accidentally including a predictor column that is correlated (in a ""bad""/cheating way) with the response column.  Splitting a data frame by rows would never cause spurious data leakage.


If your manually created train, valid and test frames create poor results, that might be due to the fact that your rows are not randomized and your model has overfit to the training set.  Since 
h2o::h2o.splitFrame()
 and 
caret::createDataPartition()
 use randomization in the splitting process, it will produce evenly distributed train, valid and test sets and producing a better model.  However, if your manual datasets were also randomly created, then what you're saying doesn't make a lot of sense to me.


Hopefully you are using 
h2o.performance(model, test)
 to determine the test set accuracy (although I don't see that in your script).  By default, H2O's Deep Learning will use the 
validation_frame
 for early stopping, so the validation metrics are not a honest estimate of the generalization error.  Hence the need for a test set.",2017-04-18T08:06:25,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43463178
43444826,43444826,18,"The way your code is currently set up won't be the best option.  I understand what you are trying to do -- execute a bunch of GBMs in parallel (each on a single core H2O cluster), so you can maximize the CPU usage across the 12 cores on your machine. However, what your code will do is try to run all the GBMs in your 
foreach
 loop in parallel on the same single-core H2O cluster.  You can only connect to one H2O cluster at a time from a single R instance, however the foreach loop will create a new R instance. 


Unlike most machine learning algos in R, the H2O algos are all multi-core enabled so the training process will already be parallelized at the algorithm level, without the need for a parallel R package like 
foreach
.


You have a few options (#1 or #3 is probably best):




Set 
h2o.init(nthreads = -1)
 at the top of your script to use all 12 of your cores.  Change the 
foreach()
 loop to a regular loop and train each GBM (on a different data partition) sequentially.  Although the different GBMs are trained sequentially, each single GBM will be fully parallelized across the H2O cluster.  


Set 
h2o.init(nthreads = -1)
 at the top of your script, but keep your 
foreach()
 loop.  This should run all your GBMs at once, with each GBM parallelized across all cores.  This could overwhelm the H2O cluster a bit (this is not really how H2O is meant to be used) and could be a bit slower than #1, but it's hard to say without knowing the size of your data and the number of partitions of you want to train on.  If you are already using 70% of your RAM for a single GBM, then this might not be the best option.  


You can update your code to do the following (which most closely resembles your original script). This will preserve your 
foreach
 loop, creating a new 1-core H2O cluster at a different port on your machine. See below.




Updated R code example which uses the iris dataset and returns the predicted class for iris as a data.frame:


library(foreach)
library(doParallel)
library(h2o)
h2o.shutdown(prompt = FALSE)

#setup parallel backend to use 12 processors
cl <- makeCluster(12)
registerDoParallel(cl)

#loop
df4 <- foreach(i = seq(20), .combine=rbind) %dopar% {
  library(h2o)
  port <- 54321 + 3*i
  print(paste0(""http://localhost:"", port))
  h2o.init(nthreads = 1, max_mem_size = ""1G"", port = port)
  df4 <- data.frame()
  data(iris)
  data <- as.h2o(iris)
  ss <- h2o.splitFrame(data)
  gbm <- h2o.gbm(x = 1:4, y = ""Species"", training_frame = ss[[1]])
  df4 <- as.data.frame(h2o.predict(gbm, ss[[2]]))[,1]
}



In order to judge which option is best, I would try running this on a few data partitions (maybe 10-100) to see which approach seems to scale the best.  If your training data is small, it's possible that #3 will be faster than #1, but overall, I'd say #1 is probably the most scalable/stable solution.",2017-04-17T03:43:23,,,,43444333
52188186,52188186,2,"Following Erin LeDell's answer, I just wanted to add that in many cases a decent practical solution can be something in between #1 and #3. To increase CPU utilization  and still save RAM you can use multiple H2O instances in parallel, but they each can use multiple cores without much performance loss relative to running more instances with only one core.


I ran an experiment using a relatively small 40MB dataset (240K rows, 22 columns) on a 36 core server.




Case 1: Use all 36 cores (nthreads=36) to estimate 120 GBM models (with default
hyper-parameters) sequentially.


Case 2: Use foreach to run 4 H2O instances on this machine, each
using 9 cores to estimate 30 GBM default models sequentially (total = 120 estimations).


Case 3: Use foreach to run 12 H2O instances on this machine, each
using 3 cores to estimate 10 GBM default models sequentially (total = 120 estimations).




Using 36 cores estimating  a single GBM model on this dataset is very inefficient. CPU utilization in Case 1 is jumping around a lot, but is on average below 50%. So there is definitely something to gain using more than one H2O instance at a time.




Runtime Case 1: 264 seconds


Runtime Case 2: 132 seconds


Runtime Case 3: 130 seconds




Given the small improvement from 4 to 12 H2O instances, I did not even run 36 H2O instances each using one core in parallel.",2018-09-05T14:56:32,Max Stroh,https://stackoverflow.com/users/10320567/max-stroh,21,43444333
43776063,43776063,0,"This can be solved by running the program with the following command, this has been tested with 
spark 1.6
 and 
H2O
 
version > 3.0


bin/pysparkling h2o_spark.py --conf spark.ext.h2o.fail.on.unsupported.spark.param=false",2017-05-04T07:04:26,LoïcR,https://stackoverflow.com/users/5463904/lo%c3%afcr,"5,049",43440345
43415584,43415584,3,"Yes.
Add the -disown flag to do exactly that.",2017-04-14T16:34:51,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43415466
43405169,43405169,1,"You can see all quantile groups in the output (Flow has a nice display). The top group is the top 1%, and lift_top_group refers to that. It can be used for early stopping. All other information from the gains/lift chart is available in all binomial model metrics for inspection. More info here: 
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/GainsLift.md
 (note that the picture is outdated, it uses 5% intervals uniformly - now there are more fine grain groups at the top).",2017-04-14T04:22:18,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43404805
43381558,43381558,0,"If your question is about adding a new node to existing H2O cluster (on Hadoop or anywhere), the answer is no. You must list all the IP address first where you want to create H2O nodes and a cluster is formed. H2O does not support dynamic allocation of resources so you can not add a new node to existing H2O cluster.",2017-04-13T00:10:26,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43381075
43415760,43415760,2,"This is hopefully a nudge in the right direction, but definitely not a complete answer.


Looking at this documentation:


https://docs.oracle.com/cd/B28359_01/appdev.111/b28370/create_function.htm#LNPLS01370


It looks like the CREATE FUNCTION capability allows the creation of Java functions.


You could perhaps take an H2O-generated POJO (Plain Old Java Object), wrap it in a Java function, and call it as part of a select statement.


Here is a pointer to a tutorial for how to do this for Hive:


http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/hive_udf_template/index.html",2017-04-14T16:48:01,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43369270
43369383,43369383,-1,"That's not possible from within Oracle SQL - Oracle SQL databases can't execute R code natively. What you could do, is generate your predictions in R and then write them to a table in the Oracle SQL DB.",2017-04-12T12:21:17,WHoekstra,https://stackoverflow.com/users/7807513/whoekstra,173,43369270
43374674,43374674,2,"You can use h2o.no_progress() method which will disable all the progress details for most of the functions. Here is a sample script with h2o.no_progress() in action:


> dpath = ""https://raw.github.com/h2oai/h2o/master/smalldata/logreg/prostate.csv""
> df1 = h2o.importFile(dpath)  
  |============================================================| 100%
> h2o.no_progress()
> df1 = h2o.importFile(dpath)
> df1
  ID CAPSULE AGE RACE DPROS DCAPS  PSA  VOL GLEASON
1  1       0  65    1     2     1  1.4  0.0       6
2  2       0  72    1     3     2  6.7  0.0       7
3  3       0  70    1     1     2  4.9  0.0       6
4  4       0  76    2     2     1 51.2 20.0       7
5  5       0  69    1     1     1 12.3 55.9       6
6  6       1  71    1     3     2  3.3  0.0       8

[380 rows x 9 columns]",2017-04-12T16:13:14,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43364961
43361636,43361636,8,"You don't need to do anything to your data when using H2O - all algorithms handle numeric/categorical/string columns automatically. Some methods do internal standardization automatically, but the tree methods don't and don't need to (split at age > 5 and income < 100000 is fine). As to whether it's ""harmful"" depends on what you're doing, usually it's a good idea to let the algorithm do the standardization, unless you know exactly what you are doing. One example is clustering, where distances depend on the scaling (or lack thereof) of the data.",2017-04-12T06:13:22,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43359169
43330288,43330288,7,"There are a few arguments you need to set in order to get H2O's GLM to match R's GLM, since by default, they do not function the same way.  Here is an example of what you need to set to get identical results:


library(h2o)
h2o.init(nthreads = -1)

path <- system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
train <- h2o.importFile(path)

# Run GLM of VOL ~ CAPSULE + AGE + RACE + PSA + GLEASON
x <- setdiff(colnames(train), c(""ID"", ""DPROS"", ""DCAPS"", ""VOL""))

# Train H2O GLM (designed to match R)
h2o_glmfit <- h2o.glm(y = ""VOL"", 
                      x = x, 
                      training_frame = train, 
                      family = ""gaussian"",
                      lambda = 0,
                      remove_collinear_columns = TRUE,
                      compute_p_values = TRUE,
                      solver = ""IRLSM"")

# Train an R GLM
r_glmfit <- glm(VOL ~ CAPSULE + AGE + RACE + PSA + GLEASON, 
                data = as.data.frame(train)) 



Here are the coefs (they match):


> h2o.coef(h2o_glmfit)
  Intercept     CAPSULE         AGE 
-4.35605671 -4.29056573  0.29789896 
       RACE         PSA     GLEASON 
 4.35567076  0.04945783 -0.51260829 

> coef(r_glmfit)
(Intercept)     CAPSULE         AGE 
-4.35605671 -4.29056573  0.29789896 
       RACE         PSA     GLEASON 
 4.35567076  0.04945783 -0.51260829 



I've added a 
JIRA ticket
 to add this info to the docs.",2017-04-10T18:21:59,Tom Wenseleers,https://stackoverflow.com/users/1887645/tom-wenseleers,"7,959",43324287
43327110,43327110,2,"Is my hypothesis that glm ≈ h2o.glm wrong?




The algorithm of h2o.glm is different from R's glm.


h2o.glm is actually far more similar to the glmnet R package because they both support Elastic Net regularization (and two of the authors of glmnet, Hastie and Tibshirani, are advisors to H2O.ai).


When building H2O's glm, we used glmnet as a measuring stick far more so than R's glm.


Having said all that, you shouldn't expect the exact same coefficients for the result, but I would also not expect such a dramatically worse MSE.",2017-04-10T15:22:33,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43324287
62921522,62921522,0,"I want to expand on the first answer and suggest:


solver = ""IRLSM""
lambda = 0
remove_collinear_columns = TRUE
compute_p_values = TRUE
objective_epsilon = 1e-8
max_iterations = 25



glm()
 uses 
glm.control(epsilon = 1e-8, maxit = 25, trace = FALSE)
 for any logistic regression.",2020-07-15T18:29:26,theneil,https://stackoverflow.com/users/6710466/theneil,518,43324287
43331029,43331029,0,"H2O (and most machine learning packages) do not support more than one response variable.  In the case above, you have two response variables, 
y1
 and 
y2
.",2017-04-10T19:02:12,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43313681
43295444,43295444,3,"Within the repo, there is a complete H2o2 dev environment implemented in Docker
based on 16.04. In the same folder there is an Ubuntu 16.04 setup script.


http://github.com/h2oai/h2o-3/docker/setup-h2o-dev.sh",2017-04-08T14:43:15,Jeff,https://stackoverflow.com/users/7837486/jeff,46,43291544
43291787,43291787,1,"I had the same problem. To resolve it I
renamed my  
~/.Rprofile
 file (even if it is the default one)


I have two R versions on my machine, R 3.2.2 and R 3.3.3, this confused the build script. 


So to make things simpler for the build script
, I ran it with a modified PATH variable, successfully! 


(What's puzzling is it still used R 3.2.2  although in /usr/bin is R 3.3.3! However, the installation continued)


export PATH=/home/knut/.virtualenvs/h2oai/bin:/home/knut/.nvm/versions/node/v6.9.4/bin:/usr/sbin:/usr/bin:/sbin:/bin  && ./gradlew build -x test



I've excluded (-x test) the tests, because they fail while spinning up a multinode cluster on my machine (java runs out of memory)


Result:


    :buildSrc:compileJava UP-TO-DATE
    ... many many UP-to-DATEs ....
    :h2o-r:compileJava UP-TO-DATE
    :h2o-r:compileGroovy UP-TO-DATE
    :h2o-r:processResources UP-TO-DATE
    :h2o-r:classes UP-TO-DATE
    :h2o-r:jar UP-TO-DATE
    :h2o-r:assemble UP-TO-DATE
    :h2o-r:getRVersion
    :h2o-r:gitbranch
    :h2o-r:pdflatex
    :h2o-r:setProperties
        Git Branch: master
        R Version: 3.2.2
        PDF LATEX: /usr/bin/pdflatex
    :h2o-r:cpH2OAppJar
    :h2o-r:setDevPackageFiles
    :h2o-r:setPackageFiles
    :h2o-r:buildPackageDocumentation     ####### here it exited previously, now continues
    :h2o-r:buildPackageDocumentation took 3.828 secs
    :h2o-r:genPDF
    :h2o-r:genPDF took 4.432 secs
    :h2o-r:cpPDF
    :h2o-r:buildPKG

    :h2o-r:buildPKG took 3.454 secs
    :h2o-r:cpToR
    :h2o-r:publishPKG
    :h2o-r:untar
    :h2o-r:cleaner
    :h2o-r:build_rh2o
    :h2o-r:check
    :h2o-r:build
    :h2o-scala_2.10:compileJava UP-TO-DATE
    :h2o-scala_2.10:compileScala UP-TO-DATE
    :h2o-scala_2.10:processResources UP-TO-DATE
    :h2o-scala_2.10:classes UP-TO-DATE
    :h2o-scala_2.10:jar UP-TO-DATE
    :h2o-scala_2.10:assemble UP-TO-DATE
    :h2o-scala_2.10:check
    :h2o-scala_2.10:build
    :h2o-scala_2.11:compileJava UP-TO-DATE
    :h2o-scala_2.11:compileScala UP-TO-DATE
    :h2o-scala_2.11:processResources UP-TO-DATE
    :h2o-scala_2.11:classes UP-TO-DATE
    :h2o-scala_2.11:jar UP-TO-DATE
    :h2o-scala_2.11:assemble UP-TO-DATE
    :h2o-scala_2.11:check
    :h2o-scala_2.11:build
    :h2o-test-accuracy:compileJava UP-TO-DATE
    :h2o-test-accuracy:processResources UP-TO-DATE
    :h2o-test-accuracy:classes UP-TO-DATE
    :h2o-test-accuracy:jar UP-TO-DATE
    :h2o-test-accuracy:assemble UP-TO-DATE
    :h2o-test-accuracy:check
    :h2o-test-accuracy:build
    :h2o-test-integ:compileJava UP-TO-DATE
    :h2o-test-integ:processResources UP-TO-DATE
    :h2o-test-integ:classes UP-TO-DATE
    :h2o-test-integ:jar UP-TO-DATE
    :h2o-test-integ:assemble UP-TO-DATE
    :h2o-test-integ:check
    :h2o-test-integ:build
    :h2o-web:assemble UP-TO-DATE
    :h2o-web:check
    :h2o-web:compileAndInstallDocFiles
    :h2o-web:build
    :h2o-assemblies:main:assemble
    :h2o-assemblies:main:check
    :h2o-assemblies:main:build
    :h2o-hadoop:h2o-mapreduce-generic:compileJava UP-TO-DATE
    :h2o-hadoop:h2o-mapreduce-generic:processResources UP-TO-DATE
    :h2o-hadoop:h2o-mapreduce-generic:classes UP-TO-DATE
    :h2o-hadoop:h2o-mapreduce-generic:jar UP-TO-DATE
    :h2o-hadoop:h2o-mapreduce-generic:assemble UP-TO-DATE
    :h2o-hadoop:h2o-mapreduce-generic:check
    :h2o-hadoop:h2o-mapreduce-generic:build
    :h2o-hadoop:h2o-yarn-generic:compileJava UP-TO-DATE
    :h2o-hadoop:h2o-yarn-generic:processResources UP-TO-DATE
    :h2o-hadoop:h2o-yarn-generic:classes UP-TO-DATE
    :h2o-hadoop:h2o-yarn-generic:jar UP-TO-DATE
    :h2o-hadoop:h2o-yarn-generic:assemble UP-TO-DATE
    :h2o-hadoop:h2o-yarn-generic:check
    :h2o-hadoop:h2o-yarn-generic:build

    BUILD SUCCESSFUL

    Total time: 31.37 secs

    Task timings:
       9.241 secs  :h2o-assemblies:main:shadowJar
       4.432 secs  :h2o-r:genPDF
       3.828 secs  :h2o-r:buildPackageDocumentation
       3.598 secs  :h2o-bindings:runGenerateRESTAPIBindingsSrc
       3.454 secs  :h2o-r:buildPKG
       2.083 secs  :h2o-py:buildDist
       0.922 secs  :h2o-web:installNpmPackages
       3.073 secs  All others



Then I installed it with 
R CMD INSTALL h2o-r/R/src/contrib/h2o_3.11.0.99999.tar.gz
 into R 3.3


If this still does not succeed, run


./gradlew build -x test --info


and update your question with the relevant output",2017-04-08T08:18:42,,,,43291544
44771222,44771222,1,"You need to sync R packags:


git clone https://github.com/h2oai/h2o-3.git
cd h2o-3
./gradlew syncSmalldata
./gradlew syncRPackages
./gradlew build



Reference:

https://github.com/h2oai/h2o-3",2017-06-27T01:56:15,CodeFarmer,https://stackoverflow.com/users/479008/codefarmer,"2,712",43291544
43379802,43379802,0,"I download the glove.6B.100d.txt test and did a quick try with latest H2O 3.10.4.3 in R and did see the same warning however the data was ingested correctly. 


I could still use the data frame which had 399,999 rows and 101 columns properly so I can confirm that the data ingest was correct and the warning did not cause any problem in data ingest. 


I have opened the following JIRA to fix the warning issue:


https://0xdata.atlassian.net/browse/PUBDEV-4284",2017-04-12T21:17:56,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43284577
43290852,43290852,1,"Since the autoencoder doesn't have any idea about ""clusters"", you would have to call h2o.kmeans() on the 2D dataset first, to get the cluster assignments. Then you can score the dataset using that k-means model, using h2o.predict(model, 2Ddata), and you'll get a cluster label for each row.",2017-04-08T06:16:05,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43267641
61102005,61102005,1,"Basically, AE can be a good DNN for reinstructing the input, however, you can use the latent layer for clustering. 


The important steps:


1- For initializing the cluster assignment you may apply simple k-means for your data and label them;


2- Train your AE to learn features;


3- Try to extract the output of the layer before the latent layer which includes the trained space of your data;


4- Cluster the data with a k-means.


I hope it helps,


Here is an example I have provided in Keras:


library(keras)
library(caret)
library(tidyverse)

c(c(xtrain, ytrain), c(xtest, ytest)) %<-% dataset_mnist()
xtrain = xtrain/255
xtest = xtest/255 

input_size = dim(xtrain)[2]*dim(xtrain)[3]
latent_size = 10
print(input_size) 

x_train = array_reshape(xtrain, dim=c(dim(xtrain)[1], input_size))
x_test = array_reshape(xtest, dim=c(dim(xtest)[1], input_size))

x <- rbind( x_test, x_train )/255.0

# Encoder
encoder_input = layer_input(shape = input_size)
encoder_output = encoder_input %>% 
  layer_dense(units=256, activation = ""relu"") %>% 
  layer_activation_leaky_relu() %>% 
  layer_dense(units=latent_size) %>% 
  layer_activation_leaky_relu()

encoderoder = keras_model(encoder_input, encoder_output)
summary(encoderoder) 

# Decoder
decoder_input = layer_input(shape = latent_size)
decoder_output = decoder_input %>% 
  layer_dense(units=256, activation = ""relu"") %>% 
  layer_activation_leaky_relu() %>% 
  layer_dense(units = input_size, activation = ""relu"") %>% 
  layer_activation_leaky_relu()

decoderoder = keras_model(decoder_input, decoder_output)
summary(decoderoder) 

# Autoencoder
autoencoderoder_input = layer_input(shape = input_size)
autoencoderoder_output = autoencoderoder_input %>% 
  encoderoder() %>% 
  decoderoder()

autoencoderoder = keras_model(autoencoderoder_input, autoencoderoder_output)
summary(autoencoderoder)

autoencoderoder %>% compile(optimizer=""rmsprop"", loss=""binary_crossentropy"")
autoencoderoder %>% fit(x_train,x_train, epochs=20, batch_size=256) 

encoderoded_imgs = encoderoder %>% predict(x_test)
decoderoded_imgs = decoderoder %>% predict(encoderoded_imgs)

# Images plot
pred_images = array_reshape(decoderoded_imgs, dim=c(dim(decoderoded_imgs)[1], 28, 28)) 

n = 10
op = par(mfrow=c(12,2), mar=c(1,0,0,0))
for (i in 1:n) 
{
  plot(as.raster(pred_images[i,,]))
  plot(as.raster(xtest[i,,]))
}


# Saving trained Net
autoencoderoder_weights <- autoencoderoder %>%
  keras::get_weights()
keras::save_model_weights_hdf5(object = autoencoderoder,filepath = '..../autoencoderoder_weights.hdf5',overwrite = TRUE)

encoderoder_model <- keras_model(inputs = encoder_input, outputs = encoderoder$output)
encoderoder_model %>% keras::load_model_weights_hdf5(filepath = ""..../autoencoderoder_weights.hdf5"",skip_mismatch = TRUE,by_name = TRUE)

encoderoder_model %>% compile(
  loss='mean_squared_error',
  optimizer='adam',
  metrics = c('accuracy')
)
embeded_points <- 
  encoderoder_model %>% 
  keras::predict_on_batch(x = x_train)

summary(encoderoder_model)

# Getting layer
layer_name<-""dense_1""
intermediate_layer_model <- keras_model(inputs = encoderoder_model$input, outputs = get_layer(encoderoder_model, layer_name)$output)
intermediate_output <- predict(intermediate_layer_model, x)

# Clustering latent space
km <- stats::kmeans( intermediate_output, centers = 10L, nstart = 20L )
labPrediction <- km$cluster 

plot(labPrediction)
# The End



labels are available in ""labPrediction"" file


For the reference:


https://www.datatechnotes.com/2020/02/how-to-build-simple-autoencoder-with-keras-in-r.html",2020-04-08T13:36:10,Rey,https://stackoverflow.com/users/8062364/rey,21,43267641
43262837,43262837,7,"Which one should I use? Direct spark with pojo or sparkling water with Binary.




There is no 'right' answer, it depends on your use case. It sounds like what you want is the POJO/MOJO in Spark, so you can do scoring without the added dependency of having an H2O cluster up.




What is the exact use of sparkling water, when we can easily deploy a model using pojo and spark itself?




The exact use of Sparkling Water is to have an H2O available within a Spark context. This is particularly useful for 
training
: you can leverage Spark's many data connectors, munging capabilities etc. POJO/MOJO + Spark is sufficient for 
scoring




Is sparkling water needed only when you have to train model on huge amounts of data? Or it can be used in PROD deployments of model's as well.




Sparkling Water is needed when you want to leverage H2O's algorithms in a context that plays nicely w/ the Spark ecosystem. 






If putting a model in ""production"" means having ""always on"" scoring exposed as a REST endpoint or similar: the POJO/MOJO is the way you want to go (H2O clusters are not highly available). You'll need to make sure you're handling incoming data correctly yourself though.


If you are doing batch scoring, nightly or otherwise, then it may make sense to use the binary model w/ Sparkling Water because parsing incoming data becomes trivial (asH2OFrame(..)) and scoring is easy as predict()",2017-04-06T18:14:26,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,43236377
43267374,43267374,0,"Yes, h2o.transform will consider each occurrence of a word for the averaging, not just the unique words. Your trick will therefore work.


There is currently no direct way to provide user defined weights. You could probably do an ugly hack and weight directly the word embeddings but that won't be a straightforward solution I could recommend.


We can add this feature to H2O. I would love to hear what API would work for you (how would you like to provide the weights).",2017-04-06T23:32:28,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,43236362
43236285,43236285,0,"The MOJO documentation is in the 
same location
 as the POJO docs in the Javadoc.  It is also easily findable in the 
H2O User Guide
 by searching the term ""MOJO"". Here is a direct link to the 
MOJO Quickstart Guide
.",2017-04-05T16:04:11,,,,43222103
43222619,43222619,4,"Rather than doing a join, you can simply column-bind the ID column on to the predict frame, since the prediction frame rows are in the same order.


R Example (ignore the fact that I am predicting on the original training set, this is for demonstration purposes only):


library(h2o)
h2o.init()

data(iris)
iris$id <- 1:nrow(iris)  #add ID column
iris_hf <- as.h2o(iris)  #convert iris to an H2OFrame

fit <- h2o.gbm(x = 1:4, y = 5, training_frame = iris_hf)
pred <- h2o.predict(fit, newdata = iris_hf)
pred$id <- iris_hf$id
head(pred)



Now you have a prediction frame with the ID column:


  predict    setosa   versicolor    virginica id
1  setosa 0.9989301 0.0005656447 0.0005042210  1
2  setosa 0.9985183 0.0006462680 0.0008354416  2
3  setosa 0.9989298 0.0005663071 0.0005038929  3
4  setosa 0.9989310 0.0005660443 0.0005029535  4
5  setosa 0.9989315 0.0005649384 0.0005035886  5
6  setosa 0.9983457 0.0011517334 0.0005025218  6",2017-04-05T05:35:17,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43216126
43213877,43213877,1,"You can use the 
h2o.distance()
 function for this with 
measure = ""l2""
, which has recently been committed to the master branch but is not released yet.  To use it you need to 
build H2O from master
.  An example of how to use the function is 
here
.",2017-04-04T17:27:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43209823
43214213,43214213,1,"you can also try downloading the latest nightly build from 
http://h2o.ai/download
, and here's a test for that distance function in R:


https://github.com/h2oai/h2o-3/blob/277ce7d3bd14514b5c34bc58c18514011256f533/h2o-r/tests/testdir_munging/runit_distance.R",2017-04-04T17:48:48,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43209823
43362315,43362315,0,"This expression should do the trick:

sqrt(apply((hex[,cols1] - hex[,col2])^2, 1, sum))",2017-04-12T06:50:40,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43209823
43189705,43189705,9,"You can try something like this: bring an H2OFrame into python as a pandas dataframe by calling .as_data_frame(), then call .tolist() on the column of interest.


A self contained example w/ iris


import h2o
h2o.init()
df = h2o.import_file(""iris_wheader.csv"")
pd = df.as_data_frame()
pd['sepal_len'].tolist()",2017-04-03T16:25:54,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,43189340
54487673,54487673,2,"You can (1) convert the H2o frame to pandas dataframe and (2) convert pandas dataframe to list as follows:


pd=h2o.as_list(h2oFrame) 
l=pd[""column""].tolist()",2019-02-01T21:57:37,Hajar Homayouni,https://stackoverflow.com/users/6121350/hajar-homayouni,590,43189340
77563987,77563987,0,"H2O as_list method returns a list of lists along with the column name, hence you need to flatten the list after extracting the column as shown below


column_as_list_of_lists = h2o.as_list(h2oFrame[:,'<col_name>'],use_pandas=False)  
flat_list = [item for sublist in column_as_list_of_lists[1:len(column_as_list_of_lists)-1] for item in sublist]",2023-11-28T12:44:00,Siddartha Kandikonda,https://stackoverflow.com/users/17248424/siddartha-kandikonda,1,43189340
43214809,43214809,1,"You've only trained a single GBM with the default parameters, so it doesn't look like you've put enough effort into tuning your model.  I'd recommend a random grid search on GBM using the 
h2o.grid()
 function.  Here is an 
H2O R code example
 you can follow.",2017-04-04T18:21:13,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43183229
43191160,43191160,1,"According to the Python 
docs
 for 
h2o.save_model()
 this is already supported (you did not mention which of the APIs you are using, so I am using Python as an example). Have you tried putting an S3 address in the file location argument of the standard model save and load functions?  If you find that this is not working, please file a bug report on the H2O 
JIRA
.",2017-04-03T17:49:40,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43174049
43381738,43381738,0,"As this problem is directly related with memory let have you set memory properly for your h2o instance and make sure the setting is working. As you are setting max_mem_size randomly to an arbitrary number (100g, 200g, 300g)  it is not going to help. First we need to know total RAM in your machine and then you can use about 80% of this memory for your h2o instance. 


For example I have 16GB in my machine and I want to give 12GB for H2O instance when started from R I will do the following:


h2o.init(max_mem_size = ""12g"")



Once H2O is up and running I will get confirmation of memory set for H2O process as below:


R is connected to the H2O cluster: 
H2O cluster uptime:         2 seconds 166 milliseconds 
H2O cluster version:        3.10.4.3 
H2O cluster version age:    12 days  
H2O cluster name:           H2O_started_from_R_avkashchauhan_kuc791 
H2O cluster total nodes:    1 
H2O cluster total memory:   10.67 GB <=== [memory setting working]
H2O cluster total cores:    8 
H2O cluster allowed cores:  2 
H2O cluster healthy:        TRUE 
H2O Connection ip:          localhost 
H2O Connection port:        54321 
H2O Connection proxy:       NA 
H2O Internal Security:      FALSE 
R Version:                  R version 3.3.2 (2016-10-31) 



If you change your dataset size during various model building step you will see OOM with random row count because sometime Java GC will clear the unused memory and sometimes waiting to clear. So you will hit OOM once with N number and sometime you will not hit OOM with 2N numbers in the same java instance. So chasing that route is not useful.


It definitely a memory related issue and make sure you give good enough memory to H2O cluster and then see how it works.",2017-04-13T00:34:52,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43171653
43151950,43151950,3,"Mostly likely, function h2o.performance is using F1 threshold to set yes and no. If you take the predict results and instrument the table to separate yes/no based based on models ""F1 threshold"" value you will see the number is almost match. I believe this is the main reason you see discrepancy in the results between h2o.performance and h2o.predict.",2017-04-01T01:53:47,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43149508
54336138,54336138,0,"When predicting on new data that does not have an actual result for comparison (a 'y' parameter in h2o terms), there is no F1 Max score or other metrics and you have to rely on the predictions made from h2o.predict().",2019-01-23T21:42:05,Art W,https://stackoverflow.com/users/10392029/art-w,1,43149508
59768088,59768088,0,"Difference in 
performance()
 and 
predict()
 is explained below. It is directly from H2O's help page - 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html#prediction


Prediction Threshold


For classification problems, when running h2o.predict() or .predict(), the prediction threshold is selected as follows:




If you train a model with only training data, the Max F1 threshold from the train data model metrics is used.


If you train a model with train and validation data, the Max F1 threshold from the validation data model metrics is used.


If you train a model with train data and set the nfold parameter, the Max F1 threshold from the training data model metrics is used.


If you train a model with the train data and validation data and also set the nfold parameter, the Max F1 threshold from the validation data model metrics is used.",2020-01-16T10:55:16,dcleere,https://stackoverflow.com/users/4614224/dcleere,11,43149508
43149744,43149744,2,"The problem you have both 32 and 64 bit of Java and then when H2O starts, it still use 32bit Java. 


First solution is to remove 32bit java so only 64bit Java is there and you are good to go.


If you have to keep both 32 and 64 bit Java then you would need to setup JAVA_HOME environment variable pointing to your 64bit Java path and then start H2O. This way H2O will get 64bit Java runtime to start and you will not see the problem. 


When you set JAVA_HOME make sue you set it correctly and it is pointing to 64bit Java.",2017-03-31T21:13:24,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43148636
55688127,55688127,1,"Maybe you could try to 
set the environment
 like this:


>install.packages(""h2o"")
>library(h2o)
>Sys.setenv(JAVA_HOME=""E:/java/JAVA(1)"") ##your own path of Java SE intalled",2019-04-15T11:23:25,Gilles Heinesch,https://stackoverflow.com/users/8399000/gilles-heinesch,"2,980",43148636
75997194,75997194,0,"Download and Install Java 64-bit.


Java 32-bit path will be in 
C:\Program Files (x86)
 and 64-bit will be in 
C:\Program Files


Change the path of JAVA_HOME to point to your 64-bit installation.


To do that, copy the installation path, navigate to your system variable, and paste the new path.
Restart your computer",2023-04-12T15:21:00,Daouda,https://stackoverflow.com/users/8030373/daouda,101,43148636
43143946,43143946,2,"The data is small so a quick solution to this would be to remove the double \t's in the file prior to ingesting. There are many ways to do this, here is a quick and dirty one:


import io
f = open(""seeds_dataset.txt"")
s = list(f.read())
for i in range(0,len(s)-1):
    if s[i] == '\t' and s[i+1] == '\t':
        s[i+1] = ''

output = open(""seeds_dataset_fixed.txt"", 'w+')
output.write("""".join(s))

import h2o
h2o.init()
h2o.import_file(""seeds_dataset_fixed.txt"")



Hope this helps",2017-03-31T15:05:08,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,43137325
43144488,43144488,1,"I followed Flow's suggested parse setup and it worked fine (found the \t separator and 8 columns) - no manual intervention needed. Can you compare your steps with these please?


importFiles [ ""https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"" ]

setupParse source_frames: [ ""https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"" ]

parseFiles
  source_frames: [""https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt""]
  destination_frame: ""seeds_dataset1.hex""
  parse_type: ""CSV""
  separator: 9
  number_columns: 8
  single_quotes: false
  column_names: null
  column_types: [""Numeric"",""Numeric"",""Numeric"",""Numeric"",""Numeric"",""Numeric"",""Numeric"",""Numeric""]
  delete_on_done: true
  check_header: -1
  chunk_size: 4194304



This is the view from 
    getFrameSummary ""seeds_dataset1.hex""


Clicked on 'View Data"":


Row C1  C2  C3  C4  C5  C6  C7  C8
1   15.2600 14.8400 0.8710  5.7630  3.3120  2.2210  5.2200  1.0
2   14.8800 14.5700 0.8811  5.5540  3.3330  1.0180  4.9560  1.0
3   14.2900 14.0900 0.9050  5.2910  3.3370  2.6990  4.8250  1.0
etc.",2017-03-31T15:30:41,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43137325
43150288,43150288,0,"So the problem is that H2O model is not seeing the data and causing NPE. The main reasons could be that h2o dataframe is deleted either at the time of prediction or just before prediction call.


We are interested to know how you do process mini batch data i.e. how mini batch is transformed into h2o data frame. 


It will also help if you explain ""how h2o model is being called to make prediction"".",2017-03-31T21:58:56,,,,43120159
43288792,43288792,2,"If multicast packets can be transmitted between the pods, then you could rely on that for the cluster formation.  Just specify a unique -name for all the nodes to share.  This is easy if it works, with no code changes.


UPDATE (2018/04/21) -- one of my colleagues says:


I used weave as the network layer, what that does is provide a connection between all the containers for that kubernetes pod group, then you dont need to use the flatfile in H2O, as h2o will multicast on startup, weave will take the multicast and send it to all instances of the pod.


in K8s run this: kubectl apply --filename 
https://git.io/weave-kube-1.6




If multicast is not an option, there isn't an out-of-the-box solution today for Kubernetes that I'm aware of.


You will need an orchestrator to distribute the flatfile information.


There are at least three examples of code to do this for other environments in the H2O github repos.




ec2 scripts




https://github.com/h2oai/h2o-3/tree/master/ec2




The hadoop driver




https://github.com/h2oai/h2o-3/blob/master/h2o-hadoop/h2o-mapreduce-generic/src/main/java/water/hadoop/h2omapper.java


In particular, look at how this class gets overridden:


https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/water/init/AbstractEmbeddedH2OConfig.java




The sparkling water driver in the sparkling water repo.",2017-04-08T00:13:24,,,,43109777
43103229,43103229,2,"import h2o
h2o.init()
df = h2o.create_frame(rows=100, cols=2, missing_fraction=0, integer_fraction=1, integer_range=5)
print(df)

def mape(a, b):
    mask = a != 0
    return (abs(a-b)/a)[mask].mean()

mape(df[0],df[1])",2017-03-29T20:11:18,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43103022
47214583,47214583,1,"Sorry, today this is unsupported in H2O-3.",2017-11-10T02:02:27,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43102725
43103759,43103759,7,"I agree that this is not an H2O-specific issue.  This works for me (same H2O and Python version):


import h2o
import pandas as pd

df = pd.DataFrame({'col1': [1,1,2], 'col2': ['César Chávez Day', 'César Chávez Day', 'César Chávez Day']})
hf = h2o.H2OFrame(df)

## -- End pasted text --
Parse progress: |█████████████████████████████████████████████████████████| 100%

In [4]: hf
Out[4]:   col1  col2
------  ----------------
     1  César Chávez Day
     1  César Chávez Day
     2  César Chávez Day

[3 rows x 2 columns]

In [5]: type('César Chávez Day')
Out[5]: str



My specs (you may need to change your default encoding):


In [6]: import sys

In [7]: sys.getdefaultencoding()
Out[7]: 'utf-8'



This thread may help: 
How do I check if a string is unicode or ascii?",2017-03-29T20:42:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43095970
47240171,47240171,0,This is unsupported for versions of Spark earlier than 2.0.,2017-11-11T16:28:42,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43089222
48392961,48392961,0,"Download the latest version of sparkling jar and add it to while starting the spark-shell:


./bin/sparkling-shell --master yarn-client --jars ""<path to the jar located>""



Then run the code by setting the extended h2o driver:


import org.apache.spark.h2o._

val conf = new H2OConf(spark).setExternalClusterMode().useAutoClusterStart().setH2ODriverPath(""//home//xyz//sparkling-water-2.2.5/bin//h2odriver-sw2.2.5-hdp2.6-extended.jar"").setNumOfExternalH2ONodes(2).setMapperXmx(""6G"")

val hc = H2OContext.getOrCreate(spark, conf)",2018-01-23T01:46:09,Adil B,https://stackoverflow.com/users/866021/adil-b,16.5k,43089222
43125080,43125080,1,"the main plotting functionality for an H2O frame is for histograms (
hist()
 in python and 
h2o.hist()
 in R).


Within Flow you can do basic data exploration if you import your dataframe, then click on 
inspect
 and then, next to the hyperlinked 
columns
, you'll see a 
plot
 button which will let you get bar charts of counts for example and other plot types.  


You can also easily convert single columns you want to plot into a pandas or R dataframe with

H2OFrame.as_data_frame()
 in python

as.data.frame.H2OFrame
 in R and then use the native python and R plotting methods",2017-03-30T17:53:15,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",43085556
47214575,47214575,0,"As you discovered, install a stable release of H2O-3.


Nightly builds are number 3.ODD.y.z


Stable builds are numbered 3.EVEN.y.z


(So 3.11.0.3820 is a random bleeding edge build, not a stable build.)",2017-11-10T02:01:00,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",43075650
54708911,54708911,0,"Did you do logarithmic transformation of response variable (i.e. 
y
) before running the model? If yes, then are you sure you did not have any 
y = 1
 values BEFORE you log-transformed it? I had a similar issue, and model worked really fast after I removed from data set the rows with 
y = 1
.",2019-02-15T12:00:21,canton7,https://stackoverflow.com/users/1086121/canton7,41.7k,43072344
43058363,43058363,4,"Here is a simple example of how to extract the cross-validated predictions from a trained H2O model in R (using the Iris dataset).  


library(h2o)
h2o.init(nthreads = -1)

data(iris)
train <- as.h2o(iris)
y <- ""Species""
x <- setdiff(names(train), y)
family <- ""multinomial""
nfolds <- 5 

gbm1 <- h2o.gbm(x = x, y = y, 
                distribution = family,
                training_frame = train,
                seed = 1,
                nfolds = nfolds,
                fold_assignment = ""Modulo"",
                keep_cross_validation_predictions = TRUE)

cvpreds_id <- gbm1@model$cross_validation_holdout_predictions_frame_id$name
cvpreds <- h2o.getFrame(cvpreds_id)



The 
cvpreds
 object is an H2OFrame that looks like this:


> cvpreds
  predict    setosa   versicolor    virginica
1  setosa 0.9986012 0.0008965135 0.0005022631
2  setosa 0.9985695 0.0004486762 0.0009818434
3  setosa 0.9981387 0.0004777671 0.0013835724
4  setosa 0.9985246 0.0006259377 0.0008494549
5  setosa 0.9989924 0.0005033832 0.0005042294
6  setosa 0.9981410 0.0013581692 0.0005008536

[150 rows x 4 columns]",2017-03-27T23:54:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43054383
43103947,43103947,2,"This will show a summary of the underlying representation in H2O's key-value store, including the full byte size:


frame.describe(chunk_summary=True)",2017-03-29T20:52:18,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,43048126
43051434,43051434,0,"This refers to 2-4 times the size of the file on disk, so rather than looking at the memory in Python, look at the original file size.  Also, the 2-4x recommendation varies by algorithm (GLM & DL will requires less memory than tree-based models).",2017-03-27T16:11:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43048126
43058254,43058254,2,"Due to the way H2O works, it cannot support arbitrary user-defined functions applied to H2OFrames the way that you can apply any function to a regular R data.frame.  We already use the Murmur hash function in the H2O backend, so I have added a 
JIRA ticket
 to expose it to the H2O R and Python APIs.  What I would recommend in the meantime is to copy just the single column of interest from the H2O cluster into R, apply the 
digest
 function and then update the H2OFrame with the result.  


The following code will pull the 
""subject""
 column into R as a 1-column data.frame.  You can then use the base R 
apply
 function to apply the murmur hash to every row, and lastly you can copy the resulting 1-column data.frame back into the 
""subject""
 column in your original H2OFrame, called 
data
.


sub <- as.data.frame(data[, ""subject""])
subhash <- apply(sub, 1, digest, algo = ""murmur32"")
data[, ""subject""] <- as.h2o(subhash)



Since you only have 43k rows, I would expect that you'd still be able to do this with no issues on even a mediocre laptop since you are only copying a single column from the H2O cluster to R memory (rather than the entire data frame).",2017-03-27T23:44:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",43035149
43018863,43018863,0,"In this case h2o.randomForest is just asking you to pass correct x (list of columns to use in prediction) and y (the column name to do prediction) so anything you will pass will be used as input. 


What you are asking is a python specific question. How you want to pass the list of columns you will need to write logic for it. You can defined the following is a function and use it as needed.


import random
myframe = [""a"",""b"",""c"",""d"",""e""] 
//You can also set myframe as column name list
//myframe.remove(_use_response_column_name) this will make it generic
selectedkeys  = [""a"",""b""]
for item in selectedkeys:
    if item in myframe:
        myframe.remove(item)
selectedkeys.append(random.choice(myframe))    
print(selectedkeys)
print(myframe)



You just need to pass the selectedkeys as input for X.",2017-03-25T16:23:38,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,43002941
42989785,42989785,1,"It looks like you are using 
h2o.predict()
 incorrectly.  The error indicates that you are trying to access the 
model_id
 slot on a H2OFrame (rather than on a model), which means you probably mixed up the order of the test set and model or just passed a test set (without a model). 


Your code should look like:  


preds <- h2o.predict(model, test)",2017-03-24T01:16:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",42989596
48624033,48624033,1,"When you use the h2o.insertMissingValues you are changing the original dataset as well. Creating two separate h2o instances and then changing just one, should solve the problem.


train <-- as.h2o(A)
test <-- as.h2o(A)
h2o.insertMissingValues(train, fraction = 0.2, seed=-1)",2018-02-05T13:47:10,jpgarcia,https://stackoverflow.com/users/9316930/jpgarcia,11,42986668
42983585,42983585,4,"thank you for your questions.


You are absolutely right, there are many situations when you don't need a custom model and pre-trained model will work well. I assume people will mostly build their own models on smaller problems in their specific domain and use pre-trained models to complement the custom model.


You can import 3rd party pre-trained models into H2O as long as they are in a CSV-like format. This is true for many available GloVe models.


To do that import the model into a Frame (just like with any other dataset):


w2v.frame <- h2o.importFile(""pretrained.glove.txt"")



And then convert it to a regular H2O word2vec model:


w2v.model <- h2o.word2vec(pre_trained = w2v.frame, vec_size = 100)



Please note that you need to provide the size of the embeddings.


H2O doens't plan to provide a model exchange/model market for w2v model as far as I know. You can use models that are available on-line: 
https://github.com/3Top/word2vec-api


We currently do not support importing Google's binary format of word embeddings, however the support is on our road map as it makes a lot of sense for our users.",2017-03-23T17:58:12,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,42982176
44237832,44237832,1,"You can use the h2o flow to inspect the model performance. Simply go to: 
http://localhost:54321/flow/index.html
 (if you changed the default port change it in the link); type ""getModel ""rf_v1"""" in a cell and it will show you all the measurements of the model in multiple cells in the flow. It's quite handy.
If you are using Python, you can find the performance in your IDE like this:


rf_perf1 = rf_v1.model_performance(test)



and then print the ROC like this:


print (rf_perf1.auc())",2017-05-29T08:25:07,lookah,https://stackoverflow.com/users/8080227/lookah,21,42981259
44130598,44130598,0,"Yes, indirectly. Get the TPRs and FPRs from the 
H2OModelMetrics
 object:


out = rf_v1.model_performance(test)
fprs = out.fprs
tprs = out.tprs
roc = zip(fprs, tprs)



(By the way, my 
H2ORandomForestEstimator
 object does not seem to have an 
roc()
 method at all, so I'm not 100% sure that this output is in the exact same format. I'm using h2o version 
3.10.4.7
.)",2017-05-23T09:14:54,abeboparebop,https://stackoverflow.com/users/1892435/abeboparebop,"7,735",42981259
42979142,42979142,2,"It seems that Windows path string is limited to (maybe) 256 length. Usually, setting a the path 
setwd(shorterExistingWorkDir)
 works and should address your issue.",2017-03-23T14:35:27,Hack-R,https://stackoverflow.com/users/3604745/hack-r,23.1k,42973949
48711606,48711606,1,"I struggled with this issue quite a bit, including upgrading. 


Most folks are assuming that you've literally just set an incredibly long path. I don't think this is the case (it wasn't for me, at least). It's that the PATH may be set on a network drive or other device where the underlying mapped paths are more complicated.


A related thread is 
here
 on the H2O forum:




Main issue is the user had a Windows drive that did not conform to the norm, i.e., ""C://"", etc. Instead, the user had a network drive
  (
DTCHYB-AZPX015/)
. This caused issues in the search for a config
  file as there was no ""root"" (In this case, ""root"" is reaching your Win
  drive). Since there was no ""root"", the path to search kept expanding
  until it caused R to error out with the above exception.


The fix is to NOT search for a config when 
h2o.init()
 is called. Rather, only search for a config if a user asks to do so. My proposal
  is to add a new field to 
h2o.init()
called 
ignore_config
. This
  field will be set to TRUE by default.",2018-02-09T17:58:31,Hack-R,https://stackoverflow.com/users/3604745/hack-r,23.1k,42973949
42981871,42981871,1,"When calling h2o.init() the R environment signal the launching of h2o application (actually a web server) in the backend which was installed when you install H2O package into R. The local runtime environment uses the full path of the location where H2O jar file is located. Because the packages is installed deep inside the nested folders in your file system it cross the valid limit of OS path 256 character length and fails to launch the backend H2O server and you see this error. In your case you are using external path so adds up more characters in the path to make the problem worse.. 


For example the h2o.jar is located in my OSX machine as below:


/Library/Frameworks/R.framework/Resources/library/h2o  <-- H2O package Path
/Library/Frameworks/R.framework/Resources/library/h2o/java/h2o.jar <-- Jar Path



As you are using Windows, what you need is to find ways to reduce this path to OS limit and it will work. 


The other solution is to run h2o.jar separately and then just use R to connect to H2O cluster. The steps are as below:




Download H2O 3.10.4.2 and unzip to a folder close to root so you do not hit 265 char limit again. Also install 3.10.4.2 R Package. (Try to keep the same version)


Run H2O > java -jar h2o.jar


From RStudio console try > h2o.init()




So if there is already H2O cluster running the h2o.init() will connect to a running H2O cluster instead to start one and you will by pass above problem. 


If you hit any problem write here and we will help you.",2017-03-23T16:32:06,Hack-R,https://stackoverflow.com/users/3604745/hack-r,23.1k,42973949
43159064,43159064,2,"Alternatively, set the check.names arg to FALSE.",2017-04-01T16:06:02,user2502338,https://stackoverflow.com/users/2502338/user2502338,899,42913138
43158847,43158847,1,"Read in the first row, I.e. the column headers, with readLines. strsplit to parse to vector. Rename duplicated elements. Then you can call read.csv with a col.names arg.",2017-04-01T15:46:46,russellpierce,https://stackoverflow.com/users/169095/russellpierce,"4,701",42913138
42965786,42965786,4,"Here is some code which demonstrates how to use the data.table package on the backend, along with some benchmarks on my macbook:


library(h2o)
h2o.init(nthreads = -1, max_mem_size = ""16G"")
hf <- h2o.createFrame(rows = 10000000)

options(""h2o.use.data.table""=FALSE)  #no data.table
system.time(df <- as.data.frame(hf))
# user  system elapsed 
# 224.387  13.274 272.252

options(""datatable.verbose""=TRUE)
options(""h2o.use.data.table""=TRUE)  # use data.table
system.time(df2 <- as.data.frame(hf))
# user  system elapsed 
# 50.686   4.020  82.946



You can get more detailed info when using data.table if you turn on this option: 
options(""datatable.verbose""=TRUE)
.",2017-03-23T01:45:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",42865609
42932790,42932790,0,"We have seen this issue with large prediction datasets when exporting to prediction dataframe or converting them to other types takes long time. I have opened the following JIRA to track it now:


https://0xdata.atlassian.net/browse/PUBDEV-4166",2017-03-21T16:21:34,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,42865609
42937920,42937920,0,"Yes there are some new options to turn on using 
data.table::fread
 to speed it up. Type 
h2o:::as.data.frame.H2OFrame
 to see the small amount of R source code containing the options, or H2O release notes. Please also try latest 
fread
 from 
dev
 which is now parallel as of yesterday.


Once users have reported success we can turn the default on by default.",2017-03-21T20:52:42,Matt Dowle,https://stackoverflow.com/users/403310/matt-dowle,59.6k,42865609
42862431,42862431,1,"updated


for older versions of H2O (3.10.2 or less) you have to use a value less than 1 for a Bernoulli distribution with H2O gbm's 
offset_column
. 
However
, for newer versions you will be able to pass in any value. In your case, using a Bernoulli distribution, one way to create the offset column is to use the predicted logit values from a previous model (just as you said you wanted to do in the comments). 


This is how the gbm offset column works:
An offset is a per-row “bias value” that is used during model training. For Gaussian distributions, offsets can be seen as simple corrections to the response (y) column. Instead of learning to predict the response (y-row), the model learns to predict the (row) offset of the response column. For other distributions, the offset corrections are applied in the linearized space before applying the inverse link function to get the actual response values. This option is not applicable for multinomial distributions.


And here is a example of how to use this parameter on a toy dataset


(example with Bernoulli distribution)


library(h2o)
h2o.init()

# import the cars dataset:
# this dataset is used to classify whether or not a car is economical based on
# the car's displacement, power, weight, and acceleration, and the year it was made
cars <- h2o.importFile(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"")

# convert response column to a factor
cars[""economy_20mpg""] <- as.factor(cars[""economy_20mpg""])

# create a new offset column by taking the log of the response column
cars[""offset""] <- as.h2o(rep(.5, dim(cars)[1]))

# set the predictor names and the response column name
predictors <- c(""displacement"",""power"",""weight"",""acceleration"",""year"")
response <- ""economy_20mpg""

# split into train and validation sets
cars.split <- h2o.splitFrame(data = cars,ratios = 0.8, seed = 1234)
train <- cars.split[[1]]
valid <- cars.split[[2]]

# try using the `off_set` parameter:
# training_frame and validation_frame
cars_gbm <- h2o.gbm(x = predictors, y = response, training_frame = train, offset_column = ""offset"",
                  validation_frame = valid, seed = 1234)

# print the auc for your model
print(h2o.auc(cars_gbm, valid = TRUE))



Gaussian example (where it makes more sense to use this option)


library(h2o)
h2o.init()

# import the boston dataset:
# this dataset looks at features of the boston suburbs and predicts         median housing prices
# the original dataset can be found at     https://archive.ics.uci.edu/ml/datasets/Housing
boston <- h2o.importFile(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/BostonHousing.csv"")

# set the predictor names and the response column name
predictors <- colnames(boston)[1:13]
# set the response column to ""medv"", the median value of owner-occupied     homes in $1000's
response <- ""medv""

# convert the chas column to a factor (chas = Charles River dummy     variable (= 1 if tract bounds river; 0 otherwise))
boston[""chas""] <- as.factor(boston[""chas""])

# create a new offset column by taking the log of the response column
boston[""offset""] <- log(boston[""medv""])

# split into train and validation sets
boston.splits <- h2o.splitFrame(data =  boston, ratios = .8, seed = 1234)
train <- boston.splits[[1]]
valid <- boston.splits[[2]]

# try using the `offset_column` parameter:
# train your model, where you specify the offset_column
boston_gbm <- h2o.gbm(x = predictors, y = response, training_frame = train,
               validation_frame = valid,
               offset_column = ""offset"",
               seed = 1234)

# print the mse for validation set
print(h2o.mse(boston_gbm, valid = TRUE))",2017-03-17T16:17:08,,,,42844585
42860507,42860507,0,"You must be using importFolder as below when passing a path with pattern:




data = h2o.importFolder(path = ""/Users/avkashchauhan/learn/datasets"", pattern = "".*.csv"", destination_frame = ""trainx"")


|================================================| 100%",2017-03-17T14:47:17,Community,https://stackoverflow.com/users/-1/community,1,42842993
42796822,42796822,1,"In the h2o R package, we have the 
h2o.arrange()
 method which will sort an H2OFrame by a column or columns.  This is similar to 
dplyr::arrange()
.  However, this is broken for floats right now (integers work fine).  The ticket for fixing the ""sort on a float column"" functionality is here: 
https://0xdata.atlassian.net/browse/PUBDEV-3525",2017-03-14T21:24:32,,,,42796452
42742517,42742517,0,"Your question title and description are talking about 2 different things and title is not clear about what you are asking. My following answer is based on your question in description field: 


If you use H2O to build your GBM model H2O replaces missing numerical, categorical & unseen values to NA. Please look at the following documentation regarding ""handling missing values in GBM"" which will help you understand more about your case:


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm-faq/missing_values.html?highlight=missing%20values",2017-03-12T01:02:42,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,42739051
42677127,42677127,1,"Please try to correct your path:



C:\Users\Mansoor\libs\spark\spark-2.1.0/bin/spark-shell.cmd --jars C:\Users\Mansoor\libs\H2o\sparkling\bin\..\assembly\build\libs\sparkling-water-assembly_2.11-2.1.0-all.jar --driver-memory 3G --conf spark.driver.extraJavaOptions=""-XX:MaxPermSize=384m""



There is also doc page about RSparkling at Windows, which can contain different troubleshooting tips...

https://github.com/h2oai/sales-engineering/tree/master/megan/RSparklingAndWindows",2017-03-08T16:47:46,Michal,https://stackoverflow.com/users/5089773/michal,437,42669040
42762193,42762193,1,"Problem is with 
spark-shell
 command while submitting jars. Workaround is to modify 
spark-defaults.conf


Adding 
spark.driver.extraClassPath
 and 
spark.executor.extraClassPath
 parameters to 
spark-defaults.conf
 file as follows:


spark.driver.extraClassPath    \path\to\jar\sparkling-water-assembly_version>-all.jar

spark.executor.extraClassPath   \path\to\jar\sparkling-water-assembly_version>-all.jar



And Remove 
--jars  \path\to\jar\sparkling-water-assembly_version>-all.jar
 from 
sparkling-shell2.cmd",2017-03-13T11:12:14,Mansoor,https://stackoverflow.com/users/4520274/mansoor,"1,259",42669040
42615972,42615972,0,"if you are building application on top of Spark and Sparkling Water please look at Sparkling Water droplet - which describes an example of configuration via Gradle or Sbt: 
https://github.com/h2oai/h2o-droplets/tree/master/sparkling-water-droplet


You need to make sure that you have all Sparkling Water libraries and required dependencies (including 
h2o-core
, 
h2o-algos
).",2017-03-06T00:57:41,Michal,https://stackoverflow.com/users/5089773/michal,437,42614890
42611520,42611520,5,"A few points:




I don't recommend trying to call score0 directly when you are just learning how to use H2O POJOs.  The 
EasyPredictModelWrapper
 API was created to provide a friendly interface, and I recommend using that if you can.  (The best reason to skip the Easy API layer would be if you're interested in pure raw speed.)


You may find it easier to work with a MOJO instead of a POJO.  MOJOs can be used in exactly the same way as POJOs, but they are data representations of the model rather than code representations of the model.  MOJOs have strong backwards compatibility guarantees, and do not need to be compiled.  I recommend using the MOJO if you can.


POJO and MOJO online documentation for the latest stable release of H2O can be found here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




Code for the 
EasyPredictModelWrapper
 can be found here:




https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/easy/EasyPredictModelWrapper.java






For people that really want to call score0 directly, the best documentation for how to do that is the 
EasyPredictModelWrapper
 code.




Here is a POJO usage code snippet from the documentation (of H2O version 3.10.4.1) of how to make a new prediction with the Easy API:


import java.io.*;
import hex.genmodel.easy.RowData;
import hex.genmodel.easy.EasyPredictModelWrapper;
import hex.genmodel.easy.prediction.*;

public class main {
  private static String modelClassName = ""gbm_pojo_test"";

  public static void main(String[] args) throws Exception {
    hex.genmodel.GenModel rawModel;
    rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();
    EasyPredictModelWrapper model = new EasyPredictModelWrapper(rawModel);
    //
    // By default, unknown categorical levels throw PredictUnknownCategoricalLevelException.
    // Optionally configure the wrapper to treat unknown categorical levels as N/A instead
    // and strings that cannot be converted to numbers also to N/As:
    //
    //     EasyPredictModelWrapper model = new EasyPredictModelWrapper(
    //         new EasyPredictModelWrapper.Config()
    //             .setModel(rawModel)
    //             .setConvertUnknownCategoricalLevelsToNa(true)
    //             .setConvertInvalidNumbersToNa(true)
    //     );

    RowData row = new RowData();
     row.put(""Year"", ""1987"");
     row.put(""Month"", ""10"");
     row.put(""DayofMonth"", ""14"");
     row.put(""DayOfWeek"", ""3"");
     row.put(""CRSDepTime"", ""730"");
     row.put(""UniqueCarrier"", ""PS"");
     row.put(""Origin"", ""SAN"");
     row.put(""Dest"", ""SFO"");

    BinomialModelPrediction p = model.predictBinomial(row);
    System.out.println(""Label (aka prediction) is flight departure delayed: "" + p.label);
    System.out.print(""Class probabilities: "");
    for (int i = 0; i < p.classProbabilities.length; i++) {
      if (i > 0) {
        System.out.print("","");
      }
      System.out.print(p.classProbabilities[i]);
    }
    System.out.println("""");
  }
}



After stuffing a new prediction value into 
row
 (which is just a Map), you call 
predictBinomial()
 to make a prediction.


Almost exactly the same code can be used for a MOJO, except you need to instantiate the model from a data file instead of from a class.  So instead of this code for POJO:


    hex.genmodel.GenModel rawModel;
    rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();
    EasyPredictModelWrapper model = new EasyPredictModelWrapper(rawModel);



you would have this code for MOJO:


    EasyPredictModelWrapper model = new EasyPredictModelWrapper(MojoModel.load(""GBM_model_R_1475248925871_74.zip""));",2017-03-05T17:22:23,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",42603673
42605333,42605333,2,"If anyone finds this thread, I found an even easier way to leverage the downloaded pojo.  H2o steam handles it nicely:


~/steam-1.1.6-linux-amd64 > java -jar var/master/assets/jetty-runner.jar --port 8888 var/master/assets/ROOT.war &
curl -X POST --form pojo=@/home/tome/pojo/DL_defaults.java --form jar=@/home/tome/pojo/h2o-genmodel.jar localhost:8888/makewar > example.war
java -jar /home/tome/steam-1.1.6-linux-amd64/var/master/assets/jetty-runner.jar --port 7077 example.war



Then you can query it:


01:34:57 PS C:\dropbox\scripts> Invoke-RestMethod ""http://notexist.eastus.cloudapp.azure.com:7077/predict?C1=4.6&C2=3.1&C3=1.5&C4=0.2""


labelIndex label       classProbabilities
---------- -----       ------------------
         0 Iris-setosa {0.9976588811416329, 0.0023411188583572825, 9.66283735443809E-15}



The main http: page provides a nice interface for building your query, and if you don't like the above, the full version of Steam provides a way to connect to H2O directly and do the download, conversion, and deployment of a model for you in a couple of clicks.",2017-03-05T06:41:45,Toenuff,https://stackoverflow.com/users/282113/toenuff,71,42603673
42604363,42604363,0,"Never mind - it looks like I had it correct after all.  The output refers to the 3 categories I have:


t[1] is setosa
t[2] is versicolor
t[3] is virginica



the 0.9976588811416329 refers to the percentage it thinks it's in that category.  So the data is 99.8% setosa.",2017-03-05T03:58:45,Toenuff,https://stackoverflow.com/users/282113/toenuff,71,42603673
42492037,42492037,1,"Specifying the 
col.types
 argument in 
h2o.importFile
 function should work for you.


write.csv(iris, ""iris.csv"")
hf0 <- h2o.importFile(""iris.csv"", col.types = c(""int"",""real"",""real"",""real"",""real"",""string""))
unlist(h2o.getTypes(hf0))
[1] ""int""    ""real""   ""real""   ""real""   ""real""   ""string""",2017-02-27T17:26:19,jmuhlenkamp,https://stackoverflow.com/users/6850554/jmuhlenkamp,"2,150",42491661
45509131,45509131,1,"This problem is caused by multiple versions commons-lang3 on the Spark class-path. This dependency is not used in H2O and Sparkling Water.


This was actually CDH bug reported here: 
http://community.cloudera.com/t5/Advanced-Analytics-Apache-Spark/Spark-2-0-App-not-working-on-cluster/m-p/52353#M2551
 


and fixed: 
http://community.cloudera.com/t5/Community-News-Release/ANNOUNCE-Spark-2-0-Release-2/m-p/51464#M161",2017-08-04T14:17:29,,,,42424156
42424493,42424493,10,"They are two different ways to construct an ensemble.  They have a different interface, but they produce the exact same type of object in the end.  




The 
h2o.stack()
 function takes as input a list of already trained (and cross-validated) H2O models, so all it needs to do is the metalearning (combiner) step, which is very fast.  This is useful if you want to use a grid of H2O models or a collection of grids of H2O models as the base learners.  The only caveat is that all the base learners must have used identical cross-validation folds.  If you use 
fold_assignment = ""Modulo""
 in all the base learners (or grid) that will ensure identical folds.


The 
h2o.ensemble()
 function allows the user to specify which base models they want in the ensemble and then does the all of the training and cross-validation of the base models, and then does the metalearning (combiner) step as well.  This takes much longer since it has to train all the base models as well.




As of the latest stable release (H2O 3.10.3.*), stacking is now available natively in H2O (R, Python, Java, Scala) as the ""Stacked Ensemble"" method.  More info on that 
here
.  However, the 
h2oEnsemble
 R package (where the 
h2o.ensemble()
 and 
h2o.stack()
 functions live) will continue to be supported as well.",2017-02-23T19:27:32,,,,42408295
44609899,44609899,4,"I just had the same problem.
You can open the url 
http://localhost:54321
 and then shutdown the cluster.
Then you can try to reconnect to h2o. 
The reason of the problem is probably because each time you close the python kernel, h2o is still running in its kernel. You can use this:


h2o.cluster().shutdown(prompt=True) 



to shutdown h2o when you finish work.",2017-06-17T22:16:22,Paul Roub,https://stackoverflow.com/users/1324/paul-roub,36.4k,42397089
76738644,76738644,1,"Just restart the h20 server and it will solve the issue.


Initiate the server using this:


h2o.init()



Stop it:


h2o.cluster().shutdown(prompt=True) 



Start it again:


h2o.init()



It will work.",2023-07-21T13:57:13,,,,42397089
42424363,42424363,0,"In Windows the maximum length of command line is 260 characters and you are hitting the limit. 


Your options are to change multiple of %DEF% operators into one single operator and reduce the overall length with some experimentation.",2017-02-23T19:20:33,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,42385017
42312567,42312567,1,"modelRdd
 will be of type 
Tuple2<Object, Rating>
 (or equivalent in Scala), 
Rating
 isn't a type we (Sparkling Water) provide automatic conversion for (it's not a 
String, Double, Float etc.
 nor does it implement 
Product
). We definitely need to throw a more meaningful error message there.


To fix this instead of making a DataFrame with 
Object, Rating
 with 
modelRdd.toDF(""Rdd"",""Rdd1"")
 you can map it into a DF with 4 columns 
Object, user, product, rating
 and then use 
hc.asH2OFrame()
.",2017-02-18T07:44:47,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,42291510
62525572,62525572,1,"This is 
super
 late but I had the same issue and I realized that increasing 
h2o.glm(...,max_mem_size)
 made that issue go away. I was converting an extremely large 
data.table
 to to an h2o object and was getting this same error message.",2020-06-23T00:38:36,theneil,https://stackoverflow.com/users/6710466/theneil,518,42284205
45463442,45463442,0,"This problem is when you are using 
h2o
 to change the data frame to 
h2o
 format as:


data_h2o <- as.h2O(data)


This is internal error for your Server.


To solve this problem you can 
restart
 your server and run it again. I hope this can help you...",2017-08-02T14:18:21,sm925,https://stackoverflow.com/users/5269047/sm925,"2,678",42284205
42321990,42321990,0,"The problem was with converting very high cardinality (hundreds of million of unique values) string columns to enums. Removing those columns from the dataframe resolved the issue. See this for more details: 
https://community.h2o.ai/questions/1747/gbm-training-with-sparkling-water-on-emr-failing-w.html",2017-02-18T23:47:09,Amir Ziai,https://stackoverflow.com/users/6896683/amir-ziai,148,42233552
42270028,42270028,2,"So since there was no reply to my question, I made some research and came up with the following:


H2O cannot be ran in a straightforward manner in Azure machine learning embedded R scripts. A workaround the problem is to consider using an Azure created environment - specially for H2O. The options available are:




Spinning up an H2O Artificial Intelligence Virtual Machine solution


Using an H2O application for HDInsight




For more reading, you can go to: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/azure.html",2017-02-16T09:36:45,Mikee,https://stackoverflow.com/users/1783739/mikee,854,42228715
42217477,42217477,0,"you can use 
**
 to raise each column of an H2O frame  


so if your H2O frame is called 
frame
 you could use the python exponentiation operator  
**
 like this: 
frame**1.5
 


import h2o  
h2o.init()  
frame = h2o.create_frame()  
frame**1.5",2017-02-14T03:40:08,RoadieRich,https://stackoverflow.com/users/105886/roadierich,"6,476",42212737
42202605,42202605,1,"Yes. This is exactly what the 
POJO
 is for. In your R script, if 
m
 is your model, then you can get the POJO with:


h2o.download_pojo(m, ""/path/to/save/in/"");



This will choose the filename, and create a java file in the directory you give. By default it will also download the jar file you need.


If saving to the local file system is not desirable, don't give a path (i.e. do just 
h2o.download_pojo(m)
) and it will output the java class to your R session, where you could capture the output, and do something with that.


Also take a look at 
h2o.download_mojo()
, which gives a different format. It is for tree models, which can get very big (in fact it only supports random forest, GBM and GLM currently).


More info on both POJO and MOJO here: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/pojo-quick-start.html",2017-02-13T11:09:24,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,42201397
42174488,42174488,0,"H2O has no support for doing this currently (as of Feb 2017, h2o 3.10.3.x); Erin opened a JIRA for it: 
https://0xdata.atlassian.net/browse/PUBDEV-4007",2017-02-11T09:51:02,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,42079678
42071341,42071341,1,"Check 
sparkling-water examples
 e.g. 
ProstateDemo.scala
 to how to write standalone sparkling-water app (creating h2o context, etc.). 


Basically you 
need to add
 
sparkling-water-core
 to your sbt/maven/gradle dependency, compile your jar. You have 2 options:




Build an assembly jar with sparkling-water-core in it. Here's an example i'm using for sbt:


libraryDependencies += ""ai.h2o"" %% ""sparkling-water-core"" % ""2.0.4"" excludeAll(
ExclusionRule(organization = ""org.apache.spark""),
ExclusionRule(organization = ""org.slf4j""),
ExclusionRule(organization = ""com.google.guava""),
ExclusionRule(organization = ""org.eclipse.jetty.orbit""),
ExclusionRule(organization = ""com.esotericsoftware.kryo""))



Compile your jar and use 
--jars
 or 
--packages
 argument to spark submit:




spark-submit --packages ai.h2o:sparkling-water-core_2.11:2.0.4 your_jar.jar",2017-02-06T15:24:40,prudenko,https://stackoverflow.com/users/3271168/prudenko,"1,701",42033052
42677573,42677573,0,"FYI: there is also Sparkling Water Droplet which contains 
stb
 definition:


https://github.com/h2oai/h2o-droplets/blob/master/sparkling-water-droplet/build.sbt",2017-03-08T17:09:33,Michal,https://stackoverflow.com/users/5089773/michal,437,42033052
42010795,42010795,1,"No, H2O does not currently support learning on multidimensional outcomes.",2017-02-02T19:32:03,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",42002989
41992992,41992992,1,"One option would be to use the 
h2o.interaction
 function.  It's not as simple as a 
paste
 function and I don't think you can choose the concatenation separator (it uses 
_
), but it may work for your purposes.  Here is a brief example.


library(h2o)
h2o.init()

h2oframe <- as.h2o(Titanic)
h2oframe$Col3 <- h2o.interaction(h2oframe,
                                 factors = list(c(""Sex"", ""Age"")),
                                 pairwise = T,
                                 max_factors = 100000,
                                 min_occurrence = 1)
head(h2oframe)
  Class    Sex   Age Survived Freq         Col3
  1   1st   Male Child       No    0   Male_Child
  2   2nd   Male Child       No    0   Male_Child
  3   3rd   Male Child       No   35   Male_Child
  4  Crew   Male Child       No    0   Male_Child
  5   1st Female Child       No    0 Female_Child
  6   2nd Female Child       No    0 Female_Child",2017-02-02T01:51:04,jmuhlenkamp,https://stackoverflow.com/users/6850554/jmuhlenkamp,"2,150",41983520
41908388,41908388,0,"I got the same horrible results. The easy fix was to stop using dropouts. So my code became:


m2 <- h2o.deeplearning(
training_frame=train, 
validation_frame=valid,   
x=1,
y=2,
activation=""Rectifier"",
hidden=c(25,25),             
epochs=100
)



This doesn't give perfect results, but much better.


Why? Dropouts are a way to deal with noisy data. Your data is the polar opposite of noisy. If using dropouts you normally have to give more hidden nodes, and more epochs, to compensate.


Going back to your linear function, H2O was only doing two scoring events, one at 10 epochs, one at 100 epochs. So, curious to see how epochs helped, I took manual control of when scoring happens: after every 5 epochs here. (I recommend against this for real work, but for kicking the tyres of H2O with artificial data sets like this, it can be educational.)


m3 <- h2o.deeplearning(
training_frame=train, 
validation_frame=valid,   
x=1,
y=2,
activation=""Rectifier"",
hidden=c(25,25),             
epochs=500,
train_samples_per_iteration = 50005, score_each_iteration=TRUE
)



The scoring history chart (from Flow) then looks like:




Early stopping kicked in at 143 epochs.",2017-01-28T09:47:19,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41896004
41841166,41841166,3,"The the problem is that you typed 
train_frame
 as the argument instead of 
training_frame
 (which defaults to 
None
).",2017-01-25T00:03:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",41840596
41842020,41842020,1,"The problem is that your function does nothing with respect the dataframe and based on your function definition it is not clear what your objective is.


fun = function(df) {
  1:2
}


if you look at h2o.ddply function documentation you will see that this function is used to apply a function on full data set based on certain criteria. 


I have changed your above example as below to explain it better:


> data1xH2O
   x row1
 1 1    1  
 2 1    2
 3 1    3
 4 1    4
 5 2    1
 6 2    2
 > fun1 = function(df) { df[,1]}
 > h2o.ddply(data1xH2O, 1:2, fun1)
     x row1 ddply_C1
   1 1    1        1
   2 1    2        1
   3 1    3        1
   4 1    4        1
   5 2    1        2
   6 2    2        2



Above the fun1 is extracting our column out from passed dataframe. Again if I change the fun to fun2 as below:


 > fun2 = function(df) { df[,2]}
 > h2o.ddply(data1xH2O, 1:2, fun2)
     x row1 ddply_C1
   1 1    1        1
   2 1    2        2
   3 1    3        3
   4 1    4        4
   5 2    1        1
   6 2    2        2",2017-01-25T01:36:41,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,41821274
41842069,41842069,0,"I did not see this question first however in the following answer fun1 and fun2 are creating the same sequence based on column name you choose. 


How to use : function in H2O ddply, R?


is that you are looking for?",2017-01-25T01:42:59,Community,https://stackoverflow.com/users/-1/community,1,41804489
41837966,41837966,2,"When you use h2o.assign it will create copy of given dataset as first argument into the name given as second argument i.e. key.


So if you will write the command as below:


valid  <- h2o.assign(df, ""hhh.hex"")



It will take df dataframe and create a new H2O specific dataframe name hhh.hex. So if you will call h2o.ls() below you will see new h2o specific dataframe as below:


> h2o.ls()

                           key
 1                     hhh.hex",2017-01-24T20:04:21,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,41788232
41837739,41837739,1,You should be using RESTful API to work with H2O backend like the way FLOW works. Based on RESTful API you can create a fully automated solution in a RESTful supported language to get it working.,2017-01-24T19:51:26,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,41725997
41785166,41785166,1,I found the answer myself there is a RestAPI I can use to do everything that i can do in the H2O Flow gui. FYI,2017-01-21T22:21:53,BumbleBeeBro,https://stackoverflow.com/users/7436842/bumblebeebro,23,41725997
41843860,41843860,0,"The problem you have reported as a bug in H2O as described:

https://0xdata.atlassian.net/browse/PUBDEV-3895


Also described here: 

https://community.h2o.ai/questions/1410/filter-h2oframe-on-pandas-dates-and-time-python.html",2017-01-25T05:12:00,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,41680746
41645916,41645916,2,"I would consider this a bug since R's data.frame can display the characters, but at the same time, the R H2OFrame cannot.  I checked that this works for H2OFrames in Python, so it's an R issue only.  I filed a bug 
here
.


Update:
 This has been fixed (I have checked that it's working in H2O 3.32.0.1, but it was probably fixed a while ago).",2017-01-14T01:37:27,,,,41627290
41629289,41629289,1,"I dont know if it is the best way but I have worked on Korean data before and this the process I generally follow. 
First, ensure that the data you need to read is encoded as ""UTF-8"". 
Second, ensure that the locale is set to English


Sys.getlocale(category=""LC_ALL"")



You can then read the file using the below statement, 


dat <- read.csv(""Test.txt"",header=T,encoding = ""UTF-8"",stringsAsFactors = F)

dat[,1]
[1] ""北京"" ""上海"" ""北京"" ""上海""

dat
        X.U.FEFF.X Y
1 <U+5317><U+4EAC> 1
2 <U+4E0A><U+6D77> 2
3 <U+5317><U+4EAC> 3
4 <U+4E0A><U+6D77> 4



As you can see, when you view the entire data.frame you see them as ""UTF-8"" encodes but you can also look at the chinese characters by looking using 
df[1,]
 and looking at each vector.",2017-01-13T07:18:35,ab90hi,https://stackoverflow.com/users/7374921/ab90hi,445,41627290
41641413,41641413,1,"Your problem is only related with R not showing encoded character inside H2O frames however the data inside h2o frames is still totally preserved as in original frame. Once you use H2O Web/FLOW UI and see the h2o frame you will see data inside h2o frame is exactly same as original frame. The following image shows results at various location i.e RStudio, R view window and in H2O FLOW UI




Please following the link below for a solution however you must be able to update locals in your machine to view those characters in the H2O data frames:


how to read data in utf-8 format in R?",2017-01-13T18:44:30,Community,https://stackoverflow.com/users/-1/community,1,41627290
41501645,41501645,2,"Yes


Not really, we are working on wrapping Spark's MLlib algorithms so you can run them from H2O's FlowUI and on wrapping H2O's algorithms so you can use them in MLlib's pipelines, though.


You need H2OContext only if you want to run H2O specific functionality.




Sparkling Water simply allows you to run H2O nodes inside Spark nodes, instead of bootstrapping the H2O cluster by hand. This also allows you to use data in both H2O and Spark.


@Edit:




None but you might have a long running Spark job, where you don't exit after doing some initial computation but lock the job (and need to kill it somehow). Then you can use FlowUI as normal. We simply start the HTTP server every time (even for demos). No reason not do to it.


You can either use one of our droplets - 
https://github.com/h2oai/h2o-droplets/tree/master/sparkling-water-droplet
 which is a template project, you add your logic in the main class and run 
./gradlew shadowJar
 and submit the jar with 
spark-submit
, it already contains all the jars. Or, as you mentioned you'll need to provide (though 
--jars
 or 
--packages
) all the necessary dependencies, H2O.jar included.",2017-01-06T08:20:17,,,,41501232
41441578,41441578,3,"You can do this with 
h2o.getGrid()
. Following on from your example code:


g_rmse <- h2o.getGrid(g@grid_id, ""rmse"")
g_rmse  #Output it



I've chosen root-MSE there. AUC is not available for your sample data: it has to be a binomial classification, and you are doing a regression.


The reason you are doing a regression is your 
y
 contains 0 and 1, so H2O has guessed it is numeric. You need to use 
as.factor()
 on that column, just after uploading it into H2O.


train <-  ...
trainHex <- as.h2o(train)
trainHex[,1] = as.factor(trainHex[,1])  #Add this

g <- ...



Then you can do this:


g_auc <- h2o.getGrid(g@grid_id, ""auc"", decreasing = TRUE)
g_auc



I've set it to 
decreasing=TRUE
 so that the best AUC is at the top.",2017-01-03T10:38:08,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41439307
41430002,41430002,2,"You are doing a multinomial classification; i.e. the prediction is going to be one of three classes. 
h2o.predict()
 is therefore returning 4 columns:


> predict(ann,newdata = testHex)
  |========================================================================================================================================================| 100%
  predict    setosa   versicolor    virginica
1  setosa 0.9999930 7.032604e-06 1.891484e-30
2  setosa 0.9998726 1.274161e-04 2.791200e-28
3  setosa 0.9999923 7.679687e-06 1.101218e-29
4  setosa 0.9999838 1.619749e-05 1.593254e-28
5  setosa 0.9999978 2.150244e-06 7.174795e-31
6  setosa 0.9999932 6.844831e-06 5.511857e-29

[150 rows x 4 columns]



I'm not completely sure what you are doing, but given this to get the predictions:


p = predict(ann,newdata = testHex)



You can do this to get a 1 for a correct answer, 0 for a mistake:


p$predict == testHex$Species



Or, doing it client-side:


p = as.data.frame( predict(ann,newdata = testHex) )
p$predict == iris$Species



More generally, 
h2o.grid()
 is better for experimenting with alternative parameters. I think this might be closer to your intention:


parts = h2o.splitFrame(as.h2o(iris), 0.8, seed=123)
trainHex = parts[[1]]
testHex = parts[[2]]

g = h2o.grid(""deeplearning"",
 hyper_params = list(
   seed = c(123456789,12345678,1234567),
   activation = c(""Rectifier"", ""Tanh"", ""TanhWithDropout"", ""RectifierWithDropout"", ""Maxout"", ""MaxoutWithDropout"")
   ),
 reproducible = TRUE,
 x = 1:4,
 y = 5,
 training_frame = trainHex,
 validation_frame = testHex,
 epochs = 1
 )
g  #Output the grid



(I've set epochs to 1 just to get it to finish quickly. Set to 50 if you want.)


I've used 
splitFrame()
 to use 80% as training data, 20% as test data; by assigning the test data to 
validation_frame
 the grid will score on that unseen data automatically for us.",2017-01-02T16:09:51,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41428543
41454135,41454135,5,"I think #2 is your best bet right now, since we don't currently have a function to do that in H2O.  I think this would be a useful utility, so  have created a JIRA ticket for it 
here
.  I don't know when it will get worked on, so I'd still suggesting coding up #2 for the time-being.


The SVMLight/LIBSVM format was originally developed for a particular SVM implementation (as the name suggests), but it's generic and not at all specific to SVM.  If you don't have labeled data, then you can fill in a dummy value where it expects a label.


To export an R data.frame in this format, you can use this 
package
 and there is more info 
here
.  You might be able to find better packages for this by searching 
""svmlight""
 or 
""libsvm""
 on 
http://rdocumentation.org
.


You can then read in the sparse file directly into H2O using the 
h2o.importFile()
 function with 
parse_type = ""SVMLight""
.",2017-01-03T23:49:10,Community,https://stackoverflow.com/users/-1/community,1,41340086
41299843,41299843,1,"Finally, I figure out the answers using the hint from the comment. 
The basic thing is we need to convert column into factor/enum before applying merge operation
. The data type of the column having either primary key or foreign key should be factor/enum.",2016-12-23T10:39:57,,,,41296728
41286109,41286109,1,"Your question is very general in nature- so my answer will have to be the same.  


Consider a recommender framework such as the one in Apache Mahout 
correlated co-occurance
.  Unlike the vanilla spark recommender, this implementation allows for multiple types of actions, such as viewed a web site, booked a trip their before, demographic information, etc.  


Now you would calculate the recommendations for each user at whatever interval. Recommendations being based on multiple criteria and what other people similar to this user has done. Consider your 'items' in this case to be every destination in the world.  So we now have every possible destination ranked for each user.  


It is then a trivial extension to index elastic search by user/the ordered list of that users recommended destinations.


For example, we have a user who has visited Berlin, looked at several hotels in Vienna, and is from Romainia. When the user types in ""au"", we would expect to see ""Austria"" come up in the results much higher than 'Austrailia'


Per the comments and down votes- you probably should have either A) asked a more specific programming question or B) asked this question on another forum such as Data Science Stack Exchange, fyi",2016-12-22T15:05:58,rawkintrevo,https://stackoverflow.com/users/2547342/rawkintrevo,659,41281064
41273481,41273481,2,"Just do 
h2o.init(startH2O=FALSE)
 and if it fails you know it wasn't running.


(Alternatively, you could make your own curl request to port 54321, and see if there is a reply.)


When you say ""multiple jobs running in parallel"", do you mean one instance of H2O, and it is making 2+ models at the same time? Or do you mean you are running 2+ instances of H2O, on a single machine, on different ports? If the latter, give the port number of interest to your 
h2o.init()
 call (but make sure you use the most recent version, the 
port
 arg was ignored until Nov 18th 2016: 
https://github.com/h2oai/h2o-3/pull/401
 )",2016-12-21T23:11:56,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41270947
64560352,64560352,1,"If you are looking for a way to just check the status without getting an error or exiting the script, you can use 
trycatch
 to achieve it.


assign(""is_h2o_running"", T, .GlobalEnv)

tryCatch(
    
    expr = {
        h2o.init(startH2O=FALSE)
    },
    error = function(e){ 
        print(e)
        assign(""is_h2o_running"", F, .GlobalEnv)
    },
    warning = function(w){
        print(w)
    }
)

print(paste0(""Is H2O running : "", is_h2o_running))",2020-10-27T18:02:33,Aman J,https://stackoverflow.com/users/2095411/aman-j,"1,835",41270947
56396530,56396530,0,"This is what you see if you try 
h2o.init(start_h2o=False)
 in Python.
""Warning: if you don't want to start local H2O server, then use of 
h2o.connect()

 is preferred.""",2019-05-31T13:59:30,Pouya BCD,https://stackoverflow.com/users/207180/pouya-bcd,"1,011",41270947
41218546,41218546,4,"They are completely independent implementations, and I doubt either has been tuned or designed with the way you are using it in mind (i.e. a single tree, 
min_rows
 set to 1). In this case it looks like R's gbm has used its single tree on learning the ""B"" inputs correctly, while 
h2o.gbm
 has concentrated on the ""A"" inputs.


When you start using real data and real settings, there may still be differences. There are a lot of parameters you are not touching (with 
h2o.gbm()
 at least, which is the one I'm familiar with). And there is also a stochastic element: try a hundred values of 
seed
 to h2o.gbm(), and a constant 
set.seed()
 before R's 
gbm
, and you will likely hit the same results on at least one of them.",2016-12-19T08:32:43,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41213721
41239636,41239636,3,"the problem is that you run out of PermGem memory which is not the same memory space as you usually configure for your driver and executors using


.set(""spark.driver.memory"", ""4g"")
.set(""spark.executor.memory"", ""4g"")



This is part of JVM's memory which contains loaded classes. To increase it for both spark driver and executors, call 
spark-submit
 or 
spark-shell
 command with following arguments.


--conf spark.driver.extraJavaOptions=""-XX:MaxPermSize=384m"" --conf spark.executor.extraJavaOptions=""-XX:MaxPermSize=384m""",2016-12-20T10:04:56,,,,41177401
41138415,41138415,1,"Use 
h2o.exportFile()
 (
h2o.export_file()
 in Python), with the 
parts
 argument set to -1. The -1 effectively means that each machine in the cluster will export just its own data. In your case you'd end up with 10 files, and it should be 10 times quicker than otherwise.


To read them back in, use 
h2o.importFile()
 and specify all 10 parts when loading:


frame <- h2o.importFile(c(
  ""s3n://mybucket/my.dat.1"",
  ""s3n://mybucket/my.dat.2"",
  ...
  ) )



By giving an array of files, they will be loaded and parsed in parallel.


For a local LAN cluster it is recommended to be using HDFS for this. I've had reasonable results by keeping the files on S3 when running a cluster on EC2.",2016-12-14T08:58:13,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,41104540
41163109,41163109,0,"I suggest to export the dataframe from Spark into SVMLight file format (see MLUtils.saveAsLibSVMFile(...). This format can be then natively ingested by H2O.


As Darren pointed out you can export data from H2O in multiple parts which speeds up the export. However H2O currently only supports export to CSV files. This is sub-optimal for your use case of very sparse data. This functionality is accessible via the Java API:


water.fvec.Frame.export(yourFrame, ""/target/directory"", yourFrame.key.toString, true, -1 /* automatically determine number of part files */)",2016-12-15T11:31:07,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,41104540
41080275,41080275,6,"You can either extract that information from the model fit (for example, if you pass a 
validation_frame
), or you can use 
h2o.performance()
 to get obtain a H2OBinomialModel performance object and extract the confusion matrix using 
h2o.confusionMatrix()
.


Example:


fit <- h2o.deeplearning(x, y, training_frame = train, validation_frame = valid, ...)
h2o.confusionMatrix(fit, valid = TRUE)



Or 


fit <- h2o.deeplearning(x, y, train, ...)
perf <- h2o.performance(fit, test)
h2o.confusionMatrix(perf)",2016-12-10T20:59:32,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",41075416
41080355,41080355,3,"Summarizing comments (answers) above: 
my_test
 must be an H2OFrame.  You can convert it from an R data.frame to H2OFrame by 
hf <- as.h2o(my_test)
, or if you load the data from disk using 
my_test <- h2o.importFile(""test.csv"")
, it will already be an H2OFrame without having to be copied from R memory.",2016-12-10T21:09:15,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",41058856
41054905,41054905,5,"Partially, I figure-out the answer using following links: 
http://datasocial.onsocialengine.com/post/4171645/spark-mllib-or-h2o


Detailed comparative analysis is provided here: 
https://github.com/szilard/benchm-ml


Slides of bench-marking results: 
https://speakerdeck.com/szilard/benchmarking-machine-learning-tools-for-scalability-speed-and-accuracy-la-ml-meetup-at-eharmony-june-2015


Video of bench-marking results: 
https://vimeopro.com/eharmony/talks/video/132838730


Technical report on Analysis of Machine Learning Library: 
https://github.com/chauhansaurabhb/Analysis-of-H2O-vs-SparkMLlib/blob/master/MLLibrary.pdf",2016-12-09T07:07:37,,,,41054025
43358594,43358594,2,"I think the problem is that for 
h2o.predict
, it can't correctly deal with the interaction between two factors.


Locate the Issue


Here I can show you that the 
h2o.predict
 incorrectly labeled your interaction terms.


pred1 <- as.data.frame(h2o.predict(h2o_glm1, hf))$p1
diff <- unname(predict(r_glm1, type = ""link"")) - log(pred1/(1-pred1))



pred1
 is the response prediction from your 
h2o_glm1
 and 
diff
 calculates the difference between 
link prediction
 of 
r_glm1
 and 
h2o_glm1
. The link prediction is just the linear combination of your input data with coefficient.


After this we can create a table of the difference by 
dow
 and 
hour


tapply(diff, list(indf$dow, indf$hour), mean)
#               6           7           8
# Fri -0.01645868 -0.01580134 -0.01580118
# Sat -0.01580673  0.01580109 -0.14319379
# Sun -0.01580207 -0.53848173  0.68233048
tapply(diff, list(indf$dow, indf$hour), sd)
# all 0



The standard deviation are all 0 indicates the difference of prediction in each levels is constant. This can prove that the errors come from the grouping of 
dow
 and 
hour
.


We can also look further to see how 
h2o.predict
 labels the interaction term.
Here I can create the correct coefficient matrix for 
dow
 and 
hour
:


coef <- h2o_glm1@model$coefficients
coef_M <- matrix(c(0,0,0,
                   0,coef[2],coef[3],
                   0,coef[4],coef[5]),3,byrow = TRUE)

#      [,1]        [,2]        [,3]
# [1,]    0  0.00000000  0.00000000
# [2,]    0  0.01580116 -0.12739263
# [3,]    0 -0.66587428  0.01645634



Then subtract the difference from this matrix, we can find the coefficient used by 
h2o.predict
:


- tapply(diff, list(indf$dow, indf$hour), mean) + coef_M
#              6           7             8
# Fri 0.01645868  0.01580134    0.01580118
# Sat 0.01580673  6.854821e-08  0.01580116
# Sun 0.01580207 -0.1273926    -0.66587414

coef[2:5]
# dow_hour.Sat_7 dow_hour.Sat_8 dow_hour.Sun_7 dow_hour.Sun_8 
#     0.01580116    -0.12739263    -0.66587428     0.01645634 



Here I also listed the coefficient of interaction terms of 
h2o_glm1
. You can see that all the values in the last table match with certain coefficients of the interaction terms but not the correct one. Therefore, the matching of the interaction of two factors is incorrect in 
h2o.predict


#          6       7        8
# Fri  Sun_8   Sat_7    Sat_7
# Sat  Sat_7       0    Sat_7
# Sun  Sat_7   Sat_8    Sun_7



Change to Numerical


However, the 
h2o.predict
 can deal with interaction between a factor variable and a numerical variable or two numerical variables.


If we change 
hour
 from factor to numeric: 
indf$hour = as.numeric(as.character(indf$hour))
 and do the same modeling process. Then the difference between base R 
glm
 and 
h2o.glm
 is quite little: 


indf2 <- indf
indf2$hour <- as.numeric(as.character(indf$hour))
r_glm3 <- glm(y ~ dow + hour + dow:hour,
          family = ""binomial"",
          data = indf2)
hf2 <- as.h2o(indf2)
h2o_glm3 <- h2o.glm(2:3,
                    1,
                    hf2,
                    solver = ""IRLSM"",
                    family = ""binomial"",
                    interactions = 2:3,
                    lambda_search = FALSE,
                    lambda = 0,
                    compute_p_values = TRUE)
max(abs(predict(r_glm3, type = ""response"") - as.data.frame(h2o.predict(h2o_glm3, hf2))$p1))
# 9.866078e-08



Create Interaction Term


I believe the best alternative solution, as you also stated in your question, is to create a new interaction variable. Here is another alternative solution, using 
h2o.interaction
 to generate this term:


hf3 <- hf
hf3$dow_hour <- h2o.interaction(hf,factors = 2:3, pairwise = TRUE, max_factors = 100, min_occurrence = 1)

h2o_glm4 <- h2o.glm(5,
                    1,
                    hf3,
                    solver = ""IRLSM"",
                    family = ""binomial"",
                    lambda_search = FALSE,
                    lambda = 0,
                    compute_p_values = TRUE)
max(abs(predict(r_glm1, type = ""response"") - as.data.frame(h2o.predict(h2o_glm4, hf3))$p1))
# 3.356773e-07",2017-04-12T01:11:01,,,,41049921
41029099,41029099,1,"Now, the server is using a 32 bit Java version and I do not have admin access. What do I need to do to get more cluster memory?




This is the problem. 32-bit processes can't allocate more than 4 GB of RAM. So your 196 GB server effectively rendered useless with 32 bit JVM. Update to 64-bit JVM and it would solve it.",2016-12-07T23:15:06,Yegor Chumakov,https://stackoverflow.com/users/1423319/yegor-chumakov,450,41029009
41029376,41029376,0,"set.seed(1234)
x1 = rnorm(100,0,1)
x2 = as.factor(rep(c(""A"",""B"",""C"",""D""), each = 25))
y = as.factor(rep(0:1, each = 50))
data = data.frame(x1 = x1, x2 = x2, y = y)



Interactions can be specified using a "":"" in the formula argument


# glm base example
fit <- glm(data = data, y ~ x1 + x2 + x1:x2, family = ""binomial"")
print(fit)



Using h2o.glm pairwise interactions can be specified by passing column indices to the interactions argument 


# h2o.glm example
library(""h2o"")
h2o.init(nthreads = -1)
data.hex = as.h2o(data)
h2o_fit <- h2o.glm(x = 1:2, y = 3, training_frame = data.hex, family = ""binomial"", interactions = 1:2)
h2o_fit@model$coefficients_table
h2o.shutdown(prompt = F)",2016-12-07T23:44:19,Peter Schubert,https://stackoverflow.com/users/6637359/peter-schubert,1,41027353
41029099,41029099,1,"Now, the server is using a 32 bit Java version and I do not have admin access. What do I need to do to get more cluster memory?




This is the problem. 32-bit processes can't allocate more than 4 GB of RAM. So your 196 GB server effectively rendered useless with 32 bit JVM. Update to 64-bit JVM and it would solve it.",2016-12-07T23:15:06,Yegor Chumakov,https://stackoverflow.com/users/1423319/yegor-chumakov,450,41023086
41102023,41102023,0,"thanks for the report.


You have actually found a bug in sparkling-water. The fix is already here 
https://github.com/h2oai/sparkling-water/pull/151
 and will go into the next release.


In the meanwhile, the simple workaround is to set 
conf.set(""spark.ext.h2o.repl.enabled"",""false"")
 on the 
sparkConf
 before you create 
sparkContext
 as Mateusz pointed out ( if you don't run Scala code from Flow UI )",2016-12-12T13:30:27,,,,41006726
40889226,40889226,2,"To find out how many epochs a model used, the best way is to look at the score history. E.g. for a model 
m
:


h2o.scoreHistory(m)



(Or for a graphical version, plot the model: 
plot(m)
 )


That may be too much information, so reduce it to just show epochs with:


h2o.scoreHistory(m)[,c(""epochs"")]



(I just noticed 
h2o.scoreHistory(m)$epochs
 will work, too.)


Show the epochs, of the final model that was returned, with:


last( h2o.scoreHistory(m)[,c(""epochs"")] )



By the way, if you had just printed the grid object you should have seen epochs as one of the columns, if it was one of your hyper-parameters.


Answering the question you didn't ask:
 take a look at early stopping, which will free you from having to try to guess in advance how many epochs you need, and therefore also save you a hyper-parameter in your grid searches.


You could also simply make the model with the highest epoch value you are considering, and look in the score history to get the scores at each of the other epoch values you were interested in.",2016-11-30T13:08:38,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40864176
47202632,47202632,0,"H2O is a platform for Machine Learning written from scratch in Java, and a collection of specific algorithms re-implemented from scratch in Java to be parallel and distributed.


The H2O package for R and Python exposes this specific set of algorithms available in the H2O platform.  The H2O R/Python package use a REST API underneath the hood to talk to an H2O cluster (including the case of a cluster of size 1 running on your local machine).  So it's a client/server architecture.


Here is a link describing the H2O software architecture:




http://docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html




R and Python of course also have thousands of other packages (many of which are actually implemented in Fortran and C).  What H2O does not do is take an arbitrary R package written in Fortran and magically parallelize and distribute it on the Java-based H2O platform.


Think of the H2O package as another package that implements several algorithms (GBM, for example) in a scalable way really well; as something that can be used side-by-side to complement your existing R/Python packages in RStudio/Jupyter, rather than trying to replace all of them.",2017-11-09T13:06:16,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",40858769
58550891,58550891,0,"I too had a similar problem with data having no missing values etc. The fix that seems to work for me is setting 
enable_assertions = FALSE
 when initializing 
h2o
.


h2o.init(nthreads = ..., enable_assertions = FALSE)",2019-10-25T00:58:53,kangaroo_cliff,https://stackoverflow.com/users/3651529/kangaroo-cliff,"6,222",40849546
40829547,40829547,4,"Deeplearning with H2O will not be reproducible if it is run on more than a single core. The results and performance metrics may vary slightly from what you see each time you train the deep learning model. The implementation in H2O uses a technique called ""Hogwild!"" which increases the speed of training at the cost of reproducibility on multiple cores.


So if you want reproducible results you will need to restrict H2O to run on a single core and make sure to use a 
seed
 in the 
h2o.deeplearning
 call.


Edit based on comment by Darren Cook:

I forgot to include the 
reproducible = TRUE
 parameter that needs to be set  in combination with the 
seed
 to make it truly reproducible. Note that this will make it a lot slower to run. And is is not advisable to do this with a large dataset.


More information on 
""Hogwild!""",2016-11-27T13:33:21,,,,40827940
40802277,40802277,9,"The deep-learning autoencoder is always unsupervised learning. The ""supervised"" part of the article you link to is to evaluate how well it did.


The following example (taken from ch.7 of my book, Practical Machine Learning with H2O, where I try all the H2O unsupervised algorithms on the same data set - please excuse the plug) takes 563 features, and tries to encode them into just two hidden nodes.


m <- h2o.deeplearning(
  2:564, training_frame = tfidf,
  hidden = c(2), auto-encoder = T, activation = ""Tanh""
  )
f <- h2o.deepfeatures(m, tfidf, layer = 1)



The second command there extracts the hidden node weights. 
f
 is a data frame, with two numeric columns, and one row for every row in the 
tfidf
 source data. I chose just two hidden nodes so that I could plot the clusters:




Results will change on each run. You can (maybe) get better results with stacked auto-encoders, or using more hidden nodes (but then you cannot plot them). Here I felt the results were limited by the data.


BTW, I made the above plot with this code:


d <- as.matrix(f[1:30,]) #Just first 30, to avoid over-cluttering
labels <- as.vector(tfidf[1:30, 1])
plot(d, pch = 17) #Triangle
text(d, labels, pos = 3) #pos=3 means above



(P.S. The original data came from 
Brandon Rose's excellent article on using NLTK
. )",2016-11-25T10:03:59,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40779282
48517280,48517280,1,"In some aspects encoding data and clustering data share some overlapping theory. As a result, you can use Autoencoders to cluster(encode) data.


A simple example to visualize is if you have a set of training data that you suspect has two primary classes. Such as voter history data for republicans and democrats. If you take an Autoencoder and encode it to two dimensions then plot it on a scatter plot, this clustering becomes more clear. Below is a sample result from one of my models. You can see a noticeable split between the two classes as well as a bit of expected overlap.



The code can be found 
here


This method does not require only two binary classes, you could also train on as many different classes as you wish. Two polarized classes is just easier to visualize. 


This method is not limited to two output dimensions, that was just for plotting convenience. In fact, you may find it difficult to meaningfully map certain, large dimension spaces to such a small space.


In cases where the encoded (clustered) layer is larger in dimension it is not as clear to ""visualize"" feature clusters. This is where it gets a bit more difficult, as you'll have to use some form of supervised learning to map the encoded(clustered) features to your training labels. 


A couple ways to determine what class features belong to is to pump the data into knn-clustering algorithm. Or, what I prefer to do is to take the encoded vectors and pass them to a standard back-error propagation neural network. Note that depending on your data you may find that just pumping the data straight into your back-propagation neural network is sufficient.",2018-01-30T08:48:29,Kenny Cason,https://stackoverflow.com/users/403682/kenny-cason,12.3k,40779282
40778389,40778389,1,"You can take a look at this 
github repository.


In this what is being done is as soon as a GET request is arrived, it takes out the data from the Cassandra and then Collect the data and throws it back as the response.


So in your case :


What you can do is , as soon as you recieve a POST request , you can get the parameters from the request and perform the operations accordingly using these parameters and the collect the Result on the master and then throw it back to the user as the Response.


P.S:
 Collecting on Master is a bit tricky and lot of data can cause OOM. What you can do is save the results on hadoop and send back the URL to the Results or something like that.


For more info look into this blog related to this github:

https://blog.knoldus.com/2016/10/12/cassandra-with-spark/",2016-11-24T05:04:44,Community,https://stackoverflow.com/users/-1/community,1,40776608
40652307,40652307,2,"If you play with the URL (change the 10 to an 8) - you'll find:


http://h2o-release.s3.amazonaws.com/h2o/rel-turing/8/index.html",2016-11-17T10:23:41,sebastian-c,https://stackoverflow.com/users/1465387/sebastian-c,15.4k,40651735
40607714,40607714,5,"If you have not yet already shutdown the H2O instance where the model was made, you can still go and get it again. Either find it in Flow, and save from there, or in an R session, use 
model = h2o.getModel(""theModelId"")
 (if you don't know the model ID, that is one of the few useful things you will be able to find in your ""my_model.RData"" file).


But I'm guessing you have already shut it down, in which case, sorry, there is no way back. You will need to rebuild the model.


Background:
 I think you've already realized, but for anyone else reading this, the 
model
 object in your R session is just a summary of information about the model, a collection of meta data about it. The actual model exists not in the R client, but in the H2O cluster, so has to be saved with an H2O command.",2016-11-15T10:40:36,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40605544
40545929,40545929,1,"My suggestion is to open Flow (
http://localhost:54321
) in a browser, then start Firebug (or the equivalent in your browser of choice), and the network tab. Then do a file import from Flow, then the parse, and make a note of exactly what it is sending.


(Alternatively do the import from R or Python with a packet sniffer going, but that sounds like harder work.)


Did you do the /3/ImportFiles calls first?
(I actually see three calls: ImportFiles, ParseSetup, Parse.)


In my quick test I'm seeing the ""nfs://"" prefix on all the paths. Don't know if that is important.


But, my first guess would be that you should be using 
--data-urlencode
 instead of 
--data
. Or manually URL-encode your data.",2016-11-11T10:24:28,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40543314
40399241,40399241,3,"It seems, your error is : 




'C:\Program' is not recognized as an internal or external command,
  operable program or batch file. Error: Command failed (1)




It happens due to the space character in location path 
(C:\Program Files)
 path. According to the documentation, 


If you want to be able to build packages from sources, we recommend that you choose an 
installation path not containing spaces.



Please refer the link : 
How do I install R for Windows?


Try changing the installation location. Then it should work fine.",2016-11-03T10:32:51,Nishu Tayal,https://stackoverflow.com/users/870483/nishu-tayal,20.7k,40398676
40370180,40370180,1,"H2O binary models are not necessarily compatible between major versions of H2O.  If you want to load a model using H2O 3.10.*, that model will have to have been trained using 3.10 rather than 3.6.",2016-11-01T23:27:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",40365149
40364315,40364315,2,"It says it has been running 13hrs. So what you are seeing is a cluster that is already running, and was (probably) started with default settings.


So, before doing your h2o.init() command you need to do h2o.shutdown():


h2o.shutdown()
h2o.init(nthreads = -1,max_mem_size = ""8g"")



(Remember when you shut down H2O that all models and data are lost, so use 
h2o.exportFile()
 and/or 
h2o.saveModel()
 if any of it cannot easily be re-created.)


UPDATE:
 I just noticed you said you had an 8GB laptop? I'd recommend not allocating more than 90% to H2O if the machine is dedicated, to be sure there is some left for the OS, Flow web server, etc.. (The 
EC2 scripts
 use 90%.) And if you intend to do other stuff on your notebook (run RStudio, check email, use StackOverflow in a browser window, etc.) subtract the memory for all that first. (My notebook is 8GB, and my general-purpose machine, so I usually give H2O ""4g"" if I think I'll be making a lot of models, ""2g"" or ""3g"" otherwise.)",2016-11-01T16:29:10,,,,40358476
40365665,40365665,0,"Regarding 
nthreads
 defaulting to 2 -- to the best of my knowledge, that is a CRAN policy restriction, which is why it's set to 2 instead of -1 (recommended).",2016-11-01T17:47:33,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",40358476
40365216,40365216,1,"yes, right now demo is Python 2 specific. However, we will update it to match Python 3 syntax. I meantime feel free to modify code or look at DeepWater which introduces Deep Learning on top of MxNet (and TF, and Caffe - in progress) 
https://github.com/h2oai/deepwater",2016-11-01T17:19:03,Michal,https://stackoverflow.com/users/5089773/michal,437,40355123
40376640,40376640,1,"Assuming you are using this python notebook: 
https://github.com/h2oai/sparkling-water/blob/master/py/examples/notebooks/TensorFlowDeepLearning.ipynb


The changes for Python 3:


In [8] put parantheses around:


print( [c.dim for c in H2O_w] )
print( [c.dim for c in H2O_b] )



In [3] add a 
list()
 around the use of 
range()
:


sc.parallelize(list(range(NODES)), NODES).map(map_fun).collect()



And [4]:


self._x = list( range(784) )



(I notice this change had already been done in the call to 
train()
.)


I couldn't spot anything else, and those changes should be compatible with Python 2. If you still get errors can you post in which section of the notebook that the error happens in?",2016-11-02T09:39:03,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40355123
40283304,40283304,2,"It is a bug in h2o. H2o returns date time in milliseconds while R expects seconds. See jira 
issue 3434
.


What you can do in the meantime is recode the date column:

as.Date(structure(returned.dataset$week_of_date/1000, class = c(""POSIXct"", ""POSIXt"")))",2016-10-27T11:18:44,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,40275946
40286029,40286029,0,"Refer to the response by phiver for a more detailed answer, but another simple workaround would be to convert the date columns to character before passing to H2O (if you do not need the column in a date format in H2O).  Here is a simple example.


# construct a sample df with a date format column
df <- data.frame(week_of_date = as.Date(c('2015-09-29','2015-10-05')))
str(df$week_of_date)
Date[1:2], format: ""2015-09-29"" ""2015-10-05""

# convert the column to H2O
df$week_of_date <- as.character(df$week_of_date)
str(df$week_of_date)
chr [1:2] ""2015-09-29"" ""2015-10-05""

# convert to H2OFRAME and pass back to R data.frame and re-convert to date
df.hex <- as.h2o(df)
df2 <- as.data.frame(df.hex)
df2$week_of_date <- as.Date(df2$week_of_date)
str(df2$week_of_date)
Date[1:2], format: ""2015-09-29"" ""2015-10-05""",2016-10-27T13:36:28,jmuhlenkamp,https://stackoverflow.com/users/6850554/jmuhlenkamp,"2,150",40275946
51470558,51470558,0,"Both answers above are great. However, my workaround which I deem more efficient would be to pass the dataset to h2o excluding the date column. Then when you train a model and then make predictions, these would have the same amount of fields/rows as that of the original dataset for which you could just attach the Date column to the predictions vector or matrix.


Of course, the predictions in this solutions is related to the period as for backtesting.",2018-07-23T01:26:57,Abdul Basit Khan,https://stackoverflow.com/users/6117474/abdul-basit-khan,724,40275946
56944038,56944038,0,"Converting to 
H2o
 and back is easy if the date-time columns are in the proper format. (Accuracy of times in milliseconds cab be lost). As mentioned in the H20 
FAQ




H2O is set to auto-detect two major date/time formats. The first
  format is for dates formatted as yyyy-MM-dd. ... The second date
  format is for dates formatted as dd-MMM-yy. 


Times are specified as HH:mm:ss. HH is a two-digit hour and must be a
  value between 0-23 (for 24-hour time) or 1-12 (for a twelve-hour
  clock). mm is a two-digit minute value and must be a value between 0-59. 
  ss is a two-digit second value and must be a value between 0-59.




Example


Example Data


dates <- c(""02/27/92"", ""02/27/92"", ""01/14/92"", ""02/28/92"", ""02/01/92"")
times <- c(""23:03:20"", ""22:29:56"", ""01:03:30"", ""18:21:03"", ""16:56:26"")
x <- paste(dates, times)
df <- data.frame(datetime = strptime(x, ""%m/%d/%y %H:%M:%S""))
# > df
#              datetime
# 1 1992-02-27 23:03:20
# 2 1992-02-27 22:29:56
# 3 1992-01-14 01:03:30
# 4 1992-02-28 18:21:03
# 5 1992-02-01 16:56:26



Change the format to one that H2o prefers


# Change format 
df$datetime <- format(df$datetime, format = ""%Y-%m-%d %H:%M:%S"")

#H2o format
h2o_df <- as.h2o(df)

# Convert back
back_df <- as.data.frame(h2o_df)

back_df
#              datetime
# 1 1992-02-27 23:03:20
# 2 1992-02-27 22:29:56
# 3 1992-01-14 01:03:30
# 4 1992-02-28 18:21:03
# 5 1992-02-01 16:56:26",2019-07-09T00:41:08,,,,40275946
40227836,40227836,1,"If memory serves, Grid grid = (Grid) gs.get(), returns you a complete grid. Now, what constitutes the best model? If you say that's the highest ROC, then sort the list by descending ""auc"" and select first element - much like in 
this post
.",2016-10-24T21:26:46,Community,https://stackoverflow.com/users/-1/community,1,40227519
40213575,40213575,3,"If 
g
 is your grid object, then:


g.sort_by('auc', False);



will give you the models ordered by AUC. The 2nd parameter of False means highest AUC will be first. It returns a 
H2OTwoDimTable
 object, so you can select the first model (the best model, by AUC) that way.


I believe it should be sorting based on scores on the validation set, not training set. However you can specify it explicitly with:


g.sort_by('auc(valid=True)', False);",2016-10-24T08:13:05,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40204743
40208004,40208004,3,"Currently there is no REST API endpoint to directly convert some JSON record into a 
Frame
 object. Thus, the only way forward for you would be to first write the data to a CSV file, then upload it to h2o using 
POST /3/PostFile
, and then parse using 
POST /3/Parse
.


(Note that 
POST /3/PostFile
 endpoint is not in the documentation. This is because it is 
handled separately
 from the other endpoints. Basically, it's an endpoint that takes an arbitrary file in the body of the post request, and saves it as ""raw data file"").


The same job is much easier to do in Python or in R: for example in order to upload some dataset into h2o for scoring, you only need to say


df = h2o.H2OFrame(plaindata)",2016-10-23T21:33:52,Alberto Bonsanto,https://stackoverflow.com/users/1689706/alberto-bonsanto,18k,40184473
48465047,48465047,0,"I am already doing something similar in my project. Since, there is no REST API endpoint to directly convert JSON record into a Frame object. So, I am doing the following: -


1- For Model Building:- first transfer and write the data into the CSV file where h2o server or cluster is running.Then import data into the h2o using POST /3/ImportFiles, and then parse and build a model etc. I am using the h2o-bindings APIs (RESTful APIs) for it. Since I have a large data (hundreds MBs to few GBs), so I use /3/ImportFiles instead POST /3/PostFile as latter is slow to upload large data.


2- For Model Scoring or Prediction:- I am using the Model MOJO and POJO. In your case, you use POST /3/PostFile as suggested by @Pasha, if your data is not large. But, as per h2o documentation, it's advisable to use the MOJO or POJO for model scoring or prediction in a production environment and not to call h2o server/cluster directly. MOJO and POJO are thread safe, so you can scale it using multithreading for concurrent requests.",2018-01-26T16:04:21,,,,40184473
40186343,40186343,4,"what you need is


sorted_grid = grid_search.get_grid(sort_by='auc',decreasing=True)
print(sorted_grid)



you can change decreasing to False if you would prefer",2016-10-21T22:35:14,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",40179875
40184202,40184202,1,"h2o.save_model will save the binary model to the provided file system, however, looking at the Java application above it seems you want to use model into a Java based scoring application. 


Because of that you should be using h2o.download_pojo API to save the model to local file system along with genmodel jar file. The API is documented as below:


download_pojo(model, path=u'', get_jar=True)
Download the POJO for this model to the directory specified by the path; if the path is """", then dump to screen.

:param model: the model whose scoring POJO should be retrieved.
:param path: an absolute path to the directory where POJO should be saved.
:param get_jar: retrieve the h2o-genmodel.jar also.



Once you have download POJO, you can use the above sample application to perform the scoring and make sure the POJO class name and the ""modelClassName"" are same along with model type.",2016-10-21T19:30:08,tRuEsAtM,https://stackoverflow.com/users/2349082/truesatm,"3,699",40157468
40159426,40159426,0,"Background: What you are seeing is one-hot encoding: a linear model can only deal with numbers, not categories. (Deep learning too.) So, it makes a boolean variable for each category (i.e. each factor level). E.g. gender_male will be 1 if they are male, 0 otherwise, while gender_female will be 1 if they are female, 0 otherwise. When you add interactions, you are seeing is a boolean for each possible combination of the categories.


H2O's deep learning algorithm has 
use_all_factor_levels
 as an argument, which defaults to true. If you set it to false then one of the factors will be done implicitly. For two-level factors that means you will get just a single column, e.g. 0 for male, 1 for female. This would give you the reduced fields you were expecting.


Unfortunately 
h2o.glm()
 doesn't have that option at the moment, and neither does 
h2o.interaction()
 as far as a I can see.


You could simulate it yourself by using 
h2o.ifelse()
, with 
h2o.cbind()
. E.g.


interact.hex <- h2o.cbind(
  Titanic.hex[,c(""Class"",""Survived"")],
  h2o.ifelse(Titanic.hex$Age == ""Adult"", 1, 0),
  h2o.ifelse(Titanic.hex$Sex == ""Female"", 1, 0)
  )
interact.hex <- h2o.cbind(
  interact.hex,
  h2o.ifelse(interact.hex$C1 == 1 && interact.hex$C10 == 1, 1, 0)
)



But that is a bit tedious, isn't it, and the columns could do with renaming afterwards.",2016-10-20T16:09:16,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40144894
40160394,40160394,0,"Posting my own workaround here that does what I want.  However, I'd still be happy to see a more elegant or built-in answer here.


# create H2OFrame and interact as in the question
Titanic.hex <- as.h2o(Titanic)
interact.hex <- h2o.cbind(Titanic.hex[,c(""Survived"",""Age"",""Sex"")]
                          ,h2o.interaction(Titanic.hex
                          ,factors = list(c(""Age"", ""Sex""))
                          ,pairwise = T
                          ,max_factors = 99
                          ,min_occurrence = 1))

# Define a function that collapses interaction levels
collapse_level1_interacts <- function(df, column, col1, col2){
  level1 <- rbind(
    data.table::CJ(h2o.levels(df[,col1])[1], h2o.levels(df[,col2]))
    ,data.table::CJ(h2o.levels(df[,col1]), h2o.levels(df[,col2])[1]))
    level1 <- paste(level1$V1, level1$V2, sep='_')
    df[,column] <- h2o.ifelse(df[,column] %in% level1, '00000', df[,column])
    return(df)
}

# Run the H2oFrame through the function
interact.hex2 <- collapse_level1_interacts(interact.hex, ""Age_Sex"", ""Age"", ""Sex"")

# Verify that we have only 2 levels for interaction
h2o.levels(interact.hex2$Age_Sex)
[1] ""00000""      ""Child_Male""

# Verify that we have only 1 dummy for the interaction
interact.h2o.glm <- h2o.glm(2:ncol(interact.hex2)
                            ,""Survived""
                            ,interact.hex2
                            ,family = 'binomial'
                            ,lambda = 0)
h2o.varimp(interact.h2o.glm)$names
[1] ""Age.Child""          ""Sex.Male""           ""Age_Sex.Child_Male"" """"",2016-10-20T17:04:44,,,,40144894
40125551,40125551,4,"Yes, you simply need to cbind the information from the frames that you want as your final output. Here is a full example: I'm doing a regression to predict a patient's height based on their age and risk category. (!)


import h2o
h2o.init()

patients = {
  'age':[29, 33, 65],
  'height':[188, 157, 175.1],
  'name':[""Tom"", ""Dick"", ""Harry""],
  'risk':['A', 'B', 'B']
  }

train = h2o.H2OFrame.from_python(
  patients,
  destination_frame=""patients""
  )

m = h2o.estimators.H2ODeepLearningEstimator()
m.train([""age"",""risk""], ""height"", train)
p = m.predict(train)

train[""name""].cbind(p[""predict""])



As I don't have any test data, for the sake of an example I predict on the training data. The final step is to take the columns from 
train
 and combine with the columns from 
p
. (With a categorization, you'll get additional columns, which you may or may not want to include.)


NOTE:
 The cbind operation takes place in your H2O cluster, not on the client. So it works perfectly well if this is 100 million rows of data spread across multiple machines.


P.S. Do 
m.train([""age"",""height""], ""risk"", train)
 to do a categorization instead.",2016-10-19T08:05:12,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,40121673
40009966,40009966,2,"you can use 
h2o.grid()
 to do your grid search


# specify your hyper parameters
hyper_params = list( ntrees = c(100,200,300,400), learn_rate =  c(1,0.5,0.1) )

# then build your grid
grid <- h2o.grid(
## hyper parameters
hyper_params = hyper_params,

## which algorithm to run
algorithm = ""gbm"",

## identifier for the grid, to later retrieve it
grid_id = ""my_grid"", 

## standard model parameters
x = features, 
y = label, 
training_frame = train, 
validation_frame = valid,

## set a seed for reproducibility
seed = 1234)



you can read more about how h2o.grid() works in the R documentation 
http://docs.h2o.ai/h2o/latest-stable/h2o-r/h2o_package.pdf",2016-10-12T23:30:09,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",40006311
40015217,40015217,0,"Lauren's answer
, to use grids, is the best one here. I'll just quickly point out that what you have written is a usable approach, and one you can fall back on when grids don't do something you need.


Your example didn't include any data (see 
https://stackoverflow.com/help/mcve
) so I couldn't run it, but I corrected the couple of syntax issues I noticed (R's for-in loop directly gives you the value, not the index, and parentheses around the 2nd for loop):


ntrees <- c(100,200,300,400)
learn_rate <- c(1,0.5,0.1)
for (n in ntrees){
  for (l in learn_rate){
    gbm_model <- h2o.gbm(
      features, label, training_frame = train, validation_frame = valid,
      ntrees = n,max_depth = 5,learn_rate = l
      )
    print(c(n,l,h2o.mse(h2o.performance(gbm_model, valid = TRUE))))
  }
}



An example of when you'd use nested loops, like this, is when you want to skip certain combinations. E.g. You might decide to only test ntrees of 100 with learn rate of 0.1, which would then look like this:


ntrees <- c(100,200,300,400)
learn_rate <- c(1,0.5,0.1)
for (n in ntrees){
  for (l in learn_rate){
    if(l == 0.1 && n > 100)next  #Skip when n is 200,300,400
    gbm_model <- h2o.gbm(
      features, label, training_frame = train, validation_frame = valid,
      ntrees = n,max_depth = 5,learn_rate = l
      )
    print(c(n,l,h2o.mse(h2o.performance(gbm_model, valid = TRUE))))
  }
}",2016-10-13T07:49:56,Community,https://stackoverflow.com/users/-1/community,1,40006311
55873665,55873665,2,"All you have to do is to shutdown the existing cluster if one is open and running. 


h2o.cluster.shutdown()



And restart / reinitiate cluster using


h2o.init()",2019-04-26T19:09:30,Bharath Kumar Mittapally,https://stackoverflow.com/users/11417388/bharath-kumar-mittapally,29,39963181
39967391,39967391,1,"Change 
model.start
 into 
model.train
 (3rd line from the bottom), and it should work.


The documentation for 
model.start()
 method says ""Train the model asynchronously"". This means that the model is being trained in the background and is not available right away for the prediction call.


The 
model.train()
 method on the other hand waits until the training is completed before continuing.",2016-10-10T21:59:06,Pasha,https://stackoverflow.com/users/958624/pasha,"6,540",39963181
39843657,39843657,2,"1) please dont use spark 2 with sw 1.6.5 - it won't work. We released sw2.0 for scala 2.11 
https://mvnrepository.com/artifact/ai.h2o/sparkling-water-core_2.11


2) you're only adding SW core in your build, the classes you are looking for are in sparkling-water-ml 
https://mvnrepository.com/artifact/ai.h2o/sparkling-water-ml_2.11",2016-10-04T03:23:56,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,39838518
40225894,40225894,0,"I have used below versions for running H2O example with Maven pom.xml and it is working




Spark - 1.6


Sparkling water - 1.6.8
 


ai h2o - 3.10.0.8




Here is maven pom.xml (please refer to GIT repo - 
https://github.com/seerampavan/H2oTesting/blob/master/pom.xml
)


<properties>
    <spark.version>1.6.0-cdh5.7.1</spark.version>
    <scala.version>2.10.4</scala.version>
    <scala.binary.version>2.10</scala.binary.version>
    <top.dir>${project.basedir}/..</top.dir>
    <hadoop.version>2.6.0-cdh5.7.1</hadoop.version>
</properties>

<dependencies>
    <!-- Force import of Spark's servlet API for unit tests -->
    <dependency>
        <groupId>javax.servlet</groupId>
        <artifactId>javax.servlet-api</artifactId>
        <version>3.0.1</version>
    </dependency>
    <dependency>
        <groupId>org.scala-lang</groupId>
        <artifactId>scala-library</artifactId>
        <version>${scala.version}</version>
        <!--<scope>provided</scope>-->
    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-core_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

        <exclusions>
            <exclusion>
                <!-- make sure wrong scala version is not pulled in -->
                <groupId>org.scala-lang</groupId>
                <artifactId>scala-library</artifactId>
            </exclusion>
            <exclusion>
                <!-- make sure wrong scala version is not pulled in -->
                <groupId>org.scala-lang</groupId>
                <artifactId>scalap</artifactId>
            </exclusion>
        </exclusions>
    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-sql_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-hive_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-mllib_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

        <exclusions>
            <exclusion>
                <groupId>org.jpmml</groupId>
                <artifactId>pmml-model</artifactId>
            </exclusion>
        </exclusions>

    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-streaming_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>

    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-streaming_${scala.binary.version}</artifactId>
        <version>${spark.version}</version>
        <type>test-jar</type>
        <classifier>tests</classifier>

    </dependency>
    <dependency>
        <groupId>org.scalatest</groupId>
        <artifactId>scalatest_${scala.binary.version}</artifactId>
        <version>2.2.1</version>

    </dependency>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.12</version>

    </dependency>

    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>${hadoop.version}</version>
        <exclusions>
            <exclusion>
                <groupId>log4j</groupId>
                <artifactId>log4j</artifactId>
            </exclusion>
            <exclusion>
                <groupId>javax.servlet</groupId>
                <artifactId>servlet-api</artifactId>
            </exclusion>
            <exclusion>
                <groupId>javax.servlet.jsp</groupId>
                <artifactId>jsp-api</artifactId>
            </exclusion>
            <exclusion>
                <groupId>org.jruby</groupId>
                <artifactId>jruby-complete</artifactId>
            </exclusion>
            <exclusion>
                <groupId>org.jboss.netty</groupId>
                <artifactId>netty</artifactId>
            </exclusion>
            <exclusion>
                <groupId>io.netty</groupId>
                <artifactId>netty</artifactId>
            </exclusion>
        </exclusions>
    </dependency>
    <dependency>
        <groupId>org.scala-lang</groupId>
        <artifactId>scala-reflect</artifactId>
        <version>2.10.5</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-web</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-scala_2.10</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-persist-s3</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-persist-hdfs</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-parquet-parser</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-genmodel</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-core</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-bindings</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-avro-parser</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-app</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>h2o-algos</artifactId>
        <version>3.10.0.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>sparkling-water-repl_2.10</artifactId>
        <version>1.6.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>sparkling-water-ml_2.10</artifactId>
        <version>1.6.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>sparkling-water-examples_2.10</artifactId>
        <version>1.6.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>sparkling-water-core_2.10</artifactId>
        <version>1.6.8</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>deepwater-backend-api</artifactId>
        <version>1.0.0</version>
    </dependency>

    <dependency>
        <groupId>joda-time</groupId>
        <artifactId>joda-time</artifactId>
        <version>2.9.2</version>
    </dependency>
    <dependency>
        <groupId>org.joda</groupId>
        <artifactId>joda-convert</artifactId>
        <version>1.8.1</version>
    </dependency>
    <dependency>
        <groupId>org.javassist</groupId>
        <artifactId>javassist</artifactId>
        <version>3.22.0-CR1</version>
    </dependency>
    <dependency>
        <groupId>gov.nist.math</groupId>
        <artifactId>jama</artifactId>
        <version>1.0.3</version>
    </dependency>
    <dependency>
        <groupId>com.google.code.gson</groupId>
        <artifactId>gson</artifactId>
        <version>2.7</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>reflections</artifactId>
        <version>0.9.11-h2o-custom</version>
    </dependency>
    <dependency>
        <groupId>ai.h2o</groupId>
        <artifactId>google-analytics-java</artifactId>
        <version>1.1.2-H2O-CUSTOM</version>
    </dependency>
    <dependency>
        <groupId>com.github.tony19</groupId>
        <artifactId>named-regexp</artifactId>
        <version>0.2.4</version>
    </dependency>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-s3</artifactId>
        <version>1.11.45</version>
    </dependency>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-kms</artifactId>
        <version>1.11.45</version>
    </dependency>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-core</artifactId>
        <version>1.11.45</version>
    </dependency>
    <dependency>
        <groupId>org.eclipse.jetty.aggregate</groupId>
        <artifactId>jetty-servlet</artifactId>
        <version>8.2.0.v20160908</version>
    </dependency>
    <dependency>
        <groupId>org.eclipse.jetty.aggregate</groupId>
        <artifactId>jetty-server</artifactId>
        <version>8.2.0.v20160908</version>
    </dependency>
    <dependency>
        <groupId>org.eclipse.jetty.aggregate</groupId>
        <artifactId>jetty-plus</artifactId>
        <version>8.1.17.v20150415</version>
    </dependency>
</dependencies>",2016-10-24T19:19:15,pavan,https://stackoverflow.com/users/5195353/pavan,61,39838518
39757792,39757792,1,"updating go to 
go1.7.1
 resolved the issue. to update, follow the instructions at golang.org to:




uninstall the old version of go


install the latest version of go",2016-09-28T21:15:53,Micah Stubbs,https://stackoverflow.com/users/1732222/micah-stubbs,"1,917",39754003
39718877,39718877,3,"When you build your model, set the flags to export weights and biases. Then once the model is built you can use 
h2o.weights()
 and 
h2o.biases()
.


model = h2o.deeplearning(x = 1:100,y = 101
                     training_frame = train,
                     activation = ""Tanh"",
                     balance_classes = TRUE, 
                     hidden = c(15,15),
                     momentum_stable = 0.99,
                     epochs = 50,
                     export_weights_and_biases = TRUE # <--- add this
                     )
firstLayerWeights = h2o.weights(model, 1)
secondLayerWeights = h2o.weights(model, 2)",2016-09-27T07:41:27,,,,39709155
39611616,39611616,1,"I think this is a bug. (Confirmed, see 
https://0xdata.atlassian.net/browse/PUBDEV-3455
)


When I did 
h2o.scoreHistory(glm_restr)
 I got:


Scoring History: 
            timestamp   duration iteration lambda predictors deviance_train
1 2016-09-21 09:25:29  0.000 sec         0  .46E2          4       9806.688
2 2016-09-21 09:25:29  0.052 sec         0  .17E2          7       1988.941
3 2016-09-21 09:25:29  0.100 sec         0   .6E1          9        294.884
4 2016-09-21 09:25:29  0.153 sec         0  .21E1          9         38.086
5 2016-09-21 09:25:29  0.203 sec         0  .77E0          9          4.919
6 2016-09-21 09:25:29  0.255 sec         0  .28E0          9          0.635
7 2016-09-21 09:25:30  0.307 sec         0   .1E0          9          0.082
8 2016-09-21 09:25:30  0.358 sec         0 .36E-1          9          0.011
9 2016-09-21 09:25:30  0.408 sec         0 .13E-1          9          0.001



I.e. the first iteration of lambda search, with a lambda value of 46, seems to have swept past 3 and gone straight to 4.


With that clue, I could get three predictors by skipping lambda search and choosing a lambda of 50:


glm_L50 <- h2o.glm(x = setdiff(colnames(mat), ""Y""), 
     y = ""Y"",
     training_frame = mat_h2o,
     solver = ""IRLSM"",
     family = ""gaussian"",
     link = ""family_default"",
     alpha = 1,
     lambda = 50)



Outputting 
glm_L50
 says:


GLM Model: summary
    family     link         regularization number_of_predictors_total
1 gaussian identity Lasso (lambda = 50.0 )                          8
  number_of_active_predictors number_of_iterations training_frame
1                           3                    0        mat.h2o

Coefficients: glm coefficients
      names coefficients standardized_coefficients
1 Intercept  -998.311697              -3657.657068
2        V1     0.000000                  0.000000
3        V2     0.000000                  0.000000
4        V3     0.000000                  0.000000
5        V4     0.000000                  0.000000
6        V5     0.000000                  0.000000
7        V6    -0.389528                -17.453935
8        V7     1.014556                 53.969163
9        V8    -1.229969                -81.328717

H2ORegressionMetrics: glm
** Reported on training data. **

MSE:  10921.23
RMSE:  104.5047
MAE:  83.98198
RMSLE:  NaN
Mean Residual Deviance :  10921.23
R^2 :  0.6932398
Null Deviance :35601860
Null D.o.F. :999
Residual Deviance :10921233
Residual D.o.F. :996
AIC :12146.34",2016-09-21T08:44:58,,,,39597281
39568760,39568760,5,"Yes, you are stuck using the same version for training and scoring. No migration route.


(You can export a model as a POJO, which can be bundled with the version of h2o-genmodel.jar that it needs. But that requires writing Java code to get the data in and results out, which is not ideal if you are using R code for data preparation.)


This has been discussed on the h2o-stream mailing list before, but I couldn't see a feature request ticket for it, so I just created one: 
https://0xdata.atlassian.net/browse/PUBDEV-3432",2016-09-19T08:37:56,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39567131
39549658,39549658,4,"NOTE: This unlikely good use of R's parallel foreach, but I'll answer your question first, then explain why. (BTW when I use ""cluster"" in this answer I'm referring to an H2O cluster (even if is just on your local machine), and not an R ""cluster"".)


I've re-written your code, assuming the intention was to have a 
single
 H2O cluster, where all the models are to be made:


library(foreach)
library(doParallel)
library(doSNOW)
library(h2o)

h2o.init(ip=""localhost"", nthreads=-1, max_mem_size = ""5G"") 

Xtr.hf = as.h2o(Xtr)
Xval.hf = as.h2o(Xval)

cl = makeCluster(6, type=""SOCK"")
registerDoSNOW(cl)
junk <- foreach(i=1:6, 
            .packages=c(""h2o""), 
            .errorhandling = ""stop"",
            .verbose=TRUE) %dopar% 
{
   for ( j in 1:3 ) { 
     bm2 <- h2o.gbm(
     training_frame = Xtr.hf,  
     validation_frame = Xval.hf, 
     x=2:ncol(Xtr.hf),
     y=1,          
     distribution=""gaussian"",
     ntrees = 100,
     max_depth = 3,
     learn_rate = 0.1,
     nfolds = 1)

   #TODO: do something with bm2 here?

  }
  return(iname)  #???
}
stopCluster(cl)



I.e. in outline form:




Start H2O, and load 
Xtr
 and 
Xval
 into it


Start 6 threads in your R client


In each thread make 3 GBM models (one after each other)




I dropped the 
h2o.shutdown()
 command, guessing that you didn't intend that (when you shutdown the H2O cluster the models you just made get deleted). And I've highlighted where you might want to be doing something with your model. And I've given H2O all the threads on your machine (that is the 
nthreads=-1
 in 
h2o.init()
), not just 2.


You 
can
 make H2O models in parallel, but it is generally a bad idea, as they end up fighting for resources. Better to do them one at a time, and rely on H2O's own parallel code to spread the computation over the cluster. (When the cluster is a single machine this tends to be very efficient.)


By the fact you've gone to the trouble of making a parallel loop in R, makes me think you've missed the way H2O works: it is a server written in Java, and R is just a light client that sends it API calls. The GBM calculations are not done in R; they are all done in Java code.


The other way to interpret your code is to run multiple instances of H2O, i.e. multiple H2O clusters. This might be a good idea if you have a set of machines, and you know the H2O algorithm is not scaling very well across a multi-node cluster. Doing it on a single machine is almost certainly a bad idea. But, for the sake of argument, this is how you do it (untested):


library(foreach)
library(doParallel)
library(doSNOW)

cl = makeCluster(6, type=""SOCK"")
registerDoSNOW(cl)
junk <- foreach(i=1:6, 
            .packages=c(""h2o""), 
            .errorhandling = ""stop"",
            .verbose=TRUE) %dopar% 
{
   library(h2o)
   h2o.init(ip=""localhost"", port = 54321 + (i*2), nthreads=2, max_mem_size = ""5G"") 

    Xtr.hf = as.h2o(Xtr)
    Xval.hf = as.h2o(Xval)

   for ( j in 1:3 ) { 
     bm2 <- h2o.gbm(
     training_frame = Xtr.hf,  
     validation_frame = Xval.hf, 
     x=2:ncol(Xtr.hf),
     y=1,          
     distribution=""gaussian"",
     ntrees = 100,
     max_depth = 3,
     learn_rate = 0.1,
     nfolds = 1)

    #TODO: save bm2 here
  }
  h2o.shutdown(prompt=FALSE)    
  return(iname)  #???
}
stopCluster(cl)



Now the outline is:




Create 6 R threads


In each thread, start an H2O cluster that is running on localhost but on a port unique to that cluster. (The 
i*2
 is because each H2O cluster is actually using two ports.)


Upload your data to the H2O cluster (i.e. this will be repeated 6 times, once for each cluster).


Make 3 GBM models, one after each other.


Do something with those models


Kill the cluster for the current thread.




If you have 12+ threads on your machine, and 30+ GB memory, 
and
 the data is relatively small, this will be roughly as efficient as using one H2O cluster and making 12 GBM models in serial. If not, I believe it will be worse. (But, if you have pre-started 6 H2O clusters on 6 remote machines, this might be a useful approach - I must admit I'd been wondering how to do this, and using the parallel library for it had never occurred to me until I saw your question!)


NOTE: as of the current version (3.10.0.6), I 
know
 the above code won't work, as there is 
a bug
 in 
h2o.init()
 that effectively means it is ignoring the port. (Workarounds: either pre-start all 6 H2O clusters on the commandline, or set the port in an environment variable.)",2016-09-17T17:18:00,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39536372
39506638,39506638,3,"I'm now fairly sure the answer is: doesn't matter.


Point 1:
 The two examples in the question are identical. This is because both h2o.cbind() and h2o.rbind() use lazy evaluation. So either way it returns immediately, and nothing happens until you perform some operation. (I've been using 
nrow()
 or 
ncol()
 to force creation of the new frame - it also allows me to check that I've got what I expected.)


Point 2:
 I've been informed by an H2O developer that they is no difference (CPU or memory), because either way the data will be copied.


Point 3:
 I've not noticed any significant speed difference on some reasonably big cbind/rbinds, with final frame size of 17GB (compressed size). This has not been rigorous, but I've never waited more than 30 to 40 seconds for the 
nrow()
 command to complete the copy.


Bonus Tip:
 Following on from point 1, it is essential you call 
nrow()
 (or whatever) to force the copy to happen, 
before
 you delete the constituent parts. If you do the 
all = rbind(parts)
, then 
h2o.rm(parts)
, then 
nrow(all)
 you get an error (and your data is lost and needs to be imported again).",2016-09-15T08:43:22,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39430734
39374545,39374545,1,"When running Sparkling Water you can convert RDD/DF/DS to H2O frames quite easily. Something like this (Scala, Python would look similar) should work:


val dataDF = sc.read.json('path/streamed-data')
val h2oContext = H2OContext.getOrCreate(sc)
import h2oContext.implicits._
val h2oFrame = h2oContext.asH2OFrame(dataDF, ""my-frame-name"")



From now on you can use the frame from code level and/or from FlowUI.


You can find more examples here 
for Python
 and here 
for Scala
.",2016-09-07T15:58:10,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,39372495
39221269,39221269,8,"No.


Remember that R is just the client, sending API calls: the algorithms (those matrix multiplications, etc.) are all implemented in Java.


What they do offer is a POJO, which is what you are asking for, but in Java. (POJO stands for Plain Old Java Object.) If you call h2o.download_pojo() on one of your models you will see it is quite straightforward. It may even be possible to write a script to convert it to R code? (Though it might be better, if you were going to go to that trouble, to convert it to C++ code, and then use Rcpp!)


Your other option is to export the weights and biases, in the case of deep learning, implement your own activation function, and use them directly.


But, personally, I've never found the Java side to be a bottleneck, either from the point of view of dev ops (install is easy) or computation (the Java code is well optimized).",2016-08-30T07:25:16,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39215243
39213568,39213568,5,"You have to fix the number of hidden layers in a grid, if experimenting with hidden_dropout_ratios. At first I messed around with combining multiple grids; then, when researching for my H2O book, I saw someone mention, in passing, how grids get combined automatically if you give them the same name.


So, you still need to call 
h2o.grid()
 for each number of hidden layers, but they can all be in the same grid at the end. Here is your example modified for that:


require(h2o)
h2o.init()
data(iris)
iris = iris[sample(1:nrow(iris)), ]
irisTrain = as.h2o(iris[1:90, ])
irisValid = as.h2o(iris[91:120, ])
irisTest = as.h2o(iris[121:150, ])

hyper_params1 <- list(
    input_dropout_ratio = c(0, 0.15, 0.3),
    hidden_dropout_ratios = list(0, 0.15, 0.3),
    hidden = list(64)
    )

hyper_params2 <- list(
    input_dropout_ratio = c(0, 0.15, 0.3),
    hidden_dropout_ratios = list(c(0,0), c(0.15,0.15),c(0.3,0.3)),
    hidden = list(c(32,32))
    )

grid = h2o.grid(""deeplearning"", x=colnames(iris)[1:4], y=colnames(iris)[5],
    grid_id = ""stackoverflow"",
    training_frame = irisTrain, validation_frame = irisValid,
    hyper_params = hyper_params1, adaptive_rate = TRUE,
    variable_importances = TRUE, epochs = 50, stopping_rounds=5,
    stopping_tolerance=0.01, activation=c(""RectifierWithDropout""),
    seed=1, reproducible=TRUE)

grid = h2o.grid(""deeplearning"", x=colnames(iris)[1:4], y=colnames(iris)[5],
    grid_id = ""stackoverflow"",
    training_frame = irisTrain, validation_frame = irisValid,
    hyper_params = hyper_params2, adaptive_rate = TRUE,
    variable_importances = TRUE, epochs = 50, stopping_rounds=5,
    stopping_tolerance=0.01, activation=c(""RectifierWithDropout""),
    seed=1, reproducible=TRUE)



When I went to print the grid, I was reminded there is a bug with grid output when using list hyper-parameters, such as hidden or hidden_dropout_ratios. Your code is a nice self-contained example, so I'll report that now. In the meantime, here is a one-liner to show the values of the hyper-parameter corresponding to each:


sapply(models, function(m) c(
  paste(m@parameters$hidden, collapse = "",""),
  paste(m@parameters$hidden_dropout_ratios, collapse="","")
  ))



Which gives:


     [,1]    [,2] [,3]        [,4]   [,5]      [,6] 
[1,] ""32,32"" ""64"" ""32,32""     ""64""   ""32,32""   ""64"" 
[2,] ""0,0""   ""0""  ""0.15,0.15"" ""0.15"" ""0.3,0.3"" ""0.3""



I.e. no hidden dropout is better than a little, which is better than a lot. And two hidden layers is better than one.


By the way,




input_dropout_ratio
: controls dropout between input layer and the first hidden layer. Can be used independently of the activation function.


hidden_dropout_ratios
: controls dropout between each hidden layer and the next layer (which is either the next hidden layer, or the output layer). If specified, you must specify one of the ""WithDropout"" activation functions.",2016-08-29T19:17:23,,,,39212635
39315859,39315859,11,"First, here is the full, reproducible, example:


library(h2o)
h2o.init()

data(iris)  #Not required?
iris <- iris[1:120,] #Remove 60% of virginica
summary(iris$Species) #50/50/20

d <- as.h2o(iris)
splits = h2o.splitFrame(d,0.8,c(""train"",""test""), seed=77)
train = splits[[1]]
test = splits[[2]]
summary(train$Species)  #41/41/14
summary(test$Species)  #9/9/6

m1 = h2o.randomForest(1:4, 5, train, model_id =""RF_defaults"", seed=1)
h2o.confusionMatrix(m1)

m2 = h2o.randomForest(1:4, 5, train, model_id =""RF_balanced"", seed=1,
  balance_classes = TRUE)
h2o.confusionMatrix(m2)

m3 = h2o.randomForest(1:4, 5, train, model_id =""RF_balanced"", seed=1,
  balance_classes = TRUE,
  class_sampling_factors = c(1, 1, 2.5)
  )
h2o.confusionMatrix(m3)



The first lines initialize H2O, then I deliberately modify the iris data set to throw away 60% of one of the 3 classes, to create an imbalance.


The next few lines load that data into H2O, and create a 80%/20% train/test data split. The seed was chosen deliberately, so that in the training data 
virginica
 is 14.58% of the data, compared to 16.67% in the original data, and 25% in the test data.


I then train three random forest models. 
m1
 is all defaults, and its confusion matrix looks like this:


           setosa versicolor virginica  Error     Rate
setosa         41          0         0 0.0000 = 0 / 41
versicolor      0         39         2 0.0488 = 2 / 41
virginica       0          1        13 0.0714 = 1 / 14
Totals         41         40        15 0.0312 = 3 / 96



Nothing to see here: it uses the data it finds.


Now here is the same output for 
m2
, which switches on 
balance_classes
. You can see it is over-sampled the 
virginica
 class to get them as balanced as possible. (The right-most columns says 41,41,40 instead of 41,41,14 as in the previous output.)


           setosa versicolor virginica  Error      Rate
setosa         41          0         0 0.0000 =  0 / 41
versicolor      0         41         0 0.0000 =  0 / 41
virginica       0          2        38 0.0500 =  2 / 40
Totals         41         43        38 0.0164 = 2 / 122



In 
m3
 we still switch on 
balance_classes
, but also tell it the truth of the situation. I.e. that the actual data is 16.67% 
virginica
, not the 14.58% it sees in the 
train
 data. The confusion matrix for 
m3
 shows that it therefore turned the 14 
virginica
 samples into 37 samples instead of 40 samples.


           setosa versicolor virginica  Error      Rate
setosa         41          0         0 0.0000 =  0 / 41
versicolor      0         41         0 0.0000 =  0 / 41
virginica       0          2        35 0.0541 =  2 / 37
Totals         41         43        35 0.0168 = 2 / 119



How did I know to write 
c(1, 1, 2.5)
, and not 
c(2.5, 1, 1)
 or 
c(1, 2.5, 1)
 ? The docs say it must be in ""lexicographic order"". You can find out what that order is with:


h2o.levels(train$Species)



which tells me:


[1] ""setosa""     ""versicolor"" ""virginica""



The opinion bit: 
balance_classes
 is good to switch on, but 
class_sampling_factors
 should only be used when you have a really good reason to believe that your training data is not representative.


NOTE:
 Code and explanation adapted from my upcoming book, Practical Machine Learning with H2O.",2016-09-04T10:16:23,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39204584
39176039,39176039,2,"The reason that code no longer works is that it's syntax from the H2O 2.0 API, which has been retired for about a year or longer.  Since H2O 3.0, 
h2o.clusterInfo()
 no longer has arguments and 
as.h2o()
 no longer has the 
key
 argument.  Check out the documentation for these functions inside your H2O R package, or 
here
 and 
here
.",2016-08-26T23:44:57,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",39175806
39176074,39176074,2,"No, there is not currently a way to force zero probabilities for certain classes within the H2O training functions.  The best solution is probably to write some code to manually process the probabilities after-the-fact.",2016-08-26T23:48:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",39156265
39129724,39129724,2,"Everything looks fine, it just looks like you need to change the 
path
 you used.


Instead of using the directory that 
h2o.save_model
 created, use a directory that you know exists and for which you know the path. As a first test you could just save to your desktop, for example use 


h2o.download_pojo(model_rf, path = '/Users/your_user_name/Desktop/', get_jar = True)



where you need to replace your_user_name (this is assuming you are using a mac)


Here's an example you can try from scratch (shutdown h2o first with 
h2o.cluster().shutdown()


     import h2o
     h2o.init()
     iris_df = h2o.import_file(""https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris.csv"")
     from h2o.estimators.glm import H2OGeneralizedLinearEstimator
     predictors = iris_df.columns[0:4]
     response_col = ""C5""
     train,valid,test = iris_df.split_frame([.7,.15], seed =1234)
     glm_model = H2OGeneralizedLinearEstimator(family=""multinomial"")
     glm_model.train(predictors, response_col, training_frame = train, validation_frame = valid)
     h2o.download_pojo(glm_model, path = '/Users/your_user_name/Desktop/', get_jar = True)



again where you need to replace 
your_user_name
 (this is assuming you are using a mac)


(what might have happened: It looks like the first time you saved an H2O model to disk with 
h2o.save_model
 a directory was created in the location you were running your original h2o cluster (check if you are connecting to an h2o cluster from different locations) and the second time you tried to save the model with 
download_pojo
 it looked at your current directory and saw that  'pojo_test2' didn't exist there.


when you run 
h2o.save_model
 it will print out the full path to where it created a new directory. See if that path is the same as your current directory.",2016-08-24T17:37:26,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",39128865
39506780,39506780,0,"The answer depends on how badly you need it...


No: you have to use one of the built-in link functions, and cannot pass your own through the API.


Yes: it is open-source, so you could hack in your custom link function to the Java back-end, give it a name, recompile, and then it should be available from the API.


I poked around in the 
Java source
 a bit, hoping to be able to give you a single link in a single file where you add your code. But it looks more complicated than that, I think it is a non-trivial project. (If you have more budget than time, becoming a paying h2o.ai customer, and making a feature request is likely to be the quickest way to get it done!)",2016-09-15T08:50:57,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,39119275
39085956,39085956,5,"The reason this code no longer works is that there was a breaking API change from H2O 2.0 to H2O 3.0 back in 2015.  The docs you have discovered (probably via a Google search) are for a very old version of H2O 2.0.  The up-to-date docs can always be found at 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html",2016-08-22T18:02:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",39071874
39073808,39073808,3,"Answering your error question:


H2O changed a bit from this documentation. Reading the iris file works as follows:


iris.hex = h2o.importFile(path = irisPath, destination_frame = ""iris.hex"")


Your second (and third question) is against SO rules. But below you will find a short list of resources:




H2O training materials (go to the 
h2o.ai

website) and go to general documentation. You can find all the
material there presented on h2o world 2015. There is also a link to
h2o university.


Check their blog. There are some gold nuggets in there.


Read the booklets they have available on GBM, GLM, Deep Learning. They contain examples in R and Python.


Kaggle. Search the scripts / kernels for h2o.




As for your third question, read their ""Why H2O pages"".",2016-08-22T07:40:46,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,39071874
39090678,39090678,1,"To answer your question about how H2O works it is little hard to put together here. however in nutshell, H2O is an open source enterprise ready machine intelligence engine with accessibility from popular machine learning languages i.e. R, Python as well as programming languages Java and Scala. Enterprise ready means users can distribute execution to multiple machines depending on extremely large size of data. The Java based core engine has builtin multiple algorithms implementation and any language interface goes through interpreter to H2O core engine which could be a distributed cluster to build models and score results. There is a lot in between so I would suggest visiting link below to learn more about H2O architecture and execution from various supported language:


http://docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html",2016-08-23T00:41:14,AvkashChauhan,https://stackoverflow.com/users/1325423/avkashchauhan,20.6k,39071874
41439725,41439725,0,"You can dig out more on H2O implementation in R starting from 
installation to implementation of h2o machine learning library in R
. Go through 
this link
. 
This also helps you in order to implement 
h2o machine learning on top of SparkR framework
. 


If you want to get an idea of 
h2o working prototype from very basic
 than follow 
this link
. It provides the basic flavor of working prototype with code walk-through (quick learning tutorial).


Apart from above points, it also covers the following key points:




How to convert H2O data frame to R and Spark data frame and vice-versa


What are the pros and cons between SparkMLlib and H2O machine library


What are the strengths of h2o compare to other ML library


How to apply ML algorithm to R and Spark data frame etc.",2017-01-03T08:57:04,Saurabh Chauhan,https://stackoverflow.com/users/5835763/saurabh-chauhan,"3,201",39071874
39046859,39046859,2,"I ran into the same issue. Trying to explain the predicted value versus the p1 value. 


H2O uses maximum F1 score by default for classification. With the p1 column you can specify your own threshold. 


It is not very obvious from reading the documentation. But you can find it in the R booklet. Strangely enough not in de DRF, GBM, or Deep Learning booklets.",2016-08-19T19:59:52,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,39046032
38980384,38980384,1,"Have you created the ~/.pgpass file, where the file belongs to the user that is running Steam?


It should contain:  
*:*:*:steam:<your password>

And also it should be only user readable 
chmod 600 ~/.pgpass",2016-08-16T16:48:33,Mark Chan,https://stackoverflow.com/users/6042258/mark-chan,26,38977870
38981107,38981107,6,"It looks like you are trying to install on Linux.
You need to install the development files for libcurl first.


eg


apt-get install libcurl4-openssl-dev


or


yum install libcurl-devel",2016-08-16T17:32:03,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",38972111
38974836,38974836,3,"For performance reasons I don't want to create a temporary df with the full dense matrix.




In fact, 
quanteda
 will convert your sparse matrix to dense before converting it 
data.frame
: 
https://github.com/kbenoit/quanteda/blob/master/R/dfm-classes.R#L513-L516


If you need to import sparse matrix to h2o, convert it to svmlight format and use 
importFile
. See this topic: 
How to use H2o on feature hashed matrix in R",2016-08-16T12:20:45,Community,https://stackoverflow.com/users/-1/community,1,38968311
38951905,38951905,3,"The error message you gave is for the second of your two install lines; you don't say what happened with the first one.


But, my recommended way to install H2O on R:


install.packages(""h2o"")



Simple! This will get the latest version from CRAN, and automatically find all the dependencies. The downside is you are a version or so behind the latest. But the product is mature (so being a version back is fine) 
and
 development is fairly rapid (so being a version back can sometimes even be better)!


Only use the 
instructions on the H2O site
 if you have a good reason to need the latest version. (And I still recommend installing the first time from CRAN, as it is harder to get something wrong, so if 
that
 doesn't work, maybe H2O is incompatible with your machine or something like that.)




P.S. The 65535 (i.e. -1) error code is probably a Windows one, and from some googling appears to be a generic one meaning something crashed. If you do pursue it, I'd be suspicious about either access permissions to certain directories, or paths with spaces in them. (IIRC, R used to recommend not installing in directories with spaces in them.)",2016-08-15T08:41:07,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,38950812
39135080,39135080,23,"texreg
 package author here. 
texreg
 is based on generic functions, which means any user can add custom 
extract
 methods for arbitrary models and make them work with 
texreg
. I will walk you through this below. I am hoping that this detailed exposition will help other people who have asked similar questions in the past to devise their own 
texreg
 extensions.


See also Section 6 in the 
2013 paper in the Journal of Statistical Software
 for another example. First, however, I will describe how the 
texreg
 architecture works more generally to give you an idea what is possible.


texreg
 and the generic 
extract
 function


There are three functions: 
texreg
 (for LaTeX output), 
htmlreg
 (for HTML output, which can also be interpreted by Word or Markdown in most usage scenarios), and 
screenreg
 (for ASCII text output in the console). These three functions serve to convert some cleaned-up information (coefficients, standard errors, confidence intervals, p-values, goodness-of-fit statistics, model labels etc.) into the respective output formats. This is not perfect and could be even more flexible, but I think it has quite a few arguments for customization at this point, including things like 
booktabs
 and 
dcolumn
 support. So the big challenge is rather to get cleaned-up model information in the first place.


This is done by providing a 
texreg
 object to any of these three functions. A 
texreg
 object is just a container for coefficients etc. and is formally defined using an S4 class. To create a 
texreg
 object, you can either use the constructor function 
createTexreg
 (as documented on the help pages), which accepts all the different pieces of information as arguments, such as the standard errors etc. Or (better) you can use the 
extract
 function to extract those pieces of information from some estimated model and return a 
texreg
 object for use with any of the three functions. The way you typically do this is by just handing over a list of several models to the 
texreg
 or 
screenreg
 etc. function, and this function will internally call 
extract
 to create 
texreg
 objects and then process the information from those objects.


However, it is equally valid to just save the output of a call of the 
extract
 function to an object, possibly manipulate this 
texreg
 object, and then call the 
texreg
 function on the manipulated object to display it as a table. This permits some flexibility in tweaking the results.


Earlier on, I mentioned that the package uses generic functions. This means that the 
extract
 function is generic in the sense that you can register methods for it that work with arbitrary classes of models. For example, if the 
extract
 function does not know how to handle 
h2o
 objects and how to extract the relevant information from such an object, you can just write a method to do that and register it with the 
extract
 function. Below, I will walk you through this step by step in the hope that people will learn from this detailed exposition and start writing their own extensions. (Note: if somebody develops a useful method, please e-mail me and I can include it in the next 
texreg
 release.) It is also worth pointing out that the source files of the package contain more than 70 examples of 
extract
 methods which you can use as templates. These examples are stored in the file 
R/extract.R
.


Identifying the class label and setting up an 
extract
 method


The first step is to identify the class name of the object. In your example, 
class(model.output.1)
 returns the following class labels: ""H2OBinomialModel"" and ""h2o"". The first label is the more specific one, and the second label is the more general one. If all 
h2o
 model objects are structured in a similar way, it will make sense to write an extension for 
h2o
 objects and then decide within the method how to proceed with the specific model. As I know virtually nothing about the 
h2o
 package, I prefer to start out with a more specific 
extract
 method for 
H2OBinomialModel
 objects in this case. It can be adjusted later on should we wish to do so.


extract
 methods are structured as follows: you write a function called 
extract.xyz
 (replace ""xyz"" by the class label), have at least one argument called 
model
, which accepts the model object (e.g., 
model.output.1
 in your example), put some code in the body that extracts the relevant information from the 
model
 object, create a 
texreg
 object using the 
createTexreg
 constructor, and return this object. Here is an empty container:


extract.H2OBinomialModel <- function(model, ...) {
  s <- summary(model)

  # extract information from model and summary object here

  # then create and return a texreg object (replace NULL with actual values):
  tr <- createTexreg(
    coef.names = NULL,    # character vector of coefficient labels
    coef = NULL,          # numeric vector with coefficients
    se = NULL,            # numeric vector with standard error values
    pvalues = NULL,       # numeric vector with p-values
    gof.names = NULL,     # character vector with goodness-of-fit labels
    gof = NULL,           # numeric vector of goodness-of-fit statistics
    gof.decimal = NULL    # logical vector: GOF statistic has decimal points?
  )
  return(tr)
}



Note that the function definition also contains the 
...
 argument, which can be used for custom arguments that should be handed over to function calls within the 
extract
 method.


Note also that the first line in the body of the function definition saves the summary of the model in an object called 
s
. This is often useful because many package writers decide to store some of the information in a simpler version in the summary, so one should usually consider both, the model and its summary, as useful sources of information. In some cases, one may have to look at the actual definition of the summary method in the respective package to find out how the pieces of information displayed on the summary page are computed when the 
summary
 command is called because not all 
summary
 methods store the different elements displayed in the 
summary
 object.


Locating the right information in an 
H2OBinomialModel
 object


The next step is to examine the object and locate all the details that should be displayed in the final table. By looking at the output of 
model.output.1
, I would guess that the following part should constitute the GOF block at the bottom of the table:


MSE:  0.202947
R^2:  0.1562137
LogLoss:  0.5920097
Mean Per-Class Error:  0.3612191
AUC:  0.7185655
Gini:  0.4371311
Null Deviance:  512.2888
Residual Deviance:  449.9274
AIC:  457.9274



And the following part should probably constitute the coefficient block in the middle of the table:


Coefficients: glm coefficients
      names coefficients standardized_coefficients
1 Intercept    -1.835223                 -0.336428
2      RACE    -0.625222                 -0.193052
3     DCAPS     1.314428                  0.408336
4       PSA     0.046861                  0.937107



In many cases, the summary contains the relevant information, but here printing the model yields what we need. We will need to locate all of this in the 
model.output.1
 object (or its summary if applicable). To do that, there are several useful commands. Among them are 
str(model.output.1)
, 
names(summary(model.output.1))
, and similar commands.


Let's start with the coefficient block. Calling 
str(model)
 reveals that there is a slot called 
model
 in the S4 object. We can look at its contents by calling 
model.output.1@model
. The result is a list with several named elements, among them 
coefficients_table
. So we can access the coefficient table by calling 
model.output.1@model$coefficients_table
. The result is a data frame the columns of which we can access using the 
$
 operator. In particular, we need the names and the coefficients. There are two types of coefficients here, standardized and unstandardized, and we can add an argument to our extract method later to let the user decide what he or she wants. Here is how we extract the coefficients and their labels:


coefnames <- model.output.1@model$coefficients_table$names
coefs <- model.output.1@model$coefficients_table$coefficients
coefs.std <- model.output.1@model$coefficients_table$standardized_coefficients



As far as I can see, there are no standard errors or p-values stored in the object. We could write some additional code to compute them should we wish to do that, but here we will focus on things that are readily provided as part of the model output.


It is important that we should not overwrite any existing function names in 
R
, such as 
names
 or 
coef
. While doing this should technically work because the code is executed within a function later, this can easily lead to confusion while trying things out, so you should better avoid that.


Next, we need to locate the goodness-of-fit statistics. By examining the output of 
str(model.output.1)
 carefully, we see that the goodness-of-fit statistics are contained in several slots under 
model@model$training_metrics@metrics
. Let's save them to some objects that are easier to access:


mse <- model.output.1@model$training_metrics@metrics$MSE
r2 <- model.output.1@model$training_metrics@metrics$r2
logloss <- model.output.1@model$training_metrics@metrics$logloss
mpce <- model.output.1@model$training_metrics@metrics$mean_per_class_error
auc <- model.output.1@model$training_metrics@metrics$AUC
gini <- model.output.1@model$training_metrics@metrics$Gini
nulldev <- model.output.1@model$training_metrics@metrics$null_deviance
resdev <- model.output.1@model$training_metrics@metrics$residual_deviance
aic <- model.output.1@model$training_metrics@metrics$AIC



In some cases, but not here, the author of a package writes methods for generic functions that can be used to extract some common information like the number of observations (
nobs(model)
), AIC (
AIC(model)
), BIC (
BIC(model)
), deviance (
deviance(model)
), or the log likelihood (
logLik(model)[[1]]
). So these are things you may want to try first; but the 
h2o
 package does not seem to offer such convenience methods.


Adding the information to the 
extract.H2OBinomialModel
 function


Now that we have located all pieces of information we need, we can add them to the 
extract.H2OBinomialModel
 function we defined above.


However, we would like to let the user decide if he or she prefers raw or standardized coefficients, and we would like to let the user decide which goodness-of-fit statistics should be reported, so we add various logical arguments to the function header and then use if-conditions inside the function to check whether we should embed the respective statistics in the resulting 
texreg
 object.


We also remove the line 
s <- summary(model)
 in this case because we don't actually need any kind of information from the summary since we found everything we need in the model object.


The complete function may look like this:


# extension for H2OBinomialModel objects (h2o package)
extract.H2OBinomialModel <- function(model, standardized = FALSE, 
      include.mse = TRUE, include.rsquared = TRUE, include.logloss = TRUE, 
      include.meanerror = TRUE, include.auc = TRUE, include.gini = TRUE, 
      include.deviance = TRUE, include.aic = TRUE, ...) {

  # extract coefficient table from model:
  coefnames <- model@model$coefficients_table$names
  if (standardized == TRUE) {
    coefs <- model@model$coefficients_table$standardized_coefficients
  } else {
    coefs <- model@model$coefficients_table$coefficients
  }

  # create empty GOF vectors and subsequently add GOF statistics from model:
  gof <- numeric()
  gof.names <- character()
  gof.decimal <- logical()
  if (include.mse == TRUE) {
    mse <- model@model$training_metrics@metrics$MSE
    gof <- c(gof, mse)
    gof.names <- c(gof.names, ""MSE"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.rsquared == TRUE) {
    r2 <- model@model$training_metrics@metrics$r2
    gof <- c(gof, r2)
    gof.names <- c(gof.names, ""R^2"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.logloss == TRUE) {
    logloss <- model@model$training_metrics@metrics$logloss
    gof <- c(gof, logloss)
    gof.names <- c(gof.names, ""LogLoss"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.meanerror == TRUE) {
    mpce <- model@model$training_metrics@metrics$mean_per_class_error
    gof <- c(gof, mpce)
    gof.names <- c(gof.names, ""Mean Per-Class Error"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.auc == TRUE) {
    auc <- model@model$training_metrics@metrics$AUC
    gof <- c(gof, auc)
    gof.names <- c(gof.names, ""AUC"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.gini == TRUE) {
    gini <- model@model$training_metrics@metrics$Gini
    gof <- c(gof, gini)
    gof.names <- c(gof.names, ""Gini"")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.deviance == TRUE) {
    nulldev <- model@model$training_metrics@metrics$null_deviance
    resdev <- model@model$training_metrics@metrics$residual_deviance
    gof <- c(gof, nulldev, resdev)
    gof.names <- c(gof.names, ""Null Deviance"", ""Residual Deviance"")
    gof.decimal <- c(gof.decimal, TRUE, TRUE)
  }
  if (include.aic == TRUE) {
    aic <- model@model$training_metrics@metrics$AIC
    gof <- c(gof, aic)
    gof.names <- c(gof.names, ""AIC"")
    gof.decimal <- c(gof.decimal, TRUE)
  }

  # create texreg object:
  tr <- createTexreg(
    coef.names = coefnames, 
    coef = coefs, 
    gof.names = gof.names, 
    gof = gof, 
    gof.decimal = gof.decimal
  )
  return(tr)
}



For the goodness-of-fit block, you can see that I first created empty vectors and then subsequently populated them with additional statistics provided that the respective statistic was switched on by the user using the respective argument.


The 
gof.decimal
 logical vector indicates for each GOF statistic whether it has decimal places (
TRUE
) or not (
FALSE
, as in the number of observations, for example).


Finally, the new function needs to be registered as a method for the generic 
extract
 function. This is done using a simple command:


setMethod(""extract"", signature = className(""H2OBinomialModel"", ""h2o""), 
definition = extract.H2OBinomialModel)



Here, the first argument of 
className
 is the class label, and the second one is the package in which the class is defined.


Summing up, the only two things that need to be done in order to write a custom extension are 1) writing an extract method, and 2) registering the method. That is, this code can be executed at runtime and doesn't have to be inserted into any package.


However, for your convenience, I have added the 
H2OBinomialModel
 method to 
texreg
 version 1.36.13, which is available on CRAN.


Note that the solution presented here does not work with any previous version of 
texreg
 because previous versions could not deal with models that had neither standard errors nor confidence intervals. This is a fairly specialized setup in my opinion, and I hadn't come across a package that merely provides the estimates without any uncertainty measures. I have now fixed this in 
texreg
.


Trying out the new 
extract
 method


Once the function definition and the 
setMethod
 command have been executed at runtime, the following command can be used to create a table:


screenreg(list(model.output.1, model.output.2), custom.note = """")



This is the output:


======================================
                      Model 1  Model 2
--------------------------------------
Intercept              -1.84    -1.11 
RACE                   -0.63    -0.62 
DCAPS                   1.31     1.31 
PSA                     0.05     0.05 
AGE                             -0.01 
--------------------------------------
MSE                     0.20     0.20 
R^2                     0.16     0.16 
LogLoss                 0.59     0.59 
Mean Per-Class Error    0.36     0.38 
AUC                     0.72     0.72 
Gini                    0.44     0.44 
Null Deviance         512.29   512.29 
Residual Deviance     449.93   449.51 
AIC                   457.93   459.51 
======================================



The 
custom.note = """"
 argument makes sense here because we don't want a significance legend since the models do not report any uncertainty measures.


It is also possible to suppress some of the GOF measures and/or use standardized coefficients:


screenreg(list(model.output.1, model.output.2), custom.note = """", 
    include.deviance = FALSE, include.auc = FALSE, standardized = TRUE)



The result:


======================================
                      Model 1  Model 2
--------------------------------------
Intercept              -0.34    -0.34 
RACE                   -0.19    -0.19 
DCAPS                   0.41     0.41 
PSA                     0.94     0.94 
AGE                             -0.07 
--------------------------------------
MSE                     0.20     0.20 
R^2                     0.16     0.16 
LogLoss                 0.59     0.59 
Mean Per-Class Error    0.36     0.38 
Gini                    0.44     0.44 
AIC                   457.93   459.51 
======================================



Other slots that can be used with 
createTexreg


The 
createTexreg
 constructor function is called within any 
extract
 method. The example above shows some simple pieces of information. Besides the details contained in the example, the following slots are available in 
texreg
 objects:




se: standard errors


pvalues: the p-values


ci.low: lower bound of a confidence interval


ci.up: upper bound of a confidence interval


model.name: the title of the current model




Note that either confidence intervals or standard errors and p-values should be used, not both.


Manipulating 
texreg
 objects


Besides handing over the models to the 
screenreg
, 
texreg
, or 
htmlreg
 functions directly, it is possible to save the extracted information to a 
texreg
 object first and manipulate it before the table is displayed or saved. The added value is that even complex changes to a table are easy to apply this way. For example, it is possible to rename coefficients or GOF statistics, add new rows, rename a model, modify the values, or change the order of coefficients or GOF statistics. Here is how you can do that: First, you call the 
extract
 function to save the information to a 
texreg
 object:


tr <- extract(model.output.1)



You can display the contents of the 
texreg
 object by just calling 
tr
, which shows the following output:


No standard errors and p-values were defined for this texreg object.

                coef.
Intercept -1.83522343
RACE      -0.62522179
DCAPS      1.31442834
PSA        0.04686106

                             GOF dec. places
MSE                    0.2029470        TRUE
R^2                    0.1562137        TRUE
LogLoss                0.5920097        TRUE
Mean Per-Class Error   0.3612191        TRUE
AUC                    0.7185655        TRUE
Gini                   0.4371311        TRUE
Null Deviance        512.2888402        TRUE
Residual Deviance    449.9273825        TRUE
AIC                  457.9273825        TRUE



Alternatively, this is the structure of the object as shown by 
str(tr)
:


Formal class 'texreg' [package ""texreg""] with 10 slots
  ..@ coef.names : chr [1:4] ""Intercept"" ""RACE"" ""DCAPS"" ""PSA""
  ..@ coef       : num [1:4] -1.8352 -0.6252 1.3144 0.0469
  ..@ se         : num(0) 
  ..@ pvalues    : num(0) 
  ..@ ci.low     : num(0) 
  ..@ ci.up      : num(0) 
  ..@ gof.names  : chr [1:9] ""MSE"" ""R^2"" ""LogLoss"" ""Mean Per-Class Error"" ...
  ..@ gof        : num [1:9] 0.203 0.156 0.592 0.361 0.719 ...
  ..@ gof.decimal: logi [1:9] TRUE TRUE TRUE TRUE TRUE TRUE ...
  ..@ model.name : chr(0) 



Now you can just manipulate this object in arbitrary ways, e.g., add a GOF statistic:


[email protected]
 <- c(
[email protected]
, ""new statistic"")
tr@gof <- c(tr@gof, 12)

[email protected]
 <- c(
[email protected]
, FALSE)



Or you can change the order of coefficients:


[email protected]
 <- 
[email protected]
[c(4, 1, 2, 3)]
tr@coef <- tr@coef[c(4, 1, 2, 3)]



When you are done with the manipulations, you can hand over the 
texreg
 object instead of the original model when you call, for example, 
screenreg
:


screenreg(list(tr, model.output.2), custom.note = """")



The new result will look like this:


======================================
                      Model 1  Model 2
--------------------------------------
PSA                     0.05     0.05 
Intercept              -1.84    -1.11 
RACE                   -0.63    -0.62 
DCAPS                   1.31     1.31 
AGE                             -0.01 
--------------------------------------
MSE                     0.20     0.20 
R^2                     0.16     0.16 
LogLoss                 0.59     0.59 
Mean Per-Class Error    0.36     0.38 
AUC                     0.72     0.72 
Gini                    0.44     0.44 
Null Deviance         512.29   512.29 
Residual Deviance     449.93   449.51 
AIC                   457.93   459.51 
new statistic          12             
======================================



TL;DR


texreg
 can be customized by users. Just write an extract method like the one shown above and register it using a 
setMethods
 call. I have included the 
H2OBinomialModel
 method in the 
latest 
texreg
 version
 1.36.13, along with a bugfix for using models without standard errors (such as this one).",2016-08-25T00:51:26,,,,38894044
38904233,38904233,1,"you can use the R xtable package with h2o's H2OTable (or 
knitr
 if you convert the H2OTable to an H2OFrame using 
as.h2o(your_H2OTable)
 ), if you extract them from the model output. 


for example to create a beautiful table from a model's coefficients you would need to first extract the coefficients table with 
model.output.1@model$coefficients_table
, then you can use xtable: 
xtable(prostate.glm@model$coefficients_table)
 to print out the Latex code.


for side by side views there are multiple posts on how to do this in knitr or 
xtable
, or 
xtable and sweave",2016-08-11T19:00:53,Community,https://stackoverflow.com/users/-1/community,1,38894044
38924517,38924517,0,"No, there is not a package that does this currently. The 
broom
 package doesn't support H2O models yet -- that would be cool!  Maybe that could happen in the future.  Once there is a way to ""tidy"" model output into an R data.frame using broom or similar functionality, then xtable, etc. will work nicely.",2016-08-12T18:40:53,,,,38894044
38879746,38879746,2,"you could save your sparse matrix to svmlight sparse format, then use 


train.hex <- h2o.uploadFile('./X_train', parse_type = ""SVMLight"", destination_frame='train')



svmlight sparse format will also be detected by 
h2o.importFile()
, which is a  parallelized  reader  and  pulls  information  from  the  server  from  a  location specified by the client.


train.hex <- h2o.importFile('./X_train', destination_frame='train')",2016-08-10T17:17:08,,,,38870109
38860691,38860691,2,"h2o doesn't currently have RMSLE implemented (only RMSE), but it makes sense to add. Here is the 
JIRA ticket
 where you can track the progress.


Update: Support has been added to implement RMSE from version 3.10.0.5.",2016-08-09T21:24:32,HackToHell,https://stackoverflow.com/users/787563/hacktohell,"2,393",38853728
38839315,38839315,1,"H2O doesn't currently have a function to display a table like that, but you can export the random forest model to POJO (a Java file) using the
h2o.download_pojo() function and then inspect the tree (individual rules) manually. 


H2O also accepts 
feature requests
.",2016-08-08T22:16:23,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",38804546
38759512,38759512,3,"This is currently unimplemented, but it makes sense to add this. Here is the 
JIRA ticket
 where you can track the progress.",2016-08-04T06:00:14,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",38710377
38724825,38724825,-2,"Edited


Because accuracy is not currently implemented as Erin pointed out, your options for evaluating the performance of your model are limited to the functions that are available to the H2OMultinomialModelMetrics.


for example you could look at the 
.mean_per_class_error()
, take a look at the multiclass confusion matrix 
model.confusion_matrix(data)
, or the log loss 
.logloss()
 to name a few.",2016-08-02T15:34:47,,,,38710377
42823389,42823389,2,"The last line of the log explains the issue:


08-02 00:40:36.613 127.0.0.1:54321       19672  main      FATAL: On /127.0.0.1 some of the required ports 54321, 54322 are not available, change -port PORT and try again.



It says, ""some of the required ports 54321, 54322 are not available"".  Make sure those ports are available, or if they can't be made available, then just start H2O on a different port using the 
port
 argument in 
h2o.init()
.",2017-03-16T00:50:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",38702463
38689601,38689601,0,"To get an h2o frame after you've used 
groupby()
, use 
.get_frame()
 which returns the result of the group-by. For example, if you wanted to get the count for each year you could do:


df=h2o.import_file(""baby-names2.csv"")
df_group=df.group_by(""year"").count()
df_group.get_frame()



which prints the year and count columns
.",2016-08-01T00:37:42,,,,38685750
51830026,51830026,0,"While h2o doesn't provide 
permutation accuracy importance
 (as you pointed out it provides variable importance) through the r/python api, you can use PDP 
h2o.partialPlot()
 to see how individual levels within a feature impact the target.",2018-08-13T20:24:07,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",38606606
38602590,38602590,1,"Just to close out this question, I'll restate the solution mentioned in the comments above.  The user was able to resolve the issue by starting H2O from the command line with 1GB of memory using 
java -jar -Xmx1g h2o.jar
, and then connected to the existing H2O server in Python using 
h2o.init()
.  


It's not clear to me why 
h2o.init()
 was not creating the correct size cluster using the 
max_mem_size_GB
 argument.  Regardless, this argument has been deprecated recently and replaced by another argument, 
max_mem_size
, so it may no longer be an issue.",2016-07-27T02:11:28,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",38548789
38515114,38515114,1,"You cannot save it as an rda file, from inside R. The model exists on the H2O cluster, and you must use 
h2o.saveModel()
 to save it. And then 
h2o.loadModel()
 to load it again.  See 
?h2o.saveModel
 and 
?h2o.loadModel
.


BTW, note the asymmetry between the functions: you give a directory to saveModel, and you give a filename to loadModel.  (The filename will be the model ID.)",2016-07-21T22:05:15,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,38510539
38446001,38446001,5,"EDIT:
 I've changed to intern=FALSE, in below examples, based on comments




You should just need to change directory; it is either that or not setting wait=FALSE (to run the command in the background).


launchH2O <- ""java -Xmx1g -jar h2o.jar -name testCluster -nthreads 1 -port 54321""
savewd <- setwd(""/path/to/h2ojar/"")
system(command = launchH2O, intern =FALSE wait=FALSE)
setwd(savewd)



The last line, and the assignment to 
savewd
 is just to preserve working directory. Alternatively this should also work:


launchH2O <- ""java -Xmx1g -jar /path/to/h2ojar/h2o.jar -name testCluster -nthreads 1 -port 54321""
system(command = launchH2O, intern =FALSE, wait=FALSE)



When on Linux, there is another way:


launchH2O <- ""bash -c 'nohup java -Xmx1g -jar /path/to/h2ojar/h2o.jar -name testCluster -nthreads 1 -port 54321 &'""
system(command = launchH2O, intern =FALSE)



(Because the last command explicitly puts it in the background, I don't think you need to set 
wait=FALSE
.)",2016-07-18T21:07:43,,,,38441250
38361213,38361213,7,"1a. Where to get the IPs?
  You get told them as you create each EC2 instance. It is the private IP you want (normally starting with 172.)
  (BTW, make sure you create them all in the same availability zone.)


1b. Use 54321 as the port. So your flatfile.txt for 3-nodes might look like:


172.31.1.123:54321
172.31.2.237:54321
172.44.99.99:54321



_2. You might make the flatfile.txt on your notebook, then scp it to each node, in your home directory. (Use the public IP for scp.)


_3. ssh in to each machine in turn, and then type that command, from the home directory, E.g.


 java -Xmx20g -jar h2o.jar -flatfile flatfile.txt -port 54321



_4. First make sure port 8787 is open in your Amazon firewall (aka ""security group""). Once you've made sure the H2O cluster is running (and assuming you have installed the H2O R package, and made sure it is exactly the same version as on each node in your cluster) then you simply do:


library(h2o)
h2o.init()



The 
h2o.init()
 looks on the local machine for any node in the cluster.




Aside:


What I have been using are the scripts found here:


https://github.com/h2oai/h2o-3/tree/master/ec2


They do almost all the steps for you, including making the flatfile, distributing it, and starting H2O on each node. You still need to set up a security group (well, optionally, I suppose: the script default is to have no security group!), and you need to set a password for the user you will use to login to RStudio with. And you need to install the H2O R package (I 
think
 that could be done from inside RStudio, if you have an aversion to the commandline).",2016-07-13T20:33:49,,,,38351835
38341393,38341393,4,"Currently, the 
H2OFrame.drop
 method does not support this, but we have added a 
ticket
 to add support for dropping multiple rows (and multiple columns).


In the meantime, you can subset rows by an index:


import h2o
h2o.init(nthreads = -1)

hf = h2o.H2OFrame([[1,3],[4,5],[3,0],[5,5]])  # 4 rows x 2 columns
hf2 = hf[[1,3],:]  # Keep some of the rows by passing an index



Note that the index list, 
[1,3]
, is ordered.  If you try to pass 
[3,1]
 instead, you will get an error.  H2O will not reorder the rows, and this is its way of telling you that.  If you have a list of out-of-order indexes, just wrap the 
sorted
 function around it first.  


hf2 = hf[sorted([3,3]),:]



Lastly, if you prefer, it's also okay to reassign the new subsetted frame to the original frame name, as follows:


hf = hf[[1,3],:]",2016-07-13T01:46:34,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",38335068
48332730,48332730,4,"Since this is now supported I wanted to highlight the comment that says how to drop by index:


df = df.drop([0,1,2], axis=0)


where if axis = 1 (default), then it drop columns; if axis=0 then drop rows.


drop(index, axis=1)


where index is a list of column indices, column names, or row indices to drop; or a string to drop a single column by name; or an int to drop a single column by index.",2018-01-19T01:11:52,Lauren,https://stackoverflow.com/users/6312126/lauren,"5,748",38335068
38282399,38282399,3,"You should try 
rJava
. This will allow you to call Java class from your R program in a more native fashion. A basic 
HelloWorld
 tutorial is 
here",2016-07-09T13:38:05,Siva Umapathy,https://stackoverflow.com/users/5924716/siva-umapathy,177,38281805
38399481,38399481,0,"After reading carefully the issue posted on github 
https://github.com/h2oai/sparkling-water/issues/32
. I tried couple of options here is what I tried

Added


--conf ""spark.scheduler.minRegisteredResourcesRatio=1"" ""spark.ext.h2o.topology.change.listener.enabled=false"" ""spark.locality.wait=3000"" ""spark.ext.h2o.network.mask=10.196.64.0/24""
 



Changed the :

Executors from 10 to 3,6 9
executor-memory from 4 to 12 and 12 to 24gb
driver-memory from 4 to 12 and 12 to 24gb



This is what I learned: GLM is memory intensive job so we have to provide sufficient memory to execute the job.",2016-07-15T15:07:54,,,,38275868
38278020,38278020,0,"I will do trouble shoot this problem with using Sparkling water shell and executing one line at a time




Start shell


Start H2O


Monitor the state of cluster




Then




Read Input data and cache it


Read Yarn logs to find why my tasks are getting killed , many times Yarn preemption kills the executors.


Increasing Spark wait time for starting H2O process


Decreasing the number of executors to just 3 / increasing cores to 3 / increasing executor memory to 6 GB


Monitor Spark UI and H2O Flow UI to see whats going on with memory in each stage




As general rule the memory size of H2O cluster should be 5 times the data input size. With each iteration are you crossing that limit ? 2 GB seems to be very small. We process huge volumes everyday using Sparkling water and Spark.


there are some suggestions on H2o website


https://github.com/h2oai/sparkling-water/blob/master/doc/configuration/internal_backend_tuning.rst",2016-07-09T03:33:50,,,,38275868
41330164,41330164,0,"There is no a final tree at the end of the random forest in R with randomForest packages. To make final predıction, random forest uses voting method. Voting means, for any data:
For example 0; 


of tree that predict the data as Class 0/total number of trees in the forest


For Class 1 it is same as the Class 0;


of tree that predict the data as Class 1/total number of trees in the forest


However you can use ctree.
library(""party"")
x <- ctree(Class ~ ., data=data)
plot(x)",2016-12-26T10:55:19,,,,38265039
38232277,38232277,2,"It is probably due to running incompatible versions and/or running a development version (the "".9999"" at the end of the version number) on your cluster.


I suggest you un-install, and install the latest R client, following 
these instructions
.  Try latest stable-build, then if no luck, try the nightly build. And if still no luck, consider upgrading your cluster to either the latest stable, or latest nightly.",2016-07-06T19:29:41,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,38150170
38116423,38116423,1,"In 
regre.1
 you use 
..
 instead of 
...
 !",2016-06-30T07:22:30,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,38111805
38109759,38109759,8,"Something is already listening on ports 54321 and/or 54322.  (Or possibly you have a very tight firewall configuration that is stopping H2O server claiming those ports.)


I'd first try and eliminate any firewall issues. Then if you're sure that isn't it, you could try giving ip and/or port explicitly:


h2o.init(nthreads = -1, max_mem_size = '2g', ip = ""127.0.0.1"", port = 54321)



If that works it might be due to something about the ipv6 addresses you are using.


But if still no luck, try another port:


h2o.init(nthreads = -1, max_mem_size = '2g', ip = ""127.0.0.1"", port = 50001)",2016-06-29T20:47:38,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,38101052
38358325,38358325,3,"I found out that there are two libraries for a Word2Vec transformation - I don't know why. 


from pyspark.mllib.feature import Word2Vec
from pyspark.ml.feature import Word2Vec



The second line returns a data frame with the function 
getVectors()
and has diffenrent parameters for building a model from the first line.


Maybe somebody can comment on that concerning the 2 different libraries.


Thanks in advance.",2016-07-13T17:36:55,sedioben,https://stackoverflow.com/users/6524396/sedioben,945,38081774
38131534,38131534,-1,"First of all in H2O we don't support a 
Vector
 column type, you'd have to make a frame like this:


word   | V1  | V2  | ...
assert | 0.3 | 0.4 | ...
sense  | 0.6 | 0.2 | ...



Now for the actual question - no, since it's a Scala 
Map
, we provide ways to create frames from data sources (files on HDFS/S3, databases etc) or conversions from RDDs/DataFrames but not from Java/Scala collections. Writing one would be possible but quite cumbersome.


Not the most performant solution but the easiest code-wise would be to make a DF (or RDD) first (by running 
sc.parallelize
 on 
map.toSeq
) and then convert it to an H2OFrame:


import hc._
val wordsDF = sc.parallelize(wordVectorsDF.toSeq).toDF
val h2oFrame = asH2OFrame(wordsDF)",2016-06-30T19:15:32,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,38081774
38056645,38056645,0,"standardize()
 is same as 
scale()
 of R. In statistical modeling you don't want effect of one variable to very heavy as compare to another variable just because of their scales. For example think age and salary in one model. Human age you expect to get in range 0-100 while salary  can go $20000-big CEOs salary. So in numerical munging in models $20000 will be very big and hence very dominating as compare to age say 20. To bring both into same level and to make these variables equally effective it is suggested to use 
standardize()
.",2016-06-27T14:30:58,abhiieor,https://stackoverflow.com/users/1582413/abhiieor,"3,534",38055840
38042926,38042926,3,"If you were just recording their main hobby, or main sport, then it would be a single enum column, e.g. hobbies, with 20 levels. You would simply write it as a string field in your csv file, and H2O would read it.


But I think what you are after is where each person has 0+ choices from 20 hobbies? In that case you need to have 20 columns in your csv file, one per hobby; each will be a 2-value enum. It doesn't matter what the two values are: Y/N, T/F, Y/blank, hobby-name/blank, etc. Your csv file might look this:


name,gender,football?,running?,data mining?,sleeping?
Tom,M,Y,,,Y
Dick,M,,,Y,
Suzy,F,,Y,Y,



Tom likes football and sleeping, Dick lives for data mining and nothing else, and Suzy is into running and data mining.


By the way, if using 
deeplearning
 then it will end up with the same network configuration: a single 20-level enum input will be converted into 20 binary inputs nodes.",2016-06-26T20:33:53,,,,38027263
39314845,39314845,2,"If you use Toree,


In /usr/local/share/jupyter/kernels/apache_toree_scala/kernel.json


You should add --packages ai.h2o:sparkling-water-core_2.10:1.6.6 on __TOREE_SPARK_OPTS__ , something like


""__TOREE_SPARK_OPTS__"": ""--master local[*] --executor-memory 12g --driver-memory 12g --packages ai.h2o:sparkling-water-core_2.10:1.6.6"",


Then, sc is created when you create your notebook. so you don't need to recreate sc.",2016-09-04T08:08:15,hyun,https://stackoverflow.com/users/6792653/hyun,36,38007814
37798836,37798836,4,"Neural networks perform best if all the input features have mean 
0
 and standard deviation 
1
. If the features have very different standard deviations, neural networks perform very poorly. Because of that 
h20
 does this normalization for you. In other words, before even training your net it computes mean and standard deviation of all the features you have, and replaces the original values with 
(x - mean) / stddev
. In your case the 
stddev
 for the second feature is 10x smaller than for the first, so after the normalization the values end up being 10x more important in terms of how much they contribute to the sum, and the weights heading to the hidden neuron need to cancel it out. That's why the weight for the second feature is 10x smaller.",2016-06-13T20:45:54,Ishamael,https://stackoverflow.com/users/3928385/ishamael,12.8k,37798134
37781534,37781534,4,"First try again with the latest version of H2O:


pip3 uninstall h2o
pip3 install http://h2o-release.s3.amazonaws.com/h2o/rel-turchin/9/Python/h2o-3.8.2.9-py2.py3-none-any.whl



If you run into the same issue, then do the following:


It looks like you already have a development version of H2O running on your machine (3.8.2.99999).  You will need to kill that H2O cluster that is running the dev version.  You can do that one of the following ways:




Navigate to the H2O Flow web GUI (if you are running locally, that would be at localhost:54321 by default).  In the GUI, click on the Admin menu item and then click on ""Shut Down.""  


Kill the Java process that is running the H2O cluster.




Once you have killed the existing H2O cluster, then reinstall the h2o module, and start the H2O cluster directly from Python as follows:


import h2o
h2o.init()



Since at this point, there won't be an existing H2O cluster running, the h2o Python module will start one up for you (and since you started it from Python, it won't get confused about versions).  


Sometimes what happens is that people download the H2O jar file separately, start an H2O cluster and then install a different version of the R or Python package, which causes the mismatch error.  I think this may be the cause of your issue.  Usually starting an H2O cluster is as simple as 
import h2o; h2o.init()
.",2016-06-13T03:47:41,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",37779076
60796630,60796630,4,"Try using a non-default port number. For example: 
h2o.init(port=8888)


This error can be caused by connecting to an already running H2O server that is the wrong version. When you run 
h2o.init()
 it first checks for an existing server running on the default port, 54321. If another user on your system is running a different H2O version on that port, it will connect and throw the version clash.",2020-03-22T06:42:55,andrew,https://stackoverflow.com/users/1884171/andrew,"4,079",37779076
48104614,48104614,2,"If you have the h2o window opened @ 
http://localhost:54321
 , make sure you shut it down (Admin->shutDown) before you import into python or python3 since they create conflicts.",2018-01-04T22:39:17,Sincole Brans,https://stackoverflow.com/users/1732587/sincole-brans,304,37779076
60327780,60327780,1,"By default, H2O is very unforgiving about version mismatches.


to work around the problem, you can try this (not guaranteed to work!):


 h2o.init(
    strict_version_check=False
)",2020-02-20T20:10:08,Clem Wang,https://stackoverflow.com/users/2263303/clem-wang,739,37779076
37780288,37780288,0,"In order to use H2O, need to update the h20 jar file to python version. 



Delete H20 versions on disk and do a fresh install.. Then 
pip install h20.
 


Or follow these instructions: 


http://www.h2o.ai/download/h2o/python",2016-06-13T00:01:38,,,,37779076
48828659,48828659,1,"I use IntelliJ IDEA with the python plugin. This way I have both java and python code in one and the same project. The data is in the database; the connection is always visible and accessible, independently of whether I have a .java or a .py file currently in the editor. In the list of configurations you can have Python scripts, Java applications, maven goals etc. 
Therefore I don't think you have to mix Python and Java code together (by calling Python scripts out of Java). That is completely unnecessary.


My workflow is (everything in IntelliJ IDEA):
1. Prepare the data (usually SQL)
2. Run python script, which applies a pipeline of transformators to the pandas data frame constructed from a certain database table and outputs a PMML.
3. Use the scikit-learn model in your java application.",2018-02-16T14:14:38,Volokh,https://stackoverflow.com/users/6522992/volokh,390,37777147
42717648,42717648,0,"If you have an ETL with HDFS backend, I would suggest deploying Spark on the cluster and using Spark's 
MLib
 machine learning algorithms. They support the methods you mentioned above.


Do you mind giving some context as to what the size (rows, columns, type) of the data that you plan to work with? Java would not be my recommended goto-language for ML but Scala compiles to JVM bytecode and has a similar syntax to java (in addition to having a Java API).


If you're producing a proof-of-concept, then Java is fine but if you're planning on working with big data, it doesn't really scale well.",2017-03-10T11:45:55,lohithbb,https://stackoverflow.com/users/7424866/lohithbb,128,37777147
46206224,46206224,0,"I have found a decent solution for my problem. I am using 
H2O.ai
 developed in Java for scalable machine learning using open source. It offers APIs in Java (Restful API), Python, R and Scala. It has best of class algorithms for classification, Regression, Clustering etc. and seamlessly integrates with Apache Hadoop and Spark (sparkling-water) as well, if someone has Spark cluster. It also offers a deep learning algorithm which is based on a multi-layer feedforward artificial neural network. I am using Java binding API/Rest API and sometimes the low-level H2o API (for h2o 3 nodes cluster management).


I come across another java based alternative, called 
Smile
 - Statistical Machine Intelligence and Learning Engine which provides regression, classification, clustering, association rule mining, feature selection etc. Does anybody have more feedback on these or similar Java based ML library?",2017-09-13T20:21:56,Gaurav Gupta,https://stackoverflow.com/users/5746807/gaurav-gupta,104,37777147
7030140,7030140,100,"Here is an example showing 10 minutes reduced to 1 second (from NEWS on 
homepage
). It's like subassigning to a 
data.frame
 but doesn't copy the entire table each time.


m = matrix(1,nrow=100000,ncol=100)
DF = as.data.frame(m)
DT = as.data.table(m)

system.time(for (i in 1:1000) DF[i,1] <- i)
     user  system elapsed 
  287.062 302.627 591.984 

system.time(for (i in 1:1000) DT[i,V1:=i])
     user  system elapsed 
    1.148   0.000   1.158     ( 511 times faster )



Putting the 
:=
 in 
j
 like that allows more idioms :


DT[""a"",done:=TRUE]   # binary search for group 'a' and set a flag
DT[,newcol:=42]      # add a new column by reference (no copy of existing data)
DT[,col:=NULL]       # remove a column by reference



and :


DT[,newcol:=sum(v),by=group]  # like a fast transform() by group



I can't think of any reasons to avoid 
:=
 !  Other than, inside a 
for
 loop. Since 
:=
 appears inside 
DT[...]
, it comes with the small overhead of the 
[.data.table
 method; e.g., S3 dispatch and checking for the presence and type of arguments such as 
i
, 
by
, 
nomatch
 etc. So for inside 
for
 loops, there is a low overhead, direct version of 
:=
 called 
set
. See 
?set
 for more details and examples. The disadvantages of 
set
 include that 
i
 must be row numbers (no binary search) and you can't combine it with 
by
. By making those restrictions 
set
 can reduce the overhead dramatically.


system.time(for (i in 1:1000) set(DT,i,""V1"",i))
     user  system elapsed 
    0.016   0.000   0.018",2011-08-11T17:18:31,,,,37748009
37735420,37735420,0,"I assume everything is the defaults, except defining a single hidden layer with 200 nodes?


Your first set of things to try are:




Use more epochs (or use less aggressive early stopping criteria)


Use a 2nd hidden layer


Use more nodes in your hidden layer(s)


Get more training data




Note that 
all
 of those will increase your training time.",2016-06-09T20:19:19,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,37730358
53637296,53637296,0,"You can use H2OGridSearch to find the best autoencoder model with the smallest MSE. 
Below is an example in Python. 
Here
 you can find example in R.


def tuneAndTrain(hyperParameters, model, trainDataFrame):
    h2o.init()
    trainData=trainDataFrame.values        
    trainDataHex=h2o.H2OFrame(trainData)
    modelGrid = H2OGridSearch(model,hyper_params=hyperParameters)
    modelGrid.train(x=list(range(0,int(len(trainDataFrame.columns)))),training_frame=trainDataHex)
    gridperf1 = modelGrid.get_grid(sort_by='mse', decreasing=True)
    bestModel = gridperf1.models[0]
    return bestModel



And you can call the above function to find and train the best model:


hiddenOpt = [[50,50],[100,100], [5,5,5],[50,50,50]]
l2Opt = [1e-4,1e-2]
hyperParameters = {""hidden"":hiddenOpt, ""l2"":l2Opt}
bestModel=tuneAndTrain(hyperParameters,H2OAutoEncoderEstimator(activation=""Tanh"", ignore_const_cols=False, epochs=200),dataFrameTrainPreprocessed)",2018-12-05T17:02:33,Hajar Homayouni,https://stackoverflow.com/users/6121350/hajar-homayouni,590,37730358
37628182,37628182,1,"What has happened is that is that all three files have been loaded into a single data frame.


E.g. I just tried with three files with 381 lines, 553 lines, and 553 lines, and got a 1484 row data frame. (I.e. it correctly recognized the header row in each csv file.)


That appears to be no way to load three files into three data frames with a single Flow command. You will need to call the Flow commands three times, once for each file.",2016-06-04T08:36:48,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,37624789
37542430,37542430,0,"So far seems to be a bug.


In 
as.data.frame.H2OFrame
 function 
getURL
 (from 
RCurl
 package) is called to retrieve the data from H2O server.


This function is used without passing any credentials.


One workaround would be to alter this function and replace 
getURL(url)
 with


ttt <- getURL(url, userpwd=paste0(conn@username,':',conn@password), httpauth = 1L)



Or check if username is given use the latter otherwise use the former.


A complete example how to use it is given 
here
.",2016-05-31T09:53:13,A.GH,https://stackoverflow.com/users/2911976/a-gh,123,37529184
37526428,37526428,0,"This is a 
bug in PySparkling
. 
A fix
 has been already committed but is still waiting for the next release, might be introduced in 1.5.15.


You can try building Sparkling Water from that branch yourself and use that before we release the next version.",2016-05-30T13:04:26,,,,37504691
37495058,37495058,1,"At this point in time, Flow is primarily a modeling tool and not a data munging tool, so there is not currently a way to do this.  Sed is an efficient tool for find/replace, so that's what I'd recommend.  Once you edit the file, you should import the file into the H2O cluster for modeling.  Or you can do more advanced munging on the data as an H2OFrame using the R or Python API for H2O.",2016-05-28T04:02:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",37492064
37436584,37436584,3,"POJO simply stands for Plain Old Java Object - the models we create are pure Java classes which have (almost) no external dependencies (only 
h2o-genmodel.jar
).


Have you went through 
the POJO quick start tutorial
? The tutorial is GBM binominal predictions as an example but you probably will be able to figure out how to use it with the NN.


After creating the model you download the POJO (either through Flow, R, Python or a REST call) and the 
h2o-genmodel.jar
 and you're all set to use it in your application. The only thing you need to do is put both the POJO (java file) and the jar on your classpath and you can use it!


@Edit:


1) To plug your POJO model into your project just copy the class to your project's source folder as you'd do with any other java class. Remember to add the appropriate 
package
 statement on top.


2) the 
h2o-genmodel.jar
 you need you can find the right version in 
Maven central.
 Add it to your pom/sbt/gradle file as you'd do with any other dependency.


3) You can find a sample how to predict CSV files 
here
 though it's not a full project. 
Here
 is a whole webapp using a POJO model though they are using a local version of 
genmodel.jar
 instead of getting it from Maven central.",2016-05-25T12:05:11,,,,37436121
37459718,37459718,1,"Mateusz Dymczyk's answer is great, though what I was looking for is a simple code snippet that presents the POJO integration. I found what I was looking for in the H2O hex.genmodel.easy 
package page
. There's also an extensive discussion on this exact issue in Google groups, 
here
.",2016-05-26T11:35:05,shakedzy,https://stackoverflow.com/users/5863503/shakedzy,"2,893",37436121
37402402,37402402,0,Turning off the proxy should fix the issue.,2016-05-24T00:00:05,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",37400821
53443675,53443675,0,"1) running with command ""python filename.py proxy=(default)"" worked for me, as this makes h2o connection to use default environment proxy.


2) have deleted http_proxy in user variables which is existing in my environmental variables.


Hope this helps",2018-11-23T09:16:05,Chandu,https://stackoverflow.com/users/874299/chandu,376,37400821
55414716,55414716,0,You should checkout if your firewall allows the connection with the h2o server. Maybe give it a try by disabling the firewall first,2019-03-29T09:53:41,George Sotiropoulos,https://stackoverflow.com/users/6346825/george-sotiropoulos,"2,103",37400821
44442782,44442782,1,"To elaborate on the OP's update, when using a remote cluster:


Make sure you install the most recent version (check the 
S3 download page
 for the redirect to the release number).  In the example below, this is 3.13.0.3908:


wget http://s3.amazonaws.com/h2o-release/h2o/master/3908/h2o-3.13.0.3908.zip
unzip h2o-3.13.0.3908.zip
mv h2o-3.13.0.3908 h2o
cd h2o
java -Xmx4g -jar h2o.jar



You then need to install the version of 
h2o-R
 that corresponds to this version.  (The correct version is likely 
not the CRAN version
.)  Otherwise you will get an error like:


Error in h2o.init(ip = ""XXX.XX.XX.XXX"", startH2O = FALSE) : 
  Version mismatch! H2O is running version 3.13.0.3908 but h2o-R package is version 3.10.4.6.
         Install the matching h2o-R version from - http://h2o-release.s3.amazonaws.com/h2o/master/3908/index.html



So you need to note the version number H2O is running (in the above example, 3908), make sure you have previously removed any existing 
h2o-R
 package (see 
here
 for more info), and then do:


install.packages(""h2o"", type=""source"", repos=""http://h2o-release.s3.amazonaws.com/h2o/master/3908/R"")



Now it should work:


library('h2o')
remoteH2O <- h2o.init(ip='XXX.XX.XX.XXX', startH2O=FALSE) #  Connection successful!",2017-06-08T18:09:42,C8H10N4O2,https://stackoverflow.com/users/2573061/c8h10n4o2,18.9k,37400149
37353694,37353694,1,"You seem to be describing what 
h2o.rbind
 does. E.g.


i1 = as.h2o(iris)
nrow(i1)   #150
i2 = h2o.rbind(i1,i1)
nrow(i2)   #300



If you check over on Flow to see what has happened, 
getFrames
, you will see ""iris"" with 150 rows, and ""RTMP_sid_abcd_2"" (i.e. some random name) with 300 rows. In other words, 
h2o.rbind()
 creates a new H2O frame.


If by ""join"" you were thinking an SQL join, where the two frames have a common index column, but otherwise different columns, then you want 
h2o.merge()
. (If that was what you wanted, but you cannot get 
h2o.merge()
 to work, then it would be helpful to see some of your data.)",2016-05-20T18:38:38,,,,37344958
37319824,37319824,2,"You'll be glad to know H2O stores that information! E.g. (this is for the Iris data set)


m <- h2o.randomForest(1:4, 5, data)



When printing 
m
 I see:


number_of_trees model_size_in_bytes min_depth max_depth mean_depth min_leaves  max_leaves mean_leaves
            150               20217         1         9    3.72667          21         15     6.17333



So there are 926 leaves (
6.17333 * 150
).


To get it with code:


ms = m@model$model_summary
ms$number_of_trees * ms$mean_leaves",2016-05-19T09:57:05,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,37311633
38331344,38331344,0,"I would recommend you do this the way you are - via Spark. From the 
FAQ
:




How do I filter an H2OFrame using Sparkling Water?


Filtering columns is easy: just remove the unnecessary columns or
  create a new > H2OFrame from the columns you want to include
  (Frame(String[] names, Vec[] vec)), then make the H2OFrame wrapper
  around it (new H2OFrame(frame)).


Filtering rows is a little bit harder. There are two ways:


Create an additional binary vector holding 1/0 for the in/out sample
  (make sure to take this additional vector into account in your
  computations). This solution is quite cheap, since you do not
  duplicate data - just create a simple vector in a data walk.


or


Create a new frame with the filtered rows. This is a harder task,
  since you have to copy data. For reference, look at the #deepSlice
  call on Frame (H2OFrame)",2016-07-12T14:12:27,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,37286030
47179200,47179200,1,"There can be multiple reasons for this behaviour. 


YARN can give you only the amount of executors based on available resources ( memory, vcores ). If you ask for more then you have resources, it will give you max what it can.


It can be also case when you have dynamic allocation enabled. This means that that Spark will create new executors when they are needed.


In order to solve some technicalities in Sparkling Water we need to discover all available executors at the start of the application by creating artificial computation and trying to utilise the whole cluster. This might give you less number of executors as well.


I would suggest looking at 
https://github.com/h2oai/sparkling-water/blob/master/doc/tutorials/backends.rst
 where you can read more about the paragraph above and how it can be solved using so called external sparkling water backend.


You can also have a look here 
https://github.com/h2oai/sparkling-water/blob/master/doc/configuration/internal_backend_tuning.rst
. This is Sparkling Water guide for tuning the configuration.


Kuba",2017-11-08T12:00:40,,,,37216280
37265026,37265026,0,"I got over the problem by changing the following four values in cloudera manager 


Setting                                  Value
yarn.scheduler.maximum-allocation-vcores 8  
yarn.nodemanager.resource.cpu-vcores     4 
yarn.nodemanager.resource.cpu-vcores     4 
yarn.scheduler.maximum-allocation-mb     16 GB",2016-05-16T23:58:25,uh_big_mike_boi,https://stackoverflow.com/users/1472831/uh-big-mike-boi,"3,440",37216280
37121763,37121763,3,"You should setup your default queue to have available resources to run 2nodes cluster. 


See warnings:




WARNING: Job memory request (2.2 GB) exceeds queue available memory capacity (0.0 GB)




you ask 1GB per node (+overhead) but there is no available resources in the YARN queue




WARNING: Job virtual cores request (2) exceeds queue available virtual cores capacity (0)




you ask for 2 virtual cores but no cores are available in your default queue






Please check YARN documentation - for example setup of capacity scheduler and max available resources:

https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html",2016-05-09T17:20:28,Michal,https://stackoverflow.com/users/5089773/michal,437,37096589
37305263,37305263,0,"I made the following changes in Cloudera Manager yarn configuration


Setting                                     Value
yarn.scheduler.maximum-allocation-vcores    8 
yarn.nodemanager.resource.cpu-vcores        4
yarn.nodemanager.resource.cpu-vcores        4
yarn.scheduler.maximum-allocation-mb        16 GB",2016-05-18T16:27:14,uh_big_mike_boi,https://stackoverflow.com/users/1472831/uh-big-mike-boi,"3,440",37096589
37064018,37064018,1,"If anyone can still provide an elegant answer to my original question, that'd be appreciated. But I found the 
.replace()
 methods on 
H2OFrame
 to be helpful. I had to use something like



for( i <- 0 until h2oFrame.numCols()) h2oFrame.replace(i, h2oFrame.vec(i).toCategoricalVec)



which solved my problem.",2016-05-06T04:01:40,S.P.,https://stackoverflow.com/users/6298061/s-p,41,37062476
37086248,37086248,0,"The solution you mentioned is the one only available at the moment at H2O.


You can make it little better by removing the returned Vec if you don't need this Vec anymore. It deletes the previous Vector from internal H2O's DKV store. The deletion is not done automatically, since in some cases you may decide to keep old Vec as well.


for( i <- 0 until h2oFrame.numCols()){
  h2oFrame.replace(i, h2oFrame.vec(i).toCategoricalVec).remove()
}



If you just want to turn one column to categorial, you can do


h2oFrame.replace(h2oFrame.find(""target""),h2oFrame.vec(""target"").toCategoricalVec).remove()",2016-05-07T08:21:10,,,,37062476
42885061,42885061,9,"I think it may be the solution you are looking for;


library(h2o)
h2o.init()
df = h2o.importFile(""http://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"")
model = h2o.gbm(model_id = ""model"",
            training_frame = df,
            x = c(""Year"", ""Month"", ""DayofMonth"", ""DayOfWeek"", ""UniqueCarrier""),
            y = ""IsDepDelayed"",
            max_depth = 3,
            ntrees = 5)
h2o.download_mojo(model, getwd(), FALSE)



Now download the latest stable h2o release from 
http://www.h2o.ai/download/
 and run the PrintMojo tool from the command line.


java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i model.zip -o model.gv
dot -Tpng model.gv -o model.png



open model.png


More info: 
http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html",2017-03-19T09:42:04,,,,37017165
53939342,53939342,1,"New Tree API introduced in 3.22.0.1 (October 2018) changes the whole game of visualizing H2O trees. General workflow may look like this:


and detailed example with code can be found here: 
Finally, You Can Plot H2O Decision Trees in R
.",2018-12-27T03:12:57,topchef,https://stackoverflow.com/users/59470/topchef,19.8k,37017165
36972317,36972317,8,"No, a Hadoop cluster is not needed. Here is the documentation 
for starting nodes from the commandline
. (I also found it useful to read the EC2 setup docs, and then browse through the EC2 scripts they supply.)


Basically you need to create a 
flatfile
, which is a simple text file listing IP address and the port of each node in your cluster. You can give the cluster a name, and I like to name the flatfile with the same name, which will be ""lantest.txt"".


Then you need to get h2o.jar on each machine, and put your flatfile in the same directory (again, on each machine). Then start it on each machine with:


java -Xmx2G -ea -jar h2o.jar -name lantest -ip 192.168.x.y -port 54321 -flatfile lantest.txt



Keep that console window open, as log messages will be written to it.


Typically you change 
.x.y
 for each machine, but everything else stays the same. The 
-Xmx2G
 says I'm giving each machine 2GB; you might want to adjust that (but it must be exactly the same for every node.)


Something else that must be exactly the same is the version of h2o.jar: a minor version difference isn't good enough as it checks the md5 checksum!


The other thing you might struggle with is firewalls. Each node has to be able to see each other node on ports 54321 and 54322. So open those ports on the firewall on each machine. (On Windows, I also had to open access to Java.)",2016-05-01T21:43:18,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,36927443
36926234,36926234,2,"it should be possible like this:


val clazz = Class.forName(""Model123123"")
val field = clazz.getDeclaredField(""NAMES"")
val value = field.get(null).asInstanceOf[Array[String]]



We get the class and ask for field in a same way as we would do for non-static field. Once we have the field we can get the value of it by calling 
get
 method. The 
null
 argument means that we are not passing it any instance from which it should get the value ( since it's static member). At last we have to manually cast the type to the type we're expecting, because type information is lost at this time.


If you need to update the value of static field you can do it as


field.set(null, Array[String](""name1"", ""name2""))



We again pass null since we don't need to set it on some specific instance since it's class member.


It's basically just java reflection used in the scala language. Another approach is to use scala mirrors - 
http://docs.scala-lang.org/overviews/reflection/environment-universes-mirrors.html",2016-04-28T21:59:19,,,,36919095
36969310,36969310,1,"In your case, the best way is to cast model instance to a common interface 
hex.genmodel.GenModel
 as you did, then you can easily call 
getNames
 method to access names. 


There is no need to use reflection to access static members.",2016-05-01T16:56:28,Michal,https://stackoverflow.com/users/5089773/michal,437,36919095
36897399,36897399,0,"Unclear what happened without more information (logs would probably say why the rbind did not take).


What version are you using? I tried your code with iris on the bleeding edge and it all worked as expected.


By the way, rbind is typically going to be expensive, especially since what you're semantically after is a subset:


test[range(10) + range(20,test.nrow),:]


should also give you the desired subset (with caveat that you make the full list of row indices in python and pass it over REST to h2o).",2016-04-27T17:55:51,rijs,https://stackoverflow.com/users/5220538/rijs,236,36894000
36813707,36813707,2,"If you are just trying to train an H2O GLM, then you do not need the h2oEnsemble package, so you can remove 
library(h2oEnsemble)
 from your code.  After 
library(h2o)
, you also must add the following line to your code, 
h2o.init(nthreads = -1)
, which will start up an H2O cluster in the background -- the ""H2O cluster"" is where the optimized Java code gets executed in parallel.


The issue you are having has to do with your 
training_frame
.  In H2O, the 
training_frame
 argument must be an ""H2OFrame"", not a typical R data.frame.  For scalability reasons, H2O uses distributed dataframes called ""H2OFrames"" instead of the standard in-R-memory data.frame object.


To convert 
df
 into an H2OFrame and train a GLM, do the following:


hdf <- as.h2o(df)  #convert data.frame to H2OFrame
modellm <- h2o.glm(y = ""v1"", x = ""v100"",training_frame = hdf, family = ""gaussian"",
               nfolds = 0, alpha = 0.1, lambda_search = FALSE)



Alternatively, if you have your data in a CSV file, for example, you can use the 
h2o.importFile()
 function to import your data into the H2O cluster directly, and then you don't need to convert it from an R data.frame to an H2OFrame.


Since you are new to H2O, I recommend looking over this 
Jupyter R notebook
 that I created to teach people how to use H2O.  Welcome to H2O!",2016-04-23T16:54:49,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",36811862
38745829,38745829,3,"H2O may be very good in various areas. but unfortunately lack of documentation and tutorial makes it's really difficult to learn...


Hoping that they watch these type of comments and improve their documentation.


At least launching one tutorial of 12GB airlines data processing can help a lot for multiple enthusiastic people who really wanted to explore H2O.",2016-08-03T14:01:22,ayush varshney,https://stackoverflow.com/users/5582677/ayush-varshney,537,36705708
36707894,36707894,2,"This is a very outdated version of the H2O docs and there have been some major API changes since H2O 3.0.  The latest R docs can always be found at: 
http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Rdoc.html


Our 
main docs landing page
 has a link to the latest R docs, Python docs, and a bunch of other links you may find useful.  We also have a Google Group called 
h2ostream
 for posting new questions and searching through old questions.  Welcome to H2O!",2016-04-19T03:15:24,,,,36705708
36712107,36712107,1,"The 
recommended way
 appears to be to save your data as an SVMLight file, then use:


yourFrame = h2o.import_file(path=""/path/to/test.svmlight"")



See also this answer (for R): 
https://stackoverflow.com/a/32877906/841830


And for exporting to svmlight from panda: 
https://github.com/coreylynch/sklearn-transform",2016-04-19T07:59:50,Community,https://stackoverflow.com/users/-1/community,1,36696541
36685570,36685570,0,"As mentioned above, t2.micro is a single core instance, so the 
H2O cluster allowed cores:  1
 is correct.  However, it looks like you are running into bug in reporting the number of 
H2O cluster allowed cores
 with virtual machines (like those used in EC2) that was documented 
here
.  This was fixed on 4/1/16 and so it should be fixed in the latest stable release.  Download the 
latest stable
 of H2O and try again -- if you still see 
H2O cluster total cores:  15
, post a comment here and we will re-open the ticket.",2016-04-18T04:37:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",36680046
36649976,36649976,4,"If your model is called 
m
, then to get just the number of epochs trained: 
last(m@model$scoring_history$epochs)


To see what other information is available (which is literally everything you can see in the Flow interface) and how to access it, use 
str(m)


Also be aware of this command: 
summary(m)
  In addition to what is shown with 
print(m)
 it adds this section (for a deeplearning model):


Scoring History: 
            timestamp   duration training_speed    epochs iterations       samples training_MSE training_deviance training_r2
1 2016-04-14 11:35:46  0.000 sec                  0.00000          0      0.000000
2 2016-04-14 11:35:52  5.218 sec 15139 rows/sec  10.00000          1  77150.000000      0.00000           0.00000     0.07884
...
7 2016-04-14 11:36:18 31.346 sec 25056 rows/sec 100.00000         10 771500.000000      0.00000           0.00000     0.72245



I.e. You can see total number of epochs by looking at the last row.


BTW, this is different to h2o's 
summary()
 command when applied to a data 
frame
; in that case it behaves like R's built-in summary function, and shows statistics on each column in the data frame.",2016-04-15T14:31:47,,,,36620585
39209897,39209897,2,"I'm quite confident in stating that the answer of Darren Cook is valid only when 
overwrite_with_best_model=FALSE
. Anyway, this parameter is set to be 
TRUE
 by default, so the previous answer can be quite misleading for reasons that you can partially find 
here
. You can check what I mean in the following output obtained tuning the network with 
h2o.grid
 and using 
m@model$scoring_history
 as Darren suggested.


epochs     validation_classification_error
0.00000    0.46562
1.43150    0.50000
100.31780  0.46562



As you can see, if 
overwrite_with_best_model=TRUE
 than the functions saves the best model in the last iteration, thus solution of Darren always corresponds in the maximum number of epochs. Assuming that you are tuning your model, I recommend the following solution: 


epochsList = m@model$scoring_history$epochs
bestEpochIndex = which.min(m@model$scoring_history$validation_classification_error)
bestEpoch = epochsList[bestEpochIndex]
print(sprintf(""The best epoch is: %d"", bestEpoch))",2016-08-29T15:27:45,Community,https://stackoverflow.com/users/-1/community,1,36620585
36641964,36641964,2,"It's actually a critical bug we know about in Sparkling Water team and it's fixed in a new release with other hotfixes. The bug is already fixed ( 
https://0xdata.atlassian.net/browse/SW-107
) and a new release should be out very soon.


I'll keep you updated and let you know when new release is out.


EDITED 29 April 2016


New release with the fix is out.


For spark 1.6 - 
http://h2o-release.s3.amazonaws.com/sparkling-water/rel-1.6/3/index.html


For spark 1.5 - 
http://h2o-release.s3.amazonaws.com/sparkling-water/rel-1.5/14/index.html


You don't need to call 
-packages
 any more to add sparkling-water-core. The pySparkling egg file already contains all necessary Java/Scala classes it needs. So all you need to do is just set egg file using the py-files option and that should be it.",2016-04-15T08:25:56,,,,36583415
43288285,43288285,2,"Running H2O with 32-bit Java is really, really not recommended, and unsupported.
It will also limit you to very small data sets.


But, if you must, you can run H2O on the command line by hand, and then connect to the running H2O process using the Web UI (or R or Python).


CMD> cd \path\to\h2o
CMD> java -Xmx1g -jar h2o.jar -ip localhost
04-07 15:59:30.483 127.0.0.1:54321       58927  main      INFO: ----- H2O started  -----
04-07 15:59:30.503 127.0.0.1:54321       58927  main      INFO: Build git branch: rel-tutte
04-07 15:59:30.503 127.0.0.1:54321       58927  main      INFO: Build git hash: e27e9002802e76b3ebb56a77f5bb82b827d5b810
04-07 15:59:30.503 127.0.0.1:54321       58927  main      INFO: Build git describe: jenkins-rel-tutte-2
...
04-07 15:59:30.922 127.0.0.1:54321       58927  main      INFO: Registered: 136 REST APIs in: 368mS
04-07 15:59:31.475 127.0.0.1:54321       58927  main      INFO: Registered: 201 schemas in 552ms
04-07 15:59:31.476 127.0.0.1:54321       58927  main      INFO: 
04-07 15:59:31.476 127.0.0.1:54321       58927  main      INFO: Open H2O Flow in your web browser: http://127.0.0.1:54321
04-07 15:59:31.476 127.0.0.1:54321       58927  main      INFO:



Now open your web browser to localhost:54321 as the instruction says at the bottom.


Instead of -Xmx1g you can then experiment with larger heaps to figure out the biggest you can use in your local environment.


[ The ""-ip"" argument makes H2O's web server bind only to localhost, so you're not accidentally exposing H2O to others not on your computer without realizing it. ]",2017-04-07T23:05:36,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",36547434
50958877,50958877,2,"I spent ages trying to work out the same thing, as this isn't documented anywhere That is, how to create an H2O frame without (slowly) round-tripping to disk.  


Here's my in-memory java solution for converting a Guava table to an H2O dataframe.  Should be trivial to adapt to your data structure.  


I haven't yet worked out how to split this into chunks though (or what the performance implications of not doing so are).  Maybe someone who knows H2O better can comment on this...?


/**
 * Converts a Guava Table to an H2O Frame (and registers it in the Distributed
 * Key/Value store) using only in-memory operations.
 * 
 * TODO everything is contained in a single chunk.  Not sure of performance implications of this...
 * 
 * @param t
 *            the guava table
 * @param tableKey
 *            a unique key to register the table in h2o under
 * @return an H2O Frame
 * @throws IOException
 */
public static Frame tableToFrame(LinkedHashBasedTable<Integer, String, Double> t, String tableKey) throws IOException {

    Set<String> cols = t.columnKeySet();
    List<Vec> vecs = new ArrayList<>();

    VectorGroup group = new VectorGroup(); //make a common group to contain vector keys.  This has something to do with Chunk distribution among nodes for parallel processing.
    for (String col : cols) {
        double[] vals = toDoubleArray(t.column(col).values());
        Key<Vec> key = group.addVec(); 
        Vec v = Vec.makeVec(vals, key);  
        vecs.add(v);
    }

    String[] names = cols.toArray(new String[cols.size()]);
    Vec[] vecArr = vecs.toArray(new Vec[vecs.size()]);

    Key<Frame> frameKey = Key.make(tableKey);
    Frame frame = new Frame(frameKey, names, vecArr);
    DKV.put(frameKey, frame); //register the new Frame in the DKV, so h2o jobs can find it.

    logger.info(""Converted Table to Frame with ""+frame.numRows()+"" rows and ""+frame.numCols()+"" cols"");

    return frame;
}",2018-06-21T00:46:26,Sam West,https://stackoverflow.com/users/4771628/sam-west,21,36483153
36556356,36556356,1,"You can use the REST API to drive your H2O instance from your Java app but this will still require you to save your data and then call something like ImportFiles (
http://h2o-release.s3.amazonaws.com/h2o/rel-turchin/2/docs-website/h2o-docs/index.html#route-%2F3%2FImportFiles
). 


If I understood your question correctly, there is currently no way to 'stream' your data from your app to the H2O instance the way you're suggesting. You could do this if you bundle H2O directly into your app but I'm not sure that's what you want.",2016-04-11T18:24:49,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,36483153
36741952,36741952,0,"Can I please ask to what is content of your 
MASTER
 environment variable ?


This can occur if you have set 
MASTER
 to 
""local-cluster[numOfExecutors,numOfExecutorCores,numOfExecMemory]""
 where 
numOfExecMemory
 is lower then your request for memory in spark-defaults file.",2016-04-20T11:09:28,,,,36465240
44039480,44039480,0,"You have a typo in your spark-defaults.conf file :


spark.executor.memory   20g
spark.driver.memory     8g



Here spark.executor.memory is set to 20g (20 gigabytes = 20480 mb) which translates to 20480 mb per worker node. Therefore the error -->


org.apache.spark.SparkException: Asked to launch cluster with 2048 MB RAM / worker but requested 20480 MB/worker



where it says you have asked to form cluster with 20480 mb per worker.


You should edit the 
spark.executor.memory  20g
 spark-defaults.conf file to 
spark.executor.memory   2g


If you want to increase the memory per worker just change 2g to the mount you want.


Also edit the spark-env.sh accordingly as this :


export SPARK_WORKER_MEMORY=108GB
export SPARK_WORKER_INSTANCES=4



will create 4 worker instances per node with 1 gb memory each.


So if you want for example 4gb each node then in spark-env.sh


export SPARK_WORKER_MEMORY=4g
export SPARK_WORKER_INSTANCES=1



and spark-defaults.conf as :


spark.executor.memory   4g
spark.driver.memory     8g",2017-05-18T05:44:08,,,,36465240
36439405,36439405,3,"If you want to run classification, then your response variable must be encoded as a ""factor"" (aka ""enum"") type.  See this 
R code example
 from the 
H2O Deep Learning booklet
.  This is the case for all H2O algorithms.",2016-04-06T00:27:51,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",36434082
36243490,36243490,1,"If you restart the virtual machine, you will also need to restart the H2O cluster.  You will start the H2O cluster like you did originally, which is probably by typing the following at the command line: 
java -jar h2o.jar
   Once the H2O cluster is running again, you will be able to reach the Flow web interface at localhost:54321.",2016-03-27T03:23:20,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",36242191
36227222,36227222,2,"It seems the Pandas DataFrame to H2OFrame conversion works fine outside Django, but fails inside Django. The problem might be with Django's pre_save not allowing the writing/reading of the temporary .csv file that H2O creates when ingesting a python object. A possible workaround is to explicitly write the Pandas DataFrame to a .csv file with 
model_data_frame.to_csv(<path>, index=False)
 and then import the file into H2O with 
h2o.import_file(<path>)
.",2016-03-25T20:07:37,Ludi Rehak,https://stackoverflow.com/users/6115462/ludi-rehak,240,36212815
36212869,36212869,2,"This sounds like it could be an issue with using a private vs public IP.  See if you can 
ping 10.0.2.5
.  If that is getting a timeout then the machine is not reachable. If you can indeed reach the machine then see if you can reach the service: 
wget http://10.0.2.15:54321",2016-03-25T01:51:23,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",36211698
36096655,36096655,6,"H2O does not have a native JDBC connector (yet).


You can leverage H2O's algorithms in Spark w/ Sparkling Water though (
https://github.com/h2oai/sparkling-water
): use Spark SQL to ingest data into an RDD, convert it to an H2OFrame (you can convert in either direction), and pass it to H2O's algos.


A more blunt approach is to query the data out into a CSV, which H2O can then read. If your data size is not too massive this may be reasonable.",2016-03-19T01:03:19,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,36080568
36059839,36059839,0,Solved: The problem was that the POJO class name obviously has to be a valid java class name; a purely numeric name is not allowed. Changing the model name resolves the issue.,2016-03-17T11:54:46,p_r,https://stackoverflow.com/users/5027705/p-r,41,36059640
42611699,42611699,0,"[ This is not a direct answer to the question, but hopefully a helpful pointer to anyone that finds this question... ]


Since this question was asked, H2O has also added the ability to export a MOJO and use it for making predictions.


An H2O POJO is a code representation of a model, and an H2O MOJO is a data representation of a model.


A MOJO can be used in the same way as a POJO, and MOJOs do not need to be compiled (they are interpreted instead).  This is especially useful for very large tree models, where trying to compile them has various technical challenges around gigabytes of code size.  So in many cases, the best way to address a compilation issue is to not compile at all.


The online documentation for both H2O POJOs and MOJOs can be found here:




http://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html




I hope people find this (delayed) answer helpful.",2017-03-05T17:36:22,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",36059640
36024146,36024146,6,"The answer is in the 
docs
.


[ In the left pane, click on ""Algorithms"", then ""Supervised"", then ""DRF"".  The FAQ section answers this question. ]


For convenience, the answer is also copied and pasted here:


""How is variable importance calculated for DRF?  Variable importance is determined by calculating the relative influence of each variable: whether that variable was selected during splitting in the tree building process and how much the squared error (over all trees) improved as a result.""",2016-03-15T23:25:19,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",36021137
35982650,35982650,2,"You have to run 
./gradlew shadowJar
 and use the jar created by it 
build/libs/sparkling-water-droplet-app.jar
 instead since it creates a fat jar which contains all classes required while submitting a job (the 
build
 task does not do that).",2016-03-14T08:28:14,Mateusz Dymczyk,https://stackoverflow.com/users/217019/mateusz-dymczyk,15.1k,35976589
35905442,35905442,2,"It looks like you are using H2O2 (H2O Classic). I recommend upgrading your H2O to the latest (H2O 3). There is a build specifically for HDP2.3 here: 
http://www.h2o.ai/download/h2o/hadoop


Running H2O3 is a little cleaner too:


hadoop jar h2odriver.jar -nodes 1 -mapperXmx 6g -output hdfsOutputDirName



Also, 512mb per node is tiny - what is your use case? I would give the nodes some more memory.",2016-03-10T00:34:14,Nick Karpov,https://stackoverflow.com/users/2580503/nick-karpov,510,35892715
35854316,35854316,2,"In this case, you can:


1) use 
h2o.predict(H2OFrame)
 method to generate prediction, but you need to transform 
RDD
 to 
H2OFrame
. It is not the perfect solution...however, for some cases, it can provide reasonable solution.


2) switch to JVM and call JVM directly via Spark's Py4J gateway
This is not fully working solution right now, since the method 
score0
 needs to accept non-primitive types on H2O side and also to be visible (right now it is protected),
but at least idea:


model = sc._jvm.water.DKV.getGet(""deeplearning.model"")
double_class = sc._jvm.double
row = sc._gateway.new_array(double_class, nfeatures)
row[0] = ...
...
row[nfeatures-1] = ...
prediction = model.score0(row)



I created JIRA improvement for this case 
https://0xdata.atlassian.net/browse/PUBDEV-2726


However, workaround is to create a Java wrapper around model which would
expose right shape of 
score0
 function:


class ModelWrapper extends Model {
   public double[] score(double[] row) {
     return score0(row)
   }
}



Please see also 
hex.ModelUtils
: 
https://github.com/h2oai/sparkling-water/blob/master/core/src/main/scala/hex/ModelUtils.scala

(again you can call them directly via Py4J gateway exposed by Spark)",2016-03-07T21:23:26,Michal,https://stackoverflow.com/users/5089773/michal,437,35829491
35786076,35786076,14,"I'm sort of surprised that this actually worked. Hopefully it works for your case. I'm quite curious to know how speed compares to reading in compressed data from disk directly from R (albeit with a penalty for non-vectorization) instead.


tblNames = fread('cat *dat.gz | gunzip | head -n 1')[, colnames(.SD)]
tbl = fread('cat *dat.gz | gunzip | grep -v ""^Day""')
setnames(tbl, tblNames)
tbl",2016-03-04T00:55:10,,,,35763574
35764724,35764724,7,"R has the ability to read gzipped files natively, using the 
gzfile
 function. See if this works.


rbindlist(lapply(dat.files, function(f) {
    read.delim(gzfile(f))
}))",2016-03-03T06:28:16,Hong Ooi,https://stackoverflow.com/users/474349/hong-ooi,57.5k,35763574
35764072,35764072,4,"The bottleneck might be caused by the use of the system() call to an external application.


You should try using the builting functions to extract the archive.
This answer explains how: 
Decompress gz file using R",2016-03-03T05:39:42,Community,https://stackoverflow.com/users/-1/community,1,35763574
42796277,42796277,0,I use the h2o R package 3.6.0.3. Reloading the data set I want to do my predictions on solves the issue for me.,2017-03-14T20:48:51,Vincent Lous,https://stackoverflow.com/users/3453731/vincent-lous,127,35735675
35783332,35783332,3,"It looks like somehow your H2O cluster was launched with 32 cores instead of the full 48.  That's what ""H2O cluster allowed cores: 32"" indicates is happening.  To use all the cores, do the following:




Shut down your existing H2O cluster using 
h2o.shutdown()


Start a new H2O cluster from R using 
h2o.init(nthreads = -1)
, which means that it will use all available cores.  If for some reason that does not work, try 
h2o.init(nthreads = 48)
.


You can also start the H2O cluster from the command line by typing the following:  
java -Xmx30g -jar h2o.jar -nthreads 48
 and then use 
h2o.init()
 to connect inside R.




Feel free to also upgrade to the 
latest stable version of H2O
 (3.8.0.2 is slightly outdated, now we are at 3.8.1.1).",2016-03-03T21:24:46,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35711772
45107153,45107153,0,It looks like this was a limitation in the old version. Using 3.10 and testing 3.12 now issue was fixed.,2017-07-14T15:55:02,user3078500,https://stackoverflow.com/users/3078500/user3078500,302,35711772
35714569,35714569,3,"Based on your comments, the reason that your models cannot be found is because you did not save them to disk properly.  All H2O objects (including models) exist in memory in the H2O cluster and if you want to save/serialize them to disk, you must the 
h2o.saveModel
 function, not the built-in R 
save
 function.  The R 
save
 function can only save objects in R memory.  


To load the models, use 
h2o.loadModel
.",2016-03-01T04:17:47,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35680363
35679932,35679932,4,"Yes, there is an easy way to extract the ""top"" model of an H2O grid search.  There are also utility functions that will extract all the model metrics (e.g. 
h2o.mse
) that you have been trying to access.  Examples of how to do these things can be found in the 
h2o-r/demos
 and 
h2o-py/demos
 subfolders on the 
h2o-3
 GitHub repo.


Since you are using R, here is a 
relevant code example
 that includes a grid search, with sorted results.  You can also find how to access this information in the R documentation for the 
h2o.getGrid
 function.


Print out the auc for all of the models, sorted by validation AUC:


auc_table <- h2o.getGrid(grid_id = ""eeg_demo_gbm_grid"", sort_by = ""auc"", decreasing = TRUE)
print(auc_table)



Here is an example of the output:


H2O Grid Details
================

Grid ID: eeg_demo_gbm_grid 
Used hyper parameters: 
  -  ntrees 
  -  max_depth 
  -  learn_rate 
Number of models: 18 
Number of failed models: 0 

Hyper-Parameter Search Summary: ordered by decreasing auc
   ntrees max_depth learn_rate                  model_ids               auc
1     100         5        0.2 eeg_demo_gbm_grid_model_17 0.967771493797284
2      50         5        0.2 eeg_demo_gbm_grid_model_16 0.949609591795923
3     100         5        0.1  eeg_demo_gbm_grid_model_8  0.94941792664595
4      50         5        0.1  eeg_demo_gbm_grid_model_7 0.922075196552274
5     100         3        0.2 eeg_demo_gbm_grid_model_14 0.913785959685157
6      50         3        0.2 eeg_demo_gbm_grid_model_13 0.887706691652792
7     100         3        0.1  eeg_demo_gbm_grid_model_5 0.884064379717198
8       5         5        0.2 eeg_demo_gbm_grid_model_15 0.851187402678818
9      50         3        0.1  eeg_demo_gbm_grid_model_4 0.848921799270639
10      5         5        0.1  eeg_demo_gbm_grid_model_6 0.825662907513139
11    100         2        0.2 eeg_demo_gbm_grid_model_11 0.812030639460551
12     50         2        0.2 eeg_demo_gbm_grid_model_10 0.785379521713437
13    100         2        0.1  eeg_demo_gbm_grid_model_2  0.78299280750123
14      5         3        0.2 eeg_demo_gbm_grid_model_12 0.774673686150002
15     50         2        0.1  eeg_demo_gbm_grid_model_1 0.754834657912535
16      5         3        0.1  eeg_demo_gbm_grid_model_3 0.749285131682721
17      5         2        0.2  eeg_demo_gbm_grid_model_9 0.692702793188135
18      5         2        0.1  eeg_demo_gbm_grid_model_0 0.676144542037133



The top row in the table contains the model with the best AUC, so below we can grab that model and extract the validation AUC:


best_model <- h2o.getModel(auc_table@model_ids[[1]])
h2o.auc(best_model, valid = TRUE)



In order for the 
h2o.getGrid
 function to be able sort by a metric on the validation set, you need to actually pass the 
h2o.grid
 function a 
validation_frame
.  In your example above, you did not pass a validation_frame, so you can't evaluate the models in the grid on the validation set.",2016-02-28T07:32:50,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35657989
38857065,38857065,3,"This seems to be valid for recent versions of h2o only, with 3.8.2.3 you get 
a Java exception saying that ""auc"" is an invalid metric.
The following fails :


library(h2o)
library(jsonlite)
h2o.init()
iris.hex <- as.h2o(iris)
h2o.grid(""gbm"", grid_id = ""gbm_grid_id"", x = c(1:4), y = 5,
     training_frame = iris.hex, hyper_params = list(ntrees = c(1,2,3)))
grid <- h2o.getGrid(""gbm_grid_id"", sort_by = ""auc"", decreasing = T)



However, replace 'auc' with 'logloss' and decrease = F, and it's fine.",2016-08-09T17:29:08,RobertoRonaldo,https://stackoverflow.com/users/6696903/robertoronaldo,31,35657989
42092632,42092632,-2,"Unfortunately the H2O grid function uses training_frame not validation_frame when you pass them both in.  Consequently the winning model is extremely overfitted and useless. EDIT: Well, correction here, it's actually useful to have training bias very low like this, for purposes of learning curve analysis and bias versus variance analyi. But to be clear I also need to be able to run again and get a validation dataset to be used as search criterion for final model fitting and selection.


For example here is a winning model from the grid function on a GBM, where validation_frame was passed in, and AUC was the search metric.  You can see that the validation_auc starts at 0.5 and actually worsens to 0.44 on the final scoring history of the winning model:


Scoring History: 
            timestamp          duration number_of_trees training_rmse
1 2017-02-06 10:09:19  6 min 13.153 sec               0       0.70436
2 2017-02-06 10:09:23  6 min 16.863 sec             100       0.70392
3 2017-02-06 10:09:27  6 min 20.950 sec             200       0.70343
4 2017-02-06 10:09:31  6 min 24.806 sec             300       0.70289
5 2017-02-06 10:09:35  6 min 29.244 sec             400       0.70232
6 2017-02-06 10:09:39  6 min 33.069 sec             500       0.70171
7 2017-02-06 10:09:43  6 min 37.243 sec             600       0.70107
  training_logloss training_auc training_lift training_classification_error
1          2.77317      0.50000       1.00000                       0.49997
2          2.69896      0.99980      99.42857                       0.00026
3          2.62768      0.99980      99.42857                       0.00020
4          2.55902      0.99982      99.42857                       0.00020
5          2.49675      0.99993      99.42857                       0.00020
6          2.43712      0.99994      99.42857                       0.00020
7          2.38071      0.99994      99.42857                       0.00013
  validation_rmse validation_logloss validation_auc validation_lift
1         0.06921            0.03058        0.50000         1.00000
2         0.06921            0.03068        0.45944         9.03557
3         0.06922            0.03085        0.46685         9.03557
4         0.06922            0.03107        0.46817         9.03557
5         0.06923            0.03133        0.45656         9.03557
6         0.06924            0.03163        0.44947         9.03557
7         0.06924            0.03192        0.44400         9.03557
  validation_classification_error
1                         0.99519
2                         0.00437
3                         0.00656
4                         0.00656
5                         0.00700
6                         0.00962
7                         0.00962",2017-02-07T14:41:15,,,,35657989
35473606,35473606,2,"Not in the current release of H2O, but ARIMA models are in development.  You can follow the progress 
here
.",2016-02-18T05:33:05,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35472785
36045783,36045783,2,"Interesting question,


I read about to declare other variables which represent previous values of the time series, similar to the methodology of regression in ARIMA models. But I'm not sure if this is a possible way to do it, so please correct me if I am wrong.


Consequently you could try to extend your dataset to something like this:


t value(t) value(t-1) value(t-2) value(t-3) ...
1 10 NA NA NA ...
2 14 10 NA NA ...
3 27 14 10 NA ...
...



After this, value(t) is your response (output neuron) and the others are your predictor variables, each refering to an input neuron.",2016-03-16T19:58:59,constiii,https://stackoverflow.com/users/6055629/constiii,648,35472785
41201223,41201223,1,"I have tried to use many of the default methods inside H2O with time series data. If you treat the system as a state machine where the state variables are a series of lagged prior states, it's possible, but not entirely effective as the prior states don't maintain their causal order.  One way to alleviate this is to assign weights to each lagged state set based on time past, similar to how an EMA gives precedence to more recent data.


If you are looking to see how easy or effective the DL/ML can be for a non-linear time series model, I would start with an easy problem to validate the DL approach gives any improvement over a simple 1 period ARIMA/GARCH type process.


I have used this technique, with varying success.  What I have had success with is taking well known non linear time series models and improving their predictive qualities with additional factors using the the handcrafted non linear model as an input into the DL method.  It seems that certain qualities that I haven't manually worked out about the entire parameter space are able to supplement a decent foundation.


The real question at that point is there is now an introduction of immense complexity that isn't entirely understood.  Is that complexity warranted in the compiled landscape when the nonlinear model encapsulates about 95% of the information between the two stages?",2016-12-17T17:31:02,theGreatKatzul,https://stackoverflow.com/users/3703564/thegreatkatzul,437,35472785
35472726,35472726,2,"The H2OConnection object (your 
localH2O
 object) is no longer supposed to be passed in to any of the uploadFile/importFile functions (it was deprecated), so you should remove argument that from the function.  Also, you should use the default, 
parse = TRUE
, if you actually want to read the data in.  


Also, it is recommended to use the 
h2o.importFile
 instead of 
h2o.uploadFile
 since it is multi-threaded.",2016-02-18T04:16:10,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35460973
35462976,35462976,1,"The pdf documentation for h2o.uploadFile shows that all the arguments are optional except for path.   I was able to successfully upload the file with:


air2008.hex = h2o.uploadFile(path = pathAirline)",2016-02-17T16:57:15,lever,https://stackoverflow.com/users/2925206/lever,684,35460973
36217935,36217935,0,"I had this happen to me while including the (true/oracle) classification label to the feature data frame used in the predict function.
Anecdotally, this specific data.frame was entirely composed of observations from one class. 


Two suggestions : 




Try to remove the label/target column from your frame


or ensure that all the classes are represented",2016-03-25T10:11:48,Val,https://stackoverflow.com/users/6113463/val,1,35424416
35279111,35279111,0,"H2O Deep Learning (2.0 and 3.0) is not reproducible by default -- you can change this by setting 
reproducible = TRUE
, however that will slow things down quite a bit, as reproducibility requires the code to be run on a single core.  Therefore the variability could be due to the randomness in the algorithm alone, rather than from the upgrade of H2O 2.0 to 3.0.


If you want to use H2O Classic (2.0), then your old code will still work, as is.  You might try running that first to see if you can track down the source of the variability.  There is nothing wrong with using H2O Classic to finish a project that you started a while ago.


Implementation details for H2O 3.0 Deep Learning are available in the 
Deep Learning booklet
.


There is more information on what has changed in H2O DL between H2O 2.0 and 3.0 
here
.",2016-02-08T20:54:09,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35261696
35233086,35233086,0,"Right now H2O does not support export of Spark models into POJO. However, you can always use Sparkling Water: prepare data in Spark then call 
val trainHF = h2oContext.asH2OFrame(sparkDataFrame)
 and build GLM model on that data. H2O's GLM model can be easily exported to POJO.


Or with some effort you can extract information from Spark's GLM model and fill them into H2O's GLM model.",2016-02-05T20:38:55,Michal,https://stackoverflow.com/users/5089773/michal,437,35231675
35234873,35234873,5,"After some research, I found this branch which was not integrated in Spark 1.6 that allowed me to run the SVM on a multi class classification problem.


Big thanks to Bekbolatov.


The commit can be ofund here:

https://github.com/Bekbolatov/spark/commit/463d73323d5f08669d5ae85dc9791b036637c966",2016-02-05T22:49:45,bobo32,https://stackoverflow.com/users/3291563/bobo32,"1,002",35230033
35279653,35279653,1,"To directly answer your question, no, H2O is not supposed to be slow. :-)  It looks like you have a decent PC and the Amazon instances (even though there are more vCPUs) are not using the best processors (like what you would find in a gaming PC).  The base / max turbo frequency of your PC's processor is 
3.5GHz / 3.9GHz
 and the c4.8xlarge is only 
2.9GHz / 3.5GHz
.


I'm not sure that this is necessary, but since the c4.8xlarge instances have 60GB of RAM, you could increase 
max_mem_size
 from 
'24G'
 to at least 
'32G'
, since that's what your PC has, or even something bigger.  (Although not sure that will do anything since memory is not usually the limiting factor, but may be worth a try). 


Also, if you are concerned about EC2 price, maybe look into spot instances instead.  If you require additional real speedup, you should consider using 
multiple nodes in your EC2 H2O cluster
, rather than a single node.",2016-02-08T21:26:58,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",35119071
35099234,35099234,1,"I've tried to solve my problem using the following code.


""""""
Code to initialize H2O instance

@author: Naimish Agarwal
""""""

import subprocess as sp
import sys
import os.path as p
import h2o

# path of h2o jar file
h2o_path = p.join(sys.prefix, ""h2o_jar"", ""h2o.jar"")

# subprocess to launch h2o
# the command can be further modified to include virtual machine parameters
sp.Popen(""java -jar "" + h2o_path)

# h2o.init() call to verify that h2o launch is successfull
h2o.init()



And it produced the following output:


--------------------------  --------------------------
H2O cluster uptime:         2 seconds 603 milliseconds
H2O cluster version:        3.6.0.8
H2O cluster name:           Ashish
H2O cluster total nodes:    1
H2O cluster total memory:   3.54 GB
H2O cluster total cores:    4
H2O cluster allowed cores:  4
H2O cluster healthy:        True
H2O Connection ip:          127.0.0.1
H2O Connection port:        54321
--------------------------  --------------------------",2016-01-30T07:23:41,Naimish Agarwal,https://stackoverflow.com/users/2702219/naimish-agarwal,516,35097514
36255456,36255456,1,"An autoencoder is trying to learn a nonlinear, reduced representation of the original data.  It is an unsupervised approach, so it will only consider the features of the data.  It is not an approach for classification.


The mean square error is a way to see how hard it is for the autoencoder to represent the output.  Anomalies are considered rows/observations with high mean squared error. 


In your case, the rows with the highest MSE should be considered anomalous. They could be rows that are 1s, but are labeled as 0.  However, that conclusion can’t be definitely drawn from an autoencoder approach.",2016-03-28T03:21:10,user3896928,https://stackoverflow.com/users/3896928/user3896928,11,35036498
35016975,35016975,0,It turns out that H2O does add an (NA) class to deal with missing values (hence we get N+1). Which is a bit strange as I have none.,2016-01-26T15:04:08,mptevsion,https://stackoverflow.com/users/5479963/mptevsion,947,34976985
34888535,34888535,1,"For classification and regression (i.e., supervised mode), H2O Deep Learning does the following:


The input into the first neural network layer is indeed 1-of-C dummies (either 0 or 1) for categorical features. Continuous features are standardized (not normalized): de-meaned and scaled by 1/variance.


For regression, the response variable is also standardized internally, to allow the (single) output neuron's activation value to be compared against it. However, for presentation to the user during scoring, the predictions are de-standardized into the original space.


For classification, we use Softmax to get probabilities for the C classes, even for binary classification.


The documentation you cited also refers to unsupervised autoencoding (by enabling the autoencoder flag). In that case, the input is normalized (i.e., scaled by 1/(max-min)) instead of being standardized. That is needed to allow the auto-encoder to have fully overlapping input and output spaces.",2016-01-19T22:56:58,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,34875137
34888230,34888230,1,"H2O achieves the effect of 1-of-C dummy encoding, without the cost.  The exact details vary by algorithm, but there's always an obvious algorithmic optimization that gives the predictive strength of a dummy encoding, without the memory or speed costs.


Cliff",2016-01-19T22:32:57,Cliff Click,https://stackoverflow.com/users/5245367/cliff-click,46,34875137
34833057,34833057,1,"There are examples in the 
H2O GBM Vignette
.",2016-01-16T22:53:20,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34796107
55604352,55604352,1,"it is not really an answer but I did what @Arno Candel has suggested. I have tried to combine test and train data and normalize to 0 - 1. After that, I split the combined and normalized data back to test and train data and run the scripts as generated by the OP. However, I am still getting a different MSE using manual calculation. The MSE is also different when I normalized test and train data separately. Is there something I can do to get the manual calculation correctly?


suppressMessages(library(purrr))
suppressMessages(library(dplyr))
suppressMessages(library(h2o))

localH2O = h2o.init(max_mem_size = '6g', # use 6GB of RAM of *GB available
                nthreads = -1) # use all CPUs (8 on my personal computer :3)

# Download and import ECG train and test data into the H2O cluster
train_ecg <- h2o.importFile(path = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/anomaly/ecg_discord_train.csv"",
                          header = FALSE,
                          sep = "","")
test_ecg <- h2o.importFile(path = ""http://h2o-public-test-data.s3.amazonaws.com/smalldata/anomaly/ecg_discord_test.csv"",
                         header = FALSE,
                         sep = "","")
### adding this section
# normalize data 
train_ecg <- as.data.frame(train_ecg)
test_ecg <- as.data.frame(test_ecg)

dat <- rbind(train_ecg,test_ecg)

get_desc <- function(x) {
  map(x, ~list(
    min = min(.x),
    max = max(.x),
    mean = mean(.x),
    sd = sd(.x)
  ))
}

normalization_minmax <- function(x, desc) {
  map2_dfc(x, desc, ~(.x - .y$min)/(.y$max - .y$min))
}

desc <- dat %>%
  get_desc()

dat <- dat %>%
  normalization_minmax(desc)

train_ecg  <- as.matrix(dat[1:20,]) ; test_ecg <- as.matrix(dat[21:43,])

# Train deep autoencoder learning model on ""normal""
# training data, y ignored
anomaly_model <- h2o.deeplearning(x = names(train_ecg),
                                 training_frame = train_ecg,
                                 activation = ""Tanh"",
                                 autoencoder = TRUE,
                                 hidden = c(50,20,50),
                                 l1 = 1e-4,
                                 epochs = 100)

# Compute reconstruction error with the Anomaly
# detection app (MSE between output layer and input layer)
recon_error <- h2o.anomaly(anomaly_model, test_ecg)

# Pull reconstruction error data into R and
# plot to find outliers (last 3 heartbeats)
recon_error <- as.data.frame(recon_error)
recon_error
plot.ts(recon_error)
test_recon <- h2o.predict(anomaly_model, test_ecg)

t <- as.vector(test_ecg[23,])
r <- as.vector(test_recon[23,])
mse.23 <- sum((t-r)^2)/length(t)
mse.23
recon_error[23,]


> mse.23
[1] 23.14947
> recon_error[23,]
[1] 8.076866",2019-04-10T03:28:25,bison72,https://stackoverflow.com/users/1594810/bison72,324,34725593
34898338,34898338,0,"For autoencoders in H2O, the MSE math is done in the normalized space to avoid numerical scaling issues. For example, if you have categorical features or very large numbers, the neural network autoencoder can't directly operate on those numbers, but instead, it first does dummy one-hot encoding and normalization of numeric features, then it does the fwd/back propagation and computation of reconstruction errors (in the normalized and expanded space). You can manually divide each column by its range (max-min) first for purely numerical data, and your results should match.


Here is a JUnit that does this check explicitly (on that very dataset): 

https://github.com/h2oai/h2o-3/blob/master/h2o-algos/src/test/java/hex/deeplearning/DeepLearningAutoEncoderTest.java#L86-L104


You can also see 
https://0xdata.atlassian.net/browse/PUBDEV-2078
 for more info.",2016-01-20T11:06:18,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,34725593
34748249,34748249,2,"H2O does a classic copy-on-write optimization.  Thus:




No true copy is made, unless you mutate the dataset.


Only changed/added columns are truly copied, all others pass-by-reference


Frames in R are pass-by-value, which H2O mimics


Frames in Python are pass-by-reference, which H2O mimics




In short, do as you would in R, and you're fine.


No extra copies.",2016-01-12T15:58:47,Jonnus,https://stackoverflow.com/users/2311633/jonnus,"3,028",34699443
34644678,34644678,2,"We pushed a fix to master for this issue: 
https://0xdata.atlassian.net/browse/PUBDEV-2526
  If you want to try it out now you can build from master as follows:


git clone https://github.com/h2oai/h2o-3
cd h2o-3
./gradlew build -x test
R CMD INSTALL ./h2o-r/R/src/contrib/h2o_3.7.0.99999.tar.gz 



Or download the next 
nightly release
 tomorrow.",2016-01-06T23:16:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34621635
34833109,34833109,0,"This question was 
resolved
 when the user successfully upgraded their H2O installation.  If you don't kill your currently running H2O instance before upgrading, the upgrade may fail.",2016-01-16T23:00:27,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34569246
34804506,34804506,2,"This has been fixed on the 
master branch of H2O
.  The source of the issue was that there are different sets of columns in the 
train1
 and 
train2
 data frames that were constant (all zeros), so different sets of columns got automatically dropped.  This caused the algorithm to think that different sets of predictors were being used in the training set and the follow-up training set used in the checkpointed model.


See 
the JIRA ticket
 for more information on the fix.  You can get the update by installing H2O from source or you can wait until the next nightly release, available 
here
.",2016-01-15T04:39:11,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34548488
34583049,34583049,1,"This might be an overly verbose check that also checks that the same columns are non constant.  Try disabling 
ignore_const_cols
 to get around the issue. 


I filed a JIRA 
here
.",2016-01-03T23:57:22,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34548488
35048552,35048552,1,"In the H2O Python API, there is an 
h2o.no_progress()
 function which disables the progress bar.  You can use 
h2o.show_progress()
 to re-enable the progress bar.  There is an open 
JIRA
 to add this to the R API (I've been told that it should be available in the next nightly release).",2016-01-27T21:38:04,,,,34502311
34517366,34517366,1,"This is actually a bug in the recent version of the h2o R package, which has been fixed.  It will be patched in the next stable release of the h2o R package, or you can download the nightly release here: 
http://h2o-release.s3.amazonaws.com/h2o/master/latest.html


The problem stems from multiple calls to 
h2o.init
.  For now, you can get around this error by shutting down all h2o instances and trying again with this in mind.


More info here: 
https://groups.google.com/forum/#!topic/h2ostream/E6u9YbWmD6k",2015-12-29T19:03:26,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34490981
34445995,34445995,2,"Look also at 
https://github.com/h2oai/h2o-droplets/tree/master/sparkling-water-droplet
 


It provides a skeleton code for a simple Sparkling Water project. Also look at these lines: 
https://github.com/h2oai/h2o-droplets/blob/master/sparkling-water-droplet/build.gradle#L34-L43
 It allows you to configure dependencies on H2O and Spark.


I would recommend to use the latest version of Sparkling water - 1.5.9.


Regarding opening project in Idea - simply open 
build.gradle
 in Idea and follow Gradle project import wizard.


One more update: the droplet now contains also Sbt definition: 
https://github.com/h2oai/h2o-droplets/blob/master/sparkling-water-droplet/build.sbt",2015-12-24T01:09:16,,,,34418187
34440562,34440562,1,"First thing is to create a Scala project in Intellij. Then you must set the dependencies inside the 
build.sbt
 file. Specifically:


name := ""Your Project Name""
version := ""1.0-SNAPSHOT""
scalaVersion := ""2.10.4""
libraryDependencies ++= Seq(
""org.apache.spark"" % ""spark-core_2.10"" % ""1.5.1"", 
""org.scalaz"" %% ""scalaz-core"" % ""7.1.5"",
""javax.servlet"" % ""javax.servlet-api"" % ""3.0.1"",
""junit"" % ""junit"" % ""4.12"",
""ai.h2o"" % ""sparkling-water-core_2.10"" % ""1.4.8""
)
assemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)



Based on your spark version and the H2O version you can search over the Maven central repository and check which are compatible with both packages and download the respective. 


You may not need the javax.servlet package in your case. 


Moreover, for the assembly plugin, you have to declare the following inside the 
/project/plugins.sbt
 file:


addSbtPlugin(""com.eed3si9n"" % ""sbt-assembly"" % ""0.13.0"")



Then open the SBT tab (at the right of the Intellij window) and press the Refresh button (upper left corner). 


Finally verify that everything is working by executing the number 4 from the below link: 

http://h2o-release.s3.amazonaws.com/sparkling-water/rel-1.4/9/index.html


Hope the above will help you.",2015-12-23T17:07:55,raschild,https://stackoverflow.com/users/4701283/raschild,198,34418187
35878975,35878975,0,This happens mainly due to the type mismatch between input and the case class.,2016-03-08T22:06:14,maogautam,https://stackoverflow.com/users/1404655/maogautam,318,34418187
34364817,34364817,1,"No, this is not available in H2O.  Here is a list of algorithms in H2O: 
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/datascience/DataScienceH2O-Dev.md",2015-12-18T22:23:39,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34354848
44966386,44966386,2,"This is really late, but (now) h2o flow models have auto-generated java code that represents the trained model (called a POJO) that can be cut and pasted (say from your remote hadoop session to a local java file). See here for a quickstart tutorial on how to use the java object (
https://h2o-release.s3.amazonaws.com/h2o/rel-turing/1/docs-website/h2o-docs/pojo-quick-start.html
). You'll have to refer to the h2o java api (
https://h2o-release.s3.amazonaws.com/h2o/rel-turing/8/docs-website/h2o-genmodel/javadoc/hex/genmodel/easy/EasyPredictModelWrapper.html
) to start customizing how you want to use the POJO, but you essentially use it as a black box that makes predictions on properly formated inputs.


Assuming you hadoop session is remote, replace ""localhost"" in the example with the IP address of your (remote) flow session.",2017-07-07T08:44:14,lampShadesDrifter,https://stackoverflow.com/users/8236733/lampshadesdrifter,"4,139",34340698
34326529,34326529,3,"This bug was recently introduced by a bulk find/replace change of a class name made to the h2o R code.  The change was inadvertently applied to the ensemble code folder as well (where we currently have manual instead of automatic tests -- soon to be automatic to prevent this sort of thing).  I've fixed the bug. 


To fix, reinstall the h2oEnsemble package from GitHub:


library(devtools)
install_github(""h2oai/h2o-3/h2o-r/ensemble/h2oEnsemble-package"")



Thanks for the report!  For a quicker response, post bugs and questions here: 
https://groups.google.com/forum/#!forum/h2ostream",2015-12-17T04:17:26,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34267983
54857551,54857551,1,"Use the below code, sometimes it happens that it is not able to recognise the model ID, so if you do force=TRUE, it will work. I was also facing the same error and it worked for me.


model_path <- h2o.saveModel(myModel, path = ""myPath/models"", force=TRUE)


The link for official H2o site is below:-

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html",2019-02-24T23:22:38,ashwin agrawal,https://stackoverflow.com/users/7702120/ashwin-agrawal,"1,611",34227323
34326702,34326702,2,"You need to use the 
h2o.saveModel
 and 
h2o.loadModel
 functions rather than the 
base::save()
 function in R. 


The models in H2O are not stored in R memory, they are stored in the H2O cluster memory, so using 
save()
 is not sufficient to save H2O models.",2015-12-17T04:37:04,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",34224528
34341852,34341852,1,"The error you've hit upon is originating from the internal H2O language processing framework (called Rapids).


The likely culprit is not predict, but rather the snippet


   x[,2:100]



which 
should
 be doing a column slice (ASTColSlice). But it looks like it's executing code in ASTRowSlice... Could get a better handle on what's going on if you're able to provide any logs (the stdout/err help here, you can get them with the method


        h2o.downloadAllLogs



One thing that stands out is:


  Error in class(obj) <- ""rs.scalar"" : attempt to set an attribute on NULL



""rs.scalar"" doesn't have any significance in our R code, is it something that you recognize? At any rate, the logs should shed more light on how the NegativeArraySizeException is occurring.


Thanks!",2015-12-17T18:35:55,rijs,https://stackoverflow.com/users/5220538/rijs,236,34221145
43808228,43808228,6,"The updated way to do this is 


h2o.init(nthreads=-1,enable_assertions = FALSE)",2017-05-05T15:03:13,slfan,https://stackoverflow.com/users/599668/slfan,"9,098",34171687
34195239,34195239,4,"As suggested by 
Spencer Aiello


Setting the assertion to FALSE in the h2o initialisation might do the trick


h2o.init(nthreads=-1, assertion = FALSE)



Make sure that you properly shutdown/restart h2o before applying the changes


h2o.shutdown()
h2o.init(nthreads=-1, assertion = FALSE)",2015-12-10T06:35:45,Lod,https://stackoverflow.com/users/5409250/lod,639,34171687
34341959,34341959,5,"Swap-to-disk was disabled by default awhile ago, because performance was so bad.  The bleeding-edge (not latest stable) has a flag to enable it: ""--cleaner"" (for ""memory cleaner"").

Note that your cluster has an EXTREMELY tiny memory:

H2O cluster total memory:   0.06 GB

That's 60MB!  Barely enough to start a JVM with, much less run H2O.  I would be surprised if H2O could come up properly there at all, never mind the swap-to-disk.  Swapping is limited to swapping the data alone.  If you're trying to do a swap-test, up your JVM to 1 or 2 Gigs ram, and then load datasets that sum more than that.


Cliff",2015-12-17T18:41:58,Cliff Click,https://stackoverflow.com/users/5687938/cliff-click,131,34082792
34061741,34061741,3,"I had the same problem. You not only need to install the java client but also the java SDK software. 


See also 
logged issue
 with H2O",2015-12-03T09:05:07,phiver,https://stackoverflow.com/users/4985176/phiver,23.6k,34060916
34054600,34054600,3,"Getting the Mean Squared Error


To get the Mean Squared Error (MSE) value, you can use the 
h2o.mse()
 function, as in the following example (Aiello, Kraljevic, & Maj, 2015):


perf <- h2o.performance(model = your_data_file.gbm, data = your_data_file.hex)
your_new_variable <- h2o.mse(perf)



Example Results


> h2o.performance(model = your_data_file.gbm, data = your_data_file.hex)
H2OBinomialMetrics: gbm
** Reported on training data. **

MSE:  0.07584147
R^2:  0.6846763
LogLoss:  0.2744668
AUC:  0.9780312
Gini:  0.9560623

> perf <- h2o.performance(model = your_data_file.gbm, data = your_data_file.hex)
> your_new_variable <- h2o.mse(perf)
> your_new_variable
[1] 0.07584147



About the Confusion Matrix


Also, the NULL value from your 
confusion matrix
 might indicate that your 
h2o.performance()
 function itself does not contain or return a confusion matrix.




References


Aiello, S., Kraljevic, T., & Maj, P. (2015, November 24). Package ‘h2o’. Retrieved December 2, 2015, from 
https://cran.r-project.org/web/packages/h2o/h2o.pdf",2015-12-02T22:49:01,summea,https://stackoverflow.com/users/1167750/summea,"7,543",34040136
33965344,33965344,0,"This:


sapply(myData, class)



prints the classes of each column and helps to identify the one which is causing the errors.


I will exclude / convert that column manually.",2015-11-27T22:05:46,Georg Heiler,https://stackoverflow.com/users/2587904/georg-heiler,17.6k,33964062
33927543,33927543,1,"Without seeing the exact parameters you're using, My guess is that the problem is that you're using 
sapply
 and not 
lapply
. 


sapply
 often attempts to simplify the result, which is good most of the time. But, if you want something that can contain any kind of object, then you want a list. 


if we define 
paramListList
 as a list, where each entry is a list containing your parameters for h2o.gbm:


Ex:


paramListList <- list(list(x = xVALUES1, 
                           y = yVALUES1, 
                           training_frame = tfVALUES1, 
                           model_id = miVALUES1, 
                           checkpoint = checkVALUES1),
                      list(x = xVALUES2, 
                           y = yVALUES2, 
                           training_frame = tfVALUES2, 
                           model_id = miVALUES2, 
                           checkpoint = checkVALUES2),
                     )



then you can do the following:


lapply(paramListList, function(paramlist) do.call(h2o.gbm, paramlist))



which will put all of your results in that one list",2015-11-25T22:29:13,Shape,https://stackoverflow.com/users/5212579/shape,"2,952",33925864
33920056,33920056,2,"Figured it out. I should've checked 
str()
 of the 
cross_validation_metrics
:


MSE <- cvmodel@model$cross_validation_metrics@metrics$MSE",2015-11-25T15:14:12,Hack-R,https://stackoverflow.com/users/3604745/hack-r,23.1k,33919640
33910322,33910322,1,"What you can do is implement your machine learning algorithms in R, and then call them via command line calls to the underlying system. I found this to be my best option when doing my thesis in Bioinformatics a few years ago.


I remember trying to call the R engine directly from Java using some kind of Java/R integration-library, but decided it was too slow and cumbersome, so I ended up instead writing simple scripts in R, which Java could call via the command line interface.


The downside of this is that slow processes may be hard to track; you might not get any result from an R-operation until it has completed and returned it's status code. 


You'll need to write some Java code to issue the R commands, and wait for the response/result from the process, preferably without locking your Java application completely (separate threads, or a background process).",2015-11-25T07:01:19,Kjartan,https://stackoverflow.com/users/336648/kjartan,19k,33909907
50350397,50350397,0,Yes you can. Please see the instructions on the H2O Flow UI pressing the POJO button after Building and Viewing a model. It gives you detailed instructions about how to download your generated model as a java file (POJO) and about how to download the h20 jar file needed to run it. You can get the same instructions pressing the Preview POJO button.,2018-05-15T12:37:00,jseteny,https://stackoverflow.com/users/615898/jseteny,420,33909907
34342672,34342672,1,"You can do a row-wise apply.
    
iris.apply(foo,1)


Where 
foo
 is some lambda that h2o understands (there are some limits on what can go in there, but all basic math ops should work fine).


Cliff",2015-12-17T19:26:44,Cliff Click,https://stackoverflow.com/users/5687938/cliff-click,131,33876256
34346322,34346322,1,"In addition to what Cliff said (which is the faster way), you can also pull the entire data frame into the Python space and then iterate on it.  


pd_frame = h2o_frame.as_data_frame(use_pandas=True)



If you don't want Pandas in the end:


np_array = h2o_frame.as_data_frame(use_pandas=True).as_matrix()



A little more about your library might help answer the question better.",2015-12-17T23:42:03,,,,33876256
33881972,33881972,0,"Not sure this will work and have not tested it, maybe you can combine the answers from:

Calling Java from Python

and 
Determine which JAR file a class is from
 to call the code for the latter from Python and determine the location of a known class?",2015-11-23T22:30:23,Community,https://stackoverflow.com/users/-1/community,1,33875922
33804502,33804502,1,"You don't tell what you want to do with the result, but the most efficient way to create such a matrix would be creating a sparse matrix.


This is a dense matrix-like object that wastes a lot of RAM for all these 
NA
 values.


test
#  UserId  2  3 12 111 333
#1      1 NA NA  1   1   1
#2      2 NA NA  1   1  NA
#3      3  1 NA NA  NA  NA
#4      4 NA  1 NA  NA  NA



You can avoid this with a sparse matrix, which internally is still basically a long-format structure, but has methods for matrix operations.


library(Matrix)
Sell[] <- lapply(Sell, factor)
test1 <- sparseMatrix(i = as.integer(Sell$UserId), 
                      j = as.integer(Sell$Code), 
                      x = rep(1, nrow(Sell)), 
                      dimnames = list(levels(Sell$UserId), 
                                      levels(Sell$Code)))
#4 x 5 sparse Matrix of class ""dgCMatrix""
#  2 3 12 111 333
#1 . .  1   1   1
#2 . .  1   1   .
#3 1 .  .   .   .
#4 . 1  .   .   .



You would need even less RAM with a logical sparse matrix:


test2 <- sparseMatrix(i = as.integer(Sell$UserId), 
                      j = as.integer(Sell$Code), 
                      x = rep(TRUE, nrow(Sell)), 
                      dimnames = list(levels(Sell$UserId), 
                                      levels(Sell$Code)))
#4 x 5 sparse Matrix of class ""lgCMatrix""
#  2 3 12 111 333
#1 . .  |   |   |
#2 . .  |   |   .
#3 | .  .   .   .
#4 . |  .   .   .",2015-11-19T12:50:52,Roland,https://stackoverflow.com/users/1412059/roland,131k,33801857
33804265,33804265,0,"I'm not sure this is a coding question...BUT...


The new Community Preview of SQL Server 2016 has R built in on the server, and you can get download the preview to try here: 
https://www.microsoft.com/en-us/evalcenter/evaluate-sql-server-2016


Doing this will bring your R code to your data and run on top of the SQL engine, allowing for the same sort of scalability you get built in with SQL.


Or you can stand up a VM in Azure, by going to the new portal, selecting ""New"" ""Virtual Machine"" and search for ""SQL""",2015-11-19T12:40:15,David Crook,https://stackoverflow.com/users/3005995/david-crook,"2,720",33801857
33779278,33779278,2,"I am not an expert in the area, but I do not think h2o is claiming to implement a deep belief network (DBN). I think they implement a deep neural network (DNN) with feedforward. The documentation (
https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/booklets/v2_2015/PDFs/online/DeepLearning_Vignette.pdf
) also states as much; in the introduction it says topic include: 




Building deep neural nets in H2O




This will explain the lack of RBMs you describe.


For some more detail on the distinction between DNNs and DBNs, also see the accepted answer here: 
https://stats.stackexchange.com/questions/51273/what-is-the-difference-between-a-neural-network-and-a-deep-belief-network/59854#59854


Regarding autoencoders, they can be used though. For details, see section 7 of the pdf linked above.",2015-11-18T11:48:15,Community,https://stackoverflow.com/users/-1/community,1,33705423
38088591,38088591,1,"I think you want to add the 'positive' argument to your function:


err.res <- confusionMatrix(pred1, hh$score_class, positive=""top"")",2016-06-29T00:55:24,MDavid,https://stackoverflow.com/users/6526001/mdavid,11,33640786
33792364,33792364,0,"I would recommend using h2o.confustionMatrix and using that to create matrices at different threshold values.


Ex. 
h2o.confusionMatrix(object = fit, threshold = 0.3)


Thanks,


Avni",2015-11-18T23:15:39,Avni,https://stackoverflow.com/users/5225312/avni,226,33640786
51971364,51971364,0,"If you want to declare a positive class directly in h2o, in order to have correct metrics (with 
h2o.confusionMatrix
, 
h2o.performance
 etc.), you can use the function 
h2o.relevel
. For instance in your example, you should add before the model training: 


ddd[max.var] <- h2o.relevel(ddd[max.var],'bottom')



(by default, I believe h2o decides of the positive class based on alphabetic order, and in your exemple h2o metric functions should work right away)",2018-08-22T16:30:40,,,,33640786
33793395,33793395,2,"The exact path of running as.h2o on a data.frame, df :


path <- write.csv(df)
h2o.upload(path)
remove.file(path)



We temporarily write to disk the data.frame and then subsequently upload rather than import the file into H2O and as soon as the file is uploaded we delete the temporary frame. There is no cleaner alternative to not writing to disk.",2015-11-19T00:53:33,Avni,https://stackoverflow.com/users/5225312/avni,226,33624415
33529451,33529451,2,"can you please provide more details about your environment - which version of H2O, platform.


I would recommend to re-try with the latest H2O (see 
http://h2o.ai/download
).",2015-11-04T18:34:32,Michal,https://stackoverflow.com/users/5089773/michal,437,33480289
34335907,34335907,2,"Agreed with @Michal that more info is needed. 


If you're using R (I would recommend using R or Python) use 
h2o.removeAll()
. 


If you're using the Flow UI select 
Data
 -> 
List All Frames
 then select the check box for all frames and then click 
Delete selected frames
.",2015-12-17T13:33:51,Frank B.,https://stackoverflow.com/users/2630758/frank-b,"1,873",33480289
33445842,33445842,2,"I have several comments:




check for NA outside the switch branch


you are missing non-NA case hence you are generating vector which is shorter than input vector (i expect you would like to generate the same length vector)




Regarding generics, you need to provide type specialization. For example, something like the following snippet:


class ReplaceNA[T](val value: T)(implicit add: TAdd[T]) extends MRTask[ReplaceNA[T]] {
  override def map(c: Chunk, nc: NewChunk): Unit = {
    for (row <- 0 until c.len()) {
      // Replace NAs by given value
      if (c.isNA(row)) {
        add.addValue(nc, value)
      } else {
        // Do something with default value
        nc.addNA()
      }
    }
  }

}

trait TAdd[T] extends Serializable {
  def addValue(nc: NewChunk, value: T)
}

object TAdd extends Serializable {
  implicit val addDouble = new TAdd[Double] { def addValue(nc: NewChunk, value: Double) = nc.addNum(value) }
  implicit val addFloat = new TAdd[Float] { def addValue(nc: NewChunk, value: Float) = nc.addNum(value) }
  implicit val addValueString = new TAdd[ValueString] { def addValue(nc: NewChunk, value: ValueString) = nc.addStr(value) }
}",2015-10-30T22:33:20,Michal,https://stackoverflow.com/users/5089773/michal,437,33442536
33439867,33439867,3,"You can parametrize your class to make it 'generic':


class test[T](a: T, b: T) extends MRTask {}



so when you'll use this class in real life type 
T
 will be determined automatically based on your input.
For 
test(""str"", ""str"" )
 , 
T
 will be 
String
 


If you want to limitat your type with 
String
 and 
Double
 you can not use both this bounds in same time. You have to find common parent class for those two. It's 
Any
. It will not help you a lot.


For ex. you need to implement some method that depends on type should apply different behaviour. For this purpose I recommend you to use pattern matching.


  case class test[T <: Any](a :T, b: T) { 

    def foo (): T = {
      a match {
        case d: Double => d
        case s: String => s
      }
    }

  }",2015-10-30T15:47:03,,,,33439768
33427366,33427366,1,"Your question was answered on the H2O google group: 
https://groups.google.com/forum/#!topic/h2ostream/nMHmBSMQRRM


Thanks!


Avni",2015-10-30T01:09:48,Avni,https://stackoverflow.com/users/5225312/avni,226,33424324
33402425,33402425,1,"Something like that:


c.atd(row) match {
  case nan: Double if nan.isNaN => nc.addNum(0)
  case 0 => nc.addNum(0)
  case _ => nc.addNum(1)
}",2015-10-28T22:05:47,kukido,https://stackoverflow.com/users/3079042/kukido,10.6k,33401869
33444516,33444516,1,"you are appending a new column which includes only 0,1 values.
Hence minimum value stored in the column is 0. Maximum value stored in the column is 1. In this case, mean==0 is suspicious, that's probably a bug.",2015-10-30T20:37:47,Michal,https://stackoverflow.com/users/5089773/michal,437,33399663
33427599,33427599,1,"H2O provides 
Chunk
 API which focuses on efficient data processing and internally uses only primitive Java types. Hence, there is no 
null
 check but you can ask for missing value at given row:


if (c.isNA(row)) { ... } else { ... }



or shorter version for your example:


nc.addNum(c.isNA(row) ? 1 : 0)",2015-10-30T01:56:28,Michal,https://stackoverflow.com/users/5089773/michal,437,33396042
33360726,33360726,0,"Thanks Spencer Aiello  for helping to fix the problem.
I was using an older version of H2O. Now I got the latest version of H2O using:


pip install http://h2o-release.s3.amazonaws.com/h2o/rel-slater/9/Python/h2o-3.2.0.9-py2.py3-none-any.whl



It fixed the error.",2015-10-27T05:48:18,Jithin K M,https://stackoverflow.com/users/5489124/jithin-k-m,1,33345675
33427500,33427500,1,"Both binomial and multinomial classification display MSE, so you will see it in the Scoring History table for both models (highlighted training_MSE column).


H2O does not evaluate a multinomial AUC. A few evaluation methods exist, but there is not yet a single widely adopted method. The 
pROC package
 discusses the method of Hand and Till, but mentions that it cannot be plotted and results rarely tested. Log loss and classification error are still available, specific to classification, as each has standard methods of evaluation in a multinomial context.


There is a confusion matrix comparing your 4 factor levels, as you highlighted. Can you clarify what more you are expecting? If you were looking for four individual confusion matrices, the four-column table contains enough information that they could be computed.",2015-10-30T01:28:45,M Landry,https://stackoverflow.com/users/5395448/m-landry,11,33331725
33340000,33340000,1,"If it worked before on the same version of H2O, then it must be a convergence issue (bad local minimum found). You can try to reduce the number of hidden layers from 
hidden = c(100,75,50,25)
 to 
hidden=c(50)
 and see if that works. Otherwise, it's almost certainly a data issue.",2015-10-26T06:54:50,Nikos,https://stackoverflow.com/users/2328841/nikos,"3,297",33287846
33158479,33158479,1,"It looks like you may be using either an older version of the h2o or h2oEnsemble package.  The object class of an H2O data frame used to be called 
H2OFrame
 and now it's just called 
Frame
, and 
h2o.cbind
 is looking for for an object of type, 
H2OFrame
.


You can fix this by updating your h2o and h2oEnsemble packages to the latest version as follows:


# The following two commands remove any previously installed H2O packages for R.
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) }
if (""h2o"" %in% rownames(installed.packages())) {remove.packages(""h2o"") }

# Now we download, install and initialize the latest stable release of the *h2o* package for R.
install.packages(""h2o"", type=""source"", repos=(c(""http://h2o-release.s3.amazonaws.com/h2o/rel-slater/5/R"")))
library(h2o)



Then update your h2oEnsemble as follows:


library(devtools)
install_github(""h2oai/h2o-3/h2o-r/ensemble/h2oEnsemble-package"")



You can always find the latest stable (or bleeding edge) version of H2O at 
http://h2o.ai/download/
.",2015-10-15T21:01:48,,,,33070159
33323835,33323835,0,"Have you tried to add model_id = ""something"" to your h2o.deeplearning command?


test.dl <- h2o.deeplearning(x = 1:3, y = 4, training_frame = df1.hex, model_id = ""myTest.dl"")



I hope it could fix your problem.",2015-10-24T22:01:55,,,,33053714
33005568,33005568,0,You should be able to access Flow if you open TCP port 54321 in the instance's security group.,2015-10-08T02:24:09,lo5,https://stackoverflow.com/users/324101/lo5,460,32988493
38533052,38533052,0,"The full set of ports I open are:




Ports 54321 and 54322, both TCP and UDP


Port 8787  (for RStudio) (TCP only)


Port 22 (for SSH)  (TCP only)




Using the H2O AMI I find I need to SSH in to create a special user and password for RStudio. (I create the account as not allowed login, by giving it a /bin/false shell, for a bit of extra security).


If you will only use H2O from the RStudio running on EC2, then I don't think you need to open 54321/54322; just opening 8787 will be sufficient.",2016-07-22T18:22:00,Darren Cook,https://stackoverflow.com/users/841830/darren-cook,28.8k,32988493
32916402,32916402,0,"Thank you for pointing this out to us. I have added a JIRA, and you can track its progress here: 
https://0xdata.atlassian.net/browse/PUBDEV-2182


You can expect the problem to be fixed soon.


Thanks!


Avni",2015-10-02T21:53:10,Avni,https://stackoverflow.com/users/5225312/avni,226,32915566
43104008,43104008,0,Please try again using the latest version. This should work now.,2017-03-29T20:55:22,Arno Candel,https://stackoverflow.com/users/5412472/arno-candel,491,32915566
32896116,32896116,3,"The error message is pretty self-explanatory:




Found JRE at C:/Program Files (x86)/Java/jre7/bin/java.exe but H2O requires the JDK to run




You need to install the JDK and point the JAVA_HOME environment variable to the JDK directory (the parent of the bin directory), if it isn't automatically done by the installer.",2015-10-01T20:15:39,Artjom B.,https://stackoverflow.com/users/1816580/artjom-b,61.8k,32896008
32877906,32877906,9,"It is cumbersome to transport data stored in R's memory to H2O's memory for essentially two reasons: R performs a POST of the file to stream up the data into H2O, which 1) doesn't take advantage of H2O's parallel reader, and 2) limits your data to existing in R.


Instead, make use of the h2o.importFile method from R to make use of H2O's parallel reader. Your data can live anywhere: HDFS, S3, regular filesystem...


H2O sports an SVMLight reader, so it is recommended to save your sparse Matrix from R in svmlight format.


Hope this helps!",2015-10-01T00:59:03,rijs,https://stackoverflow.com/users/5220538/rijs,236,32843267
32876973,32876973,1,"In genenral, the method that you are trying to utilize does not speed the process up since scoring a single dataset will occupy the CPU's, multiple calls will only create unnecessary contention.


Also, you can only boot a single H2O instance from within R, if you are trying to boot more than one instance, you can do so from the command line (java -jar h2o.jar).",2015-09-30T23:09:52,David Arenburg,https://stackoverflow.com/users/3001626/david-arenburg,92.2k,32819368
32876793,32876793,0,"You can refer to the H2O documentation to see how the DRF algorithm handles missing values in various situations:

http://h2o-release.s3.amazonaws.com/h2o/rel-slater/5/docs-website/h2o-docs/index.html#Data%20Science%20Algorithms-DRF-FAQ


In terms of R's GBM, they create trees that are ready to handle NA's. In other words, it explicitly handles NA's as a special case. R's GBM actually handles NAs as a special case and builds tree branches for them: left, right, NA is the result of every decision.


Hope this helps!


Avni",2015-09-30T22:49:50,,,,32764021
32893382,32893382,3,"H2O model objects are different from R-objects. H2O model object is stored in H2O cluster and in R you can see only reference to it which looks like a normal R model. Hence, if you save your R session, and restart it later, probably you will be running against different H2O cluster which does not have the model referenced by your R-session.


The solution is to save/load H2O model via 
h2o.saveModel
/
h2o.saveModel
 methods. 


For example:


model <- h2o.randomForest(...)
model_path <- h2o.saveModel(
        object = model, 
        path = ""/tmp/mymodel"", 
        force = TRUE)

print(model_path)



See documentation for more examples: 
http://h2o-release.s3.amazonaws.com/h2o/rel-slater/5/docs-website/h2o-r/h2o_package.pdf",2015-10-01T17:26:36,Michal,https://stackoverflow.com/users/5089773/michal,437,32652500
32688384,32688384,0,"I found the answer my self..


> rand_num <- h2o.runif(sample_3gb, seed = 123)
> sample_3gb[,""status""] <- ifelse(rand_num > 0.3, 1, 0)
> sample_3gb[,""status""]
H2OFrame with 9227049 rows and 1 column

First 10 rows:
   status
1       0
2       0
3       0
4       1
5       1
6       1
7       1
8       1
9       1
10      1",2015-09-21T06:08:58,Ravi Kumar,https://stackoverflow.com/users/4958076/ravi-kumar,161,32605158
32877883,32877883,3,"If you are using R you need to use as.factor to convert your binary 1-0 variables, and if you are using Flow, you need to convert your binary 1-0 variables to enums. After you do this, H2O's random forest will automatically recognize this as a classification problem.


Thanks,


Avni",2015-10-01T00:55:42,Avni,https://stackoverflow.com/users/5225312/avni,226,32586740
32895257,32895257,0,"Here are the answers to your questions:
1. MSE stands for mean squared error. Essentially it measures the difference between the estimator and the estimated.R2 measures how well-fit a statistical model is.




Using MSE you can judge how often you model misclassified data.  


If you are using Flow, click on 
Inspect
 and then 
output-training_metrics
 to see MSE, R2, AUC, gini, etc.


Sorry, I'm not sure I understand this question. Are you asking if a decreaed gini or AUC equate to improved model performance? 




Avni",2015-10-01T19:20:20,Avni,https://stackoverflow.com/users/5225312/avni,226,32583945
32494779,32494779,0,"This is the original H2OFrame


val OriginalTable: H2OFrame = SomeDataFrame



convert original H2OFrame to DataFrame, add the column via sql function, make an implicit conversion back to H2OFrame


val NewTable: H2OFrame = createH2OSchemaRDD(OriginalTable).withColumn(""newCol"", log($""oldCol""))",2015-09-10T06:35:23,,,,32482658
34326922,34326922,1,"It retrieves the cross-validated AUC.


Since you set the 
nfolds
 argument to something non-zero, the 
h2o.gbm
 function also performs k-fold cross-validation in addition to training a GBM model on the full training set.  In your command, you did not specify a validation set, so the AUC values you can retrieve are training AUC, 
h2o.auc(perf, train = TRUE)
, and cross-validated AUC (as above).


If you want to evaluate performance on a separate validation (or test) set, you can pass that frame using the 
validation_frame
 argument and retrieve the validation AUC using 
h2o.auc(perf, valid = TRUE)
.",2015-12-17T04:59:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",32416579
32495080,32495080,0,"be sure to import the H2OFrame first


import water.fvec.H2OFrame



this is an implicit conversion from DataFrame (""oldFrame"") to H2OFrame 
(""newFrame"")


val newFrame:H2OFrame = oldFrame",2015-09-10T06:52:24,danny,https://stackoverflow.com/users/864836/danny,31,32400447
32259829,32259829,2,"The documentation that you are referencing is actually for an older version of H2O. You can reference our new documentation here: 
http://h2o-release.s3.amazonaws.com/h2o/rel-simons/7/docs-website/h2o-docs/index.html#%E2%80%A6%20On%20EC2%20and%20S3


This should cover the questions that you have. If not, please let me know!",2015-08-27T21:34:19,Avni,https://stackoverflow.com/users/5225312/avni,226,32256502
32322132,32322132,1,"You can use h2o.weights to extract the neural net weigths. You can reference our documentation here:

http://h2o-release.s3.amazonaws.com/h2o/rel-simons/7/docs-website/h2o-r/h2o_package.pdf


and get an example of h2o.weights's usage here:

https://github.com/h2oai/h2o-3/blob/master/h2o-r/tests/testdir_algos/deeplearning/runit_deeplearning_weights_and_biases.R


Hope this helps!",2015-09-01T01:13:57,Avni,https://stackoverflow.com/users/5225312/avni,226,32222780
32238367,32238367,0,"H2O does not currently allow you to access models built in one version of H2O from another version. In other words, you can only access models from the H2O version they were orginally built in.",2015-08-26T23:34:01,Avni,https://stackoverflow.com/users/5225312/avni,226,32164045
32120568,32120568,1,"It seems like non ASCII values in the colnames where the problem.


#clean colnames
colnames(data.model) <- iconv(colnames(data.model), to='ASCII', sub='')



fixed it.",2015-08-20T14:10:10,Fabian Hertwig,https://stackoverflow.com/users/2577416/fabian-hertwig,"1,113",32119553
41153635,41153635,1,"I encountered similar problem with reading a csv file. I traced the problem to a column named as 
July4th
. I guess h2o didn't like a column name with a number buried in the middle. Renaming it to July4 worked.",2016-12-14T22:53:43,user3634351,https://stackoverflow.com/users/3634351/user3634351,111,32119553
31916583,31916583,1,"Shoulda RTFM!


GET /99/Models.bin/<model-id>
POST /99/Models.bin



More details in the H2O REST API:


http://h2o-release.s3.amazonaws.com/h2o/rel-simons/4/docs-website/h2o-docs/index.html#route-%2F99%2FModels.bin%2F(%3F%3Cmodelid%3E.*)",2015-08-10T09:57:21,AndrewKelly,https://stackoverflow.com/users/5046185/andrewkelly,21,31876597
31972411,31972411,1,"this was fixed in the latest stable release 


http://h2o-release.s3.amazonaws.com/h2o/rel-simons/7/index.html


python wasn't polling to wait for the split frame to finish before it went off to the next step (resulting in that not found exception)",2015-08-12T18:07:49,rijs,https://stackoverflow.com/users/5220538/rijs,236,31765161
55614018,55614018,4,"For Ubuntu users, try running this command in the terminal: 


sudo apt install default-jre",2019-04-10T13:37:29,Stephen King,https://stackoverflow.com/users/7563191/stephen-king,577,31723236
65101496,65101496,4,"I find it easiest to use 
Anaconda
. Install H2O and Java Development Kit (JDK) with conda:


conda install -c conda-forge h2o-py openjdk -y



For me, H2O automatically found this Java version correctly even in my separate conda environment I created for H2O.",2020-12-02T02:47:59,wordsforthewise,https://stackoverflow.com/users/4549682/wordsforthewise,15.5k,31723236
31953158,31953158,2,"You should try to set JAVA_HOME environment variable manually and that might work.Following is the process.




Set JAVA_HOME:




Right click My Computer and select Properties.

On the Advanced tab, select Environment Variables, and then edit JAVA_HOME to point to where the JDK software is located, for example, C:\Program Files\Java\jdk1.8.0_51



Then go to the h2o directory and run 


java -jar h2o.jar



However if still it can't find java then run following command


at C:\Program Files\Java\jdk1.8.0_51


java -jar \path to\h2o.jar",2015-08-11T22:34:38,,,,31723236
51492728,51492728,1,"We need to install both h2o and h2o-py. After install h2o, we'll get h2o.jar inside ""C:\Users\admin\Anaconda3\h2o_jar"", which is the folder that h2o.init() looks at for h2o.jar.",2018-07-24T07:20:48,Nguyen Phi Vu,https://stackoverflow.com/users/3484398/nguyen-phi-vu,11,31723236
79155191,79155191,0,"Step 1: download the jdk (
https://jdk.java.net/archive/
)


Step 2: Creat a new folder called ""Java"" in C://Program Files


Step 3: Unzip your jdk.zip, and put the folder called jdkxxx into Java folder


Step 4: Add the path ""C://Program Files//Java"" into your environment variable path


Then it willl work.",2024-11-04T11:07:29,Fedor,https://stackoverflow.com/users/7325599/fedor,20.5k,31723236
31624645,31624645,0,"Then this code will do it:


h2o_frame[is.na(h2o_frame$b), ""b""] <- 0



All the credits to Spencer Aiello on the H2O Google forum!",2015-07-25T08:40:54,Sebastian Hätälä,https://stackoverflow.com/users/2407819/sebastian-h%c3%a4t%c3%a4l%c3%a4,"1,035",31624644
31572847,31572847,6,"I am, unfortunately, not familiar with the web interface but I can offer a workaround involving H2O in R. The functions 


h2o.saveModel(object, dir = """", name = """", filename = """", force = FALSE)



and


h2o.loadModel(path, conn = h2o.getConnection())



Should offer what you need. I will try to have a look at H2O Flow.


Update


I cannot find the possibility to explicitly save a model either. What you can do instead is save the 'Flow'. You ergo could upload/import your file, build the model and then save / load the status :-)",2015-07-22T19:57:04,,,,31522341
32749374,32749374,3,"When viewing the model in H2O Flow, you will see an 'Export' button as an action that can be taken against a model 


From there, you will be prompted to specify a path in 'Export Model' dialog.  Specify the path and hit the 'Export' button.  That will save you model to disk.


I'm referring to H2O version 3.2.0.3",2015-09-23T20:59:52,Hank Roark,https://stackoverflow.com/users/5369578/hank-roark,41,31522341
31953195,31953195,1,"A working example that I've used recently while building a deep learning model in version 2.8.6 in h2o.The model was saved in hdfs.For latest version you probably have to remove the classification=T switch and have to replace data with training_frame


library(h2o)
h = h2o.init(ip=""xx.xxx.xxx.xxx"", port=54321, startH2O = F)

cTrain.h2o <- as.h2o(h,cTrain,key=""c1"")
cTest.h2o <- as.h2o(h,cTest,key=""c2"")

nh2oD<-h2o.deeplearning(x =c(1:12),y=""tgt"",data=cTrain.h2o,classification=F,activation=""Tanh"",
                        rate=0.001,rho=0.99,momentum_start=0.5,momentum_stable=0.99,input_dropout_ratio=0.2,                        
                        hidden=c(12,25,11,11),hidden_dropout_ratios=c(0.4,0.4,0.4,0.4),
                        epochs=150,variable_importances=T,seed=1234,reproducible = T,l1=1e-5,
                        key=""dn"")

hdfsdir<-""hdfs://xxxxxxxxxx/user/xxxxxx/xxxxx/models""

h2o.saveModel(nh2oD,hdfsdir,name=""DLModel1"",save_cv=T,force=T)

test=h2o.loadModel(h,path=paste0(hdfsdir,""/"",""DLModel1""))",2015-08-11T22:38:03,,,,31522341
33102005,33102005,1,"This 
should
 be what you need: 


library(h2o)
h2o.init()
path = system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
h2o_df = h2o.importFile(path)
h2o_df$CAPSULE = as.factor(h2o_df$CAPSULE)
model = h2o.glm(y = ""CAPSULE"",
              x = c(""AGE"", ""RACE"", ""PSA"", ""GLEASON""),
              training_frame = h2o_df,
              family = ""binomial"")
h2o.download_pojo(model)



http://h2o-release.s3.amazonaws.com/h2o/rel-slater/5/docs-website/h2o-docs/index.html#POJO%20Quick%20Start",2015-10-13T11:52:30,Frank B.,https://stackoverflow.com/users/2630758/frank-b,"1,873",31522341
41611019,41611019,1,"How to save models in H2O Flow:




go to ""List All Models""


in the model details, you will find an ""Export"" option


enter the model name you want to save it as


import it back again




How to save a model trained in h2o-py:


# say ""rf"" is your H2ORandomForestEstimator object. To export it
>>> path = h2o.save_model(rf, force=True) # save_model() returns the path
>>> path
u'/home/user/rf'

#to import it back again(as a new object)
>>> rafo = h2o.load_model(path)
>>> rafo   # prints model details
Model Details
=============
H2ORandomForestEstimator :  Distributed Random Forest
Model Key:  drf1
Model Summary:
######Prints model details...................",2017-01-12T10:41:26,Hng,https://stackoverflow.com/users/6926393/hng,148,31522341
31525994,31525994,11,"The syntax for importing a frame from R into H2O has changed since the last stable release of H2O-Classic and the latest stable release of H2O-3.0. I believe you used a H2O-3.0 release which means some of the arguments in the functions has since changed, the ambiguous ""key"" argument has been changed to ""destination_frame"".


H2O-3.0 will behave differently in that it will make note that the first 5 columns are ordered factors in the R data frame; and at the moment we don't have a way of preserving orders for categorical columns. However, to reproduce the same results as the one posted on 
http://blenditbayes.blogspot.co.uk/2014/07/things-to-try-after-user-part-1-deep.html
 you'll have to for now write the frame to disk as a CSV and import it into H2O.


library(mlbench)
dat = BreastCancer[,-1] #reading in data set from mlbench package

library(h2o)
localH2O <- h2o.init(ip = ""localhost"", port = 54321, startH2O = TRUE)

#dat_h2o <- as.h2o(dat, destination_frame = 'dat') 
## Will return a ""Provided column type c(""ordered"", ""enum"") is unknown."" error

pathToData <- paste0(normalizePath(""~/Downloads/""), ""/dat.csv"")
write.table(x = dat, file = pathToData, row.names = F, col.names = T)
dat_h2o <- h2o.importFile(path = pathToData, destination_frame = ""dat"")



For R data.frames that do not have ordered factor columns you can simply use 
h2o_frame <- as.h2o(object = df)
 where 
class(df)
 is a 
data.frame
.",2015-07-20T20:44:51,Amy Wang,https://stackoverflow.com/users/5136512/amy-wang,111,31442820
38212715,38212715,1,"The BreastCancer data frame has 5 ord.factors and 5 factors.  As Amy Wang wrote, you have to convert factors into numeric.  If you don't want to write data to disc and then to read again the data you can convert them with sapply().


## Format data with no factor
data(BreastCancer, package = 'mlbench') # Load data from mlbench package
dat <- BreastCancer[, -1]  # Remove the ID column
dat[, c(1:ncol(dat))] <- sapply(dat[, c(1:ncol(dat))], as.numeric) # Convert factors into numeric



## Start a local cluster with default parameters
library(h2o)
localH2O <- h2o.init(ip = ""localhost"", port = 54321, startH2O = TRUE)

## Convert Breast Cancer into H2O
dat.h2o <- as.h2o(dat, destination_frame = ""midata"")",2016-07-05T21:04:21,Juan Pueyo,https://stackoverflow.com/users/4651181/juan-pueyo,163,31442820
50383257,50383257,1,"Try this. It worked for me.


## S3 method for class 'data.frame'
dat.hex <- as.h2o(dat, destination_frame = ""dat.hex"", ...)",2018-05-17T04:16:31,Nikhar Khandelwal,https://stackoverflow.com/users/2016216/nikhar-khandelwal,11,31442820
31568173,31568173,0,"I was also facing the same problem. In my case the problem JAVA_HOME env variable on Mac OSX mavericks pointing to old java version 6. My solution is on h2o google groups stream 
here",2015-07-22T15:55:29,Rajiv Ranjan Singh,https://stackoverflow.com/users/4821765/rajiv-ranjan-singh,43,31442820
45407188,45407188,0,"You should try:


dat_h2o <- as.h2o(dat)



Or:


dat <- as.data.frame(dat)
dat_h2o <- as.h2o(dat)



Hope this helps!",2017-07-31T03:48:25,Anh Pham,https://stackoverflow.com/users/5624053/anh-pham,"2,118",31442820
31368028,31368028,2,"You need to use Spark 1.3 for Sparkling Water 1.3.6 release.


Naming of Sparkling Water releases follows Spark release:




1.2.x is for Spark 1.2


1.3.x is for Spark 1.3


1.4.x is for Spark 1.4",2015-07-12T13:00:01,Michal,https://stackoverflow.com/users/5089773/michal,437,31236639
31270146,31270146,0,"H2O JIRA contains issue 
PUBDEV-1566
 which is referencing your problem. 


You can try to use the latest H2O - 3.0.0.26 which contains fix for the issue. You can find it 
here
.",2015-07-07T13:37:37,Michal,https://stackoverflow.com/users/5089773/michal,437,31196199
39277049,39277049,1,"https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors


The above Kaggle article explains few ways to overcome this challenge (but, in Python). There are,




Vector averaging (as mentioned by Avni)


Clustering


Paragraph Vector 
Check this paper




I think the ideas might help.",2016-09-01T16:56:06,Vasu Bandaru,https://stackoverflow.com/users/6784343/vasu-bandaru,11,30901595
32000026,32000026,0,"So there are a few ways you can go about accomplishing your task of using H2O for this application.
First though, you need to normalize the texts in your dataset. 


I'm assuming you are doing some text cleaning / tokenization which will produce a sequence of individual word strings.  Then you are going to run your Word2Vec model on those individual word strings.  Problem is each text document can be N number of words long and so you might want to try averaging the word2vec vectors for a given string.


So in your above example on sentence2:
v(another) + v(sentence) + v(and) + v(another) / 4 (individual words)
This would produce an average vector of X features long for each individual text document.


After which you can use our h2o.cbind() function in R. 
So partition your dataset into 2 data frames whereby frame 1 is just the sentiment of a document (-1, 0, 1) and the next data frame is the tweets ('Another sentence. And another').  Run the above steps on the tweet dataframe and then cbind the two. 


Be sure to pass both data frames into h2o BEFORE using our h2o.cbind() command however and then you should be ready to run our h2o.deeplearning() model on your dataset!


Good luck!",2015-08-13T23:22:38,Avni,https://stackoverflow.com/users/5225312/avni,226,30901595
36029359,36029359,0,"I have used 
rword2vec
 package instead of tmcn.word2vec.


To train wordvec model, there should not be any punctuation marks and all words should be lowercase for better results


train=data$Text
train=tolower(train)
train=gsub(""[[:punct:]]"", """", train)
write(train,""text_data.txt"")



Now train word2vec model on this text file.
Output file can be .txt or .bin.


Pro of .txt output file: you can easily change or do operations on word vectors. 


Con of .txt output file: you cannot use other rword2vec functions(distance,analogy) on .txt file.


To train word2vec model:


model=word2vec(train_file = ""text_data.txt"",output_file =""model1.bin"",layer1_size = 300,min_count = 40,num_threads = 4,window = 10,sample = 0.001,binary=1)



To get .txt file from the binary output file:


bin_to_txt(""model1.bin"",""model1text.txt"") 



We need ""model1text.txt"" to create training dataset. There are two popular ways to create training dataset:




Vector Averaging (for each row create a feature vector, by taking average of all word vectors present in that row)


Bag of Centroids (cluster word vocabulary and then create bag of centroids as similar to bag of words)




For more info, check out 
this
 tutorial series:


I have built a sentiment classification model using above methods for kaggle's bag of words meets bag of popcorn(
Github Repo link
). You can use this code to get training dataset for your text data by making some necessary changes.


Finally, train this on the training dataset using h2o or any othe machine learning algorithm to get sentiment classification model.",2016-03-16T07:36:14,mukul,https://stackoverflow.com/users/4776772/mukul,55,30901595
33029404,33029404,5,"Its an OutOfMemoryError. A variation of this error message on the R side is:


Error in .h2o.doSafeREST(conn = conn, h2oRestApiVersion = h2oRestApiVersion,  : 
  Unexpected CURL error: Empty reply from server



Checking the h2o server logs, which you should do as well, will tell you:


10-08 20:11:57.165 192.168.0.4:54321     2125   #58072-18 INFO: Total file size: 1.81 GB
10-08 20:11:57.165 192.168.0.4:54321     2125   #58072-18 INFO: Parse chunk size 4194304
        onExCompletion for water.parser.ParseDataset$MultiFileParseTask@3588360e
        java.lang.OutOfMemoryError: Java heap space
:
:
Exception in thread ""FJ-0-11"" java.lang.OutOfMemoryError: Java heap space
2015-10-08 20:13:14.493:WARN:oejut.QueuedThreadPool:1 threads could not be stopped
10-08 20:13:23.033 192.168.0.4:54321     2125   FJ-0-5    ERRR: Out of Memory, Heap Space exceeded, increase Heap Size, from /192.168.0.4:54321
10-08 20:13:23.458 192.168.0.4:54321     2125   FJ-0-3    ERRR: Out of Memory, Heap Space exceeded, increase Heap Size, from /192.168.0.4:54321
10-08 20:13:23.033 192.168.0.4:54321     2125   FJ-0-13   ERRR: Out of Memory, Heap Space exceeded, increase Heap Size, from /192.168.0.4:54321
10-08 20:13:23.033 192.168.0.4:54321     2125   FJ-0-7    ERRR: Out of Memory, Heap Space exceeded, increase Heap Size, from /192.168.0.4:54321
10-08 20:13:26.541 192.168.0.4:54321     2125   FJ-0-5    FATAL: Exiting.
10-08 20:13:26.574 192.168.0.4:54321     2125   FJ-0-7    FATAL: Exiting.
10-08 20:13:26.575 192.168.0.4:54321     2125   FJ-0-3    FATAL: Exiting.
10-08 20:13:26.575 192.168.0.4:54321     2125   FJ-0-13   FATAL: Exiting.



I am running this on h2o Slater (3.2.0.5), so depending on your version, this may vary.",2015-10-09T03:26:14,Kingz,https://stackoverflow.com/users/1642266/kingz,"5,256",30882686
30883384,30883384,4,"Probably you're out of memory. Try looking on system's memory usage during forest growing. Also try to launch training directly from H2O web console (
http://localhost:54321/
 by default), may be it will give more detailed error.",2015-06-17T06:02:35,cyberj0g,https://stackoverflow.com/users/4939144/cyberj0g,"3,787",30882686
30852030,30852030,13,"Since you are running H2O locally, you want to save that data as a file and then use:


h2o.importFile(localH2O, file_path, key='test_intput')



This will have each thread read their parts of the file in parallel.  If you run H2O on a separate server, then you would need to copy the data to a location that the server can read from (most people don't set the servers to read from the file system on their laptops).  


as.h2o()
 serially uploads the file to H2O.  With 
h2o.importFile()
, the H2O server finds the file and reads it in parallel.  


It looks like you are using version 2 of H2O.  The same commands will work in H2Ov3, but some of the parameter names have changed a little.  The new parameter names are here: 
http://cran.r-project.org/web/packages/h2o/h2o.pdf",2015-06-15T18:06:30,Brandon,https://stackoverflow.com/users/5012504/brandon,131,30821865
55739333,55739333,5,"Having also struggled with this problem, I did some tests and found that for objects in R memory (i.e. you don't have the luxury of already having them available in .csv or .txt form), by far the quickest way  to load them (~21 x) is to use the 
fwrite function
 in data.table to write a csv to disk and read it using h2o.importFile.


The four approaches I tried:




Direct use of as.h2o()


Writing to disk using write.csv() then load using h2o.importFile()


Splitting the data in half, running as.h2o() on each half, then combining using h2o.rbind()


Writing to disk using fwrite() from data.table then load using h2o.importFile()




I performed the tests on a data.frame of varying size, and the results seem pretty clear.


The code, if anyone is interested in reproducing, is below.


library(h2o)
library(data.table)
h2o.init()

testdf <-as.data.frame(matrix(nrow=4000000,ncol=100))
testdf[1:1000000,] <-1000       # R won't let me assign the whole thing at once
testdf[1000001:2000000,] <-1000
testdf[2000001:3000000,] <-1000
testdf[3000001:4000000,] <-1000

resultsdf <-as.data.frame(matrix(nrow=20,ncol=5))
names(resultsdf) <-c(""subset"",""method 1 time"",""method 2 time"",""method 3 time"",""method 4 time"")
for(i in 1:20){
    subdf <- testdf[1:(200000*i),]
    resultsdf[i,1] <-100000*i
    
    # 1: use as.h2o()
    
    start <-Sys.time()
    as.h2o(subdf)
    stop <-Sys.time()
    resultsdf[i,2] <-as.numeric(stop)-as.numeric(start)
    
    # 2: use write.csv then h2o.importFile() 

    start <-Sys.time()
    write.csv(subdf,""hundredsandthousands.csv"",row.names=FALSE)
    h2o.importFile(""hundredsandthousands.csv"")
    stop <-Sys.time()
    resultsdf[i,3] <-as.numeric(stop)-as.numeric(start)

    # 3: Split dataset in half, load both halves, then merge

    start <-Sys.time()
    length_subdf <-dim(subdf)[1]
    h2o1 <-as.h2o(subdf[1:(length_subdf/2),])
    h2o2 <-as.h2o(subdf[(1+length_subdf/2):length_subdf,])
    h2o.rbind(h2o1,h2o2)
    stop <-Sys.time()
    resultsdf[i,4] <- as.numeric(stop)-as.numeric(start)
    
    # 4: use fwrite then h2o.importfile()

    start <-Sys.time()
    fwrite(subdf,file=""hundredsandthousands.csv"",row.names=FALSE)
    h2o.importFile(""hundredsandthousands.csv"")
    stop <-Sys.time()
    resultsdf[i,5] <-as.numeric(stop)-as.numeric(start)

    plot(resultsdf[,1],resultsdf[,2],xlim=c(0,4000000),ylim=c(0,900),xlab=""rows"",ylab=""time/s"",main=""Scaling of different methods of h2o frame loading"")
    for (i in 1:3){
        points(resultsdf[,1],resultsdf[,(i+2)],col=i+1)
        }
    legendtext <-c(""as.h2o"",""write.csv then h2o.importFile"",""Split in half, as.h2o and rbind"",""fwrite then h2o.importFile"")
    legend(""topleft"",legend=legendtext,col=c(1,2,3,4),pch=1)

    print(resultsdf)
    flush.console()
    }",2019-04-18T04:51:32,,,,30821865
34326848,34326848,0,"I can't reproduce the problem.


library(h2o)
localH2O <- h2o.init(nthreads = -1, max_mem_size = '7g')
data(iris)
iris.hex <- as.h2o(localH2O, iris)

random <- h2o.runif(iris.hex, seed=-1) 
print(random)



Produces:


        rnd
1 0.4668078
2 0.9952272
3 0.7743285
4 0.1585492
5 0.2527465
6 0.9686618



However, if I run it again, it produces something different (as expected):


        rnd
1 0.1059295
2 0.2621405
3 0.1191477
4 0.3412595
5 0.3589089
6 0.9686884",2015-12-17T04:51:59,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",30790969
32000834,32000834,1,"When you are building your model, add the following condition: 
variable_importance = T
 


This will ensure that when your model is built, it will return your variable importances. 


In the Deep Learning demo for R, this requires that you modify the model building process. First, launch the demo by running the following code:


library(h2o)
conn <- h2o.init(nthreads = -1)
demo(h2o.deeplearning)



Then, adjust the code the initiates your model build by adding in the condition mentioned earlier:


model = h2o.deeplearning(x = setdiff(colnames(prostate.hex), c(""ID"",""CAPSULE"")), y = ""CAPSULE"", training_frame = prostate.hex, activation = ""Tanh"", hidden = c(10, 10, 10), epochs = 10000, variable_importances = T)



Finally, you can do the following to get your variable importances:


> h2o.varimp(model)
Variable Importances:
  variable relative_importance scaled_importance percentage
1      PSA            1.000000          1.000000   0.175660
2      VOL            0.937293          0.937293   0.164645
3  GLEASON            0.930565          0.930565   0.163463
4      AGE            0.799607          0.799607   0.140459
5    DCAPS            0.793741          0.793741   0.139429
6    DPROS            0.703781          0.703781   0.123626
7     RACE            0.527824          0.527824   0.092718



Hope this helps!",2015-08-14T01:05:53,Avni,https://stackoverflow.com/users/5225312/avni,226,30413447
30338009,30338009,0,"I've resolved this by building the project rather than downloading a zip.  The setup that currently works for me (I do not claim it is the only one that works) is: openjdk7, hadoop 2.6, spark 1.2.0.  Note HADOOP_HOME and SPARK_HOME must be exported shell variables, and the machine's private IP must be added to the /etc/hosts table, which can be done with:


echo $(ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | cut -d' ' -f1) $(hostname) localhost >> /etc/hosts



Then git clone the sparkling-water project and ./gradlew build in the project directory.",2015-05-19T23:47:04,tresbot,https://stackoverflow.com/users/1464641/tresbot,"1,620",30270400
31999499,31999499,4,"Firstly, I would recommend downloading the latest version of H20-3. This may solve the problem of you getting a NA value for your standard deviation. 
Relative importance quantifies the contributions of a specific predicator against those made by other individual predictors in predicting the response variable.  The number that you might be thinking of that needs to be between 1 and 100 is the scaled importance.
Lastly, the reason you are not getting a confusion matrix in your output is that you have a regression model rather than a classification model. Confusion matrices are only produced for classification models. 


You can run a random forest example in R by running the following commands:


library(h2o)
conn <- h2o.init()
demo(h2o.randomForest)



You can then see your confusion matrix/relative and scaled importance table by doing the following:


> h2o.confusionMatrix(iris.rf)
Confusion Matrix - (vertical: actual; across: predicted):
                Iris-setosa Iris-versicolor Iris-virginica  Error      Rate
Iris-setosa       50.000000        0.000000       0.000000 0.0000 =  0 / 50
Iris-versicolor    0.000000       47.000000       3.000000 0.0600 =  3 / 50
Iris-virginica     0.000000        6.000000      44.000000 0.1200 =  6 / 50
Totals            50.000000       53.000000      47.000000 0.0600 = 9 / 150
> h2o.varimp(iris.rf)
Variable Importances:
   variable relative_importance scaled_importance percentage
1 petal_len         1926.421509          1.000000   0.445738
2 petal_wid         1756.277710          0.911679   0.406370
3 sepal_len          493.782562          0.256321   0.114252
4 sepal_wid          145.390717          0.075472   0.033641



Thanks and hope this helps!",2015-08-13T22:32:05,,,,30225921
31573366,31573366,0,"h2o.saveModel(object, dir = """", name = """", filename = """", force = FALSE)



and


h2o.loadModel(path, conn = h2o.getConnection())",2015-07-22T20:28:00,Sebastian Hätälä,https://stackoverflow.com/users/2407819/sebastian-h%c3%a4t%c3%a4l%c3%a4,"1,035",30137628
31953225,31953225,0,"A working example that I've used recently while building a deep learning model in version 2.8.6 in h2o.The model was saved in hdfs.For latest version you probably have to remove the classification=T switch and have to replace data with training_frame


library(h2o)
h = h2o.init(ip=""xx.xxx.xxx.xxx"", port=54321, startH2O = F)

cTrain.h2o <- as.h2o(h,cTrain,key=""c1"")
cTest.h2o <- as.h2o(h,cTest,key=""c2"")

nh2oD<-h2o.deeplearning(x =c(1:12),y=""tgt"",data=cTrain.h2o,classification=F,activation=""Tanh"",
                        rate=0.001,rho=0.99,momentum_start=0.5,momentum_stable=0.99,input_dropout_ratio=0.2,                        
                        hidden=c(12,25,11,11),hidden_dropout_ratios=c(0.4,0.4,0.4,0.4),
                        epochs=150,variable_importances=T,seed=1234,reproducible = T,l1=1e-5,
                        key=""dn"")

hdfsdir<-""hdfs://xxxxxxxxxx/user/xxxxxx/xxxxx/models""

h2o.saveModel(nh2oD,hdfsdir,name=""DLModel1"",save_cv=T,force=T)

test=h2o.loadModel(h,path=paste0(hdfsdir,""/"",""DLModel1""))",2015-08-11T22:42:20,0xF,https://stackoverflow.com/users/5041140/0xf,586,30137628
29889006,29889006,0,"You can convert waterTrain to a data frame using as.data.frame method and later you filter (subset) conveniently using standard R methods


waterTrain.data.frame <- as.data.frame(waterTrain)



Alternatively you can also,


irisPath <- system.file(""extdata"", ""iris.csv"", package=""h2o"")
iris.hex <- h2o.importFile(localH2O, path = irisPath, key = ""iris.hex"")
iris.hex.top10 <- iris.hex[1:10,1:3]",2015-04-27T06:50:20,,,,29828978
29607558,29607558,2,"It doesn't look like multiple response columns are currently supported in H2O (
H2O FAQ
 and 
H2O Google Group topic
). Their suggestion is to train a new model for each response.


(Nonsensical) example:


library(h2o)
localH2O <- h2o.init()
irisPath <- system.file(""extdata"", ""iris.csv"", package = ""h2o"")
iris.hex <- h2o.importFile(localH2O, path = irisPath)

m1 <- h2o.deeplearning(x = 1:2, y = 3, data = iris.hex, activation = ""Tanh"", 
         hidden = c(10, 10), epochs = 5, classification = FALSE)
m2 <- h2o.deeplearning(x = 1:2, y = 4, data = iris.hex, activation = ""Tanh"", 
         hidden = c(10, 10), epochs = 5, classification = FALSE)



However, it appears that multiple responses are available through the 
deepnet
 package (check 
library(sos); findFn(""deep learning"")
). 


library(deepnet)
x <- as.matrix(iris[,1:2])
y <- as.matrix(iris[,3:4])
m3 <- dbn.dnn.train(x = x, y = y, hidden = c(5,5))",2015-04-13T14:15:20,,,,29603624
48505392,48505392,0,"If Cox models are supported, then time-varying covariates are supported. The key is ensuring the data are formatted in the proper way. Each event change is a censoring event, then the participant is re-entered into the study at the change time with the new covariates. There is one line per time-varying event and then a final censoring or death event. If need be, the dataset must be transformed from wide to long which is easily done in base R or virtually any statistical programming language.",2018-01-29T16:05:28,AdamO,https://stackoverflow.com/users/821649/adamo,"4,910",29152961
29174788,29174788,0,Try using Nginx.  There is a lot more support for it.  H2O is a little more complicated to setup and the docs aren't as well written.,2015-03-20T19:52:48,veshant,https://stackoverflow.com/users/3103879/veshant,1,29065974
28992429,28992429,0,"I think the reason of your problem is that you should define ip. So try something like this


localH2O = h2o.init(ip = ""enter your ip-address"", port = 54321, startH2O = F)",2015-03-11T16:42:26,Fedorenko Kristina,https://stackoverflow.com/users/2131442/fedorenko-kristina,"2,747",28877755
32383886,32383886,1,"I see the failure occurs in the crossValidate() method.  The cross-validation implementation in the latest version of H2O (H2O-3) has been rewritten.


Try the latest stable version from here: 
http://h2o.ai/download


But I don't see how to access the data anywhere in the original post, so I can't verify the issue is truly fixed.",2015-09-03T19:24:38,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",28771582
50789794,50789794,0,"Try re-installing your java (
https://java.com/en/download/windows-64bit.jsp
). I had the same problem with H2O-3.20.0.1 and it worked for me!",2018-06-11T02:26:13,Majid,https://stackoverflow.com/users/6935834/majid,"1,844",28771582
58584129,58584129,0,"I also had the error 
Error: java.lang.AssertionError:
, the fix that worked for me was having 
enable_assertions = FALSE
 in 
h2o.init
. 


library(h2o)
h2o.init(nthreads = 12, max_mem_size = ""64g"", enable_assertions = FALSE)



From the h2o documentation:




enable_assertions
: (Optional) A logical value indicating whether H2O should be launched with assertions enabled. This is used mainly for error checking and debugging purposes.",2019-10-27T23:07:29,kangaroo_cliff,https://stackoverflow.com/users/3651529/kangaroo-cliff,"6,222",28771582
31972561,31972561,3,"use the function from R like you normally would. by the way, there's no h2o.addFunction in H2O's latest H2O-3 (functions just work like magic).


Here's an example:


   apply(fr,2, function(x) { 2*x + 5 })



Or:


    simpleFun <- function(x) { 2*x + 5 }
    apply(fr, 2, simpleFun)",2015-08-12T18:16:26,rijs,https://stackoverflow.com/users/5220538/rijs,236,28741176
29337647,29337647,9,"This answer is for the original H2O project (releases 2.x.y.z).


In the original H2O project, the H2O R package creates lots of temporary H2O objects in the H2O cluster DKV (Distributed Key/Value store) with a ""Last.value"" prefix.


These are visible both in the Store View from the Web UI and by calling h2o.ls() from R.


What I recommend doing is:




at the bottom of each loop iteration, use h2o.assign() to do a deep copy of anything you want to save to a known key name


use h2o.rm() to remove anything you don't want to keep, in particular the ""Last.value"" temps


call gc() explicitly in R somewhere in the loop




Here is a function which removes the Last.value temp objects for you.  Pass in the H2O connection object as the argument:


removeLastValues <- function(conn) {
    df <- h2o.ls(conn)
    keys_to_remove <- grep(""^Last\\.value\\."", perl=TRUE, x=df$Key, value=TRUE)
    unique_keys_to_remove = unique(keys_to_remove)
    if (length(unique_keys_to_remove) > 0) {
        h2o.rm(conn, unique_keys_to_remove)
    }
}



Here is a link to an R test in the H2O github repository that uses this technique and can run indefinitely without running out of memory:


https://github.com/h2oai/h2o/blob/master/R/tests/testdir_misc/runit_looping_slice_quantile.R",2015-03-30T02:50:02,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",28703121
34319119,34319119,4,"New suggestion as of 12/15/2015: update to latest stable (Tibshirani 3.6.0.8 or later).
We've completely reworked how R & H2O handle internal temp variables, and the memory management is much smoother.


Next: H2O temps can be held ""alive"" by R dead variables... so run an R gc() every loop iteration.  Once R's GC removes the dead variables, H2O will reclaim that memory.  


After that, your cluster should only hold on to specifically named things, like loaded datasets, and models.  These you'll need to delete roughly as fast as you make them, to avoid accumulating large data in the K/V store.


Please let us know if you have any more problems by posting to the google group h2o stream: 
  
https://groups.google.com/forum/#!forum/h2ostream


Cliff",2015-12-16T18:07:17,Cliff Click,https://stackoverflow.com/users/5687938/cliff-click,131,28703121
45442649,45442649,2,"The most current answer to this question is that you should probably just use the 
h2o.grid()
 function rather than writing a loop.",2017-08-01T16:04:35,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",28703121
56173937,56173937,0,"With the H2O new version (currently 3.24.0.3), they suggest to use the following recommendations:


my for loop {
 # perform loop

 rm(R object that isn’t needed anymore)
 rm(R object of h2o thing that isn’t needed anymore)

 # trigger removal of h2o back-end objects that got rm’d above, since the rm can be lazy.
 gc()
 # optional extra one to be paranoid.  this is usually very fast.
 gc()

 # optionally sanity check that you see only what you expect to see here, and not more.
 h2o.ls()

 # tell back-end cluster nodes to do three back-to-back JVM full GCs.
 h2o:::.h2o.garbageCollect()
 h2o:::.h2o.garbageCollect()
 h2o:::.h2o.garbageCollect()
}



Here the source: 
http://docs.h2o.ai/h2o/latest-stable/h2o-docs/faq/general-troubleshooting.html",2019-05-16T17:41:50,lucazav,https://stackoverflow.com/users/416988/lucazav,878,28703121
32691020,32691020,8,"When you run h2o.kmeans it just builds the model.


You will have to run the h2o.predict method using the model that you have built to get the data that you want.",2015-09-21T08:55:11,Gunjan Karun,https://stackoverflow.com/users/1622607/gunjan-karun,795,28540882
28542435,28542435,4,"There is a function 
h2o.getFrame
 which get frame by the 
key
. 
h2o.kmeans
 generates the frame with key from 
h2o.kmeans
  + ""_clusters"". So this code gets clusters:


clusters <- h2o.getFrame( localH2O, ""kmeansKey_clusters"" );",2015-02-16T13:23:54,Fedorenko Kristina,https://stackoverflow.com/users/2131442/fedorenko-kristina,"2,747",28540882
34144036,34144036,3,"+1 Gunjan Karun's answer.


Steps I followed:
1. Predict using h2o.predict
2. h2o.cbind with the identifying column in train data set, in my case, customer ID",2015-12-07T21:56:38,julian_b,https://stackoverflow.com/users/3749766/julian-b,45,28540882
28649783,28649783,0,"I took the advice of @screechOwl and asked on the 0xdata.atlassian.net board for h2o and was given a clear answer:


It was supplied by user 
""cliff""
.


Hi, yes H2O - when importing a folder - takes all the files in the folder; it unzips gzip'd or zip'd files as needed, and parses them all into one large CSV.  All the files have to be compatible in the CSV sense - same number and kind of columns.  


H2O does not currently handle bzip files.",2015-02-21T18:42:55,EngrStudent,https://stackoverflow.com/users/2259468/engrstudent,"1,972",28385028
31972477,31972477,5,"you're looking for h2o.table


From R:


   fr <- as.h2o(iris)
   h2o.table(iris[,""Species""])



From python:


   fr[""Species""].table()",2015-08-12T18:11:48,rijs,https://stackoverflow.com/users/5220538/rijs,236,28366209
28347846,28347846,3,"But of course.... 


To go from ""h2o"" to ""R"" the command is: ""
as.data.frame.H2OParsedData
"" 


From the example:


library(h2o)
localH2O = h2o.init()
prosPath = system.file(""extdata"", ""prostate.csv"", package=""h2o"")
prostate.hex = h2o.importFile(localH2O, path = prosPath)
prostate.data.frame <- as.data.frame(prostate.hex)
summary(prostate.data.frame)
head(prostate.data.frame)



To go from ""R"" to ""h2o"" the command is: ""
as.h2o
""


From the example, the code is:


data(iris)
summary(iris)
iris.r <- iris
iris.h2o <- as.h2o(localH2O, iris.r, key=""iris.h2o"")
class(iris.h2o)



so try this:


m = matrix(c(1,2,3,4), ncol=2)
localH2O = h2o.init()
m2 <- as.h2o(client=localH2O, object=m)
class(m2)",2015-02-05T15:30:51,,,,28301125
47247103,47247103,0,"Probably the H2O functionality improved at the time of me reading this...


m2 <- as.h2o(x = m, destination_frame = ""m2"")



This will save R object m2 into H2O cluster",2017-11-12T09:04:13,vlad1490,https://stackoverflow.com/users/5499595/vlad1490,365,28301125
28225088,28225088,2,"The error occurs because 
hour
 is a numeric column. The function 
h2o.sub
 and 
h2o.gsub
 do not work with numeric data.


The command 
str(dat.mini.hex$hour)
 will show you that 
hour
 is a numeric column.


str(dat.mini.hex$hour)



You can convert 
hour
 to a factor and save the result in a new column 
hour2
.


dat.mini.hex$hour2 <- as.factor(dat.mini.hex$hour)



Now, you can use 
h2o.sub
. However, I suppose you will not like the result...


h2o.sub('^(.{6}).*$','\\1', dat.mini.hex$hour2)
#   hour2
# 1   \\1
# 2   \\1
# 3   \\1
# 4   \\1
# 5   \\1
# 6   \\1



As you can see, 
h2o.sub
 uses 
\\1
 literally but not for the first matching group. This behaviour is in contrast to base R's 
sub
.


You can change your regex and replace the characters after the first six ones with the empty string.


h2o.sub('(?<=^.{6}).*$','', dat.mini.hex$hour2)
#    hour2
# 1 141021
# 2 141022
# 3 141028
# 4 141029
# 5 141028
# 6 141024



Here, 
(?<=^.{6})
 is a positive lookbehind. It matches the position that is preceded by the beginning of the string and the first 6 digits.",2015-01-29T21:37:34,Sven Hohenstein,https://stackoverflow.com/users/1627235/sven-hohenstein,81.6k,28220745
28202714,28202714,3,"Use capture groups:


gsub('(.+)..','\\1', df1$var1)



This regex matches (.+).. with 
df1$var1
, and replace it with the substring that matches the first capture group 
(.+)
. Since there is 
..
 at the end of the regex, the last two characters are not matched with the 
.+
, thus they are not in the result.",2015-01-28T21:27:21,zw324,https://stackoverflow.com/users/688653/zw324,27.1k,28202645
28202762,28202762,1,"Capture the first 6 value like so using a pattern that matches the whole sting


gsub('^(.{6}).*$','\\1', df1$var1)



A slightly more general replacement for 
substr(x,start,stop)
 is 


if(start > 1)
     gsub('^(.{*start-1*})(.{*stop-start+1*})).*$','\\1', 'asdfhjkl')
else
     gsub('^(.{*stop*})).*$','\\1', 'asdfhjkl')



where the values between the 
*
 characters are the actual integer values of the expression.  (although you'll have to make sure that 
nchar(x)
is less than 
stop
, otherwise the patterns won't match b/c the string is too short.)",2015-01-28T21:29:39,,,,28202645
28225211,28225211,1,"The regex 
(?<=^.{6}).*$
 matches al characters after the first 6 ones. If you want to replace 
substr(df1$var1, 1, 6)
 with 
sub
, you can use this command:


sub('(?<=^.{6}).*$', '', df1$var1, perl = TRUE)

# [1] ""141022"" ""141023"" ""141024"" ""141025"" ""141026"" ""141027"" ""141028"" ""141029""
# [9] ""141030"" ""141031""



This command replaces all digits after the first 6 ones with the empty string.",2015-01-29T21:44:43,Sven Hohenstein,https://stackoverflow.com/users/1627235/sven-hohenstein,81.6k,28202645
27759590,27759590,4,"Yes, h20 is an 
in-memory architecture
 and hence limited by physical memory.
They do support about 15 different compression schemes under the hood, including ones designed to compress sparse data.


They say some streaming support is ""on the roadmap but not implemented yet"".


If your dataset doesn't fit, and you can't compress or encode your datatypes any more efficiently (factor, logical, splitting into ranges, text preprocessing), then you'll need either a big cluster or big cloud instance.


Also, FYI the 
support for R
 is only a subset:




A note on R: H2O supports an R-like language - not full R semantics -
  but the obviously data-parallel data-munging aspects of R, and of
  course all the operators run fully parallel and distributed. There is
  a REPL. You can use it to add or drop columns or rows, manufacture
  features, impute missing values, or drop-in many R-expressions and
  have them run at-scale.




So e.g. use their Pre-Baked Algorithms wherever possible (high-performance native Java implementation) rather than generic R algorithm code.


Is your need prototyping or production?
You might ask if they have any reference customers in production on R-H2O.",2015-01-03T21:11:43,,,,27759277
35243251,35243251,35,"As per h2o version 3.6.0.8, it does not require any parameters. Example:


iris.hex <- as.h2o(iris)",2016-02-06T16:17:16,Ram,https://stackoverflow.com/users/5892517/ram,351,27553362
27579400,27579400,16,"Please try this:


prostate.hex <- as.h2o(localH2O, prostate.data.frame, key=""prostate.hex"")",2014-12-20T10:44:43,Dusan Grubjesic,https://stackoverflow.com/users/3638373/dusan-grubjesic,945,27553362
34955775,34955775,13,"The accepted answer is out of date at this point (Jan-22-2016), so here's what works at present day


prostate.hex <- as.h2o(prostate.data.frame, destination_frame=""prostate.hex"")",2016-01-22T20:54:11,Matthew Drury,https://stackoverflow.com/users/2300239/matthew-drury,"1,095",27553362
27296668,27296668,5,"I'm not sure if this is the most ""hydrophilic"" way to do this but:


transType <- trans$Type
sub1 <- trans[transType == 1,]



Seems to work for me with no problem.


For a more reproducible example, consider


library(h2o)
localH2O <- h2o.init()

prosPath <- system.file(""extdata"", ""prostate.csv"", package = ""h2o"")
prostate.hex <- h2o.importFile(localH2O, path = prosPath)
prostate.hex[prostate.hex$GLEASON == 6,]",2014-12-04T14:36:48,StevieP,https://stackoverflow.com/users/2113367/steviep,"1,619",27181616
26477801,26477801,1,"Here I've defined a function 
name_stats
 that does as you request. You'll need to run the code in your question to create TrainingNames first before the function will work.


You can edit whatever you like to make it fit your specific needs.


name_stats=function(name){
    df=subset(TrainingNames,FirstName==name)
    gender=tapply(df[,'Freq'],df[,'Gender'],sum)
    prob_male=gender['M']/sum(gender)
    prob_female=gender['F']/sum(gender)
    age=tapply(df[,'Freq'],as.factor(df[,'Year']),sum)
    dimnames(age)=list(age=round((Sys.Date()-as.Date(unlist(dimnames(age)),format='%Y'))/365))
    mean_age=mean(rep(as.numeric(unlist(dimnames(age))),age))
    sd_age=sd(rep(as.numeric(unlist(dimnames(age))),age))
    cat('Probability',name,'is male is',round(prob_male,6),'\n','Probability',name,'is female is',round(prob_female,6),'\n','Mean age of',name,'is',round(mean_age,6),'\n','SD age of',name,'is',round(sd_age,6))
}",2014-10-21T02:03:10,CephBirk,https://stackoverflow.com/users/3990506/cephbirk,"6,700",26393977
24687705,24687705,2,"Figured it out. My cluster was using an old version of H2O and it is supposed to give an error saying ""version mismatch"". But for some reason, it was not giving that error. Updating the R H2O package and the H2O cluster jar to the latest stable version resolved the issue.",2014-07-10T23:03:35,FirstName LastName,https://stackoverflow.com/users/1647211/firstname-lastname,"1,911",24683428
31953261,31953261,1,"H2O 3.x versions has an option called 
strict_version_check=False
 in python to relax the version conflict between client and server. You can use that.",2015-08-11T22:46:00,Nathaniel Ford,https://stackoverflow.com/users/442945/nathaniel-ford,21.1k,24683428
29337790,29337790,2,"It's hard to read the screenshot error pasted into the screen, but it looks like InvalidProtocolBufferException.


In this case, it looks like the ""hdfs://172.16.53.31:"" is not well-formed.


Try ""hdfs://172.16.53.31"" with no port.
Or try adding the correct port for your Hadoop installation.


If you give a totally wrong port, the thing you point to won't speak protobuf.


This error can also happen when the Hadoop client version is too different from the Hadoop server version.  (Note that if you start H2O with the 'hadoop jar' method, the correct Hadoop libraries are put on the client classpath by 'hadoop jar'.)


If you start H2O using 'hadoop jar' then you generally pick up the name node from the environment, and can just give ""hdfs:///path/to/file.csv"" with no name node specified.",2015-03-30T03:06:36,TomKraljevic,https://stackoverflow.com/users/2085461/tomkraljevic,"3,671",24604458
28368294,28368294,1,"I did have the same problem.


Try to add the 9000 port number to your hdfs path. 


Something like this:


hdfs://<ip>:9000/<dataPath>/",2015-02-06T14:45:20,Daniel Londoño,https://stackoverflow.com/users/4537540/daniel-londo%c3%b1o,11,24604458
