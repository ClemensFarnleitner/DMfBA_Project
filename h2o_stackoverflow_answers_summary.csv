,answer_id,vote_count,answer_content,creation_date,user_name,user_profile_link,reputation_score,post_id
73137883,73137883,1,"This is expected behavior, H2OAutoML is not reproducible by default.
To make H2OAutoML reproducible you need to set 
max_models
, 
seed
 and exclude DeepLearning (
exclude_algos=[""DeepLearning""]
) and make sure 
max_runtime_secs
 is not set.


To compare models you can use 
model explanations
 or you can just compare the 
model metrics
.",2022-07-27T12:24:06,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,73137419
72900660,72900660,1,"Yes, the 
h2o.explain
 uses the provided 
test_set
. The confusion matrix itself in your case is generated by 
h2o.confusionMatrix(object = model@leader, newdata = test_set)
.


Confusion matrix
 aggregates the data from 
h2o.predict
 thus providing some high level view on how does the model perform. 
h2o.predict
 gives you individual predictions without any aggregation.",2022-07-07T15:38:17,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72900276
72961595,72961595,1,"Created the Azure Python Timer Trigger Function in VS Code.


Installed the below dependencies in the VS Code Project terminal:




pip install requests
pip install tabulate
pip install future





If any existing or previous versions of H2o is available, uninstall it using the below command:



Next, run this command to install H2o module in the Project integrated terminal:




pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o





With the version of 
h2o==3.32.0.2
, I also got the same exceptions in VS Code output terminal.
So, I have tried with the below versions and working well.


requirements.txt file
:


azure-functions
h2o==3.36.1.2



Result
:




It also working with the version 
3.14.0.2
 H2o module in Python
.",2022-07-13T06:02:57,,,,72888069
72897315,72897315,1,"In H2O3, the 
model.explain()
 will return 
h2o.explanation._explain.H2OExplanation
 object. You can iterate through it to save your plots.


param 
render
, if 
True
, render the model explanations otherwise model explanations are just returned.


I was able to do it with the below function


tested with h2o version 
'3.36.1.2'


def save_explain_plots(model, data):
    obj = model.explain(data, render=False)
    for key in obj.keys():
        print(f""saving {key} plots"")
        if not obj.get(key).get(""plots""):
            continue
        plots = obj.get(key).get(""plots"").keys()

        os.makedirs(f""./images/{key}"", exist_ok=True)
        for plot in plots:
            fig = obj.get(key).get(""plots"").get(plot).figure()
            fig.savefig(f""./images/{key}/{plot}.png"")",2022-07-07T11:50:13,,,,72562340
72564512,72564512,0,"I think this is bug (off-by-one error) in the SVMLight parser, so I filed a bug 
here
.  For now, I'd recommend just naming the columns after you import the file.  Thank you for the reproducible example and bug report!",2022-06-09T17:41:56,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",72560442
72468521,72468521,0,"This is not an issue with H2O, it is a known vulnerability with much older versions of Java: 
https://nvd.nist.gov/vuln/detail/CVE-2012-0507",2022-06-01T22:02:04,TheFon,https://stackoverflow.com/users/5225817/thefon,31,72465078
72463879,72463879,1,"H2O.ai offers a bunch of ML solutions: h2o-3, driverless ai, hydrogen torch to name the main ones.


Driverless AI is AutoML driven, the user has, however, an option to provide a custom recipe (in Python) to customize it. Driverless AI has Snowflake integration.


H2O-3 is a framework that implements a collection of popular ML algorithms. H2O-3 also integrates an AutoML solution utilizing the built-in algos. There is no option to integrate a 3rd party solution into H2O-3 AutoML and to extend H2O-3 algos other than by coding in Java (small Python customizations can be made by providing eg. custom loss function in GBM).",2022-06-01T14:49:21,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72456723
72411068,72411068,3,"Removing the object from the R session using 
rm(h2o_df)
 will eventually trigger garbage collection in R and the delete will be propagated to H2O. I don't think this is ideal, however.


The recommended way is to use 
h2o.rm
 or for your particular use case, it seems like 
h2o.removeAll
 would be the best (takes care of everything, models, data..).",2022-05-27T21:04:54,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72400864
72377082,72377082,1,"I believe the issue is in the 
metalearner_algorithm
 specification - it should be one of 
""AUTO""
, 
""glm""
, 
""gbm""
, 
""drf""
, 
""deeplearning""
, or 
""xgboost""
. See the 
documentation
 for more details.",2022-05-25T11:49:26,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72376952
72352330,72352330,2,"This is happening because H2O considers value -Double.MAX_VALUE to be the lowest possible representable floating-point number. This value corresponds to -1.80e308. I agree this is confusing and I would consider this to be a bug. You can file an issue in our bug tracker: 
https://h2oai.atlassian.net/
 (PUBDEV project)",2022-05-23T17:06:19,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,72253927
72255034,72255034,1,"Not sure how to achieve that with 
h2o.group_by()
 – I get the same weird value when running your code. If you are open for a somewhat hacky workaround, you might want to try the following (I included the part on H2O initialization for future reference):




convert your frame to long format, ie key-value representation


split by group and apply aggregate function using 
h2o.ddply()


convert your frame back to wide format




## initialize h2o
library(h2o)

h2o.init(
  nthreads = parallel::detectCores() * 0.5
)

df_h2o = as.h2o(
  df
)

## aggregate per group
df_h2o |> 
  
  # convert to long format
  h2o.melt(
    id_vars = ""Group""
    , skipna = TRUE # does not include `NA` in the result
  ) |> 
  
  # calculate `max()` per group
  h2o.ddply(
    .variables = c(""Group"", ""variable"")
    , FUN = function(df) {
      max(df[, 3])
    }
  ) |> 
  
  # convert back to wide format
  h2o.pivot(
    index = ""Group""
    , column = ""variable""
    , value = ""ddply_C1""
  )

# Group ID VarA VarB VarD
#     1  4    3  NaN   16
#     2  7   12   14   14
#     3 10   14   16   16
#     4 12   14   16   16
#     5 16   16   16   16
# 
# [5 rows x 5 columns] 

## shut down h2o instance
h2o.shutdown(
  prompt = FALSE
)",2022-05-16T06:41:50,,,,72253927
72099329,72099329,0,"Unfortunately, the 
explain
 method in H2O-3 is supported only for the supervised algorithms.


What you could do is to use a surrogate model and look at explanations on it.
Basically, you'd fit a GBM (or DRF as those 2 models support the 
TreeSHAP
) on the data + the prediction of the Extended Isolation Forest which would be the response.",2022-05-03T12:22:55,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,72098968
72104750,72104750,0,"Here is another approach how to explain prediction of (E)IF: 
https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/isolation-forest/interpreting_isolation-forest.ipynb",2022-05-03T19:50:29,Adam Valenta,https://stackoverflow.com/users/18505934/adam-valenta,36,72098968
72062440,72062440,1,Right now we do not support categorical columns in generating splines.  It is on our roadmap though.,2022-04-29T18:42:43,Wendy Wong,https://stackoverflow.com/users/15170707/wendy-wong,11,72048657
74668911,74668911,0,"I could run successfully following the steps:




Downloaded sparkling water distribution zip: 
http://h2o-release.s3.amazonaws.com/sparkling-water/spark-3.1/3.36.1.1-1-3.1/index.html


Dependent JARs path: s3://bucket_name/sparkling-water-assembly-scoring_2.12-3.36.1.1-1-3.1-all.jar


--additional-python-modules, h2o-pysparkling-3.1==3.36.1.1-1-3.1",2022-12-03T17:15:33,,,,71928885
72014048,72014048,1,"I believe you are looking for the 
learning curve plot
. In h2o you can retrieve the ""scoring history"" data using 
model.scoring_history()
.


You can influence the frequency of scoring as well as amount of data used for the loss estimate using parameters prefixed with 
score_
, e.g., 
score_interval
, 
score_validation_samples
 etc.",2022-04-26T12:33:26,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,71777142
71741875,71741875,2,"You can use 
aml.leader
 to get the top model or you can use 
get_best_model
 to pick the model by some criterium. If you want to pick some specific model from the leaderboard you can use 
h2o.get_model(""model_id"")
 (the model_id is from the leaderboard).


To get parameters from all the base models you can use the following:


{base_model: h2o.get_model(base_model).actual_params
 for base_model in h2o.get_model(""model_id"").base_models}



You might also want to get parameters from the stacked ensemble and the metalearner:


metalearner_params = h2o.get_model(""SE_model_id"").metalearner().actual_params
se_params = h2o.get_model(""SE_model_id"").actual_params",2022-04-04T18:08:54,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,71741263
71699115,71699115,4,"There's a few things wrong with the code (we need to do a better job of documenting the 
random_columns
 parameter).  Currently the 
random_columns
 parameter only supports column indexes (not column names) and I created a 
JIRA
 to improve this.


The error is not actually saying that the column has to be numeric; in fact it needs to be a factor.  And lastly, you need to set 
HGLM = TRUE
.  To fix your code above, you can do:


df2$ID2 <- as.factor(df2$ID2)

test_glm2 <- h2o.glm(family = ""gaussian"",
                     x = ""x"",
                     y = ""y"",
                     training_frame = df2,
                     random_columns = c(4),
                     HGLM = TRUE,
                     lambda = 0,
                     compute_p_values = TRUE)



EDIT: This still causes a bug, so I filed a bug report 
here
.",2022-03-31T21:04:02,,,,71693880
71617486,71617486,1,"It seems that your environment still contains old H2O R library. 
cacert
 is an 
valid parameter
 and it was introduced in H2O 3.26.0.6.",2022-03-25T13:08:37,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,71616995
71616883,71616883,1,"See 
this tutorial
 please. The newer versions of Rsparkling use {H2OContext.getOrCreate(h2oConf)} instead of {h2o_context(sc)}.",2022-03-25T12:19:19,Marek Novotny,https://stackoverflow.com/users/12774229/marek-novotny,116,71609592
71530878,71530878,1,"I am sorry, the XGBoost is not supported on Apple M1 processor yet.


https://h2oai.atlassian.net/browse/PUBDEV-8482",2022-03-18T17:19:44,Adam Valenta,https://stackoverflow.com/users/18505934/adam-valenta,36,71529386
71238234,71238234,0,"userIdAttribute=""uid"" worked for me.
Now the authentication from LDAP is successful, however now it's failing with same exception mentioned at:

https://github.com/eclipse/jetty.project/issues/2648
, and the suggested fix is NOT included in h2o.jar, hence the failure.
#h2o team needs to update the h2o.jar with this fix.",2022-02-23T13:57:32,Pankaj Mahadik,https://stackoverflow.com/users/16570951/pankaj-mahadik,31,71172747
71150841,71150841,0,"This typically means one of the nodes crashed, it can be due to many different reasons - memory is the most common one.


I see your machine has about 64GB of physical memory and H2O is getting 48GB out of that. XGBoost runs in native memory, not in the JVM memory. For XGBoost we recommend splitting the physical memory 50-50 to H2O and XGBoost.


You are running a development version of H2O (3.33) - I suggest upgrading to the latest stable.",2022-02-17T00:02:39,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71146238
71150782,71150782,0,"Stacked Ensemble is a model that is based on outputs of other models. To re-train the SE model you will need to re-train the individual models.


Apart from that AutoML will not pre-process the data. It delegates the pre-processing to downstream models. There is one exception - target encoding.


Did you enable TE in AutoML?",2022-02-16T23:54:28,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71138526
71150875,71150875,1,Based on description in comments - this seems like a bug and fix will be needed.,2022-02-17T00:06:57,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71093974
71150717,71150717,0,"Can you post a list of all built models and their performances? The best one has  a depth 10, it would be useful to know what other hyperparameters were explored.


You max runtime is only 5 minutes, it is possible most of the hyperparameter space was not explored. Lets see what other models were build.",2022-02-16T23:46:43,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71081912
71069800,71069800,1,"With the glm your predictions are in log form. To compare them you need to use the exponential of the predictions.


Metrics::rmse(exp(pred), test$DriversKilled)
[1] 18.09796



If you make a prediction with h2o you will see that it has already taken care of the exponential operation.


Note that the models differ slightly in the rmse. 
h2o.glm
 has a lot more going on in the background.",2022-02-10T17:39:03,phiver,https://stackoverflow.com/users/4985176/phiver,23.5k,71068729
71150632,71150632,0,"This is because you cannot use an older model in a newer version of H2O. When you are working with binary models, the version has to be the same.",2022-02-16T23:34:54,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,71063715
70804860,70804860,0,"Article 
https://www.h2o.ai/blog/hacking-algorithms-into-h2o-quantiles/
 is still relevant, some details changed by the main concept remained the same.


Everything you read about map-reduce and DKV is still relevant to this day. The foundation of the article didn't change.


We will refresh the article to make it up to date with the current code base.",2022-01-21T16:55:35,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70759860
71150866,71150866,0,"I already added an example of extending H2O: 
https://github.com/h2oai/h2o-3/pull/6070


It gives you a skeleton of the implementation of H2O algorithm.",2022-02-17T00:05:26,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70759860
70737274,70737274,1,"Try this instead:


from h2o.estimators.model_selection import H2OModelSelectionEstimator



If you can't import it, then you probably don't have the latest version of H2O, so you should 
download
 it.  
ModelSelection
 was just released in 3.36.0.1.",2022-01-17T06:22:36,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70721119
70682629,70682629,4,"Thank you for the question, Roshan,


Snowflake Partner Connect enables a 14-day trial of Driverless AI to be started directly from the Snowflake UI.


When Driverless AI is deployed independently or in the H2O.ai Managed cloud it can connect to Snowflake using the Snowflake connector or JDBC.


Partner Connect is only for trials and labs that demonstrate the capabilities of the products. Customers would then pick a deployment (on-prem, cloud, managed cloud etc.) that aligns with your deployment requirements.


Both Driverless AI and H2O-3 can connect to Snowflake to access data for training, using the Snowflake Connector (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/connectors/snowflake.html
) or JDBC (
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/getting-data-into-h2o.html#jdbc-databases
)


When inferencing (scoring) models can be used with Snowflake as either external functions or user defined functions (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/snowflake-integration.html
)


The functionality in Driverless AI can be used via an API, here is a link the describes how to use the client and notebooks (
https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/python_client.html
)


Please reach out if you have any questions.",2022-01-12T13:43:06,Eric Gudgion,https://stackoverflow.com/users/17915291/eric-gudgion,41,70637288
70678604,70678604,2,"Changing Java install to 
FROM openjdk:15.0.2-jdk-slim
 has solved the issue",2022-01-12T08:48:55,sandoronodi,https://stackoverflow.com/users/6126355/sandoronodi,315,70622044
70609024,70609024,1,"Unfortunately, H2O-3 doesn't currently support exporting GLM with interactions as MOJO. There's a bug that allows the GLM to be exported with interactions but the MOJO doesn't work correctly - the interactions are replaced by missing values. This should be fixed in the next release (3.36.0.2) - it will not allow to export that MOJO in the first place.


There's not much other than writing the stacked ensemble in R (base model predictions preprocessing (e.g., interaction creation) and then feeding it to the h2o.glm) that you can do. There is now an unmaintained package 
h2oEnsemble
 that might be helpful for that. You can also use another metalearner model that is more flexible, e.g., GBM.",2022-01-06T14:54:28,Tomáš Frýda,https://stackoverflow.com/users/13566678/tom%c3%a1%c5%a1-fr%c3%bdda,591,70597370
70883882,70883882,1,"This functionality is called ""row binding"", it is not exposed as an API method. It is, however, available as a Rapids expression (simple scheme-like language). You can follow this example to row-bind 2 H2O Frames: 
https://github.com/h2oai/h2o-3/blob/master/h2o-core/src/test/java/water/rapids/ast/prims/mungers/AstRBindTest.java#L40
 In a nutshell, if you have 2 frames with keys A and B you would run water.rapids.Rapids.exec(""rbind A B"").getFrame()",2022-01-27T18:28:01,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70471661
70442318,70442318,1,"Did you try Notebook-scoped library concepts ?  Notebook-scoped libraries let you create, modify, save, reuse, and share custom Python environments that are specific to a notebook. When you install a notebook-scoped library, only the current notebook and any jobs associated with that notebook have access to that library. Other notebooks attached to the same cluster are not affected. You can ref : 
link


Limitations : Notebook-scoped libraries do not persist across sessions. You must reinstall notebook-scoped libraries at the beginning of each session, or whenever the notebook is detached from a cluster.",2021-12-21T22:39:00,Karthikeyan Rasipalay Durairaj,https://stackoverflow.com/users/9599091/karthikeyan-rasipalay-durairaj,"2,320",70440726
70467722,70467722,3,"H2O.ai has releases/patches upgraded to the latest log4j version 2.17 to address the various vulnerabilities found. Updates are at:


https://www.h2o.ai/security/bulletins/h2o-2021-001/",2021-12-23T21:49:01,Satish Maruvada,https://stackoverflow.com/users/17711973/satish-maruvada,46,70408222
70408223,70408223,1,"H2O.ai is closely tracking the vulnerabilities and publishing updates at 
https://www.h2o.ai/security/bulletins/h2o-2021-001/
.",2021-12-19T00:35:45,Michal,https://stackoverflow.com/users/5089773/michal,437,70408222
70366535,70366535,3,"A jar file is just a compressed folder with a different name. You can explore your packages looking for this information.


H2Os official statement, including affected versions and recommendations: 
https://www.h2o.ai/security/bulletins/h2o-2021-001/",2021-12-15T15:46:58,Luna,https://stackoverflow.com/users/16686308/luna,185,70366277
70366543,70366543,3,"As stated on 
https://logging.apache.org/log4j/2.x/security.html
 Log4J 1.x versions are not affected by this vulnerability. And it seems that 
h2o
 is using 
log4j-1.2.15.jar
 so you are okay.",2021-12-15T15:47:13,bradley101,https://stackoverflow.com/users/7373144/bradley101,721,70366277
71150938,71150938,0,"Uninstalling a simply a matter of deleting the H2O jar file in your case.


To my knowledge Windows will only open the port for the given piece of software. Once you remove H2O from your computer the firewall rule will no longer apply.


This is more of a Windows-firewall question rather than H2O question, so please take my answer with a grain of salt.",2022-02-17T00:15:38,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70311395
71150953,71150953,0,"One way to define the threshold would be to calculate a say 0.95 quantile of MSE on your training set and use that for a threshold.


Is part of your data labeled - that would open up possibilities for other ways of defining threshold.",2022-02-17T00:18:45,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70294943
70719459,70719459,0,"You cannot add new methods in your pipeline in Flow.  Flow is just a simple GUI which allows you to do things like create train/test splits, train models, test models and view some metrics.  You'd have to use the R or Python client to create a pipeline of any sort.",2022-01-15T06:56:57,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70279189
71150888,71150888,0,"Yes, this is expected. Once one of the nodes crashes, you will need to restart the whole cluster. You need to make sure that you configure your kubernets jobs so that the pods are not preempted.",2022-02-17T00:08:37,Michal Kurka,https://stackoverflow.com/users/7301183/michal-kurka,566,70274744
70211830,70211830,2,"My guess is that the first approach will give better performance due to less context switching. I'm not too familiar with H2O but I guess they start a thread per core. So if you have 3 H2O instances, you get 3 threads per core which will lead to an increased number of context switches and hence reduced performance.


And I'm pretty sure that H2O can work with huge amounts of memory. They can pool the created arrays, so there should not be too much need for garbage collection for the actual data.",2021-12-03T09:08:53,pveentjer,https://stackoverflow.com/users/2245707/pveentjer,11.2k,70205550
70719466,70719466,0,Running H2O on a single node is always better (when possible) because there's communication overhead between the cluster nodes.  Models will train faster on a single node.,2022-01-15T06:58:37,Erin LeDell,https://stackoverflow.com/users/5451344/erin-ledell,"8,809",70205550
70186489,70186489,0,"The master node is also known as the ""driver"" so yes, you can set the driver memory: 
spark.driver.memory
  Here's a 
complete list of settings
 you can tweak.",2021-12-01T15:01:08,Matt Andruff,https://stackoverflow.com/users/13535120/matt-andruff,"5,100",70178457
