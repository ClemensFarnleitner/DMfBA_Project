,post_id,date_created,last_activity_date,view_count,question_text,detailed_tags,user_name,user_profile_link,reputation_score,badges
73138864,73138864,2022-07-27T13:30:00,2022-07-27 13:30:00Z,0,"Recently I started working with the h2o package in R-Studio. But now I have a different problem: everytime I try to 
load_all()
 my own project package, which has absolutely nothing to do with h2o, it initiates h2o without me saying. This causes different problems with functions that are masked by h2o.


> devtools::load_all()

â„¹ Loading my_own_package
 Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:        blabla 
    H2O cluster timezone:       blabla 
    H2O data parsing timezone:  blabla
    H2O cluster version:        blabla
    H2O cluster version age:    blabla 
    H2O cluster name:           blabla
    H2O cluster total nodes:    blabla
    H2O cluster total memory:   blabla
    H2O cluster total cores:    blabla 
    H2O cluster allowed cores:  blabla
    H2O cluster healthy:        blabla
    H2O Connection ip:          blabla
    H2O Connection port:        blabla
    H2O Connection proxy:       blabla
    H2O Internal Security:      blabla
    R Version:                  blabla 

Error in UseMethod(""mutate"") : 
  no applicable method for 'mutate' applied to an object of class ""function""
In addition: There were 50 or more warnings (use warnings() to see the first 50)



Is there a way such that I can 
devtools::load_all()
 my own package but not load h2o?","['r', 'h2o', 'devtools']",MJimitater,https://stackoverflow.com/users/12097191/mjimitater,939,"{'gold': '', 'silver': '', 'bronze': ''}"
73137419,73137419,2022-07-27T11:51:28,2022-07-27 13:17:59Z,0,"im getting different output for feature importance, when I run the automl in azure, google and h2o. even though the data is same and all the features are also same. what would be the reason for it.
is there any other method to compare the models","['azure', 'h2o', 'automl', 'google-cloud-vertex-ai']",molbdnilo,https://stackoverflow.com/posts/73137419/revisions,66.2k,"{'gold': '', 'silver': '', 'bronze': ''}"
72960854,72960854,2022-07-13T04:11:13,2022-07-14 02:20:06Z,80,"I'm using the 
h2o
 package in Python.


When 
binomial_double_trees == True
, I want to know information about internal all trees for a class.


This is my parameter:


h2o_rfe = H2ORandomForestEstimator(ntrees=3, max_depth=12, min_rows=10, binomial_double_trees=True)



If I use:


h2o_rfe.predict_leaf_node_assignment()



I can see that each tree is classified according to a separate tree and is also in 
h2o
 flow web page.


However, if I use:


list_of_trees = [H2OTree(model=h2o_rfe, tree_number=t, tree_class=None) for t in range(h2o_rfe.params['ntrees']['actual'])]'



I can't know the information of each internal tree according to the class.


Also I tried to set the 
tree_class
 (domain is 0,1):


list_of_trees = [H2OTree(model=h2o_rfe, tree_number=t, tree_class=""0"") for t in range(h2o_rfe.params['ntrees']['actual'])]'



When 
tree_class
 is 
'0'
, it is okay:


list_of_trees = [H2OTree(model=h2o_rfe, tree_number=t, tree_class=""1"") for t in range(h2o_rfe.params['ntrees']['actual'])]'



But when 
tree_class
 is 
'1'
, this error occurs:




Error: For binomial, only one tree class has been built per each iteration: 0




How to check the internal trees?","['python-3.x', 'random-forest', 'decision-tree', 'h2o', 'h2o.ai']",Daniel Walker,https://stackoverflow.com/posts/72960854/revisions,"6,638","{'gold': '', 'silver': '', 'bronze': ''}"
72900276,72900276,2022-07-07T15:10:38,2022-07-07 20:19:43Z,0,"I am trying to understand how the confusion matrix in h2o.explain is generated.
If I use the following code:
h2o.explain(model@leader, test_set, include_explanations=""confusion_matrix""), is the generated confusion matrix evaluating the model accuracy on the test set?
How would this be different from using h2o.predict on the test set (e.g. h2o.predict(model@leader, test_set)?","['r', 'h2o', 'confusion-matrix', 'automl']",M--,https://stackoverflow.com/posts/72900276/revisions,28.4k,"{'gold': '', 'silver': '', 'bronze': ''}"
72888069,72888069,2022-07-06T18:02:36,2022-07-13 06:02:57Z,0,"I am trying to create an Azure python function which uses H20 module. When I tried to test it locally I am getting module not available error even though I have specified it in requirements.txt and it seem to be installed in the virtual env and I am able to run using virtual environment manually.


Minimal Python code:


import datetime
import logging

import h2o
import azure.functions as func

def main(mytimer: func.TimerRequest) -> None:
    utc_timestamp = datetime.datetime.utcnow().replace(
        tzinfo=datetime.timezone.utc).isoformat()
    if mytimer.past_due:
        logging.info('The timer is past due!')
    logging.info('Python timer trigger function ran at %s', utc_timestamp)



requirement.txt


h2o==3.32.0.2



Error.txt:




Python version 3.9m Windows 10 OS.","['python-3.x', 'azure-functions', 'h2o']",The6thSense,https://stackoverflow.com/users/4251775/the6thsense,"8,325","{'gold': '', 'silver': '', 'bronze': ''}"
72665283,72665283,2022-06-17T22:16:33,2022-06-17 22:37:50Z,156,"I just installed the most recent version of h2o for Python.


And it generates the following error:


import h2o
h2o.init()
h2o_df = h2o.H2OFrame(some_df)



the error:


Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'
Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'
Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'
Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'
Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'
Traceback (most recent call last):
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_console_utils.py"", line 417, in execTableCommand
    success, res = exec_table_command(command, command_type,
  File ""C:\Users\some_user\AppData\Local\JetBrains\DataSpell 2022.1\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_tables.py"", line 43, in exec_table_command
    res += repr(tmp_var.head().to_html(notebook=True,
AttributeError: 'H2OFrame' object has no attribute 'to_html'



It also dumps all previous calls and output of h2o. What is wrong here?


UPDATE


I guess I have to add that I am running it in DataSpell. Everything seems to be fine in Jupyter notebook.","['python', 'h2o', 'dataspell']",,https://stackoverflow.com/posts/72665283/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
72562340,72562340,2022-06-09T14:44:20,2022-07-07 11:55:28Z,775,"I am trying to save the output images (graphs) I get when I use 
explain()
 in H2O models. Currently I am just saving the SHAP output using the 
model.shap_summary_plot(test, save_plot_path=`shap_summary.png`)
. There is no 
save_plot_path
 for explain.






import h2o
from h2o.automl import H2OAutoML

h2o.init()

df = h2o.import_file(""https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"")

response = ""quality""

predictors = [
  ""fixed acidity"", ""volatile acidity"", ""citric acid"", ""residual sugar"", ""chlorides"", ""free sulfur dioxide"",
  ""total sulfur dioxide"", ""density"", ""pH"", ""sulphates"", ""alcohol"",  ""type""
]


train, test = df.split_frame(seed=1)

aml = H2OAutoML(max_runtime_secs=120, seed=1)
aml.train(x=predictors, y=response, training_frame=train)

leader_model = aml.leader 

leader_model.explain(test) # save this output








However I want to save all the graphs generated via 
explain()
 instead of creating them individually. Also I want it to run as a script and not as a jupyter notebook.


Here is sample code,(edited 
Explain-wine-example
)


H2O explain docs","['python', 'h2o', 'h2o.ai']",Andreas Rossberg,https://stackoverflow.com/posts/72562340/revisions,36k,"{'gold': '', 'silver': '', 'bronze': ''}"
72560442,72560442,2022-06-09T12:40:15,2022-06-09 17:41:56Z,150,"It is a strange error when I use the 
col_names=
 argument in 
h2o.import_file
. However, setting the column names by a separate line works fine.


import os
import h2o

h2o.init() # It shows H2O_cluster_version 3.36.1.2 and Python version 3.9.7 final

os.system(""wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.tr.bz2"")
os.system(""bzip2 -d ijcnn1.tr.bz2"")

# These lines work
col_names = ['class'] + ['F' + str(i) for i in range(22)]
df1 = h2o.import_file(path=""ijcnn1.tr"")
df1.columns = col_names

# But this line does not work
df2 = h2o.import_file(path=""ijcnn1.tr"", col_names=col_names)

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_20191/3817572867.py in <module>
----> 1 df2 = h2o.import_file(path=""ijcnn1.tr"", col_names=col_names)

~/anaconda3/lib/python3.9/site-packages/h2o/h2o.py in import_file(path, destination_frame, parse, header, sep, col_names, col_types, na_strings, pattern, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    498         return lazy_import(path, pattern)
    499     else:
--> 500         return H2OFrame()._import_parse(path, pattern, destination_frame, header, sep, col_names, col_types, na_strings,
    501                                         skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    502 

~/anaconda3/lib/python3.9/site-packages/h2o/frame.py in _import_parse(self, path, pattern, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    459             path = os.path.abspath(path)
    460         rawkey = h2o.lazy_import(path, pattern)
--> 461         self._parse(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,
    462                     skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    463         return self

~/anaconda3/lib/python3.9/site-packages/h2o/frame.py in _parse(self, rawkey, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    476                na_strings=None, skipped_columns=None, custom_non_data_line_markers=None, partition_by=None, quotechar=None,
    477                escapechar=None):
--> 478         setup = h2o.parse_setup(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,
    479                                 skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    480         return self._parse_raw(setup)

~/anaconda3/lib/python3.9/site-packages/h2o/h2o.py in parse_setup(raw_frames, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)
    872                     % (len(column_names), parse_column_len))
    873         else:
--> 874             if len(column_names) != len(j[""column_types""]): raise ValueError(
    875                 ""length of col_names should be equal to the number of columns: %d vs %d""
    876                 % (len(column_names), len(j[""column_types""])))

ValueError: length of col_names should be equal to the number of columns: 23 vs 22","['import', 'h2o']",rozyang,https://stackoverflow.com/users/2669433/rozyang,619,"{'gold': '', 'silver': '', 'bronze': ''}"
72527070,72527070,2022-06-07T06:58:36,2022-06-07 06:58:36Z,44,"Trying out the h2o autoML option preprocessing = [""target_encoding""].The test performance did improve. How do I apply similar transformation on the unseen/ out of time data to check performance?","['python', 'target', 'h2o', 'automl', 'data-preprocessing']",Payal Sengupta,https://stackoverflow.com/users/19196718/payal-sengupta,21,"{'gold': None, 'silver': None, 'bronze': ''}"
72465078,72465078,2022-06-01T16:16:20,2022-06-01 22:02:04Z,107,"I ceased using h2o a few yeas back when I discovered a malware issue.


After obtaining a new Mac, I decided to give it another shot and install h2o.  The problem still persists.  I use VirusBarrier Scanner and rarely experience any inflected files of any type.


Has anyone else experienced the same problem?",['h2o'],,https://stackoverflow.com/posts/72465078/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
72456723,72456723,2022-06-01T05:17:18,2022-06-01 14:49:21Z,145,"i have a few questions regarding H2O AI. As per my understanding, h2o AI powers Auto ML functionality. but need to integrate my own python jupyetr ML model. so my questions are,




Can we use H2O AI without Auto ML and with our own python jupyter ML algorithm?


If yes, can we integrate that own manual scripted ML with Snowflake?


If we can integrate our own scripted ml algorithm with snowflake, what are the advantages of doing it that way? instead of an own manually-created python ML algorithm?","['python', 'snowflake-cloud-data-platform', 'h2o', 'automl', 'h2o.ai']",johnson,https://stackoverflow.com/users/11409289/johnson,429,"{'gold': None, 'silver': '', 'bronze': ''}"
72400864,72400864,2022-05-27T05:31:47,2022-05-27 21:04:54Z,0,"I am running a loop to upload a csv file from my local machine, convert it to a h2o data frame, then run a h2o model. I then remove the h2o data frame from my r environment and the loop continues. These data frames are massive so I can only have one data frame loaded at a time (hence the reason for me removing the data frame from my environment).


My problem is that h2o creates temporary files which quickly max out my memory. I know I can restart my r session, but is there another way to flush this out in code so my loop can run happily? When I look at my task manager the all my memory is sucked up in Java(TM) Platform SE Binary.","['r', 'h2o']",chipsin,https://stackoverflow.com/users/13326190/chipsin,675,"{'gold': '', 'silver': '', 'bronze': ''}"
72376952,72376952,2022-05-25T11:39:23,2022-05-25 12:19:19Z,169,"I tried using the 2 best models from AutoML and used one of them as Meta learner for stacking. Named the new model stack_test. Code that I used is:


stack_test = H2OStackedEnsembleEstimator(base_models=[model1_xg, model2_xg],
metalearner_algorithm=model1_xg)

stack_test.train(x=x, y=y, training_frame=h2o_train)
stack_test.model_performance(h2o_test).auc()



Error I am getting:


NameError: name 'stack_test' is not defined



What am I doing wrong here?","['python', 'h2o']",medium-dimensional,https://stackoverflow.com/posts/72376952/revisions,"2,203","{'gold': None, 'silver': '', 'bronze': ''}"
72253927,72253927,2022-05-16T03:35:18,2022-05-23 17:06:19Z,0,"I have started using 
h2o
 for aggregating large datasets and I have found peculiar behaviour when trying to aggregate the maximum value using h2o's 
h2o.group_by
 function. My dataframe often has variables which comprise some or all NA's for a given grouping. Below is an example dataframe.


df <- data.frame(""ID"" = 1:16)
df$Group<- c(1,1,1,1,2,2,2,3,3,3,4,4,5,5,5,5)
df$VarA <- c(NA_real_,1,2,3,12,12,12,12,0,14,NA_real_,14,16,16,NA_real_,16)
df$VarB <- c(NA_real_,NA_real_,NA_real_,NA_real_,10,12,14,16,10,12,14,16,10,12,14,16)
df$VarD <- c(10,12,14,16,10,12,14,16,10,12,14,16,10,12,14,16)

   ID Group VarA VarB VarD
1   1     1   NA   NA   10
2   2     1    1   NA   12
3   3     1    2   NA   14
4   4     1    3   NA   16
5   5     2   12   10   10
6   6     2   12   12   12
7   7     2   12   14   14
8   8     3   12   16   16
9   9     3    0   10   10
10 10     3   14   12   12
11 11     4   NA   14   14
12 12     4   14   16   16
13 13     5   16   10   10
14 14     5   16   12   12
15 15     5   NA   14   14
16 16     5   16   16   16



In this dataframe Group == 1 is completely missing data for VarB (but this is important information to know, so the output for aggregating for the maximum should be NA), while for Group == 1 VarA only has one missing value so the maximum should be 3.


This is a link which includes the behaviour of the behaviour of the 
na.methods
 argument (
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/groupby.html
).


If I set the 
na.methods = 'all'
 as below then the aggregated output is NA for Group 1 for both Vars A and B (which is not what I want, but I completely understand this behaviour).


h2o_agg <-  h2o.group_by(data = df_h2o, by = 'Group', max(), gb.control = list(na.methods = ""all""))

  Group max_ID max_VarA max_VarB max_VarD
1     1      4      NaN      NaN       16
2     2      7       12       14       14
3     3     10       14       16       16
4     4     12      NaN       16       16
5     5     16      NaN       16       16



If I set the 
na.methods = 'rm'
 as below then the aggregated output for Group 1 is 3 for VarA (which is the desired output and makes complete sense) but for VarB is -1.80e308 (which is not what I want, and I do not understand this behaviour).


h2o_agg <-  h2o.group_by(data = df_h2o, by = 'Group', max(), gb.control = list(na.methods = ""rm""))

  Group max_ID max_VarA  max_VarB max_VarD
  <int>  <int>    <int>     <dbl>    <int>
1     1      4        3 -1.80e308       16
2     2      7       12  1.4 e  1       14
3     3     10       14  1.6 e  1       16
4     4     12       14  1.6 e  1       16
5     5     16       16  1.6 e  1       16



Similarly I get the same output if set the 
na.methods = 'ignore'
.


h2o_agg <-  h2o.group_by(data = df_h2o, by = 'Group', max(), gb.control = list(na.methods = ""ignore""))

  Group max_ID max_VarA  max_VarB max_VarD
  <int>  <int>    <int>     <dbl>    <int>
1     1      4        3 -1.80e308       16
2     2      7       12  1.4 e  1       14
3     3     10       14  1.6 e  1       16
4     4     12       14  1.6 e  1       16
5     5     16       16  1.6 e  1       16



I am not sure why something as common as completely missing data for a given variable within a specific group is being given a value of -1.80e308? I tried the same workflow in dplyr and got results which match my expectations (but this is not a solution as I cannot process datasets of this size in dplyr, and hence my need for a solution in h2o). I realise dplyr is giving me 
-inf
 values rather than NA, and I can easily recode both 
-1.80e308
 and 
-Inf
 to NA, but I am trying to make sure that this isn't a symptom of a larger problem in 
h2o
 (or that I am not doing something fundamentally wrong in my code when attempting to aggregate in 
h2o
). I also have to aggregate normalised datasets which often have values which are approximately similar to -1.80e308, so I do not want to accidentally recode legitimate values to NA.


library(dplyr)
df %>%
  group_by(Group) %>% 
  summarise(across(everything(), ~max(.x, na.rm = TRUE)))

  Group    ID  VarA  VarB  VarD
  <dbl> <int> <dbl> <dbl> <dbl>
1     1     4     3  -Inf    16
2     2     7    12    14    14
3     3    10    14    16    16
4     4    12    14    16    16
5     5    16    16    16    16","['r', 'dplyr', 'h2o']",,https://stackoverflow.com/posts/72253927/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
72098968,72098968,2022-05-03T11:52:42,2022-05-03 19:50:29Z,389,"I have been struggling with this error for a few hours now, but seem lost even after reading through the documentation.


I'm using H2O's Extended Isolation Forest (EIF), an unsupervised model, to detect anomalies in an unlabelled dataset. Which is working as intended, however for the project i'm working on the model explainability is extremely important. I discovered the 
explain
 function, which supposedly returns several explainablity methods for a model. I'm particularly interested in the SHAP values from this function.


The documentation states




The main functions, h2o.explain() (global explanation) and h2o.explain_row() (local explanation) work for individual 
H2O models,
 as well a list of models or an H2O AutoML object.  The h2o.explain() function generates a list of explanations.




Since the H2O models link brings me to a page which covers both supervised and unsupervised models I assume the explain function would work for both types of models.


When trying to run my code the following code works just fine.


import h2o
from h2o.estimators import H2OExtendedIsolationForestEstimator

h2o.init()
df_EIF = h2o.H2OFrame(df_EIF)
predictors = df_EIF.columns[0:37]

eif = H2OExtendedIsolationForestEstimator(ntrees = 75, sample_size =500, extension_level = (len(predictors) -1)  )

eif.train(x=predictors, training_frame = df_EIF)
eif_result = eif.predict(df_EIF)
df_EIF['anomaly_score_EIF') = eif_result['anomaly_score']



However when trying to call explain over the model (eif)


eif.explain(df_EIF)



Gives me the following KeyError


KeyError                                  Traceback (most recent call last)
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx.py in <module>
----> 1 eif.explain(df_EIF)
      2 
      3 
      4 
      5 

C:\ProgramData\Anaconda3\lib\site-packages\h2o\explanation\_explain.py in explain(models, frame, columns, top_n_features, include_explanations, exclude_explanations, plot_overrides, figsize, render, qualitative_colormap, sequential_colormap)
   2895     plt = get_matplotlib_pyplot(False, raise_if_not_available=True)
   2896     (is_aml, models_to_show, classification, multinomial_classification, multiple_models, targets,
-> 2897      tree_models_to_show, models_with_varimp) = _process_models_input(models, frame)
   2898 
   2899     if top_n_features < 0:

C:\ProgramData\Anaconda3\lib\site-packages\h2o\explanation\_explain.py in _process_models_input(models, frame)
   2802         models_with_varimp = [model for model in models if _has_varimp(model)]
   2803     tree_models_to_show = _get_tree_models(models, 1 if is_aml else float(""inf""))
-> 2804     y = _get_xy(models_to_show[0])[1]
   2805     classification = frame[y].isfactor()[0]
   2806     multinomial_classification = classification and frame[y].nlevels()[0] > 2

C:\ProgramData\Anaconda3\lib\site-packages\h2o\explanation\_explain.py in _get_xy(model)
   1790     """"""
   1791     names = model._model_json[""output""][""original_names""] or model._model_json[""output""][""names""]
-> 1792     y = model.actual_params[""response_column""]
   1793     not_x = [
   1794                 y,

KeyError: 'response_column



From my understanding this response column refers to a column that you are trying to predict. However, since i'm dealing with an unlabelled dataset this response column doesn't exist. Is there a way for me to bypass this error? Is it even possible to utilize the explain() function on unsupervised models? If, so how do I do this? If it is not possible, is there another way to extract the Shap values of each variable from the model? Since the shap.TreeExplainer also doesn't seem to work on a H2O model.


TL;DR: Is it possible to use the .explain() function from h2o on an (Extended) Isolation forest? If so how?","['pandas', 'dataframe', 'h2o', 'isolation-forest']",Sebastiaan van Dijk,https://stackoverflow.com/users/19023547/sebastiaan-van-dijk,3,"{'gold': None, 'silver': None, 'bronze': ''}"
72048657,72048657,2022-04-28T18:30:00,2022-04-29 18:42:43Z,156,"I have fit a GAM model in h2o with several gam variables (P-splines) using the h2o.estimators.gam package. I'd like to get a table with the factor loading for every level of each gam variable. For example, one of my variables is age, and I need a table of the coefficient for each age.","['python', 'h2o', 'gam', 'bspline', 'h2o.ai']",Carver Coleman,https://stackoverflow.com/users/18977015/carver-coleman,11,"{'gold': None, 'silver': None, 'bronze': ''}"
71996637,71996637,2022-04-25T08:34:59,2022-04-26 07:15:13Z,206,"I have trained a stacked ensemble model with automl() function provided by H2O (3.36.0.4)for R. Once the model is trained, i have exported it to .zip format with the download_mojo() function.


I have created a Java app following instructions, but when running the program, the model always predicts the same value.


This is the app developed in Java:


import java.io.*;
import hex.genmodel.easy.RowData;
import hex.genmodel.easy.EasyPredictModelWrapper;
import hex.genmodel.easy.prediction.*;
import hex.genmodel.MojoModel;

public class App {
    public static void main(String[] args) throws Exception {

        EasyPredictModelWrapper model = new EasyPredictModelWrapper(MojoModel.load(""StackedEnsemble_BestOfFamily_8_AutoML_1_20220407_144828.zip""));

        BufferedReader csvReader = new BufferedReader(new FileReader(""dataset.csv""));
        RowData inputrow = new RowData();
        String row;
        String[] colnames = new String[36];
        String[] data;
        for (int i = 0; i <= 10; i++) {
            row = csvReader.readLine();
            if (i == 0) {
                colnames = row.split("","");
            } else {
                data = row.split("","");
                for (int k = 0; k < colnames.length - 2; k++) {
                    inputrow.put(colnames[k], data[k]);
                }
                RegressionModelPrediction prediction = model.predictRegression(inputrow);
                System.out.println(""Prediction ""+i+"": "" + prediction.value);
            }
        }
        System.out.println("""");
    }
}



It returns this:


Prediction 1: 0.09239077248718583
Prediction 2: 0.09239077248718583
Prediction 3: 0.09239077248718583
Prediction 4: 0.09239077248718583
Prediction 5: 0.09239077248718583
Prediction 6: 0.09239077248718583
Prediction 7: 0.09239077248718583
Prediction 8: 0.09239077248718583
Prediction 9: 0.09239077248718583
Prediction 10: 0.09239077248718583



For more details, training and test datasets have the same variables and the model have been trained with following parameters:


aml <- h2o::h2o.automl(y = y,
                       training_frame = df_h2o,
                       nfolds = 10,
                       max_models = 150,
                       max_runtime_secs = NULL,
                       keep_cross_validation_predictions = TRUE,
                       stopping_metric = 'RMSE',
                       sort_metric ='RMSE',
                       verbosity = ""info"")



And I have performed the following checks, with the same dataset used in java:


modelPath <- paste0(getwd(), ""/StackedEnsemble_BestOfFamily_8_AutoML_1_20220407_144828"")
loaded_model <- h2o.loadModel(modelPath)


val_df <-  read.csv(""dataset.csv"")
input_row <- val_df[1:10 ,1:36]
new_data <- as.h2o(input_row)

h2omodel_preditions <-as.vector(h2o.predict(loaded_model, new_data, exact_quantiles=TRUE))


original_mojo_path <- paste0(getwd(), ""/StackedEnsemble_BestOfFamily_8_AutoML_1_20220407_144828.zip"")
mojo_model <- h2o.upload_mojo(original_mojo_path)
mojo_predictions  <- as.vector( h2o.predict(mojo_model, new_data))


> h2omodel_preditions
 [1] 0.27564401 0.25663341 0.17848737 0.05179671 0.02977053 0.28588998 0.29157313 0.19800770 0.06251480 0.23992213
> mojo_predictions
 [1] 0.27564401 0.25663341 0.17848737 0.05179671 0.02977053 0.28588998 0.29157313 0.19800770 0.06251480 0.23992213","['java', 'prediction', 'h2o', 'mojo']",,https://stackoverflow.com/posts/71996637/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
71928885,71928885,2022-04-19T17:20:01,2022-12-03 17:16:48Z,216,"I am try to using 
pysparkling.ml.H2OMOJOModel
 for predict a spark dataframe using a MOJO model trained with h2o==3.32.0.2 in AWS Glue Jobs, how ever a got the error: TypeError: 'JavaPackage' object is not callable.


I opened a ticket in AWS support and they confirmed that Glue environment is ok and the problem is probably with sparkling-water (pysparkling). It seems that some dependency library is missing, but I have no idea which one.
The simple code bellow works perfectly if I run in my local computer (I only need to change the mojo path for GBM_grid__1_AutoML_20220323_233606_model_53.zip)


Could anyone ever run sparkling-water in Glue jobs successfully?


Job Details:
-Glue version 2.0
--additional-python-modules, h2o-pysparkling-2.4==3.36.0.2-1
-Worker type: G1.X
-Number of workers: 2
-Using script ""createFromMojo.py""


createFromMojo.py:


import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
import pandas as pd
from pysparkling.ml import H2OMOJOSettings
from pysparkling.ml import H2OMOJOModel
# from pysparkling.ml import *

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, [""JOB_NAME""])

#Job setup
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

job = Job(glueContext)
job.init(args[""JOB_NAME""], args)

caminho_modelo_mojo='s3://prod-lakehouse-stream/modeling/approaches/GBM_grid__1_AutoML_20220323_233606_model_53.zip'
print(caminho_modelo_mojo)
print(dir())

settings = H2OMOJOSettings(convertUnknownCategoricalLevelsToNa = True, convertInvalidNumbersToNa = True)
model = H2OMOJOModel.createFromMojo(caminho_modelo_mojo, settings)

data = {'days_since_last_application': [3, 2, 1, 0], 'job_area': ['a', 'b', 'c', 'd']}

base_escorada = model.transform(spark.createDataFrame(pd.DataFrame.from_dict(data)))

print(base_escorada.printSchema())

print(base_escorada.show())

job.commit()","['python', 'apache-spark', 'h2o', 'sparkling-water']",MaxReis86,https://stackoverflow.com/users/14055804/maxreis86,26,"{'gold': None, 'silver': None, 'bronze': ''}"
71849829,71849829,2022-04-12T22:33:47,2022-04-12 22:33:47Z,0,"So I wrote a script that takes the weights of a h2o model and plants them into a keras model. I then found that the results from running the model through keras do not match up with h2o.



Here's the code I used to get this graph:


library(h2o)
library(keras)
library(tensorflow)

# create data

x <- rnorm(10000,sd=3)
y <- 2*x + rnorm(10000,sd=0.4) + 0.3*rt(10000,5) -0.1*x^2 + 2.4*sin(1.2*x)
plot(x,y, main=""h2o model vs keras model with h2o weights"" )

df <- data.frame(x=x,y=y)

# apply h2o fit to data

h2o.init()
h2odf <- as.h2o(df)


model <- h2o.deeplearning(x = 1, y = 2,
                    training_frame = h2odf,
                    hidden = c(100,10),
                    activation = ""Tanh"",        # use ""Rectifier"" for relu
                    export_weights_and_biases = TRUE,
                    export_checkpoints_dir=getwd(),
                    verbose=TRUE)

newdf <- as.h2o(data.frame(x=seq(-10,10,by=0.01)))

predict <- as.data.frame(predict(model,newdf))
lines(seq(-10,10,by=0.01),predict$predict,col=2,lwd=2)


# Get the weights from h2o and convert them into a format that tensorflow will accept

layers <- model@parameters$hidden
activation <- model@parameters$activation
weights <- list()

for(i in 1:(1+length(layers))){
    W <- as.matrix(h2o.weights(model,matrix_id=i))
    B <- as.array(as.vector(h2o.biases(model,vector_id=i)))
    colnames(W) <- NULL
    W <- t(W)
    weights[[2*i-1]] <- W
    weights[[2*i]] <- B
    
}



# set up Keras model with the same layers and activation functions

k_clear_session()
model2 <- keras_model_sequential()
model2 %>% layer_dense(units=layers[1],input_shape=1,activation=tolower(activation))

for(i in 2:(length(layers))){
    model2 %>% layer_dense(units = layers[i],
                    activation = tolower(activation))
}
                
model2 %>% layer_dense(name=""output"",units = 1,activation = ""linear"")       # Can try tanh activation here, still doesn't make it right.    


# Inject h2o weights into the keras model

set_weights(model2,weights)

newdf <- data.frame(x=seq(-10,10,by=0.01))
predict2 <- predict(model2,as.matrix(newdf))

lines(seq(-10,10,by=0.01),predict2,col=4,lwd=2)
legend(""topleft"",legend=c(""h2o"",""keras""),col=c(2,4),lwd=2)



Now one thing you might notice is that the blue line is a scaled down version of the red line.
I manually tweaked the scale until it matched up, and the scaling factor was 3 * x in the horizontal direction and 6.45 * y - 1 in the vertical direction. Weird scaling but ok.


plot(x,y, main=""h2o model vs stretched keras model with h2o weights"" )
s <- seq(-10,10,by=0.01)
lines(s,predict$predict,col=2,lwd=2)

lines(3*s,6.45*predict2-1,col=4,lwd=2)
legend(""topleft"",legend=c(""h2o"",""keras""),col=c(2,4),lwd=2)





I tried the same process on a dummy classification task. I found that typically, the two lines wouldn't match up even under scaling.




# classification task

# generate binary classification data from the nonlinear function y_gen

x <- rnorm(10000,sd=2.6)
y_gen <-   20*dnorm(x,sd=1.2)*x #2*(0.6*x +0.2*sin(2*x)+0.1-0.01*x^3)

y <-vector(length=length(x))
for(i in 1:length(x)){
    y[i] <- sample(0:1,prob=c(exp(y_gen[i]),1),replace=TRUE)
}

y <- as.logical(y)
df <- data.frame(x=x,y=y)


# generate the h2o fit

h2odf <- as.h2o(df)


model <- h2o.deeplearning(x = 1, y = 2,
                    training_frame = h2odf,
                    hidden = c(100,10),
                    activation = ""Tanh"",
                    export_weights_and_biases = TRUE,
                    export_checkpoints_dir=getwd(),
                    verbose=TRUE)

newdf <- as.h2o(data.frame(x=seq(-10,10,by=0.01)))

predict <- as.data.frame(predict(model,newdf)[,3])
names(predict) <- ""y""

plot(x,1-exp(y_gen)/(1+exp(y_gen)),main=c(""h2o model vs keras model with h2o weights"",""classification test""))
lines(seq(-10,10,by=0.01),predict$y,col=2,lwd=2)


layers <- model@parameters$hidden
activation <- model@parameters$activation
weights <- list()

for(i in 1:(1+length(layers))){
    W <- as.matrix(h2o.weights(model,matrix_id=i))
    B <- as.array(as.vector(h2o.biases(model,vector_id=i)))
    colnames(W) <- NULL
    W <- t(W)

    
    if(i == 1+length(layers)){
        weights[[2*i-1]] <- as.matrix(W[,2])    # h2o output for a classification task is of length 2. value 1 is the negative probability, value 2 is the positive probability.
        weights[[2*i]] <- as.array(B[2])        # so here we only need one of them so we take only one of them
    } else {
        weights[[2*i-1]] <- W
        weights[[2*i]] <- B
    }   
}



# set up tensorflow

k_clear_session()
model2 <- keras_model_sequential()
model2 %>% layer_dense(units=layers[1],input_shape=1,activation=tolower(activation))

for(i in 2:(length(layers))){
    model2 %>% layer_dense(units = layers[i],
                    activation = tolower(activation))
}
                
model2 %>% layer_dense(name=""output"",units = 1,activation = ""sigmoid"")

set_weights(model2,weights)

predict2 <- predict(model2,as.matrix(newdf))

lines(seq(-10,10,by=0.01),predict2,col=4,lwd=2)
legend(""topleft"",legend=c(""h2o"",""keras""),col=c(2,4),lwd=2)



I suspect there is something funny with the way h2o sets up its activation layers
. H2o doesn't allow nearly as much 'under the hood' access as keras, so I've been so far unable to look at the inner goings on in the h2o model. For instance, how is h2o able to do regression on data that extends beyond (-1,1) with only tanh activation functions?


I've tried the above code with ReLu as well as Tanh, and I've tried altering the final layer of the keras model from tanh tanh to linear, to no avail.


My questions are:


How does the h2o model give different results to the Keras model even when the same weights are used? What goes on under the hood when h2o is performing a prediction?


and


is there any other basic mistake I made when attempting to convert the weights?","['r', 'tensorflow', 'keras', 'h2o']",Ingolifs,https://stackoverflow.com/users/8968617/ingolifs,301,"{'gold': None, 'silver': '', 'bronze': ''}"
71777142,71777142,2022-04-07T06:08:55,2022-04-26 12:33:26Z,156,"I would like to plot a loss vs epoch graph from a deep quantile regression model in H2O. I'm using the H2ODeepLearningEstimator but can't seem to find a way to retrieve the loss like in Keras.


https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/


Could somebody please point me in the right direction?","['python', 'h2o', 'h2o.ai']",mj_whales,https://stackoverflow.com/users/14039621/mj-whales,122,"{'gold': '', 'silver': '', 'bronze': ''}"
71741263,71741263,2022-04-04T17:19:22,2022-04-04 18:08:54Z,484,"I used H2O's automl on my dataset, and the top model is a stackedensemble model. I like to get all basemodels with it's parameters of this stacked model. How do I get this models?","['python', 'h2o']",seb2704,https://stackoverflow.com/users/5269959/seb2704,530,"{'gold': '', 'silver': '', 'bronze': ''}"
71693880,71693880,2022-03-31T14:00:33,2022-06-30 14:29:18Z,0,"I would like to use h2o in 
R
 for glm regression but with random effects (HGLM, seems possible from 
this page
 ). I do not manage to make it work yet, and get errors I do not understand.


Is here my working example: I define a dataset with Simpson paradox: a global increasing trend, but a decreasing trend in each group


library(tidyverse)
library(ggplot2)
library(h2o)
library(data.table)

global_slope <- 1
global_int <- 1

Npoints_per_group <- 50
N_groups <- 10
pentes <- rnorm(N_groups,-1,.5)

centers_x <- seq(0,10,length = N_groups)
center_y <- global_slope*centers_x + global_int

group_spread <- 2

group_names <- sample(LETTERS,N_groups)

df <- lapply(1:N_groups,function(i){
  x <- seq(centers_x[i]-group_spread/2,centers_x[i]+group_spread/2,length = Npoints_per_group)
  y <- pentes[i]*(x- centers_x[i])+center_y[i]+rnorm(Npoints_per_group)
  data.table(x = x,y = y,ID = group_names[i])
}) %>% rbindlist()



You can recognize something similar to the example of the 
wiki page of Simpson paradox
:


ggplot(df,aes(x,y,color = as.factor(ID)))+
  geom_point()





The linear regression without random effect sees the increasing trend:


lm(y~x,data = df) %>% 
summary()

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.28187    0.13077   9.803   <2e-16 ***
x            0.94147    0.02194  42.917   <2e-16 ***



A standard multilevel regression would look like that:


library(lme4)
library(lmerTest)

lmer( y ~ x + (1+x|ID) ,data = df) %>% 
  summary()



And would estimate properly a decreasing trend:


Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)    
(Intercept)  11.7192     2.6218  8.8220   4.470 0.001634 ** 
x            -1.0418     0.1959  8.9808  -5.318 0.000486 ***



Now I test with 
h2o
:


library(h2o)
h2o.init()

df2 <- as.h2o(df)
test_glm <- h2o.glm(family = ""gaussian"",
                        x = ""x"",
                        y = ""y"",
                        training_frame = df2,
                        lambda = 0,
                        compute_p_values = TRUE)
test_glm



And it works well, similar to the linear model above:


Coefficients: glm coefficients
      names coefficients std_error   z_value  p_value standardized_coefficients
1 Intercept     1.281868  0.130766  9.802785 0.000000                  5.989232
2         x     0.941473  0.021937 42.916536 0.000000                  3.058444



But when I want to use random effects:


test_glm2 <- h2o.glm(family = ""gaussian"",
                     x = ""x"",
                     y = ""y"",
                     training_frame = df2,
                     random_columns = ""ID"",
                     lambda = 0,
                     compute_p_values = TRUE)




I got




Error in .h2o.checkAndUnifyModelParameters(algo = algo, allParams = ALL_PARAMS, : vector of random_columns must be of type numeric, but got character.




Even if I force 
df2$ID  <- as.numeric(df2$ID)
.


What Am I doing wrong? What is the proper way to find something similar to the mixed effect model with 
lmer
 (i.e. random slope and intercept)?




EDIT


I changed to use, as suggested by Erin LeDell, the column number. I now get a different error, that I do not understand either:


df2$ID  <- as.factor(df2$ID)

test_glm2 <- h2o.glm(family = ""gaussian"",
                     x = ""x"",
                     y = ""y"",
                     training_frame = df2,
                     random_columns = c(3),
                     HGLM = TRUE,
                     lambda = 0,
                     compute_p_values = TRUE)

DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.NullPointerException

DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.NullPointerException
    at water.MRTask.getResult(MRTask.java:660)
    at water.MRTask.getResult(MRTask.java:670)
    at water.MRTask.doAll(MRTask.java:530)
    at water.MRTask.doAll(MRTask.java:482)
    at hex.glm.GLM$GLMDriver.fitCoeffs(GLM.java:1334)
    at hex.glm.GLM$GLMDriver.fitHGLM(GLM.java:1505)
    at hex.glm.GLM$GLMDriver.fitModel(GLM.java:2060)
    at hex.glm.GLM$GLMDriver.computeSubmodel(GLM.java:2526)
    at hex.glm.GLM$GLMDriver.doCompute(GLM.java:2664)
    at hex.glm.GLM$GLMDriver.computeImpl(GLM.java:2561)
    at hex.ModelBuilder$Driver.compute2(ModelBuilder.java:247)
    at hex.glm.GLM$GLMDriver.compute2(GLM.java:1188)
    at water.H2O$H2OCountedCompleter.compute(H2O.java:1658)
    at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)
    at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)
    at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)
    at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)
    at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)





Edit 2:


I actually found a way to remove the above error, by adding


rand_link = c(""identity""),
rand_family = c(""gaussian""),



to the 
h2o.glm
 arguments:


h2o.glm(family = ""gaussian"",
                     rand_link = c(""identity""),
                     rand_family = c(""gaussian""),
                     # compute_p_values = TRUE,
                     x = ""x"",
                     y = ""y"",
                     training_frame = df2,
                     random_columns = c(3),
                     HGLM = TRUE,
                     lambda = 0)



Works. But when I set 
compute_p_values = TRUE
, and then find a new error:



Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  : 
  

ERROR MESSAGE:

degrees of freedom (0)","['r', 'h2o', 'glm']",,https://stackoverflow.com/posts/71693880/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
71616995,71616995,2022-03-25T12:26:18,2022-03-25 20:41:20Z,0,"I am running Spark 2.4.4 using Yarn and interfacing using RSparkling and Sparklyr


As per 
these
 instructions I've




Installed Sparklyr


Called the library for Sparklyr


Removed any prior installs of H2O


Installed the latest version of H2O (rel-zorn)


Installed rsparkling 3.36.0.3-1-2.4


Called the library for rsparkling


Specified my spark_config()


Successfully made a connection to Spark using Yarn


Ran h2oConf <- H2OConf()




When I try to make a H2O context using the h2oConf above I get the following error:


Error in h2o.init(strict_version_check = FALSE, https = https, insecure = insecure,  : 
  unused argument (cacert = conf$sslCACert())



I've tried multiple different versions of RSparkling and H2O and have been unsuccessful connecting.


Is there some obvious step that I'm missing? Any suggestions would be greatly appreciated.


Solution:
Based on feedback from @Marek Novotny below I discovered that I had a reference to an old version of H2O in my namespace. Once I unloaded the package I was able to resolve this issue and moved on to the 
next","['r', 'rstudio', 'h2o', 'sparklyr', 'h2o.ai']",,https://stackoverflow.com/posts/71616995/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
71609592,71609592,2022-03-24T21:23:05,2022-03-25 12:19:19Z,0,"I am trying to get H2O working with Sparklyr on my spark cluster (yarn)


spark_version(sc) = 2.4.4

My spark cluster is running V2.4.4


According to 
this
 page the compatible version with my spark is 2.4.5 for Sparkling Water and the H2O release is rel-xu patch version 3. However when I install this version I am prompted to update my H2O install to the next release (REL-ZORN). Between the H2O guides and the sparklyr guides it's very confusing and contradictory at times.




Since this is a yarn deployment and not local, unfortunately I can't provide a repex to help with trobleshooting.


url <- ""http://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.4/5/sparkling-water-2.4.5.zip""

download.file(url = url,""sparkling-water-2.4.5.zip"")

unzip(""sparkling-water-2.4.5.zip"")

# RUN THESE CMDs FROM THE TERMINAL
cd sparkling-water-2.4.5
bin/sparkling-shell --conf ""spark.executor.memory=1g""

# RUN THESE FROM WITHIN RSTUDIO
install.packages(""sparklyr"")
library(sparklyr)

# REMOVE PRIOR INSTALLS OF H2O
detach(""package:rsparkling"", unload = TRUE)
if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload = TRUE) }
if (isNamespaceLoaded(""h2o"")){ unloadNamespace(""h2o"") }
remove.packages(""h2o"")

# INSTALLING REL-ZORN (3.36.0.3) WHICH IS REQUIRED FOR SPARKLING WATER 3.36.0.3
install.packages(""h2o"", type = ""source"", repos = ""https://h2o-release.s3.amazonaws.com/h2o/rel-zorn/3/R"")

# INSTALLING FROM S3 SINCE CRAN NO LONGER SUPPORTED
install.packages(""rsparkling"", type = ""source"", repos = ""http://h2o-release.s3.amazonaws.com/sparkling-water/spark-2.4/3.36.0.3-1-2.4/R"")

# AS PER THE GUIDE
options(rsparkling.sparklingwater.version = ""2.4.5"")
library(rsparkling)

# SPECIFY THE CONFIGURATION
config <- sparklyr::spark_config()
config[[""spark.yarn.queue""]] <- ""my_data_science_queue""
config[[""sparklyr.backend.timeout""]] <- 36000
config[[""spark.executor.cores""]] <- 32
config[[""spark.driver.cores""]] <- 32
config[[""spark.executor.memory""]] <- ""40g""
config[[""spark.executor.instances""]] <- 8
config[[""sparklyr.shell.driver-memory""]] <- ""16g""
config[[""spark.default.parallelism""]] <- ""8""
config[[""spark.rpc.message.maxSize""]] <- ""256""

# MAKE A SPARK CONNECTION
sc <- sparklyr::spark_connect(
  master = ""yarn"",
  spark_home = ""/opt/mapr/spark/spark"",
  config = config,
  log = ""console"",
  version = ""2.4.4""
)



When I try to establish a H2O context using the next chunk I get the following error


h2o_context(sc)

Error in h2o_context(sc) : could not find function ""h2o_context""



Any pointers as to where I'm going wrong would be greatly appreciated.","['r', 'apache-spark', 'h2o', 'sparklyr']",Phil,https://stackoverflow.com/posts/71609592/revisions,"8,052","{'gold': '', 'silver': '', 'bronze': ''}"
71587437,71587437,2022-03-23T12:42:50,2022-03-23 12:42:50Z,0,"when running h2o.init() (using the latest package version) from r, it is creating libxgboost4j_gpu*.so files within temp directory which take significant amount of space and pile up (when run several times). Does anyone know how to stop this?","['r', 'h2o', 'temp']",martin_hulin,https://stackoverflow.com/users/14849337/martin-hulin,43,"{'gold': None, 'silver': None, 'bronze': ''}"
71529386,71529386,2022-03-18T15:26:31,2022-09-09 01:15:54Z,660,"I am currently trying to use H2O from Python, and I encounter some problems on my Mac OS with XGBoost.
It seems like H2O does not find it anywhere.


More precisely, the next simple snippet


import pandas as pd
import h2o

data = [['2015-01-01', '2490.925806' , '-0.41'],
        ['2015-01-02', '2412.623113' , '-0.48'],
        ['2015-01-03', '2365.611276' , '-0.55']]
df = pd.DataFrame(data, columns=[""time"", ""base"", ""target""]).set_index(""time"", drop=True)

h2o.init(nthreads=-1)
estimator = h2o.estimators.H2OXGBoostEstimator()
training_frame = h2o.H2OFrame(df) 
estimator.train([""base""], ""target"", training_frame)



gives me the error :


H2OResponseError: Server error water.exceptions.H2ONotFoundArgumentException:
  Error: POST /3/ModelBuilders/xgboost not found
  Request: POST /3/ModelBuilders/xgboost
    data: {'training_frame': 'Key_Frame__upload_893634781f588299bbd20d51c98d43a9.hex', 'nfolds': '0', 'keep_cross_validation_models': 'True', 'keep_cross_validation_predictions': 'False', 'keep_cross_validation_fold_assignment': 'False', 'score_each_iteration': 'False', 'fold_assignment': 'auto', 'response_column': 'target', 'ignore_const_cols': 'True', 'stopping_rounds': '0', 'stopping_metric': 'auto', 'stopping_tolerance': '0.001', 'max_runtime_secs': '0.0', 'seed': '-1', 'distribution': 'auto', 'tweedie_power': '1.5', 'categorical_encoding': 'auto', 'quiet_mode': 'True', 'ntrees': '50', 'max_depth': '6', 'min_rows': '1.0', 'min_child_weight': '1.0', 'learn_rate': '0.3', 'eta': '0.3', 'sample_rate': '1.0', 'subsample': '1.0', 'col_sample_rate': '1.0', 'colsample_bylevel': '1.0', 'col_sample_rate_per_tree': '1.0', 'colsample_bytree': '1.0', 'colsample_bynode': '1.0', 'max_abs_leafnode_pred': '0.0', 'max_delta_step': '0.0', 'score_tree_interval': '0', 'min_split_improvement': '0.0', 'gamma': '0.0', 'nthread': '-1', 'build_tree_one_node': 'False', 'calibrate_model': 'False', 'max_bins': '256', 'max_leaves': '0', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': '0.0', 'one_drop': 'False', 'skip_drop': '0.0', 'tree_method': 'auto', 'grow_policy': 'depthwise', 'booster': 'gbtree', 'reg_lambda': '1.0', 'reg_alpha': '0.0', 'dmatrix_type': 'auto', 'backend': 'auto', 'gainslift_bins': '-1', 'auc_type': 'auto', 'scale_pos_weight': '1.0'}



For more information about my distribution:




OS: Monterey 12.3


Processor: Apple M1


Python: 3.9.10


H2O: 3.36.0.3




I suspect Apple M1 to be the cause of the error, but is that really the case ?","['xgboost', 'h2o', 'apple-m1']",Clej,https://stackoverflow.com/users/11963167/clej,466,"{'gold': None, 'silver': '', 'bronze': ''}"
71412682,71412682,2022-03-09T16:24:41,2022-03-09 16:24:41Z,0,"I have been trying to replicate the results from cross-validation from 
h2o
 by hand, but I'm puzzled on why the results are different. In my understanding, if a 
fold_column
 is specified, then cross-validation happens according to the groups defined within that column. Therefore, for fold 1, the model should train on folds 2, 3, 4 and 5.


set.seed(1)
iris$fold <- sample(1:5, nrow(iris), replace = TRUE)

fit_cv <- h2o.glm(x = c(""Species"", ""Petal.Width"", ""Petal.Length""),
                  y = c(""Sepal.Length""),
                  training_frame = as.h2o(iris),
                  fold_column = ""fold"", 
                  alpha = 0.2, lambda = 0.1, seed=1,
                  keep_cross_validation_models = TRUE)



This outputs for fold 1 a training MAE of:


fit_fold1 <-  h2o.cross_validation_models(fit_cv)[[1]]

> fit_fold1@model$training_metrics@metrics$mae
[1] 0.3035526



However, if fitted by hand, the training MAE is (slightly) different:


dd_fold1_fit <- iris[iris$fold != 1,]

fit_fold1_direct <- h2o.glm(x = c(""Species"", ""Petal.Width"", ""Petal.Length""),
                                y = c(""Sepal.Length""),
                                training_frame = as.h2o(dd_fold1_fit),
                                alpha = 0.2, lambda = 0.1, 
                                seed=1)
    
fit_fold1_direct@model$training_metrics@metrics$mae
[1] 0.3004132



This is a minimal example, the issue is that with real data that I am working with the difference is larger, and I can't replicate the cross-validation results.


Any idea on what the explanation could be?","['r', 'h2o']",Theodor,https://stackoverflow.com/users/2236837/theodor,"1,016","{'gold': '', 'silver': '', 'bronze': ''}"
71172747,71172747,2022-02-18T11:30:19,2022-02-23 13:57:32Z,95,"I configured h2o application to use openLDAP configuration referring to the link:

https://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/tutorials/ldap.html

Added userNameAttribute=uid to ovreride 'cn' to use 'uid' field instead.


However it is not working. The query getting passed on LDAP still has cn=user_id instead of uid=user_id.


Am I doing something wrong or is a bug?


ldap.conf:


    ai.h2o.org.eclipse.jetty.plus.jaas.spi.LdapLoginModule required
    debug=""true""
    useLdaps=""true""
    contextFactory=""com.sun.jndi.ldap.LdapCtxFactory""
    hostname=""ldap.h2o.ai""
    port=""389""
    bindDn=""cn=admin,dc=h2o,dc=ai""
    bindPassword=""h2o""
    authenticationMethod=""simple""
    forceBindingLogin=""true""
    userBaseDn=""ou=users,dc=h2o,dc=ai""
    userNameAttribute=""uid"";
};```","['ldap', 'h2o', 'openldap']",Pankaj Mahadik,https://stackoverflow.com/users/16570951/pankaj-mahadik,31,"{'gold': None, 'silver': None, 'bronze': ''}"
71146238,71146238,2022-02-16T17:07:49,2022-02-17 00:02:39Z,156,"We use XGBoost model for regression prediction model, We use XGBoost as grid search hyper parameter tuning process,


We run this model on 90GB h2o cluster. This process now running over 1.2 years, but suddenly this process stop due to ""Closing connection _sid_af1c at exit""


Training data set is 800 000, due to this error we decreased it to 500 000 but same error occurred.


ntrees - 300,400


depth - 8.10


variables - 382


I have attached H2o memory log and our application error log. Could you please support to fixed this issue.


----------------------------------------H2o Log [Start]----------------------

**We start H2o as 2 node cluster, but h2o log crated on one node.** 

INFO water.default: ----- H2O started  -----
INFO water.default: Build git branch: master
INFO water.default: Build git hash: 0588cccd72a7dc1274a83c30c4ae4161b92d9911
INFO water.default: Build git describe: jenkins-master-5236-4-g0588ccc
INFO water.default: Build project version: 3.33.0.5237
INFO water.default: Build age: 1 year, 3 months and 17 days
INFO water.default: Built by: 'jenkins'
INFO water.default: Built on: '2020-10-27 19:21:29'
WARN water.default: 
WARN water.default: *** Your H2O version is too old! Please download the latest version from http://h2o.ai/download/ ***
WARN water.default: 
INFO water.default: Found H2O Core extensions: [XGBoost, KrbStandalone]
INFO water.default: Processed H2O arguments: [-flatfile, /usr/local/h2o/flatfile.txt, -port, 54321]
INFO water.default: Java availableProcessors: 20
INFO water.default: Java heap totalMemory: 962.5 MB
INFO water.default: Java heap maxMemory: 42.67 GB
INFO water.default: Java version: Java 1.8.0_262 (from Oracle Corporation)
INFO water.default: JVM launch parameters: [-Xmx48g]
INFO water.default: JVM process id: 
[emailÂ protected]

INFO water.default: OS version: Linux 3.10.0-1127.10.1.el7.x86_64 (amd64)
INFO water.default: Machine physical memory: 62.74 GB
INFO water.default: Machine locale: en_US
INFO water.default: X-h2o-cluster-id: 1644769990156
INFO water.default: User name: 'root'
INFO water.default: IPv6 stack selected: false
INFO water.default: Possible IP Address: ens192 (ens192), xxxxxxxxxxxxxxxxxxxx
INFO water.default: Possible IP Address: ens192 (ens192), xxxxxxxxxxx
INFO water.default: Possible IP Address: lo (lo), 0:0:0:0:0:0:0:1%lo
INFO water.default: Possible IP Address: lo (lo), 127.0.0.1
INFO water.default: H2O node running in unencrypted mode.
INFO water.default: Internal communication uses port: 54322
INFO water.default: Listening for HTTP and REST traffic on http://xxxxxxxxxxxx:54321/
INFO water.default: H2O cloud name: 'root' on /xxxxxxxxxxxx:54321, discovery address /xxxxxxxxxxxx:57653
INFO water.default: If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):
INFO water.default:   1. Open a terminal and run 'ssh -L 55555:localhost:54321 root@xxxxxxxxxxxx'
INFO water.default:   2. Point your browser to http://localhost:55555
INFO water.default: Log dir: '/tmp/h2o-root/h2ologs'
INFO water.default: Cur dir: '/usr/local/h2o/h2o-3.33.0.5237'
INFO water.default: Subsystem for distributed import from HTTP/HTTPS successfully initialized
INFO water.default: HDFS subsystem successfully initialized
INFO water.default: S3 subsystem successfully initialized
INFO water.default: GCS subsystem successfully initialized
INFO water.default: Flow dir: '/root/h2oflows'
INFO water.default: Cloud of size 1 formed [/xxxxxxxxxxxx:54321]
INFO water.default: Registered parsers: [GUESS, ARFF, XLS, SVMLight, AVRO, PARQUET, CSV]
INFO water.default: XGBoost extension initialized
INFO water.default: KrbStandalone extension initialized
INFO water.default: Registered 2 core extensions in: 2632ms
INFO water.default: Registered H2O core extensions: [XGBoost, KrbStandalone]
INFO hex.tree.xgboost.XGBoostExtension: Found XGBoost backend with library: xgboost4j_gpu
INFO hex.tree.xgboost.XGBoostExtension: XGBoost supported backends: [WITH_GPU, WITH_OMP]
INFO water.default: Registered: 217 REST APIs in: 353ms
INFO water.default: Registered REST API extensions: [Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4]
INFO water.default: Registered: 291 schemas in 112ms
INFO water.default: H2O started in 4612ms
INFO water.default: 
INFO water.default: Open H2O Flow in your web browser: http://xxxxxxxxxxxx:54321
INFO water.default: 
INFO water.default: Cloud of size 2 formed [mastera.xxxxxxxxxxxx.com/xxxxxxxxxxxx:54321, masterb.xxxxxxxxxxxx.com/xxxxxxxxxxxx:54321]
INFO water.default: Locking cloud to new members, because water.rapids.Session$1
INFO hex.tree.xgboost.task.XGBoostUpdater: Initial Booster created, size=448
ERROR water.default: Got IO error when sending a batch of bytes: 
java.io.IOException: Connection reset by peer
    at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
    at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
    at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
    at sun.nio.ch.IOUtil.write(IOUtil.java:51)
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:468)
    at water.H2ONode$SmallMessagesSendThread.sendBuffer(H2ONode.java:605)
    at water.H2ONode$SmallMessagesSendThread.run(H2ONode.java:588)
----------------------------------------H2o Log [End]--------------------------------

----------------------------------------Application Log [Start]----------------------
Checking whether there is an H2O instance running at http://localhost:54321 . connected.
Warning: Your H2O cluster version is too old (1 year, 3 months and 17 days)! Please download and install the latest version from http://h2o.ai/download/
--------------------------  ------------------------------------------------------------------
H2O_cluster_uptime:         19 mins 49 secs
H2O_cluster_timezone:       Asia/Colombo
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.33.0.5237
H2O_cluster_version_age:    1 year, 3 months and 17 days !!!
H2O_cluster_name:           root
H2O_cluster_total_nodes:    2
H2O_cluster_free_memory:    84.1 Gb
H2O_cluster_total_cores:    40
H2O_cluster_allowed_cores:  40
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://localhost:54321
H2O_connection_proxy:       {""http"": null, ""https"": null}
H2O_internal_security:      False
H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4
Python_version:             3.7.0 final
--------------------------  ------------------------------------------------------------------
--------------------------  ------------------------------------------------------------------
H2O_cluster_uptime:         19 mins 49 secs
H2O_cluster_timezone:       Asia/Colombo
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.33.0.5237
H2O_cluster_version_age:    1 year, 3 months and 17 days !!!
H2O_cluster_name:           root
H2O_cluster_total_nodes:    2
H2O_cluster_free_memory:    84.1 Gb
H2O_cluster_total_cores:    40
H2O_cluster_allowed_cores:  40
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://localhost:54321
H2O_connection_proxy:       {""http"": null, ""https"": null}
H2O_internal_security:      False
H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4
Python_version:             3.7.0 final
--------------------------  ------------------------------------------------------------------
release memory here...
Checking whether there is an H2O instance running at http://localhost:54321 . connected.
Warning: Your H2O cluster version is too old (1 year, 3 months and 17 days)! Please download and install the latest version from http://h2o.ai/download/
--------------------------  ------------------------------------------------------------------
H2O_cluster_uptime:         19 mins 49 secs
H2O_cluster_timezone:       Asia/Colombo
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.33.0.5237
H2O_cluster_version_age:    1 year, 3 months and 17 days !!!
H2O_cluster_name:           root
H2O_cluster_total_nodes:    2
H2O_cluster_free_memory:    84.1 Gb
H2O_cluster_total_cores:    40
H2O_cluster_allowed_cores:  40
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://localhost:54321
H2O_connection_proxy:       {""http"": null, ""https"": null}
H2O_internal_security:      False
H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4
Python_version:             3.7.0 final
--------------------------  ------------------------------------------------------------------
Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%
xgboost Grid Build progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆClosing connection _sid_af1c at exit
H2O session _sid_af1c was not closed properly.
Closing connection _sid_9313 at exit
H2O session _sid_9313 was not closed properly.
----------------------------------------Application Log [End]----------------------","['machine-learning', 'artificial-intelligence', 'xgboost', 'h2o']",James Z,https://stackoverflow.com/posts/71146238/revisions,12.3k,"{'gold': '', 'silver': '', 'bronze': ''}"
71138526,71138526,2022-02-16T08:38:17,2022-02-16 23:54:28Z,278,"I am using h2o autoML on python.


I used the autoML part to find the best model possible: it is a StackedEnsemble.


Now I would like to take the model and retrain it on a bigger dataset (which was not possible before because I would explode the google colab free RAM capacity).


But AutoML does some preprocessing to my data and I don't know which one.


How can I get the preprocessing steps to re-apply it to my bigger data before feeding it to the model ?


Thanks in advance,


Gab","['python', 'google-colaboratory', 'h2o', 'automl', 'data-preprocessing']",Gabiboubibel,https://stackoverflow.com/users/13354125/gabiboubibel,75,"{'gold': None, 'silver': None, 'bronze': ''}"
71093974,71093974,2022-02-12T16:58:15,2022-02-17 00:06:57Z,0,"I have just computed a gamma GLM with the h2o package in R.


When I'm trying to predict on the test set I get this error:




Illegal argument(s) for GLM model: GLM_model_R_1644680218230_95. Details: ERRR on field: _family: Response value for gamma distribution must be greater than 0.




I understand that a gamma model cannot be trained on data with zero response, but one should be able to predict on data with a true value 0 (this is used a a lot in actuaries).


Does any one know a h2o solution? I know I can simply make the model with glm() or something similar, but I'm relying on mean encoded categorical variables (which is really convenient in h2o).


Thanks!","['r', 'h2o', 'glm', 'glmnet']",marc_s,https://stackoverflow.com/posts/71093974/revisions,752k,"{'gold': '', 'silver': '', 'bronze': ''}"
71081912,71081912,2022-02-11T14:41:22,2022-02-16 23:46:43Z,0,"I am running a randomForest model using h2o in R. The exercise is a binary classification problem in which I have approx. 5x as many â€˜1â€™s as â€˜0â€™s.


Because the dataset is a time series (approx. 50k observations), I am using a growing window validation scheme as opposed to the typical CV schemes used in most ML cases. For each step I train the model on 60% of the data available up to that time point and then hold out the remaining 40% to be split equally between the validation frame and the testing data.


I am getting extremely poor performance in both my hold out validation data and test data which suggests that I am overfitting to the training dataset. If anyone can spot any obvious, glaring errors in how I am setting up my model and the hyper parameter search Iâ€™d really appreciate some pointers. It may be that I simply have in sufficient number of features (n = 27) to adequately capture the response, but I would like to rule out incorrect model specification first.


Here is the specification of my model and the hyper-parameter grid search.


# create feature names
y <- ""Response""
x <- setdiff(names(gwWF1_train[, -c(1:3)]), y)

# turn training set into h2o object
gwWF1_train.h2o <- as.h2o(gwWF1_train[, -c(1:3)])

# turn validation set into h2o object
gwWF1_valid.h2o <- as.h2o(gwWF1_valid[, -c(1:3)])

# hyperparameter grid
hyper_grid.h2o <- list(
  ntrees      = seq(50, 1000, by = 50),
  mtries      = seq(2, 10, by = 1),
  max_depth   = seq(2, 10, by = 1),
  min_rows    = seq(5, 15, by = 1),
  nbins       = seq(5, 40, by = 5),
  sample_rate = c(.55, .632, .75)
)

# random grid search criteria
search_criteria <- list(
  strategy = ""RandomDiscrete"",
  stopping_metric = ""auc"",
  stopping_tolerance = 0.005,
  stopping_rounds = 20,
  max_runtime_secs = 5*60
  )

# build grid search 
random_grid <- h2o.grid(
  algorithm = ""randomForest"",
  grid_id = ""rf_grid"",
  x = x, 
  y = y, 
  seed = 29,
  balance_classes = TRUE,
  training_frame = gwWF1_train.h2o,
  validation_frame = gwWF1_valid.h2o,
  hyper_params = hyper_grid.h2o,
  search_criteria = search_criteria
  )
  
# collect the results and sort by our model performance metric of choice
grid_perf <- h2o.getGrid(
  grid_id = ""rf_grid"", 
  sort_by = ""auc"", 
  decreasing = TRUE
  )
print(grid_perf)



Here is the performance on the training and validation frames


Model Details:
==============

H2OBinomialModel: drf
Model ID:  rf_grid_model_14 
Model Summary: 
  number_of_trees number_of_internal_trees model_size_in_bytes min_depth max_depth mean_depth min_leaves max_leaves mean_leaves
1             100                      100              224183        10        10   10.00000         99        272   173.86000


H2OBinomialMetrics: drf
** Reported on training data. **
** Metrics reported on Out-Of-Bag training samples **

MSE:  0.1154841
RMSE:  0.3398295
LogLoss:  0.3836627
Mean Per-Class Error:  0.3434005
AUC:  0.716039
AUCPR:  0.3877677
Gini:  0.432078
R^2:  0.08126146

Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
           0    1    Error         Rate
0      12089 2009 0.142502  =2009/14098
1       1327 1111 0.544299   =1327/2438
Totals 13416 3120 0.201742  =3336/16536

Maximum Metrics: Maximum metrics at their respective thresholds
                        metric threshold        value idx
1                       max f1  0.182031     0.399784 175
2                       max f2  0.133141     0.498254 264
3                 max f0point5  0.229674     0.437443 119
4                 max accuracy  0.263718     0.863147  94
5                max precision  0.705162     1.000000   0
6                   max recall  0.019641     1.000000 396
7              max specificity  0.705162     1.000000   0
8             max absolute_mcc  0.209525     0.298843 139
9   max min_per_class_accuracy  0.153280     0.651354 225
10 max mean_per_class_accuracy  0.174269     0.661033 188
11                     max tns  0.705162 14098.000000   0
12                     max fns  0.705162  2437.000000   0
13                     max fps  0.010717 14098.000000 399
14                     max tps  0.019641  2438.000000 396
15                     max tnr  0.705162     1.000000   0
16                     max fnr  0.705162     0.999590   0
17                     max fpr  0.010717     1.000000 399
18                     max tpr  0.019641     1.000000 396

Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`
H2OBinomialMetrics: drf
** Reported on validation data. **

MSE:  0.1340771
RMSE:  0.3661654
LogLoss:  0.4422115
Mean Per-Class Error:  0.5
AUC:  0.5295048
AUCPR:  0.1770512
Gini:  0.05900952
R^2:  -0.006636504

Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
       0     1    Error          Rate
0      0 13220 1.000000  =13220/13220
1      0  2485 0.000000       =0/2485
Totals 0 15705 0.841770  =13220/15705

Maximum Metrics: Maximum metrics at their respective thresholds
                        metric threshold        value idx
1                       max f1  0.025167     0.273227 399
2                       max f2  0.025167     0.484500 399
3                 max f0point5  0.161209     0.203459 140
4                 max accuracy  0.291947     0.841770   1
5                max precision  0.291947     0.500000   1
6                   max recall  0.025167     1.000000 399
7              max specificity  0.302964     0.999924   0
8             max absolute_mcc  0.178262     0.056716 103
9   max min_per_class_accuracy  0.133292     0.525553 215
10 max mean_per_class_accuracy  0.140828     0.529093 195
11                     max tns  0.302964 13219.000000   0
12                     max fns  0.302964  2485.000000   0
13                     max fps  0.030503 13220.000000 398
14                     max tps  0.025167  2485.000000 399
15                     max tnr  0.302964     0.999924   0
16                     max fnr  0.302964     1.000000   0
17                     max fpr  0.030503     1.000000 398
18                     max tpr  0.025167     1.000000 399

Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`



And here is the performance on the testing data


H2OBinomialMetrics: drf

MSE:  0.1293883
RMSE:  0.3597059
LogLoss:  0.4274263
Mean Per-Class Error:  0.4719334
AUC:  0.530868
AUCPR:  0.1588326
Gini:  0.06173602
R^2:  -0.001929629

Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
          0     1    Error          Rate
0      4321 12888 0.748910  =12888/17209
1       603  2490 0.194956     =603/3093
Totals 4924 15378 0.664516  =13491/20302

Maximum Metrics: Maximum metrics at their respective thresholds
                        metric threshold        value idx
1                       max f1  0.128344     0.269612 283
2                       max f2  0.084278     0.473644 380
3                 max f0point5  0.140284     0.194700 248
4                 max accuracy  0.313605     0.847601   1
5                max precision  0.313605     0.333333   1
6                   max recall  0.050387     1.000000 399
7              max specificity  0.316369     0.999884   0
8             max absolute_mcc  0.128344     0.047063 283
9   max min_per_class_accuracy  0.152158     0.522793 210
10 max mean_per_class_accuracy  0.140284     0.531315 248
11                     max tns  0.316369 17207.000000   0
12                     max fns  0.316369  3093.000000   0
13                     max fps  0.062918 17209.000000 398
14                     max tps  0.050387  3093.000000 399
15                     max tnr  0.316369     0.999884   0
16                     max fnr  0.316369     1.000000   0
17                     max fpr  0.062918     1.000000 398
18                     max tpr  0.050387     1.000000 399

Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`","['r', 'machine-learning', 'random-forest', 'h2o']",DaveTheRave,https://stackoverflow.com/users/12774843/davetherave,77,"{'gold': None, 'silver': '', 'bronze': ''}"
71068729,71068729,2022-02-10T16:27:26,2022-02-10 17:39:03Z,0,"I want to make sure the weights_column arguments in h2o.glm() is the same as the weights argument in glm(). To compare, I am looking at the rmse of both models using the Seatbelts dataset in R. I don't think a weight is needed in this model, but for the sake of demonstration I added one.


head(Seatbelts)

Seatbelts<-Seatbelts[complete.cases(Seatbelts),]

## 75% of the sample size
smp_size <- floor(0.75 * nrow(Seatbelts))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(Seatbelts)), size = smp_size)

train <- Seatbelts[train_ind, ]
test <- Seatbelts[-train_ind, ]

# glm()
m1 <- glm(DriversKilled  ~  front + rear + kms + PetrolPrice + VanKilled + law,
          family=poisson(link = ""log""),
          weights = drivers,
          data=train)

pred <- predict(m1, test)
RMSE(pred = pred, obs = test$DriversKilled)



The rmse is 120.5797.


# h2o.glm()
library(h2o)
h2o.init()

train <- as.h2o(train)
test <- as.h2o(test)
m2 <- h2o.glm(x = c(""front"", ""rear"", ""kms"", ""PetrolPrice"", ""VanKilled"", ""law""),
                 y = ""DriversKilled"",
                 training_frame = train,
                 family = 'poisson',
                 link = 'log',
                 lambda = 0,
                 weights_column = ""drivers"")

# performance metrics on test data
h2o.performance(m2, test)



The rmse is 18.65627. Why do these models have such different rmse? Am I using the weights_column argument in h2o.glm() incorrectly?","['r', 'h2o', 'glm']",,https://stackoverflow.com/posts/71068729/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
71063715,71063715,2022-02-10T10:46:21,2022-02-16 23:34:54Z,0,"So I'm about to write my master thesis, and doing some data modelling/scoring in R, where I have some issues. I have been given a ReadMe file to follow with older versions of R, but did not seem to work, and therefore I have tried to update R and the code for it. But I have never modelled with h2o in R, and it makes an error when I try to loadmodel from the given code of the author. Can anyone help me with a solution?


I run this code:
w2v_model <- h2o.loadModel(w2v_fname)


which results in this error:
ERROR: Unexpected HTTP Status code: 400 Bad Request (url = http://localhost:54321/99/Models.bin/)


java.lang.IllegalArgumentException
[1] ""java.lang.IllegalArgumentException: Found version 3.10.4.6, but running version 3.36.0.2\n\nFor more information visit:\n  
http://jira.h2o.ai/browse/TN-14""

[2] ""    water.AutoBuffer.checkVersion(AutoBuffer.java:296)""

[3] ""    water.AutoBuffer.(AutoBuffer.java:277)""

[4] ""    water.AutoBuffer.(AutoBuffer.java:257)""

[5] ""    hex.Model.importBinaryModel(Model.java:3192)""

[6] ""    water.api.ModelsHandler.importModel(ModelsHandler.java:250)""

[7] ""    java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)""

[8] ""    java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)""

[9] ""    java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)""

[10] ""    java.base/java.lang.reflect.Method.invoke(Method.java:568)""

[11] ""    water.api.Handler.handle(Handler.java:60)""

[12] ""    water.api.RequestServer.serve(RequestServer.java:470)""

[13] ""    water.api.RequestServer.doGeneric(RequestServer.java:301)""

[14] ""    water.api.RequestServer.doPost(RequestServer.java:227)""

[15] ""    javax.servlet.http.HttpServlet.service(HttpServlet.java:707)""

[16] ""    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)""

[17] ""    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)""

[18] ""    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:535)""

[19] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)""

[20] ""    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)""

[21] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)""

[22] ""    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)""

[23] ""    org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)""

[24] ""    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)""

[25] ""    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)""

[26] ""    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)""

[27] ""    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)""

[28] ""    water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)""

[29] ""    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)""

[30] ""    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)""

[31] ""    org.eclipse.jetty.server.Server.handle(Server.java:531)""

[32] ""    org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)""

[33] ""    org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)""

[34] ""    org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)""

[35] ""    org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)""

[36] ""    org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)""

[37] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)""

[38] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)""

[39] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)""

[40] ""    org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)""

[41] ""    org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)""

[42] ""    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)""

[43] ""    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)""

[44] ""    java.base/java.lang.Thread.run(Thread.java:833)""


Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  :


ERROR MESSAGE:


Found version 3.10.4.6, but running version 3.36.0.2


For more information visit:

http://jira.h2o.ai/browse/TN-14


Thanks in advance.","['r', 'h2o']",Super Kai - Kazuya Ito,https://stackoverflow.com/posts/71063715/revisions,1,"{'gold': None, 'silver': None, 'bronze': None}"
70759860,70759860,2022-01-18T17:26:35,2022-02-17 00:05:26Z,106,"I have a requirement to add new algorithms built in Python/Java to H2O and making it available in Flow UI. I have not found much information other than these old posts




https://groups.google.com/g/h2ostream/c/lFXdizcgemE?pli=1


https://www.h2o.ai/blog/hacking-algorithms-into-h2o-quantiles/




Please let me know if there is a way to do it. I don't think these articles are still relevant. Thanks in advance!",['h2o'],python dev,https://stackoverflow.com/users/2020301/python-dev,219,"{'gold': '', 'silver': '', 'bronze': ''}"
70721119,70721119,2022-01-15T11:47:31,2022-01-17 06:22:36Z,190,"Is the H2OModelSelectionEstimator deprecated? When I run the code


from h2o.estimators import H2OModelSelectionEstimator



I get the message: ImportError: cannot import name 'H2OModelSelectionEstimator' from 'h2o.estimators'","['python', 'h2o', 'glm']",lostwanderer,https://stackoverflow.com/users/12029329/lostwanderer,163,"{'gold': '', 'silver': '', 'bronze': ''}"
70637288,70637288,2022-01-08T23:33:47,2023-07-13 18:03:24Z,111,"I see Snowflake has a partner connect through which I could activate the H2O Driverless AI and access Snowflake from there.
I also see that H2O Driverless AI can be independently deployed on any cloud cluster, by we managing our own cluster instances.


How are both the clusters in above different?
In the H2O Driverless AI activated through the partner connect from Snowflake, don't we not require to manage the instances of H2O Driverless AI, so are we charged accordingly for that?


In the H2O Driverless AI deployed on our own Cloud cluster instances, is it the licensed version of H2O Driverless AI that we deploy and manage? Also, can we deploy the H2O-3(h2o flow) on these instances for building using h20 python packages, since i don't see any notebooks on Driverless AI for developing from ground-up?","['h2o', 'driverless-ai', 'h2o.ai']",topchef,https://stackoverflow.com/posts/70637288/revisions,19.8k,"{'gold': '', 'silver': '', 'bronze': ''}"
70622044,70622044,2022-01-07T13:35:43,2022-01-12 08:48:55Z,72,"h2o version: h2o-3.34.0.3 (rel-zizler)


Java version: openjdk version ""15.0.2"" 2021-01-19
(installed  with: 
FROM adoptopenjdk:15-jre-openj9-focal
)


I want to build an XGBoost model using Java 15, but the same code with the same data which runs without issues on Java 14 (openjdk version ""14.0.2"" 2020-07-14) fails on Java 15, producing the following error messages:


water.exceptions.H2OIllegalArgumentException: Illegal argument: o of function: IcedWrapper: 
    at water.IcedWrapper.<init>(IcedWrapper.java:152) ~[h2o.jar:?]
    at water.util.TwoDimTable.set(TwoDimTable.java:254) ~[h2o.jar:?]
    at water.util.ReproducibilityInformationUtils.createNodeInformationTable(ReproducibilityInformationUtils.java:72) ~[h2o.jar:?]
    at hex.Model$Output.createReproducibilityInformationTable(Model.java:1199) ~[h2o.jar:?]
    at hex.Model$Output.<init>(Model.java:991) ~[h2o.jar:?]
    at hex.Model$Output.<init>(Model.java:973) ~[h2o.jar:?]
    at hex.tree.xgboost.XGBoostOutput.<init>(XGBoostOutput.java:16) ~[h2o.jar:?]
    at hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:419) ~[h2o.jar:?]
    at hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:393) ~[h2o.jar:?]
    at hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:379) ~[h2o.jar:?]
    at hex.ModelBuilder$Driver.compute2(ModelBuilder.java:246) ~[h2o.jar:?]
    at water.H2O$H2OCountedCompleter.compute(H2O.java:1652) ~[h2o.jar:?]
    at jsr166y.CountedCompleter.exec(CountedCompleter.java:468) ~[h2o.jar:?]
    at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263) [h2o.jar:?]
    at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974) [h2o.jar:?]
    at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477) [h2o.jar:?]
    at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104) [h2o.jar:?] 



I launch the h2o server with the following command:


ENTRYPOINT /bin/bash -c ""cd h2o && java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -XshowSettings:vm -jar h2o.jar


Has anyone came across with similar issues? It looks like a version incompatibility to me, but based on a comment from this, h2o should support Java 15 from version 3.32.1.1 and up.

Running H2O with Java 16 on R","['java', 'xgboost', 'h2o']",,https://stackoverflow.com/posts/70622044/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
70597370,70597370,2022-01-05T17:49:20,2022-01-06 14:54:28Z,0,"Using the h2o package for R, I created a set of base models using AutoML with StackedEnsemble's disabled. Thus, the set of models only contains the base models that AutoML generates by default (GLM, GBM, XGBoost, DeepLearning, and DRF). Using these base models I was able to successfully train a default stacked ensemble manually using the h2o.stackedEnsemble function (i.e., a GLM with default params). I exported the model as a MOJO, shutdown the H2O cluster, restarted R, initialized a new H2O cluster, imported the stacked ensemble MOJO, and successfully generated predictions on a new validation set.


So far so good.


Next, I did the exact same thing following the exact same process, but this time I made one change: I trained the stacked ensemble 
with all pairwise interactions between the base models
. The interactions were created automatically by feeding a list of the base model Ids to the interaction metalearner_parameter. The model appeared to train without issue and (as I described above) was able to export it as a MOJO, restart the h2o cluster, restart R, and import the MOJO. However, when I attempt to generate predictions on the same validation set I used above I get the following error:


DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.ArrayIndexOutOfBoundsException

DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.ArrayIndexOutOfBoundsException
    at water.MRTask.getResult(MRTask.java:660)
    at water.MRTask.getResult(MRTask.java:670)
    at water.MRTask.doAll(MRTask.java:530)
    at water.MRTask.doAll(MRTask.java:549)
    at hex.Model.predictScoreImpl(Model.java:2057)
    at hex.generic.GenericModel.predictScoreImpl(GenericModel.java:127)
    at hex.Model.score(Model.java:1896)
    at water.api.ModelMetricsHandler$1.compute2(ModelMetricsHandler.java:491)
    at water.H2O$H2OCountedCompleter.compute(H2O.java:1658)
    at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)
    at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)
    at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)
    at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)
    at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)
Caused by: java.lang.ArrayIndexOutOfBoundsException

Error: DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.ArrayIndexOutOfBoundsException



When I exported the stacked ensemble with interactions as a MOJO I also exported it as a binary. When I instead import the binary for the stacked ensemble with interactions it is able to generate predictions on the validation set without error.


I'm running R 4.1.2 and this was all done using h2o_3.36.0.1


Does anyone have any suggestions for resolving this issue?


EDIT (more info): The datasets used to train and validate the model all contain continuous predictors and targets, so I do not believe this is related to one-hot encoding as might be the case for others getting this error.","['r', 'h2o', 'glm']",,https://stackoverflow.com/posts/70597370/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
70471661,70471661,2021-12-24T09:57:18,2022-01-27 18:28:01Z,71,"I am implementing my own algorithm in H2O's Java source code (under package 
h2o-algos
).


How can I join two frames' rows (i.e. vectors) in H2O given H2O Java methods?


For instance, given two Frame A and B


Frame A:

| Id       | Name           |
| -------- | -------------- |
| 123      | John           |
| 456      | Bob            |
Frame B:
| Id       | Name           |
| -------- | -------------- |
| 789      | Alice          |



I want the resultant Frame C to be:


| Id       | Name           |
| -------- | -------------- |
| 123      | John           |
| 456      | Bob            |
| 789      | Alice          |



Is there a way to do this faster then: making new vectors, than create a new frame from the new vectors? I have read the documentation and found that the 
Frame::append()
 method would create new columns, not joining rows.","['java', 'h2o']",Huy Ngo,https://stackoverflow.com/users/3972907/huy-ngo,194,"{'gold': None, 'silver': None, 'bronze': ''}"
70440726,70440726,2021-12-21T19:32:36,2021-12-21 22:39:00Z,412,"In a Databricks notebook, I am trying to load an H2O model that was trained for H2O version 3.30.1.3.


I have installed the version of Sparkling Water which corresponds to the Spark version used for the model training (3.0), 
h2o-pysparkling-3.0
, which I pulled from PyPI.


The Sparkling Water server is using the latest version of H2O rather than the version I need. Maybe there is a way to specify the H2O version when I initiate the Sparkling Water context?  Something like this:


import h2o
from pysparkling import H2OContext
from pysparkling.ml import H2OBinaryModel

hc = H2OContext.getOrCreate(h2o_version='3.30.1.3')
model = H2OBinaryModel.read('s3://bucket/model_file')



I run the above code without an argument to 
H2OContext.getOrCreate()
 and I get this error:


IllegalArgumentException: 
 The binary model has been trained in H2O of version
 3.30.1.3 but you are currently running H2O version of 3.34.0.6.
 Please make sure that running Sparkling Water/H2O-3 cluster and the loaded binary
 model correspond to the same H2O-3 version.



Where is the Python API for Sparkling Water? If I could find that I might be able to determine if there's an H2O version argument for the context initializer but surprisingly it's been impossible for me to find so far with Google and poking around in the docs.


Or is this something that's instead handled by installing an H2O version-specific build of Sparkling Water? Or perhaps there's another relevant configuration setting someplace?","['h2o', 'sparkling-water']",James Adams,https://stackoverflow.com/users/85248/james-adams,"8,687","{'gold': '', 'silver': '', 'bronze': ''}"
70408222,70408222,2021-12-19T00:35:45,2021-12-23 21:49:01Z,89,"My question is if Open Source H2O-3, Open Source Sparkling Water and Driverless AI are affected by CVE-2021-44228 and CVE-2021-45046.","['h2o', 'sparkling-water', 'driverless-ai', 'h2o.ai']",Michal,https://stackoverflow.com/users/5089773/michal,437,"{'gold': None, 'silver': '', 'bronze': ''}"
70366277,70366277,2021-12-15T15:29:29,2021-12-15 15:47:13Z,0,"A vulnerability of 
log4j
 became public.
Amongst other packages, I am using R 
shiny
 and 
h2o
 packages.
I already found out, that 
shiny
 is not affected by the vulnerability, since it uses 
log4js
(see 
https://github.com/log4js-node/log4js-node/issues/1105
), which is an implementation in Javascript.


Now we come to 
h2o
. I know that this package provides an API to the 
h2o
-framework in Java. In the documentation of building 
h2o
 from source from github (see 
https://h2o-release.s3.amazonaws.com/h2o/rel-noether/4/docs-website/developuser/quickstart_git.html
), i found along the lines


javac -source 1.6 -target 1.6 -sourcepath src/main/java -classpath
""../lib/log4j/log4j-1.2.15.jar:../target/h2o.jar:../lib/hadoop/mapr2.1.3/hadoop-0.20.2-dev-core.jar""
-d classes/mapr2.1.3 src/main/java/water/hadoop/*.java
warning: [options] bootstrap class path not set in conjunction with -source 1.6
1 warning
jar cf target/h2odriver_mapr2.1.3.jar -C classes/mapr2.1.3 .
make build_inner HADOOP_VERSION=cdh3
mkdir classes/cdh3
javac -source 1.6 -target 1.6 -sourcepath src/main/java -classpath
""../lib/log4j/log4j-1.2.15.jar:../target/h2o.jar:../lib/hadoop/cdh3/hadoop-core-0.20.2-cdh3u6.jar"" -d
classes/cdh3 src/main/java/water/hadoop/*.java
warning: [options] bootstrap class path not set in conjunction with -source 1.6
1 warning
jar cf target/h2odriver_cdh3.jar -C classes/cdh3 .
make build_inner HADOOP_VERSION=cdh4
mkdir classes/cdh4
javac -source 1.6 -target 1.6 -sourcepath src/main/java -classpath
""../lib/log4j/log4j-1.2.15.jar:../target/h2o.jar:../lib/hadoop/cdh4/hadoop-common.jar:../



It seems like 
h2o
 is using 
log4j
, but I don't know much about Java and its dependencies.


Can anyone with more knowledge clearify whether the 
h2o
-package is affected by the 
log4j
 vulnerability? And if so, how to solve or workaround this?


Thank you very much in advance.","['java', 'r', 'security', 'log4j', 'h2o']",Jonas,https://stackoverflow.com/users/14316488/jonas,"1,788","{'gold': '', 'silver': '', 'bronze': ''}"
70311395,70311395,2021-12-10T23:22:57,2022-02-17 00:15:38Z,328,"As my plan was to exclusively use H2O's web GUI, I installed H2O following these steps: 
https://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html#download-and-run-from-the-command-line
. I got a Windows Firewall popup asking me to allow h2o to communicate on public networks (I was connected to a public network at that moment). I accepted.


Now I would like to uninstall it, but I have not been able to find info about it. Also, it does not appear in the list of installed applications in Windows 10 settings. I have not found any rules related to H2O or port 54321 in Windows firewall either.


Please note:




This is the first time I install programs this way.


I do not have Python or R installed in my computer, as it was not necessary for using H2O's web GUI.","['uninstallation', 'h2o']",,https://stackoverflow.com/posts/70311395/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
70294943,70294943,2021-12-09T18:27:46,2022-02-17 00:18:45Z,107,"With the latest version of 
hex.genmodel
 java library, we can get the MSE value. But I need to define the threshold value to identify the anomaly from generated H2O Poco class itself. Even a calculation would be helpful.


Thanks for the help.","['java', 'h2o', 'autoencoder', 'threshold', 'anomaly-detection']",Niroshan K,https://stackoverflow.com/users/10318195/niroshan-k,88,"{'gold': None, 'silver': None, 'bronze': ''}"
70279189,70279189,2021-12-08T17:22:34,2022-04-15 12:24:11Z,73,"I'm new to machine learning and H2O tools, and I'd like to know if there is a high-level H2O interface that allows us to implement new methods into a pipeline.


I know we can build models thanks to Flow interface and export them as POJO/MOJO. But how can I, for example, decide to use kNN method as an imputation method for my data, when Flow only allows simple imputation like mean/mode ?","['methods', 'h2o', 'imputation']",General Grievance,https://stackoverflow.com/posts/70279189/revisions,"4,957","{'gold': '', 'silver': '', 'bronze': ''}"
70274744,70274744,2021-12-08T12:06:17,2022-02-17 00:08:37Z,171,"plz help~


i create h2o-stateful-set which set replicas: 3, then i run a h2o automl job, it works well. but suddenly one of pod breakdown, i use 
kubectl delete pod h2o-k8s-1
 to delete this pod. the statefulset create a new pod has same name h2o-k8s-1.
But here's the problem, the new pod can't join h2o cluster, and  job stuck, logs as follows


FJ-126-3  WARN water.default: Killing h2o-stateful-set-1.h2o-service.dhr-h2o.svc.cluster.local/10.177.5.212:54321 because the cloud is no longer accepting n
ew H2O nodes.



i know New H2O nodes join to form a cluster during launch. After a job has started on the cluster, it prevents new members from joining. but what should i do if cluster pod breakdown during training?","['h2o', 'h2o.ai']",dhr,https://stackoverflow.com/users/11118784/dhr,1,"{'gold': None, 'silver': None, 'bronze': ''}"
70205550,70205550,2021-12-02T19:43:29,2022-01-15 06:58:37Z,382,"I have recently started learning about H2O AutoML. I am wondering which one of the following options works better. Single node with 6GB of memory or a cluster of three nodes with 2GB memory each.




java -Xmx6g -jar h2o.jar -name MyCluster


java -Xmx2g -jar h2o.jar &   java -Xmx2g -jar h2o.jar &   java -Xmx2g -jar h2o.jar &




If there are drawbacks with single node deployment, can you recommend any methods to optimize the performance?
Thanks in advance!","['h2o', 'h2o.ai']",python dev,https://stackoverflow.com/users/2020301/python-dev,219,"{'gold': '', 'silver': '', 'bronze': ''}"
70178457,70178457,2021-12-01T02:29:58,2021-12-06 07:33:54Z,183,"In my algorithm, master node needs more memory (say 20GB) while the worker nodes need much less memory (say 3GB). However, as far as I know, in H2O it is only possibly to set the master node the same memory as worker nodes using 
-mapperXmx
.


In Apache Spark, it is possible to specify the driver memory with 
--driver-memory
 argument. However, I have 
not
 been able to find a equivalent way to set ""master/driver"" node's memory in H2O.


I am running H2O (
not
 Sparkling Water) on a Hadoop cluster (essentially on a YARN cluster) using this command:

hadoop jar h2o-hadoop-3/h2o-cdh6.3-assembly/build/libs/h2odriver-3.33.1.jar -nodes 5 -mapperXmx 3g -output my/output/dir/on/hdfs
. This way I am able to specify worker nodes' memory as 3GB. However, I could not find the argument to specify the master node's memory.  Is it possible to set the master node 20GB?","['java', 'hadoop', 'hadoop-yarn', 'h2o']",,https://stackoverflow.com/posts/70178457/revisions,,"{'gold': None, 'silver': None, 'bronze': None}"
70071481,70071481,2021-11-22T19:39:50,2021-11-22 19:39:50Z,0,"I am trying to convert some R code to Python. The code builds h2o models and uses Lime for explanations. The Lime modules in each language seem to be quite different.


What would be the equiavlent python functions to this R code?


explainer <- lime(x=observations, model=mymodel)
explainations <- lime::exaplin(x=observations, explainer=explainer,n_permutations=5000, feature_select=""highest_weights"", n_labels=5, n_features=10)



This is a multiclass classification problem with 3 classes. I was thinking the best translation in Python would be to use the LimeTabularExplainer.


explainer = lime.lime_tabular.LimeTabularExplainer(observations, mode='classification', class_names=myclasses,feature_names=observationCols)
explainations = explainer.explain_instance(observations, mymodel, num_samples=5000, num_features=8)



This doesn't seem to be working through so I am not confident. Is there a better way to translate this R code, or better Lime documentation somewhere for explaining models.","['python', 'r', 'model', 'h2o', 'lime']",Jacqueline Schafer,https://stackoverflow.com/users/17482226/jacqueline-schafer,11,"{'gold': None, 'silver': None, 'bronze': ''}"
