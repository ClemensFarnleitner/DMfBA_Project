,comment_id,content,creation_date,user_name,user_profile_link,reputation_score,answer_id
139391547,139391547,"It is for regression. The problem with your solution, is you are loosing all the data for x3 in the training stage, and so the model will not perform as well as it could have.   Instead, I am looking for a way to group x1 and x3 together so that it trains them as the same, even thought their values aren't.",Oct 4 at 11:32,,,,79049681
139463667,139463667,Hi Adam. I still don't understand your problem well. Could you please explain your issue using a simple example with concrete data? Thanks!,Oct 16 at 9:11,,,,79049681
139285027,139285027,"Yes, the column names are the same. That's the reason why the error that I'm getting makes no sense to me. At first I thought that I had failed to convert some variable into an h2o frame, but that doesn't seem to be the case either.",Sep 17 at 20:27,,,,78995415
139285078,139285078,"I also thought that in the test set I might need the y variable as a placeholder (even though it isn't used), but I get the same results with or without it in x_df_new",Sep 17 at 20:34,,,,78995415
139032506,139032506,"Thanks for the response - I think using frequency to weigh the relative importance across the levels within a categorical predictor is reasonable; on the other hand, SHAP seems to work for only tree-based models and I'm curious if there are similar measures for GLMs.",Aug 11 at 0:57,,,,78854135
139043415,139043415,"In newer versions of H2O, SHAP works for all the models that are available in H2O’s AutoML (DeepLearning, DRF, GBM, GLM, StackedEnsemble, XGBoost). You just need to specify 
background_frame
.  SHAP works on tree-based models even without background frame because we can use the structure of the trees to efficiently estimate how each feature influences the prediction. But even for tree-based models it’s usually better to estimate SHAP with background frame since it contains the information about distributions of individual variables.",Aug 12 at 20:21,,,,78854135
139053710,139053710,Appreciated the feedback - do you know where I could find documentation regarding implementing SHAP on GLMs or non tree-based models in general?,Aug 14 at 5:21,,,,78854135
139061995,139061995,"Most of the papers that were used for implementing the SHAP should be in h2o’s documentation 
docs.h2o.ai/h2o/latest-stable/h2o-docs/…
 . You can also check the references from the PR that added the SHAP to H2O: 
github.com/h2oai/h2o-3/pull/15734
 (I’m lazy and I didn’t update the PR’s description so some of the issues there mentioned are already resolved). If you want specifically GLM SHAP then you can have a look at this paper: 
arxiv.org/abs/2006.16234
 and 
nature.com/articles/s41467-022-31384-3
 for the conversion from link space.",Aug 15 at 6:34,,,,78854135
139053756,139053756,Thanks - the idea of using standardized coefficients to measure variable importance makes sense to me as they are scale independent. What I'm struggling with is how to aggregate these coefficients so that I can have a single number for each predictor (given that each level within a categorical predictor has its own coefficient),Aug 14 at 5:31,,,,78862361
138315359,138315359,"Thank you! So if I dont want the predictions of bush_name to be specific (as in I want to be able to predict future bushes that havent been planted yet, vs retraining the model each time), then should I still convert bush_name into a factor?",May 9 at 17:02,,,,78453131
138320130,138320130,"For random forest you should probably remove the 
bush_name
 from training. But for, e.g., mixed-effects models (e.g., HGLM) you can use it to separate the influence of the individual bush and the other variables (you can see why it can be useful when you look at Simpson's paradox).  I would probably try to train it with and without 
bush_name
 and if the influence of having 
bush_name
 is big (in CV metrics), I would try to add some more information if possible, e.g., environmental factors - is the bush in the shade, is it more exposed to wind etc.",May 10 at 8:05,,,,78453131
138490543,138490543,If I do 'step_dummy(bush_name)' is this similar to the factorizing of the variable? Thank you,May 30 at 14:37,,,,78453131
137950531,137950531,"Eureka!! Thank you Darren, I spliced the dataframe to only use the first 10 rows and I got a result, you're awesome. (I couldn't post the csv because the data in sensitive)",Mar 30 at 16:42,,,,78248479
137927362,137927362,You are right. Launching h2o cluster manually resolved the randomness that I was facing. I was previously starting h2o within my code.,Mar 28 at 1:47,,,,78201658
137832323,137832323,"Ahhh thank you!  I don't quite follow the matrix algebra above, but I think what you're saying is it's possible to rotate an orthogonal pattern matrix (which the unrotated PCA is) without having the correlation matrix.  It looks like the GPArotation R package can do that with functions like promax() and bifactor(). Thanks again!",Mar 18 at 18:20,,,,78181801
137356950,137356950,Error:'file' must be a character string or connection with as.data.frame(),Jan 31 at 11:38,,,,77911914
137242323,137242323,Yeah i did it but it says pyspark don't have h2o model,Jan 19 at 19:52,,,,77841614
136976650,136976650,Many thanks! Weirdly enough that only works if the the (binary) model is loaded (using h2o.load_model()) in the same sessions as it was saved. Otherwise I still get error mentioned in the openingpost. I will open a ticket.,"Dec 21, 2023 at 8:50",,,,77680312
136114462,136114462,"Thank you. I have used as.h2o on the train and validation data separately because when I use it on the data frame first, my train data runs an error.  I am still getting a cardinality error","Oct 1, 2023 at 8:25",,,,77209082
136112479,136112479,"Before sending the data to the H2O model, ensure that your response column is a factor with three levels. For instance, if your data frame is df and your response column is response, you can convert it to a factor using somting like this, df$response <- as.factor(df$response)","Sep 30, 2023 at 22:03",,,,77208591
136112855,136112855,Thank you very much for the helpful information. Do you know how to ensure the multi-class setting is on ?,"Sep 30, 2023 at 23:49",,,,77208591
137996089,137996089,In my case it didn't work,Apr 4 at 14:51,,,,78046835
135657219,135657219,"Krasinski, thank you for your response. I tried two github codes: 1. download the stable release 
github.com/h2oai/h2o-3/archive/refs/tags/…
; 2. git clone the master branch. Both have the same build problem.","Aug 22, 2023 at 11:14",,,,76952165
135657384,135657384,"And 
./gradlew build -x test
 also has this problem.","Aug 22, 2023 at 11:28",,,,76952165
135662854,135662854,can you please share the full log building the newest revision of rel-3.42.0 branch?,"Aug 22, 2023 at 17:47",,,,76952165
135666980,135666980,"Krasinski, I just updated the question with full log above, using the latest rel-3.42.0 branch.","Aug 23, 2023 at 3:35",,,,76952165
135561796,135561796,Thank you. I also add that I solved this clash using a python virtual environment.,"Aug 14, 2023 at 8:34",,,,76871083
135362388,135362388,"Checkpoint will address disk issue. I think the only catch is that I need to keep model up in memory in my server. If somehow my server goes down, then will need to retrain the complete dataset.","Jul 27, 2023 at 16:25",,,,76775726
134745832,134745832,"I use h2o 3.34 (I cannot update it), and run it on Jupyter (Python 3.8).","Jun 6, 2023 at 14:38",,,,76394821
134577167,134577167,"Ty!, I thought I did it with 
apt-get install -y r-cran-jsonlite
?","May 23, 2023 at 15:49",,,,76316527
134522123,134522123,Your last state shows me how to save one csv file as a H2O dataframe. I already know how to do that. But I need to merge all the data together and then train it. Could you elaborate how your solution helps me do so,"May 18, 2023 at 20:28",,,,76275385
134335558,134335558,Thanks for your answer. I edited my post to add the leaderboard of the models. There is no deeplearning model used. I always computed training confusion matrix this way and never had an issue. I will try with your suggestion and come back to you,"May 4, 2023 at 15:29",,,,76174460
134336320,134336320,"@Guest6117 I forgot we use the same ""trick"" in the Stacked Ensemble so I updated the answer (even worse I think I was the one who added the parameter to the Stacked Ensemble). Thank you for adding the leaderboard!","May 4, 2023 at 16:20",,,,76174460
134344868,134344868,"Ok I understand now !  Is it possible to pass this parameter to the autoML function, down to the stacked ensemble ? And if the default value is 10k why do I have 9955 cases and not 10k exactly ?","May 5, 2023 at 8:21",,,,76174460
134345707,134345707,It's not possible to easily pass this argument to AutoML. Why 9955 instead of 10k? The sampling process works in parallel - estimate the proportion of rows that we want to get and in each worker sample that proportion. So the number of rows in the sample should be close to the 10k but it doesn't guarantee it will be exactly 10k.,"May 5, 2023 at 9:30",,,,76174460
134264760,134264760,Any corroboration for answer #2?,"Apr 28, 2023 at 20:44",,,,76132980
134099901,134099901,"Thanks for bringing clarification to the first part. But the only thing that confuses me is to use the hyperparameters of the models obtained as a result of the train with the data that does not include June, although we fit a model to entire dataset afterwards. My point is, if we include the previous Junes in the train subset, it seems that the models can obtain more tuned hyperparameters for especially June.  Besides wouldn't it be enough to make the validation_frame a subset of June months to realize what you've stated? I mean, does h2o.automl fit model to the entire dataset in this case?","Apr 17, 2023 at 12:53",,,,76033531
133769454,133769454,"Thanks, but as I see in example it is step outside of model. So, it will require to build additional process how data scientist can deliver those steps. Assume not many data scientists will be able to deliver java code.","Mar 24, 2023 at 16:36",,,,75822097
133772414,133772414,"With SW, you can train the pipeline that contains data munging steps and h2o-3 algorithm. You can do that with Scala or Python API. Or you can fit h2o-3 model separately, download mojo artifact, 
load mojo to SW
 and plug the mojo model stage into a pipeline with preprocessing steps. This should cover users of R API, but you will duplicate the preprocessing/data munging logic.","Mar 24, 2023 at 20:29",,,,75822097
133776959,133776959,"Our analytics saying it's not possible to integrate munging steps into MOJO zip file, but they can generate Transformer java class. Maybe it will be possible to use in our standard spark ETL jobs. At this stage we experimenting with standard spark and H2O libraries inside spark reading MOJO models in Hadoop environment. SW looks like more complex config, where experts prefer to use together with H2O instance and data transfer between spark and instance. I will try to check also SW variant.","Mar 25, 2023 at 9:26",,,,75822097
133583387,133583387,"Yes, I realised that it is ggplot output and you have to modify relevant layer point size: 
plt$layers[[2]]$aes_params$size=4","Mar 13, 2023 at 14:50",,,,75723237
133528596,133528596,Is it likely a bug? It's hard to make reprex with large data for me though. I'm trying h2o 3.40.0.2,"Mar 9, 2023 at 20:13",,,,75689319
133358492,133358492,"As it’s currently written, your answer is unclear. Please 
edit
 to add additional details that will help others understand how this addresses the question asked. You can find more information on how to write good answers 
in the help center
.","Feb 28, 2023 at 7:10",,,,75548216
132855468,132855468,"The way to extract 
df
 is to call 
df = model.varimp(use_pandas=True)
. If you can add this to your answer, it might help others as well. Thanks.","Jan 30, 2023 at 21:30",,,,75289520
132619715,132619715,"If you encoded your data separately, you will take up more memory for your dataset.  There is no advantage encoding your categorical columns.  If any, it may slow down the algos.","Jan 17, 2023 at 22:18",,,,75152725
132638135,132638135,"The original data i have has multiple text values under each cell so 30 column and each column row cell have multiple values, i have to separate them but that was increases exponentially in the rows so the hot encoding sounds reasonable. Example Suppose X is one column, one cell/row has A,B,C and that goes with 30 column. Is there any other way i can handle this? else i am stuck with hot encoded data and my initial question remains unanswered","Jan 18, 2023 at 18:45",,,,75152725
132019947,132019947,"Thanks. But, after 
unbundle
, although 
predict()
 works, these two don't: 
rank_results(auto_fit)
 and 
tidy(auto_fit)
. Please advice.","Dec 15, 2022 at 0:53",,,,74800319
132172874,132172874,"Does 
bundle(
 accept 
c(
 input?","Dec 23, 2022 at 4:36",,,,74800319
131636599,131636599,"Thank you very much @Tomas!  I've set 
stopping_metric = ""AUCPR""
 and it indeed improved the AUCPR from 0.1 to 0.3.  I also tried the 
themis
 package to use different oversample/downsample methods (e.g., SMOTE, ROSE, Tomek). However, the AUCPR didn't improve much further, sometimes even worse. May I ask: given the prevalence of minority class in my data is 0.05, whether an AUCPR of 0.3 is acceptable? Does it have to be close to 1?","Nov 25, 2022 at 14:37",,,,74487467
131636637,131636637,"Or, can I use other metrics to evaluate the model handling imbalanced data, such as AUC or logloss?","Nov 25, 2022 at 14:39",,,,74487467
131676308,131676308,"This is highly dependent on the use-case but AUCPR 0.3 seems low. Depending on your use-case you can guess the costs of individual errors (false positives vs false negatives, low precision vs low recall etc.) and use 
weight_column
 to do the balancing/weighing manually.   AUCPR shows you the overall performance for the model so it's good for comparing different models but in production you often care about what errors are made (FP vs FN), this can be inspected using 
confusion matrix
.","Nov 28, 2022 at 9:01",,,,74487467
131303896,131303896,I set n_folds=0 so X_df is the entire training dataset (i.e. it should be the same I think).,"Nov 9, 2022 at 15:14",,,,74373233
131311994,131311994,"I believe with your settings it will take 20% of 
df
 for validation and leaderboard data: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/…","Nov 9, 2022 at 21:50",,,,74373233
135650398,135650398,R2 is just normalized MSE with a sign change & constant shift. It is much more general than just linear models & idk why people think that.,"Aug 21, 2023 at 21:06",,,,74373233
130498678,130498678,"Thank you, mate, your answer is absolutely great!","Sep 30, 2022 at 10:11",,,,73905821
130412580,130412580,"With further experiments, I realized that 
data_frame$Sepal.Length
 results in vector, 
H2O.Frame$Sepal.Length
 results in 
H2O.Frame
, so 
length()
 does not do what I was trying to achieve.","Sep 26, 2022 at 15:25",,,,73838367
134261592,134261592,"@LeDell Thank you very much. Does standardize = TRUE in Deep Learning, GLM, ..., standardize the target variable altogether, or only features?","Apr 28, 2023 at 16:00",,,,74120543
134265163,134265163,"Linking your answered question here: 
stackoverflow.com/questions/76131318/…","Apr 28, 2023 at 21:23",,,,74120543
139409253,139409253,"Out of curiosity, why do you recommend an article on gamma in response to a question about alpha and lambda? The article doesn't actually mention alpha or lambda, which are associated with L1 and L2 regularization, respectively. Gamma instead relates to tree depth.",Oct 7 at 21:04,,,,73546872
129661840,129661840,"Maybe this helps: 
towardsdatascience.com/…","Aug 19, 2022 at 21:40",,,,73422497
129500931,129500931,getFeatureImportances() - this function is returning None object!,"Aug 12, 2022 at 6:30",,,,73321499
129514069,129514069,Can you share leaderboard for your particular run?,"Aug 12, 2022 at 17:00",,,,73321499
129524548,129524548,Model Details =============== H2OXGBoost Model Key: XGBoost_1_AutoML_1_20220813_162406_08ae0501887b Model summary Number of Trees: 30 Training metrics RMSLE: 1.9279105523758344 Nobs: 10.0 RMSE: 11.10180165558726 MAE: 9.5 MeanResidualDeviance: 123.25 ScoringTime: 1.660388047538E12 MSE: 123.25 R2: -2.734848484848485 Cross validation metrics RMSLE: 1.9279105523758344 Nobs: 10.0 RMSE: 11.10180165558726 MAE: 9.5 MeanResidualDeviance: 123.25 ScoringTime: 1.660388047546E12 MSE: 123.25 R2: -2.734848484848485,"Aug 13, 2022 at 10:57",,,,73321499
129553608,129553608,"The XGBoost model should have feature importances available. Only StackedEnsemble models return 
None
 on 
getFeatureImportances()
 method.  You can try that on other models from leaderboard.  ```     aml.fit(sparkDF)     models = automl.getAllModels()     models[1].getFeatureImportances().show()     models[2].getFeatureImportances().show() ```","Aug 15, 2022 at 10:49",,,,73321499
129414523,129414523,"While trying to run using this, I got this following error:    #2319  1654622-15  WARN water.default: ERROR MESSAGE: 08-08 19:40:17.287 10.255.11.32:54321    #2319  1654622-15  WARN water.default:  08-08 19:40:17.288 10.255.11.32:54321    #2319  1654622-15  WARN water.default: Resource /3/verifyWebOpen not found","Aug 8, 2022 at 14:11",,,,73276790
129487002,129487002,"Can you share logs from H2O nodes. By default, they are stored to 
h2ologs
 folder in user home directory on each server.","Aug 11, 2022 at 14:02",,,,73276790
129222289,129222289,"Thanks! I was trying this from 2 days and couldnt understand the problem. Also, The main problem was naming my python script ""h2o.py"" as this was causing the problem.","Jul 29, 2022 at 13:42",,,,73167339
128902190,128902190,I have selected this has answered because it ran in local but still the issue exists in Azure Function. When I tried to run it as a Azure function it fails with no logs. Can you try it in a function?,"Jul 14, 2022 at 13:57",,,,72961595
128902517,128902517,"In Azure Portal Function App, you're asking? If yes, could you please raise a new thread so that I'll try assisting separately for getting that fix on portal function app!","Jul 14, 2022 at 14:10",,,,72961595
128903919,128903919,Yes @The6thSense,"Jul 14, 2022 at 15:11",,,,72961595
128904163,128904163,Okay will do the same,"Jul 14, 2022 at 15:21",,,,72961595
128905951,128905951,"Thanks @The6thSense, I'll look into the issue in Portal also and get back to you in that post!","Jul 14, 2022 at 16:45",,,,72961595
128019789,128019789,"Thanks TheFon.  With the Java/CVE-201200507 file quarantined, I downloaded and installed the current version of Java from java.com (version 8 333). I then attempted another initialization of h2o.  It indicated it was performing a one time install of h2o.jar as it did this morning before the malware was detected and quarantined.  I immediately scanned the downloaded version of h2o.jar, and I received the exact same malware quarantine notification again.  Thoughts?","Jun 1, 2022 at 23:08",,,,72468521
128043066,128043066,"I tried scanning the last release and I was able to reproduce the issue. We do not believe there is any malware in the h2o.jar and we expect this to be a false alarm. We do have security scans on our products and this vulnerability was never flagged, also the description of the vulnerability doesn't match what the content of the jar has.","Jun 2, 2022 at 22:13",,,,72468521
128043762,128043762,"H2O bundles this library that is being flagged by the antivirus software: org.threeten:threetenbp:1.5.2 - this library is safe and doesn't present any risk to the users. We will be reporting the issue to the makers of VirusBarrier here: 
intego.com/support/submit-malware","Jun 2, 2022 at 23:26",,,,72468521
128059435,128059435,"Thank you, Michal.  That's peace of mind.","Jun 3, 2022 at 16:21",,,,72468521
127861968,127861968,"Thanks. The more specific question here is: Can i use an already existing model from AutoML to create a stack/ metalearner model? If yes, then how?","May 25, 2022 at 12:15",,,,72377082
127871899,127871899,@PayalSengupta You can use models from AutoML just as base models but you can't use them as metalearner. Metalearner gets predictions of the base models as its input.,"May 25, 2022 at 19:06",,,,72377082
127872135,127872135,"The 
metalearner_algorithm
 param is an algorithm, not a trained model.  You train the metalearner as part of the StackedEnsemble training, so that's why you can't pass an already trained model to the 
metalearner_algorithm
 argument.","May 25, 2022 at 19:19",,,,72377082
127392753,127392753,"I considered this as a possible solution as well, but was put off with the hope of another solution. However it seems like this is the only possible way to extract the feature contribution. I guess this isn't really considered as a clean way of doing so.  If it was up to you would you still prefer the EIF from h2o (with the benefit of possible better outlier detection due to removing the tree branching bias) over the IF from Sklearn which is able to extract shap values? Or is this fully depended on the intended result?","May 3, 2022 at 12:31",,,,72099329
127393080,127393080,"I can't give you ""unbiased"" answer - I work for h2o. But generally speaking I'd consider the size of the data (h2o should scale better) and also the importance of the information from SHAP. IIRC there is 
KernelExplainer
 in 
shap
 package that should work on any algorithm (but it is slower) but maybe that could be used as well on the Isolation Forest.","May 3, 2022 at 12:46",,,,72099329
127393341,127393341,"I will have a look at the KernelExplainer, really appreciate it!","May 3, 2022 at 12:58",,,,72099329
127330017,127330017,"Thanks for the quick response! Sorry, my question wasn’t clear. I’m referring to a continuous variable that I’m modeling with splines, but there are 1000 possible values of the continuous variable and I’d like to know the effect of each possible value on the response.","Apr 29, 2022 at 18:53",,,,72062440
127341692,127341692,"As it’s currently written, your answer is unclear. Please 
edit
 to add additional details that will help others understand how this addresses the question asked. You can find more information on how to write good answers 
in the help center
.","Apr 30, 2022 at 14:48",,,,72062440
126721573,126721573,"Thank you Erin! Yes the doc was not very clear, but I could have guessed from the example given","Apr 1, 2022 at 8:40",,,,71699115
126722157,126722157,"I am still getting an error: 
Error: DistributedException from localhost/127.0.0.1:54321: 'null', caused by java.lang.NullPointerException","Apr 1, 2022 at 9:10",,,,71699115
126722289,126722289,"I edited my question to report the new error. I tried on two different machine, one windows, one linux, and got the same error","Apr 1, 2022 at 9:17",,,,71699115
126737950,126737950,There was a typo in my code above (wrong column index) but I fixed it and the bug is still there (will try to follow-up soon with an answer/fix).,"Apr 1, 2022 at 23:36",,,,71699115
126844461,126844461,I added a link to the JIRA ticket -- this is indeed a bug.,"Apr 7, 2022 at 6:07",,,,71699115
126575047,126575047,"I've removed all references to old H2O installations using # REMOVE PRIOR INSTALLS OF H2O if (""package:h2o"" %in% search()) { detach(""package:h2o"", unload=TRUE) } if (""h2o"" %in% rownames(installed.packages())) { remove.packages(""h2o"") }","Mar 25, 2022 at 13:54",,,,71617486
126575057,126575057,Is there something else I should be doing to flush out old versions?,"Mar 25, 2022 at 13:54",,,,71617486
126576861,126576861,"What do you get when you execute: 
packageVersion(""h2o"")
?","Mar 25, 2022 at 15:06",,,,71617486
126576914,126576914,"or 
getNamespaceVersion(""h2o"")","Mar 25, 2022 at 15:08",,,,71617486
126577448,126577448,"getNamespaceVersion(""h2o"") returned an old version of h20. I am in the process of restarting R and unloading the namespace to clear any old references.","Mar 25, 2022 at 15:31",,,,71617486
126573072,126573072,"thanks for the reply. I've just opened a new question here which references this exact approach except with an error 
stackoverflow.com/questions/71616995/…","Mar 25, 2022 at 12:28",,,,71616883
131555000,131555000,"This failed for me too. Raised a ticket, and still waiting for a response. 
github.com/h2oai/sparkling-water/issues/2838","Nov 21, 2022 at 22:00",,,,71616883
125851838,125851838,"I understand.  But what is the pre-processing to downstream models then ?  What is ""TE""?","Feb 20, 2022 at 19:19",,,,71150782
125906450,125906450,"TE = Target Encoding. The individual models might drop some features (eg. constant columns), might explicitly encode categoricals when needed (eg. xgboost).   I think for your use case of re-training, you do not need to worry about any kind of pre-processing the model does. It doesn't apply here.","Feb 22, 2022 at 23:23",,,,71150782
125837791,125837791,Thanks after many days of playing with the h2o package Ive seen that as you hypothesised 5 mins run time was much too short. Running for several hours leads to much more robust estimation comparing IS and OOS AUC.,"Feb 19, 2022 at 21:51",,,,71150717
125634115,125634115,Thank you so much!,"Feb 10, 2022 at 18:14",,,,71069800
128615069,128615069,"you need to set few other parameters to find the same too, see 
stackoverflow.com/questions/43324287/…","Jun 30, 2022 at 13:18",,,,71069800
124821568,124821568,"Just to be clear, the bug is that I'm allowed to successfully export the GLM+Interactions as a MOJO at all? And that the fix that is coming in the next release will be to prevent people from exporting GLMs with interactions?","Jan 6, 2022 at 16:36",,,,70609024
124895976,124895976,@Jdclark Exactly.,"Jan 10, 2022 at 11:07",,,,70609024
124539684,124539684,"Thanks for this suggestion, @Karthikeyan Rasipalay Durairaj. The scope is not relevant for me per se. In your example, it looks like you're specifying the H2O version after the == in the install command, so I will try this as it may be the mechanism I was thinking about rather than specifying the H2O version in code when starting the H2OContext. I will give this a whirl and report back (or just check your answer as accepted). In any event, I appreciate your help!","Dec 22, 2021 at 17:27",,,,70442318
125828322,125828322,I managed to calculate the threshold from the model and saved it in a DB. So I can now refer to the calculated threshold values ​​using a repo call.,"Feb 19, 2022 at 9:52",,,,71150953
125091925,125091925,Thank you @pveentjer,"Jan 18, 2022 at 17:15",,,,70211830
125091968,125091968,Thank you @Erin LeDell,"Jan 18, 2022 at 17:17",,,,70719466
124114105,124114105,Thanks for your answer but my question is about H2O.ai not Apache Spark,"Dec 3, 2021 at 7:25",,,,70186489
124169032,124169032,My bad. My question is unclear and misleading. I have added more details to it.,"Dec 6, 2021 at 7:40",,,,70186489
125812194,125812194,"Also H2O-3 supports permutation variable importance(
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…
)  in the recent versions.  One thing to add to this answer is to use a different loss than ""mse"" for the classification task (e.g. 
FeatureImp$new(predictor.glm, loss = ""f1"")
 works for me).","Feb 18, 2022 at 13:44",,,,71153576
129201124,129201124,"See also answer at: 
stackoverflow.com/questions/72930868/…","Jul 28, 2022 at 15:06",,,,71153576
122583245,122583245,Java version of h2o doesn't support every algorithm. Does it?,"Sep 28, 2021 at 1:21",,,,69354466
122598209,122598209,"@RumeshMadhusanka Java ""version"" has everything. In fact H2O is written in Java, and both R and Python APIs are just thin clients around calls to the Java server. When you do 
h2o.init()
 it starts the Java server running, if it is isn't already.","Sep 28, 2021 at 14:04",,,,69354466
127899338,127899338,"this is still giving same error. Please refer 
stackoverflow.com/questions/72398521/…","May 27, 2022 at 0:37",,,,69114412
121399683,121399683,"Thanks.  This problem is known when adding nodes on a cluster: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…
  So that would suggest the same is true for cores in a single node.","Aug 7, 2021 at 16:00",,,,68680725
120889627,120889627,"I see, so you're saying that I'd have to do something like in the updated question, correct (since I see from the docs that models use whatever 
stopping_metric
 is set to 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…
)? BTW, should I be using 
>
 or 
>=
 (couldn't tell from the docs)?","Jul 16, 2021 at 3:34",,,,68401329
120743741,120743741,"Hello, I tried your suggestion to download h2o from the link you gave me ''' '''  but I got this error","Jul 9, 2021 at 15:21",,,,68313233
120743822,120743822,"package or namespace load failed for ‘h2o’ in get(method, envir = home):  lazy-load database 'C:/Users/Documents/R/win-library/4.0/h2o/R/h2o.rdb' is corrupt De plus : Warning messages: 1: In .registerS3method(fin[i, 1], fin[i, 2], fin[i, 3], fin[i, 4],  :   redémarrage de l'évaluation d'une promesse interrompue 2: In get(method, envir = home) :   redémarrage de l'évaluation d'une promesse interrompue 3: In get(method, envir = home) : internal error -5 in R_decompress1","Jul 9, 2021 at 15:26",,,,68313233
120786869,120786869,"It looks to me like there is a problem during the installation. I'd suggest to restart the R session and try again. Also it is possible that h2o is loaded on load for whatever reason so it might be worth trying to ""Session -> Clear workspace..."" before the installation. If it still doesn't work try installing it in vanilla R session (run in CMD 
R --vanilla
), that should ensure that nothing gets preloaded before the installation which seems to me was the cause.","Jul 12, 2021 at 8:14",,,,68313233
119915142,119915142,"Something to note is that XGBoost (included in AutoML) uses memory outside of the H2O cluster.  So when you use all the available memory on your machine with the H2O cluster, there's nothing left for XGBoost to use, and that might be what caused this issue.  We have a ticket open to warn the user, which should lead to less confusion in the future: 
h2oai.atlassian.net/browse/PUBDEV-8095","Jun 4, 2021 at 19:40",,,,67830165
119915252,119915252,"Also, you can probably leave nthreads = -1 (use all threads), and increase your memory size for the H2O cluster to about 2/3 of the total free RAM on your machine.  I think your current config is a bit conservative, but that was a good way to try to identify the issue and fix it!","Jun 4, 2021 at 19:45",,,,67830165
119710319,119710319,"Excuse my ignorance. But the performance results obtained from using the resample function with the same 3-fold CV, is the actual performance of my fitted model with the tuned parameters?","May 27, 2021 at 16:47",,,,67725424
119710610,119710610,"It is a performance 
estimate
 -- what, based on the resampling and data you've given, appears to be the performance. The 
actual
 performance can and will be different (as you've seen) when different data/resamplings are used. One way to get a more robust performance estimate is to increase the number of folds (10 fold is quite standard) and, for tuning, use nested resampling -- 
mlr.mlr-org.com/articles/tutorial/nested_resampling.html","May 27, 2021 at 16:58",,,,67725424
119710973,119710973,"Then, when training the model, how do I use the same data/resamplings that are used during the tuning process?","May 27, 2021 at 17:12",,,,67725424
119711164,119711164,You usually don't. You would take the data and resampling for your actual task. The performance of a model trained with the hyperparameters from the tuning process is estimated by the the result of the tuning process. It is however only an estimate and therefore the performance you observe may be different.,"May 27, 2021 at 17:20",,,,67725424
121863836,121863836,"What @MarcelBischoff suggests works, but is slow for my problem. I have a huge H2O Frame 
df2
, and can convert it to Pandas as 
df0= df2.as_data_frame()
. An then 
df = h2o.H2OFrame(python_obj=df0)
. But it is slow!!  Instead I use 
df = h2o.deep_copy(df2, 'df')
. This is much faster. This solution was inspired by @MarcelBischof .","Aug 27, 2021 at 14:08",,,,68839331
119467031,119467031,ad1 makes totally sense to me! Ill check about serialization of models in h2o. Do you want me to open an issue/feature request on github?,"May 18, 2021 at 15:21",,,,67589199
119467053,119467053,"Thanks, let's discuss at 
github.com/ropensci/targets/issues/464
.","May 18, 2021 at 15:22",,,,67589199
119493342,119493342,"Moved to a discussion: 
github.com/ropensci/targets/discussions/466","May 19, 2021 at 13:29",,,,67589199
119380529,119380529,"Thanks for the answer. I was able to import the model with the gs path. I should have been more clear, the ls code was run on the VM running the H2O cluster on GCP – so the file was there but I don't know why H2O couldn't load the model.","May 14, 2021 at 21:05",,,,67529082
118401350,118401350,"Neema, thank you so much for answering, right that was what I was afraid of. Does this mean I can not use the H2O Grid (Hyperparameter) Search 
link
?  The best combination of parameters is provided given some metric, which would be either MSE or RMSE. I'm trying to find the best low rank (k) and weights gamma x and gamma y. Do you have any suggestion on how to do this, or should I try it by hand and compare metrics like the ones you said: Sum of Squared Error (Numeric) and the loss function (objective)?","Apr 7, 2021 at 9:24",,,,66979694
118416646,118416646,"AKAIK, grid search can be done. These are the hyperparameters that can be used 
docs.h2o.ai/h2o/latest-stable/h2o-docs/…
.  MSE/RMSE NaN is planned to be removed 
h2oai.atlassian.net/browse/PUBDEV-8089","Apr 7, 2021 at 18:22",,,,66979694
118278479,118278479,Excellent explanation. Thank you,"Apr 1, 2021 at 22:50",,,,66912082
118512372,118512372,Thanks for the very helpful answer. Just one follow-up question: Was I right in assuming that MSE is used for gaussian and logloss for binomial? Are there any differences between XGBoost and GBM in terms of the loss functions?,"Apr 11, 2021 at 16:52",,,,66966786
118222687,118222687,"Another thing you can do is define your working directory and file names separately 
my_dir <- '/home/my/path/'
 then use 
paste(my_dir, 'sample_csv.csv', sep="""")","Mar 31, 2021 at 1:25",,,,66867972
118206246,118206246,"It looks like with those settings, i receive individual timeseries prediction per ID (each ID has diff. proba for given TimeStamp). I'm looking more for something analogous as if I use featuretools to derive time dependant features, and those would be incorporated into model.","Mar 30, 2021 at 12:43",,,,66859455
118242807,118242807,"@Ingelik, I am not sure I understand what you are trying to do. DAI creates the transformed features and also models which it incorporates the new features. Another option is create the model/experiment, then use ""Transform on another dataset"" 
docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/…
, but this can lead to overfitting if you reuse these for a new model. If you are looking for only feature engineering (no modeling), I don't think there is an option for that at the moment.","Mar 31, 2021 at 16:52",,,,66859455
118105501,118105501,"Thanks! The 'update to latest java' message appears with a link in the startup messages triggered by R command 
library('h2o')
 when Java is not installed.","Mar 26, 2021 at 9:06",,,,66806706
118188399,118188399,"Thanks for clarifying -- we will clean up that message too to be more clear.  The new stable release of H2O, v3.32.1.1 (released a few days ago) now officially supports Java 15.  You can download the latest stable at this link: 
h2o-release.s3.amazonaws.com/h2o/latest_stable.html","Mar 29, 2021 at 20:14",,,,66806706
117870889,117870889,"It worked nicely, after only a few adjustments (like loading model file from a shared folder and passing h2o container url and credentials via other env vars). I did manage to automate the creation of 
template.ipynb
 as well (using this approach: 
stackoverflow.com/a/45672031/9962007
).","Mar 17, 2021 at 18:28",,,,66654564
117825850,117825850,"Thank you, but I do want the whole validation output, not just accuracy (to save as a text file to MLflow). No redirections I tried worked... if you managed to hack it, do post it though.","Mar 16, 2021 at 10:30",,,,66653300
117838366,117838366,"A way to remember which args go in which method (the 
H2OAutoML()
 method or the 
.train()
 method) is that all algo-related args go in the former and all data-related args (e.g. 
weights_column
) go in the latter.","Mar 16, 2021 at 17:27",,,,66621323
117257576,117257576,"It is admittedly very strange for MSE & RMSE to be used in 
classification
 settings.","Feb 23, 2021 at 0:05",,,,66325195
117235061,117235061,"Thanks for the response Neema, indeed this process is quite subjective and hence expert knowledge should be involved here. Just to share that I have tried to limit the number of variables though ""max_orig_cols_selected"" as you suggested, but still the highly correlated variables would be included in the final model, guess it means statistically these variables are important to improve the model performance. I am now using some alternative methods to remove some correlated features before importing data into H2O.","Feb 22, 2021 at 9:05",,,,66311564
118858102,118858102,Thanks Neema for your response!,"Apr 24, 2021 at 14:30",,,,67203844
117189133,117189133,"I've tried, but h2o.str() lists it as CHR string, and when I'd like to train the model, I get the following error message, like before:  
Warning message: In .h2o.processResponseWarnings(res) :   Dropping bad and constant columns: [M1Date_Time].
  Constant is like: 2021-02-10 08:15:00 2021-02-10 08:14:00 2021-02-10 08:13:00 etc, since these are values of different minute candles on a stock chart.","Feb 19, 2021 at 21:58",,,,66253696
116988847,116988847,"h2o.interactions()  is Categorical Interaction Feature Creation in H2O, whereas i am looking for interaction for continuous features.","Feb 12, 2021 at 12:42",,,,66167538
117005517,117005517,"GBMs are able to find (non-linear) interactions on their own and you thus typically do not need to explicitly specify interactions. This is why H2O GBM has no such parameter (as opposed to H2O GLM which does have this parameter). If you do feel like your model would benefit from interactions - you can create them explicitly by modifying the training frame, eg. hf_train[""int_1""] = hf_train[""feature_1""] * hf_train[""feature_2""]","Feb 13, 2021 at 2:57",,,,66167538
117109131,117109131,"Getting this error while fetching interaction information by "".feature_interaction()"" in python - AttributeError: type object 'ModelBase' has no attribute 'feature_interaction' please let me know if I am missing anything.","Feb 17, 2021 at 10:37",,,,66167538
117133628,117133628,"What version of H2O are you using? Feature interactions were added to GBM and XGBoost in H2O 3.32.0.2 (
github.com/h2oai/h2o-3/blob/master/…
)","Feb 18, 2021 at 4:41",,,,66167538
117133728,117133728,"For whatever reason, H2O is finding the incorrect Java (the one you don't want). H2O will check your ""PATH"" environment variable then if no Java is found, it will check ""JAVA_HOME"". Check that your ""PATH"" has your desired Java directory listed first. Also, check if you have a directory set for ""JAVA_HOME"".","Feb 18, 2021 at 4:50",,,,66097159
116609349,116609349,"Thanks for the response, can you let me know what you think I should change stopping_tolerance and stopping_rounds to. I also have stopping_metric set to RMSE already, did you mean to change it to something else?","Jan 29, 2021 at 10:37",,,,65948328
116836782,116836782,"You can try changing them first to the default values, and after that you could follow my recommendations above to increase stopping tolerance.","Feb 7, 2021 at 2:03",,,,65948328
116606586,116606586,"Sure, gpu can be disabled in docker level but if you are using a shared server that might not be possible. As I mentioned, I exclude XGBoost and I can run AutoML if this is handled within h2o, then that would be amazing. Thank you.","Jan 29, 2021 at 8:45",,,,65950029
116607393,116607393,We will fix this.,"Jan 29, 2021 at 9:20",,,,65950029
116429623,116429623,"The brakets are not extras. Maybe the problem could be that, since the function DatiRev_h2o <- as.h2o(DatiRev) provides this error ""Provided column type c(""ordered"", ""enum"") is unknown"" I have tried to use the function ""localH2O <- h2o.init(ip = ""localhost"", port = 54321, startH2O = TRUE) #sets up the cluster  pathToData <- paste0(normalizePath(""~/Downloads/""), ""/dat.csv"") write.table(x = dat, file = pathToData, row.names = F, col.names = T) dat_h2o <- h2o.importFile(path = pathToData, destination_frame = ""dat"")"" but I don't know if it is ok (
xspdf.com/help/50383257.html
)","Jan 22, 2021 at 18:43",,,,65850617
116406084,116406084,"Thank you for the information, however even after making this change I am still getting the same error, do you have any more ideas? (I have added an image of the full error above)","Jan 22, 2021 at 0:37",,,,65836827
116406147,116406147,"You're still getting a boot timeout with an error that your process isn't binding to 
$PORT
? That exact error message?","Jan 22, 2021 at 0:42",,,,65836827
116406174,116406174,What is the reason why it needs to listen to a port?,"Jan 22, 2021 at 0:45",,,,65836827
116406202,116406202,Because that's how servers work. They listen for connections on (usually one) port.,"Jan 22, 2021 at 0:47",,,,65836827
116428615,116428615,"One other thing I forgot to mention is that when I run locally, I need to start the server first by executing a ./waved command in the SDK package for wave, would I need to include this in my deployment as well?","Jan 22, 2021 at 17:56",,,,65836827
116237920,116237920,That's a great example to describe my question and the solution. Thank you!,"Jan 15, 2021 at 20:25",,,,65742754
116544751,116544751,Good idea! I suppose there is no function for this in h2o library.,"Jan 27, 2021 at 9:22",,,,65897238
116595778,116595778,Not that I know at the moment. But opening it as text should work fine,"Jan 28, 2021 at 20:35",,,,65897238
116595789,116595789,It would be good practice to save your files with version numbers or by folders so you know,"Jan 28, 2021 at 20:35",,,,65897238
115955290,115955290,"The problem though is I can't seem to release gbm_grid2. When I do, it tells me it failed. And it needs to be an h2o object. Is it not an h2o object? It seems this code worked in the past, but recent API changes have deprecated it.","Jan 5, 2021 at 18:20",,,,65559976
115956418,115956418,"Try 
h2o.rm('gbm_grid2')
. I just tested it on 3.32.0.1, and it works","Jan 5, 2021 at 19:07",,,,65559976
115959771,115959771,"Cool, the command ran through just fine. But my memory has not seemed to recover. Based on the script I gave above where gbm_grid2 is my local variable ... am I recovering memory correctly that way? I've also updated my post with the results of h2o.ls()","Jan 5, 2021 at 21:27",,,,65559976
115964195,115964195,"You are correctly recovering memory, but you need to do it for each grid you create. Your screenshot shows objects from gbm_grid1, try also doing 
h2o.rm('gbm_grid1')
. Whatever you see returned in 
h2o.ls()
, you can call to remove. You can also remove all objects using 
h2o.removeAll()
.","Jan 6, 2021 at 2:01",,,,65559976
116023099,116023099,Okay cool I'm iterating over with h2o.ls(). Is there a way to determine which h2o object is taking the most memory? I don't see that information in h2o.ls() The reason why is even after iterating through and removing almost every object my memory is still at 95%.,"Jan 8, 2021 at 1:38",,,,65559976
115643535,115643535,"Alex, thank you for your answer.  So, changing the path to /dbfs/FileStore/tables/iris.csv solved my initial problem, and I was able to successfully read the csv file.  However, once I read in the file, I called:","Dec 22, 2020 at 14:51",,,,65391232
115644266,115644266,"it's better to ask this as a separate question, because primary topic of your question was about file path","Dec 22, 2020 at 15:17",,,,65391232
115672400,115672400,Okay.  Thank you.,"Dec 23, 2020 at 16:04",,,,65391232
115016019,115016019,Thank you for your elaborate answer. I'll look into the options that you provided. Upvoted but it's not displayed since I'm new to stack :(,"Nov 29, 2020 at 6:59",,,,65050822
114738431,114738431,Thank you! I found that amazonaws link but on first glance thought it wasn't useful due to it not having a version number for the release. Turns out for the R packages they don't give the release number but the working name.,"Nov 18, 2020 at 16:32",,,,64809800
114747711,114747711,"Yeah it's a bit confusing with the version number and version name, so the only way to get all the info is to look in Changes.md.","Nov 18, 2020 at 22:45",,,,64809800
114586746,114586746,"Caveat: This only works for versions that were released to CRAN.  Not all H2O versions are released to CRAN (major versions are, but not all minor versions are).","Nov 12, 2020 at 18:30",,,,64802583
114505289,114505289,"Thanks a lot! It is helpful! I will avoid using both cv and parallelism in 
h2o.grid()
 for a while.","Nov 10, 2020 at 2:03",,,,64754816
114553651,114553651,"After getting cross_validation_fold_assignment(), do you know how to use it for another model. For example, I will re-run with gbm (change parameters such as number of trees, topping_round, ...etc). Thanks,","Nov 11, 2020 at 16:29",,,,64704448
114556976,114556976,"Answered here: 
stackoverflow.com/questions/64790872/…","Nov 11, 2020 at 18:36",,,,64704448
114335541,114335541,"In my model (XGBoost), all the nodes has leftward as false. Does that mean for missing values, it always goes to right node? I did some testing to print the tree path and I observed thats not the case. I am wondering if inclusiveNa also has something to do with missing nodes.","Nov 3, 2020 at 14:01",,,,64657414
114356191,114356191,"You should generate JSON printout in two ways - first using H2O tools, and then using XGBoost own tools. Perhaps the latter will be more informative/easier to interpret. Right now you have XGBoost model formatted according to H2O decision tree model ""standards""; perhaps this representation is missing some crucial information.","Nov 4, 2020 at 8:12",,,,64657414
114401161,114401161,"I was able to use graphviz and dot format to see the missing node, I think json format to print mojo do not properly show the missing node for the nodes which has two terminal nodes.","Nov 5, 2020 at 16:56",,,,64657414
114115124,114115124,Thanks Neema for the answers and good suggestions! Your questions about my 2nd question are something I need to think about.,"Oct 26, 2020 at 12:51",,,,64509104
113981568,113981568,"That works, but is it only possible to run this service at root? I have a number of other services that I wanted to put on their own subpaths e.g. 
/h2otest
.  How could I run this service at a subpath?","Oct 21, 2020 at 9:14",,,,64459302
113982105,113982105,"That's more of an application configuration issue. Take kibana for example, it has an environment variable called 
SERVER_BASEPATH
 which is exactly for this case. Maybe h2o has similar setting?","Oct 21, 2020 at 9:34",,,,64459302
113753669,113753669,"but still we need to provide username and password right ? in the doc its mentioned  cli = Client(address=address, username=username, password=password)  which requires credentials to initialize a client.","Oct 13, 2020 at 6:08",,,,64312872
113812318,113812318,"Yes, the user will need to log in as the licensed user for that instance","Oct 14, 2020 at 23:17",,,,64312872
132953756,132953756,"This code never uses that 
sort_grid
 function. Anyway that huge 
elif
 block isn't very pythonic. You should probably be using a dict.","Feb 4, 2023 at 21:27",,,,75302587
112486152,112486152,"thanks @deja , I tried following the instruction mentioned in the h2o website, h2o 3.30.1.1 is available in 
h2o-release.s3.amazonaws.com/h2o/latest_stable_R
. But when i tried to load the h2o after downloading it now, i am getting an error message   : Error: package or namespace load failed for ‘h2o’ in get(method, envir = home):  lazy-load database 'C:/XXXX/h2o.rdb' is corrupt","Aug 27, 2020 at 8:23",,,,63610605
112486205,112486205,can you please suggest how to deal with it,"Aug 27, 2020 at 8:26",,,,63610605
111714629,111714629,"Did it.  Identical.  I made sure of that.  That is not the problem.  I made sure to match the data-frame, then transport into h2o.  When I run the predict outside of the optim loop it runs perfectly fine.  It gives results without issue.  It is only when it gets wrapped in optim that it gives the error.  I am currently thinking that R isn't wanting to glue C to Java well here.","Jul 30, 2020 at 14:25",,,,63164270
111724156,111724156,You were right and wrong.  The optim function stripped it of data-frame information.  I augmented the function to put the numeric data into the df form then pass it to h2o.ai and it worked well.  Thank you.,"Jul 30, 2020 at 20:15",,,,63164270
111363905,111363905,"I have converted the target binary variable to factor using asfactor(). As this is a classification problem, I have used H2ORandomForestEstimator and H2OXGBoostEstimator as my base estimators and H2OGradientBoostingEstimator as a meta-estimator inside H2OStackedEnsembleEstimator object.","Jul 19, 2020 at 0:05",,,,62973353
111382465,111382465,I figured out the issue. I mistakenly converted a different target column to factor type. Thanks for the clarification.,"Jul 19, 2020 at 21:08",,,,62973353
111379173,111379173,Thanks Tom for the suggestion!  The code was able to run after I removed the categorical variable that has 5032 unique values. I will think about how to aggregate it into a smaller number of levels.,"Jul 19, 2020 at 18:03",,,,62973351
111317236,111317236,"Thanks for your answer. I am going to try changing seeds and be careful about any small changes in error metrics. Besides, I am also going to change fold_column.","Jul 17, 2020 at 6:46",,,,62945264
111420089,111420089,Thank you very much Erin! Exciting to see what h2o has achieved so far!,"Jul 21, 2020 at 3:43",,,,62959141
111663894,111663894,"Did you always use matching client & server version, e.g. the failing 3.30.0.6 failed with 3.30.0.6 backend ?","Jul 29, 2020 at 4:53",,,,63056849
111702428,111702428,"Thank you, Pavel. That was the problem. Updated the answer accordingly","Jul 30, 2020 at 7:55",,,,63056849
111210812,111210812,"Thanks a lot for the information, Pavel. That helps. Hope we get an update soon with it fixed.","Jul 14, 2020 at 5:56",,,,62776105
111032758,111032758,Thanks for reply. Interesting! Is there any other way this can be achieved as running binary models in prod would mean I am stuck with older version of h2o as time passes!,"Jul 8, 2020 at 3:56",,,,62775816
110544122,110544122,"Thanks, Neema. As mentioned, I don't want to remove all AutoML objects, since there may be objects related to a different session which are still needed. If I can determine - or even better, if I can specify in advance - the 'key' you mentioned ('AutoML_YYYYMMDD_xxxxx'), then I agree I can use this method. Right now I can only think to try parsing the names of the models in my leaderboard to get this, and then following your method. Do you know a better way? I wish h2o had a remove_session_objects() method or something, it would be so much easier.","Jun 22, 2020 at 5:31",,,,62507391
110574569,110574569,"For those searching, the answer to this question is the aml.project_name attribute. You will still have to remove the frames separately (which is easy to do since you created these explicitly anyway), but you can target the rest of the objects with the following command:  h2o.remove([k for k in h2o.ls()['key'] if aml.project_name in k])","Jun 23, 2020 at 0:31",,,,62507391
110575928,110575928,"Nice find! Yes, 
aml.project_name
 will give you the key","Jun 23, 2020 at 2:25",,,,62507391
110483041,110483041,"Yes, you are right! The estimated probability is 0.226, exatcly the value I get when I apply this formula to the value -1.23 in the graph. Thanks a lot!","Jun 19, 2020 at 14:14",,,,62450652
110483097,110483097,"I'm still having problems with this when my predictive variables are categorical. In H2O I don't need to one-hot encode the variables, so I can't use shap directly. And the logic applied to this problem doesn't solve it.","Jun 19, 2020 at 14:16",,,,62450652
110509175,110509175,"Thanks Neema! This is helpful! It shows on that webpage that ""Currently (3.26.0.6 ) you cannot run grid search on isolation forest. One option would be to update the isolation forest implementation so that it can support a validation dataset with a response column."" Does this mean that the isolation forest with grid search supported in 3.30.1.1 will require a response column in the validation dataset? Thanks!","Jun 20, 2020 at 15:17",,,,62481514
110542359,110542359,It should not require a response column. You could try using for loops to get what you need till grid search support comes in 3.30.1.1.,"Jun 22, 2020 at 3:23",,,,62481514
110555004,110555004,"Thanks Neema for the suggestion! I was thinking to do so, but I couldn't find a metric in the output of H2O isolation forest to measure which model is the best. Do you have any suggestion on this? Thank you very much!","Jun 22, 2020 at 12:12",,,,62481514
110558593,110558593,"Neema, I posted another two questions in 
stackoverflow.com/questions/62516100/…
. One of them is the question I just asked here. If you have any suggestions, please provide them under that post. Thanks!","Jun 22, 2020 at 13:58",,,,62481514
110482138,110482138,"Thanks for sharing the notebook. I might be wrong, but looks like h2o is not using the normalization used in the original paper [
cs.nju.edu.cn/zhouzh/zhouzh.files/publication/…
 which is score=2^(-mean length/c(n)), c(n) is alway positive for n>0, so the scores should be always less than 1.","Jun 19, 2020 at 13:49",,,,62465381
123766843,123766843,"As it’s currently written, your answer is unclear. Please 
edit
 to add additional details that will help others understand how this addresses the question asked. You can find more information on how to write good answers 
in the help center
.","Nov 18, 2021 at 4:44",,,,70011697
111092544,111092544,Kindly help to suggest on this...Elasticsearch is no sql database but it provides a sql jdbc driver using which any application can connect and import elasticsearch index table as wrapper sql table.Does h2o sql import support this ?    I am trying to import but only schema(columns ) are imported but no data is imported..,"Jul 9, 2020 at 18:32",,,,62266833
109604495,109604495,Thank you Mr. Cook for your cool help. The issue was that I had installed two different java versions of h2o-3.31.0.5077 and h2o-3.31.0.5079. Now everything works perfect :). Thank you so much Sir and enjoy a pleasantly weekend.,"May 23, 2020 at 9:42",,,,61958803
110606228,110606228,Thank you so much. What a relief!!! I'd appreciate it if you would update the code in the respective notebook as well.,"Jun 23, 2020 at 21:02",,,,61961011
109229080,109229080,Thanks for the answer but I'm only interested in using the H2O package.,"May 12, 2020 at 13:15",,,,61752419
109253599,109253599,"We just made an update to the code to produce a more clear error.  Thanks. 
github.com/h2oai/h2o-3/pull/4605","May 13, 2020 at 4:59",,,,61766740
109290297,109290297,"Got it. Understood now, and makes sense why I was getting the error for some of the cases and not for all. Thanks. Let me look into it much deeper. But, this solves and gives me a better idea for further process.","May 14, 2020 at 1:42",,,,61766740
109394136,109394136,"Thank you! That note in the documentation I've missed. Though, weird that in GBM it works (at least doesn't through an error and trains model)","May 17, 2020 at 8:45",,,,61764153
109083364,109083364,Right but are there any efficiencies to be gained by the fact that the predictors are not changing?  So one should have to read the enter matrix every time which is what will happen with the SVMLight import.,"May 7, 2020 at 22:34",,,,61648444
109011709,109011709,"Thanks for this suggestions. However, I wasn't able to load all 20 cols that was meant to be bound to form the new file. Is there another way to clear some of the data from the RAM during this process? I have tried to do this by dividing them into 4 parts in binding them in two steps but it still failed. Is there is way to write the data directly to the hard disk so I don't keep this data in the RAM?","May 6, 2020 at 4:57",,,,61442498
109029246,109029246,"Without knowing more of your fuller context or reproducible example, not sure if I can help more. Again, I advise to avoid holding helper copies in your global environment that take up memory like 
d2
, 
lai
, etc.. Here reads data directly from disk but can be changed for SQLite with 
dbGetQuery
 into 
h2o
.","May 6, 2020 at 14:27",,,,61442498
108459266,108459266,"I have adapted the question a little. My main question is: Do I have to manually release the memory of all h2o objects at the end of the method? When the method is called too often, it will result in an memory error. Thanks!","Apr 19, 2020 at 18:00",,,,61308425
108490595,108490595,Thank you so much! I will try both out and see how they go. Much appreciated.,"Apr 20, 2020 at 16:12",,,,61293373
108499426,108499426,"If you post data, it should be enough data to reproduce the problem. See 
stackoverflow.com/help/minimal-reproducible-example
 or the R-specific: 
stackoverflow.com/a/5963610/841830","Apr 20, 2020 at 21:02",,,,61293373
108538735,108538735,"Sorry, my fault I am pretty new to stack overflow I will try to figure it out; however, I removed the header row and it worked so thank you for that solution! Im quite new to R so I am trying to learn all these new things :)","Apr 21, 2020 at 22:19",,,,61293373
108546522,108546522,"> I removed the header row and it worked  That is strange, as the data glimpse showed it had correctly interpreted the header row, and the first real data was a 
0
.   Anyway, glad it now works!","Apr 22, 2020 at 6:49",,,,61293373
108220308,108220308,"Thanks a lot for your suggestions and advice. Missed to mention under ""I'm planning to"" section, but I was already thinking to separate out h2o from the flask app and host it in different servers. But no guarantee that this issue will not come again. I'm more interested and looking forward to understand the reason for the memory leakage. I tried GC manually in h2o as I mentoined above.  But no use. Then what is causing this? I don't see anything with h2o.ls() before or after GC (h2o.api(“POST /3/GarbageCollect”); h2o.remove_all())","Apr 12, 2020 at 15:28",,,,61173397
108220440,108220440,"I hope I'm scoring one row at a time -> for 1 user, 2 or 3 types of score-generation (rules) in one HTTP request. Additional to this, 10 + other rules are running. tat is ~10s","Apr 12, 2020 at 15:31",,,,61173397
108915624,108915624,"We have approximately 70 million records(around 90 GB Data) and we need to ingest in h2o and then we need to do modeling in h2o.  Please suggest the approximate h2o distributed environment we need to create..like Heapsize, Number of nodes instances, Nodes configuration and how will multiple instances will communicate..As we need to give estimation to our client..So please suggest these configurations.","May 3, 2020 at 10:32",,,,60699132
108954094,108954094,I recommend accepting the answer to this question and creating a new question.,"May 4, 2020 at 14:34",,,,60699132
107344313,107344313,Thank you very much. It is exactly what I was looking for <3,"Mar 13, 2020 at 14:45",,,,60672395
129848126,129848126,"I really do not follow why the h2o doc is so messy, there are quite a few versions deployed in a few places, and in many cases it is hard to find what I need. This even makes TensorFlow doc look better in comparison, hmm.","Aug 29, 2022 at 15:01",,,,60672395
129874166,129874166,"@VincentYuan it's hard for me to completely disagree with you on this topic: the doc structure is quite old, but we can try to improve its usability. What is your main issue? H2O doc for Py in particular? Can't find the H2O function for a common functionality (even with the search field)? Can't find details or examples about a given function? Cross-referencing?","Aug 30, 2022 at 16:30",,,,60672395
129886051,129886051,"Hi @Seb, are you working at h2o? I can share a few pain points for the Python H2O doc: first of all, put all source of truth in one place, including the doc and the code examples. Then need to optimize the doc structure, for instance, make the doc for each class concise instead of putting them all in one long page, because that leads to searching results linked to multiple classes. also, can optimize the table of content to link to deep level of sections, say methods.  I believe some modern framework like mkdocs-materials provide a good solution, just fyi.","Aug 31, 2022 at 7:31",,,,60672395
111086534,111086534,Perfect! The key fix for me here was to keep the data as a pandas dataframe all the way until it was time to pass the data to the JVM for training. Only then did I convert it to a H2OFrame. Since doing this I'm yet to encounter this problem again.,"Jul 9, 2020 at 15:12",,,,62305338
107012402,107012402,"Hi thanks for the answer, but it's still not worked for me? I've added the error message from h2o.accuracy() and a snippet of the model summary which suggests that it's doing regression rather than classification.","Mar 2, 2020 at 14:42",,,,60490781
117094342,117094342,"The ice_root path seems to redirect some types of log files but not all of them. Even when setting ice_root to a different location. H2O is producing folders in the /tmp directory that look like the examples below. The issue is that if /tmp is ever full, it prevents H2O from even starting in the first place: tmppnjcsy09 tmppotv7bq7 tmpq6qnjq8t tmptkeiujzp tmpud_oc1x0 tmpvish6c5r tmpwldy9f6b tmpwt3z99ss tmpy34xsomx tmpypbdfie3 tmpzi0tvkla","Feb 16, 2021 at 20:12",,,,60439949
134036265,134036265,"ice_root
 is not working for me. When I don't specify it, using 
h2o.init()
, h2o will use 
tempdir()
 as the layover location when I'm writing to S3, which is good. If I do specify 
ice_root
, h2o uses 
/tmp
 as the layover location.  The problem is, when I launch h2o on another server using the CLI, 
tempdir()
 on my driver doesn't exist on the remote server. I have specified 
ice_root
 in this case to a location that is visible by driver and remote server. Still though, it writes to 
/tmp
 which is not good.","Apr 12, 2023 at 14:41",,,,60439949
109598369,109598369,"I confirmed having 
19.3.1
 on the machine I had tried to build with","May 23, 2020 at 1:30",,,,61966139
106689803,106689803,"Did you check your 
h2o
 version?","Feb 20, 2020 at 6:09",,,,60310709
106691577,106691577,H2O cluster version:	3.28.0.3 Python version:	3.7.4 final,"Feb 20, 2020 at 7:36",,,,60310709
106553699,106553699,"yeah, this is what I'm looking for. Interpreting machine learning models, thanks!","Feb 15, 2020 at 15:08",,,,60237223
106450505,106450505,"Thank you, I will use one of the APIs. A workaround with phantomjs sounds hacky.","Feb 12, 2020 at 9:05",,,,60168307
106602796,106602796,"I had that line at the beginning of the code. After some debugging, I realized that there were some transformers in the pipeline (not from the pysparkling package) that were causing the error. I remove them and the import works just fine. Thank you anyway :)","Feb 17, 2020 at 16:54",,,,60254336
106223753,106223753,"The blueprint in the 
cor_fun
 was just what I needed. Also I really enjoyed your regression modeling blog post.","Feb 4, 2020 at 16:04",,,,60054083
106164906,106164906,"Many thanks for the detailed answer. I will try out these suggestions in the next days. However, the data set is very small (263 rows x 25 columns) and I set max memory, so I am unsure how too much memory could occur at all? But lets wait and see what the tests bring about.","Feb 2, 2020 at 19:42",,,,60028598
106219844,106219844,"I would try a different/bigger host first then, to rule out some unknown issue on your own computer.","Feb 4, 2020 at 14:18",,,,60028598
105826254,105826254,"Those are helpful suggestions to work around the limitations of the R API. However, I want to confirm: Are you saying that with the Python API,  
custom_metric_func
 will work how I want for cross-validation? It wasn't clear in the documentation what exactly this option does.  Yes, I need to use R because of its document generating abilities. Another possible workaround is to call the Python API from R using 
reticulate
.   Yes, I have already used 
glmnet
, but H2O has additional statistics for feature importance that 
glmnet
 is lacking and I'm not sure what their formula is.","Jan 21, 2020 at 17:17",,,,59835713
105827600,105827600,"Disclaimer  I have not tried this in R. You write a custom metric: 
mymetric
 in a  script.py   and upload it to the cluster as in 
this link
  then specify the option 
custom_metric_function=mymetric
. This definitively works with 
python
. You could test it in R. Since the function is in the cluster I guess you should be able to access it in R. But is just a guess.","Jan 21, 2020 at 18:10",,,,59835713
105993677,105993677,"I could not understand the custom metric code in the link you provided. For example, their descriptions of 
map
, 
reduce
 and 
metric
 were not clear at all. So I implemented my own lambda loop similar to what you described, but using 
h2o.grid
 to do a grid search on labmda. I will post this in a separate answer.","Jan 27, 2020 at 17:20",,,,59835713
105993749,105993749,Great I am glad you figured it out,"Jan 27, 2020 at 17:23",,,,59835713
105994297,105994297,"Thanks, but it would probably have been better to figure out how to use their 
custom_metric_func
.","Jan 27, 2020 at 17:46",,,,59835713
105443885,105443885,I can export data to csv from mongo and after that I can take data from csv to H2O. But this is two way process. I am looking for any better solution for performance perspective.,"Jan 8, 2020 at 7:30",,,,59640385
120731610,120731610,"I am using sparkML's RandomForestClassifier. From the docs description, would I then just need to set 
numTrees = whatever_id_normally_set * 2
 to have the same situation (or perhaps I am misunderstanding what ""internal"" trees are)?","Jul 9, 2021 at 6:17",,,,59573572
105213654,105213654,Thanks for the suggestion @topchef. I run the code you provided but I received a warning message. Please see the edited version of the question. I am not sure whether it ran properly.,"Dec 29, 2019 at 16:50",,,,59508429
105214516,105214516,@ssaha this appears as different issue not related to the original question. Try searching for answers and if can't find it then post as another question.,"Dec 29, 2019 at 17:44",,,,59508429
105238394,105238394,"I agree with you @topchef, the warning message is not related to the original question. Thanks again.","Dec 30, 2019 at 17:06",,,,59508429
105002047,105002047,"Thank you Erin, it looks this works also with numpy objects like this: 
h2o.H2OFrame(np.zeros([10,5]))","Dec 19, 2019 at 9:52",,,,59398056
105016274,105016274,"About the first bull, I though it was not necessary because I though that performing leave-one-out, I should have avoided the overfitting. Indeed in the cross_validation_metrics they are saying that the metrics are cross-validated. Is the overfitting due to the fact that the meta learner of the Stacked Ensemble is not trained using the cross-validation? In that case I was thinking to run the above code as many times as the number of the instances in my dataset, dropping an instance in each run and use it as validation set, in order to perform by myself the leave-one-out validation.","Dec 19, 2019 at 17:32",,,,59384246
104519380,104519380,"Hi @Erin LeDell, I just re-did h2o.shotdown() and re-run h2o.init() from the R Console and it's still using the old version. Is there a way I can check the updated version is installed? Thanks a lot!","Dec 2, 2019 at 21:14",,,,59146192
104584930,104584930,"Hi @Erin LeDell, I have resolved the issue. I asked my IT to uninstall my Java Run Time environment, re-install then, run the .jar for h2o and it works. Might have been permission issues since IT has administrative rights (Not sure though). Thanks a lot!","Dec 4, 2019 at 17:54",,,,59146192
104590002,104590002,"Hi @Erin LeDell, Turned out the issue props again after I restarted my AWS instance. I am not back to h2o version 3.24.0.5. Do you think it's possibly a systems configuration level issue? Thanks, Zarni","Dec 4, 2019 at 21:21",,,,59146192
104658472,104658472,"@Zami If there's an older H2O cluster that's running, then you'll have to kill it (but I don't know why this would restart automatically after restarting your AWS instance)?","Dec 6, 2019 at 23:32",,,,59146192
104506547,104506547,We tried on single node with 64GB but it didnt work.,"Dec 2, 2019 at 13:27",,,,59078562
104507422,104507422,"We have also tried to provide enough resources. below is one of the config we tried      conf$spark.executor.memory <- ""192g"" conf$spark.executor.cores <-5 conf$spark.executor.instances <- 9 conf$'sparklyr.shell.executor-memory' <- ""32g"" conf$'sparklyr.shell.driver-memory' <- ""32g"" conf$spark.yarn.am.memory <- ""32g"" conf$spark.dynamicAllocation.enabled <- ""false"" conf$spark.driver.memory=""57.6g"" sc <- spark_connect(master = ""yarn-client"", version = ""2.4.3"",config = conf)","Dec 2, 2019 at 13:53",,,,59078562
104507489,104507489,"The data set size is 6GB, we have 300 columns. we have 2500 different values for stratification. more than 70% columns are taken as categorical variables. for sample file T_stop column is varying between .05 - 7 approximately.","Dec 2, 2019 at 13:55",,,,59078562
104099944,104099944,"Yes I understand that but the column type is boolean for the columns, and I believe this line here is causing it to be treated as a numerical value rather than categorical- 
github.com/h2oai/h2o-3/blob/…
, Is this correct?","Nov 18, 2019 at 16:47",,,,58917361
104107355,104107355,"@user12302914 Good find: I'd suggest posting that as a bug (
0xdata.atlassian.net/projects/PUBDEV/summary
), and perhaps as a self-answer. Looks like parquet files need to work the same way as csv files for int (i.e. decide if just a few categories or if they are real numbers) and always treat boolean as enum? (P.S. But do wait for Tom's reply, in case we've both misunderstood that code!)","Nov 18, 2019 at 21:12",,,,58917361
104238604,104238604,@TomKraljevic any thoughts on the above?,"Nov 22, 2019 at 12:18",,,,58917361
104251789,104251789,"Thanks for pointing this out.  The engineering team is taking a look at that.  It does appear to be inconsistent to me, as well.","Nov 22, 2019 at 19:41",,,,58917361
104251819,104251819,"You are right, I think this really is a bug. We turn booleans into 0/1 numeric but we could turn it to True/False categorical instead.  I filed an issue for you 
0xdata.atlassian.net/browse/PUBDEV-7093","Nov 22, 2019 at 19:42",,,,58917361
104076123,104076123,Thanks Nijat. I had to go to workspace -> storageexplorer to locate the file. Glad that I could locate it at last.,"Nov 18, 2019 at 0:59",,,,58906510
104143459,104143459,"From the first link, I guess the values are logit since the distribution is Bernoulli, so I try to recover the logit using 
1 / (1 + exp(-f))
. The values look right but when I try to match them with the values from h2o.predict(), I discovered that I could not reproduce any of them...","Nov 19, 2019 at 20:46",,,,58913968
104145120,104145120,I filtered the data using the tree logic and see what's the unique prediction of that subset. I was able to get some simple threshold such as if the prediction is bigger than -0.002 then yes.,"Nov 19, 2019 at 21:48",,,,58913968
103765801,103765801,Thanks! It would be useful to let user to take control of it.,"Nov 6, 2019 at 20:20",,,,58736635
104010120,104010120,"I don't know if this helps you, but it's possible to override algorithm parameters via the H2O AutoML Python API via a recently added hidden argument called 
algo_parameters
 (for reference). Example: 
github.com/h2oai/h2o-3/blob/…","Nov 15, 2019 at 5:36",,,,58736635
104095596,104095596,Definitely will try it. Thanks for sharing!,"Nov 18, 2019 at 14:41",,,,58736635
104110298,104110298,"@XWen Make sure to download the nightly release as this has not been in a stable release yet. 
h2o-release.s3.amazonaws.com/h2o/master/latest.html","Nov 18, 2019 at 23:22",,,,58736635
103654053,103654053,Thank you for the reply. I'm running Version: 3.26.0.8.,"Nov 3, 2019 at 0:49",,,,58675987
103654106,103654106,"Sorry, hit reply too soon.   Here's the autoML statement.   !
imgr
   I get this error in the console:    15532  FJ-2-21   WARN: Grid search: model builder for parameters hex.tree.gbm.GBMModel$GBMParameters@11ee9a55 failed! Exception: java.lang.IllegalArgumentException: class_sampling_factors must have 2 elementsjava.lang.IllegalArgumentException: class_sampling_factors must have 2 elements","Nov 3, 2019 at 0:55",,,,58675987
103772176,103772176,"I tried your  example after updating to the most recent version, and am still getting the same error.","Nov 7, 2019 at 2:43",,,,58675987
103637956,103637956,Thanks a lot TomKraljevic. I have got a more clearly understanding by now. Your first-two-sentences worth hundreds of h2o manual pages.,"Nov 2, 2019 at 1:26",,,,58661954
103570630,103570630,Thank you for your reply. Secondary question. Is it redundant to have both validation set and nfold parameter?,"Oct 30, 2019 at 18:38",,,,58631479
103570802,103570802,"Great question @user1700890, from the scientific papers I have read, k fold is cross-validating right, so you don't need another data partition that is specifically validation. However this point is debatable. I have read scientific papers that suggest cross-validation produces estimates with lower error bias in comparison to just using a validation data partition. Personally, I only using kfold cross-validation, not a validation data set.","Oct 30, 2019 at 18:44",,,,58631479
103570906,103570906,"Some great reading material if you have time.(1) Koul A, Becchio C, Cavallo A. Cross-Validation Approaches for Replicability in Psychology. Front Psychol. 2018;9. doi:10.3389/fpsyg.2018.01117 (2) Jung Y, Hu J. AK-fold averaging cross-validation procedure. Journal of Nonparametric Statistics. 2015;27(2):167-179. doi:10.1080/10485252.2015.1010532 (3) Kohavi R. A Study of CrossValidation and Bootstrap for Accuracy Estimation and Model Selection. International Joint Conference on Articial Intelligence (IJCAI). 1995.","Oct 30, 2019 at 18:48",,,,58631479
103623175,103623175,"Thanks for the submission, but since the models will need to be accessed by all team members, we would need to mount a network drive and at that point it starts becoming a bit more work. I will post an answer for the solution I used.","Nov 1, 2019 at 13:27",,,,58652055
103540963,103540963,"Thank you, I wish they highlighted 
ordered
 in error message: 
Provided column type ordered is unknown","Oct 29, 2019 at 21:22",,,,58615548
103541064,103541064,"Yes. 1) they should report something like 
Provided column type ""ordered"" is unknown
, and 2) they could probably still recognize that it inherits from 
factor
, and so maybe it should not produce an error in the first place.","Oct 29, 2019 at 21:27",,,,58615548
103541930,103541930,"I personally think we should just do the conversion automatically and provide a warning. I have filed a ticket here to fix: 
0xdata.atlassian.net/browse/PUBDEV-5798","Oct 29, 2019 at 22:17",,,,58615548
103496169,103496169,I see...the wierd part is that XGBoost does support Windows (I can run it separately in Windows via the CMD)...And after I build the XGBoost dll and copied it to my java lib folder H2O also loads Xgboost when it starts up + makes it visible in the UI...so everything seems to work in regards to installation/setup - but eventually it doesn't when I actually try to use it :(,"Oct 28, 2019 at 13:14",,,,58583275
103500909,103500909,"Did you run the 
xgboost
 on vanilla windows, or did you setup some virtual env to run your model.","Oct 28, 2019 at 15:41",,,,58583275
103503167,103503167,plain vanilla Windows 10 64 bit,"Oct 28, 2019 at 16:55",,,,58583275
103503265,103503265,"I will have to check then, as still 
xgboost
, is not available for windows.","Oct 28, 2019 at 16:58",,,,58583275
103904277,103904277,FYI (I ended up installing Ubuntu as my second OS): XGBOOST is integrated into the Linux version (you don't have to manually compile the dll first - like in the Windows version).,"Nov 12, 2019 at 6:08",,,,58583275
103607260,103607260,Hmmm. I've tried using comma delimited strings with no luck,"Oct 31, 2019 at 21:14",,,,58494695
103272659,103272659,Can you please explain how yours is different and therefore correct. Just dumping some code out gives zero context,"Oct 20, 2019 at 1:02",,,,58469171
103272718,103272718,I think only exclude_ algos = [ '.....'] and  project_name = 'gtp' need to be added to the python version of codes. Is there any problem?,"Oct 20, 2019 at 1:10",,,,58469171
102987898,102987898,thanks for the answer and i assume you work for h2o and is the credible source. if you can add some reference it would be even great.,"Oct 9, 2019 at 23:37",,,,58275180
102835268,102835268,Is there any conda env recipe that could be used?,"Oct 4, 2019 at 5:48",,,,58226069
102850680,102850680,"@GuillermoEPonce-Campos are you referring the DAI python client package? 
anaconda.org/h2oai/repo
 and documentation here 
docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/…
.","Oct 4, 2019 at 15:10",,,,58226069
102871900,102871900,"Thanks, I'll check that.  I want to setup h2o.jar and DAI in an HPC system.  So far the h2o.jar is working in one node but still struggling to make it work with 4 nodes.  I've tried the -flatfile and -network parameters and still not able to make it work.  I did a question regarding this in the h2o gitter channel, are you in there?","Oct 5, 2019 at 17:36",,,,58226069
102405280,102405280,"For others finding this post, note that I am not trying to do user impersonation from root as the answer here seems to imply (the original post only uses root as a test). Basically, the main takeaway from the answer is that h2o expects the calling user to have a home folder existing in 
hdfs:///user/<username>
.","Sep 18, 2019 at 19:38",,,,57987997
102435614,102435614,"For the record, Spark also uses the HDFS HomeDir by default, it's a common pattern.","Sep 19, 2019 at 17:09",,,,57987997
102246791,102246791,"While this code may answer the question, it would be better to explain how it solves the problem without introducing others and why to use it. Code-only answers are not useful in the long run.","Sep 12, 2019 at 20:13",,,,57907016
102059583,102059583,"Thanks, @ErinLeDell. Do I need any additional set-up to enable de GPU instance to work with H2O AutoML? Like, install some libraries or anything else?","Sep 6, 2019 at 0:00",,,,57814156
102065343,102065343,"You need to check that you have Nvidia GPUs and CUDA 8 installed.  You can monitor the GPU usage during the AutoML run via the command line using the 
nvidia-smi
 command.","Sep 6, 2019 at 7:13",,,,57814156
102076742,102076742,"Thanks, @ErinLeDell, another doubt! To get both installed, can I only install CUDA Toolkit? I saw on Cuda's website that the most recent version of CUDA is 10.1.243, could I install that version(10) or I need specifically to install the version 8?","Sep 6, 2019 at 13:49",,,,57814156
110909447,110909447,"@Erin LeDell, can the H2O AutoML XGBoost utilize TPU in Google Colab?","Jul 3, 2020 at 14:26",,,,57814156
111336407,111336407,"@Md.HishamurRahman No, there's no TPU support, just GPU.","Jul 17, 2020 at 17:39",,,,57814156
101992695,101992695,"1) Looking at the downloads page, can't tell how h2o would be run on multiple nodes without using hadoop (saw something similar here (
stackoverflow.com/a/50766014/8236733
), but could not tell from the linked docs which lead to... 2) Would the model training and prediction performance be slowed if had same mem/cpu, but on a single machine (the original intent of my question)?","Sep 3, 2019 at 21:24",,,,57778839
101994193,101994193,"1) standalone h2o can be run on multiple nodes using the flatfile approach:  
docs.h2o.ai/h2o/latest-stable/h2o-docs/…","Sep 3, 2019 at 23:22",,,,57778839
101994199,101994199,2) it depends.  you have to try.,"Sep 3, 2019 at 23:22",,,,57778839
101991676,101991676,"I see, thanks. For others finding this post, found links here (
docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.0/…
) and here (
docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.0/…
) that may be helpful for further understanding.","Sep 3, 2019 at 20:31",,,,57778286
101962468,101962468,"In your original post, you have 26.67GB in memory given to the H2O cluster and here you are actually using 
more
 memory than you were before (40GB).  Are you sure that you need to limit the number of threads to 2? If you have 72 available, it would be a shame to not use them.  I would start by lowering incrementally to see where the issue is rather than trying 2.","Sep 2, 2019 at 22:58",,,,57759360
101972190,101972190,"When I limit the max memory to 200 GB without nthreads, exception is same. I solve it when number of threads param is limited. Herein, 2 threads is just a trial. It returns exception when nthreads is greater than 36 (half of my total cores).","Sep 3, 2019 at 9:11",,,,57759360
124046021,124046021,"As it’s currently written, your answer is unclear. Please 
edit
 to add additional details that will help others understand how this addresses the question asked. You can find more information on how to write good answers 
in the help center
.","Nov 30, 2021 at 16:04",,,,70171016
101992876,101992876,Thank you so much.  I ended up converting it to panda frame and used the display format.,"Sep 3, 2019 at 21:35",,,,57752985
101673367,101673367,Thanks a lot for the good input. I think it will be very useful if they add option to control the shuffle in h2o flow.,"Aug 22, 2019 at 12:09",,,,57599747
101676852,101676852,"no problem! were you able to create the JIRA tickets for your two issues? Instructions on how to create JIRA tickets can be found here:
github.com/h2oai/h2o-3#21-issue-tracking-and-feature-requests
.","Aug 22, 2019 at 13:45",,,,57599747
101682268,101682268,"Thank once again for sharing the link. I don't have experience with JIRA tickets but I shall try for it. About the date issue, I can fix it in R with the following commands    test$date <- as.POSIXct(test$date/ 1000, origin=""1970-01-02"") test$date <- format(as.POSIXct(test$date,format='%m/%d/%Y %H:%M:%S'),format='%m/%d/%Y'). But I could not fix the split issue of H2O Flow.","Aug 22, 2019 at 16:26",,,,57599747
101683074,101683074,"if you are using the latest version of H2O, you shouldn't have to fix the date format, it should be handled automatically. But yes, if you are using an older version you may still see the issue. It would be awesome if you could create the JIRA for flow for the time issue and the split issue. thanks again!","Aug 22, 2019 at 16:58",,,,57599747
101694312,101694312,I am using h2o-3.26.0.2 and I think this is latest version. As the mentioned that date should in this format 2004-02-01. But date issue is still there.,"Aug 23, 2019 at 4:54",,,,57599747
101621736,101621736,"Thanks for the quick response @not-dave that's how I would import a binary model file but, int my case, I wish to import a MOJO export. If I unzip that .zip I have three folders (domains, experimental, trees) and a file (model.ini). As h2o binary models are only compatibles with the same version, I wish to import a MOJO into R so no different version issues appear. Thanks again","Aug 20, 2019 at 20:30",,,,57580842
101622152,101622152,"see my updated answer above. I believe you want to use the model to do some predictions. You can use 
mojo_predict_df
 function to do that.","Aug 20, 2019 at 20:50",,,,57580842
101631279,101631279,Thanks for the answer. Edited my post and added the locale settings.,"Aug 21, 2019 at 7:45",,,,57578655
101631575,101631575,"I got the error right after running the 
h2o.gbm
. (Or 
h2o.grid
). The encoding is UTF-8.","Aug 21, 2019 at 7:56",,,,57578655
101634668,101634668,"Unfortunately, I am in a highly regulated environment and cannot edit/change .Rprofile, or system settings as I lack administrative rights. Sys.setlocale() does not allow me to make changes. Sys.setenv(LANG) works but does not change anything in the locale settings. If there is any h2o package specific setting that allows the umlaut in the column names, is what I'd like to do.  (The normal session, 
data.table
 or 
data.frame
 works with these column names.)","Aug 21, 2019 at 9:33",,,,57578655
101698255,101698255,"@maop Maybe you could try starting h2o from the commandline, instead of using 
h2o.init()
. Or, if you call 
h2o.init()
 after your 
Sys.setenv()
 call, does it work?  But I'd also try to persuade your system administrators to embrace UTF8/Unicode and move on from 20th Century encodings  :-)","Aug 23, 2019 at 8:05",,,,57578655
101698366,101698366,"Persuading sys admins is a good advice :) I tried initializing h2o after I made sure that I called setenv(). I kind of gave up and changed the column names using 
setnames()
 and assigning new names like this: 
paste0(""v"", seq(1, length(predictors), 1))
.","Aug 23, 2019 at 8:10",,,,57578655
102003552,102003552,thank you... we were hoping this is silly mistake on our side.. probably would be worth to have something like this documented in H2O AutoML FAQ section,"Sep 4, 2019 at 9:04",,,,57763395
102019850,102019850,"Agreed!  The docs could be improved.  I will extend the H2O AutoML demo in the user guide 
0xdata.atlassian.net/browse/PUBDEV-6845
 and improve the general ""Prediction and Performance"" section as well: 
0xdata.atlassian.net/browse/PUBDEV-6849","Sep 4, 2019 at 17:35",,,,57763395
101611742,101611742,"Thank you @pat-s. The h2o learner expects ""hidden_dropout_ratios"" parameter to be of the same length as the number of hidden layers. Am I correct to think that if one tunes the number of layers via the ""hidden"" parameter there is no way to specify the  ""hidden_dropout_ratios"" in mlr? Not even if I would like to specify one dropout value for all layers? This is what I tried in the second attempt. The 
makeModelMultiplexer
 approach runs sold for me now.","Aug 20, 2019 at 14:22",,,,57575551
101619378,101619378,"hidden_dropout_ratios
 needs to be a VectorParam as the error msg indicates. So when you tune it, you won't get the same value for each 
hidden
 layer, yes. You can set a fixed value for all layers by declaring the parameter via 
param_vals
 during learner creation and removing it from the ParamSet. ParamSet = used in tuning, 
param_vals
 = fixed across all instances","Aug 20, 2019 at 18:46",,,,57575551
127150238,127150238,A similar solution worked for me!,"Apr 21, 2022 at 15:03",,,,66777374
101460772,101460772,"I'm running H2O as a Hadoop job. According to H2O's document, Hadoop job is the only way to connect Kerberlized Hive. I tried standalone too, with kerberos authentication like you posted above, but no lucky.","Aug 14, 2019 at 13:19",,,,57490426
101499729,101499729,"if you are running as hadoop job you need to make sure hive is on mapreduce classpath, either via libjars or via hadoop conf","Aug 15, 2019 at 20:33",,,,57490426
101625946,101625946,"Thanks for your reply. I've checked classpath, I think it's on the right place. I think the instance of 
GroupMappingServiceProvider
 is not expected, but I don't know how to setup a right instance.","Aug 21, 2019 at 2:12",,,,57490426
101343387,101343387,"Thank you TomKraljevic, I could import the model, but this was a random forest model. Later I am passing this model to H2OTree method. But I get an error that this is not a tree based model. I think it gets imported as MOJO model. Is there any way to import tree based model.","Aug 9, 2019 at 14:59",,,,57421285
101362952,101362952,"Instead of exporting a MOJO, you can call saveModel and loadModel.  But the H2O-3 software version number needs to be the same.","Aug 10, 2019 at 15:32",,,,57421285
101405458,101405458,"Yes, but this model was exported as mojo in past.","Aug 12, 2019 at 18:04",,,,57421285
101122056,101122056,"That is what I ended up doing.  I tried stacking, but these are million by hundred size arrays right now and they can overwhelm the 32-bit java.  I think Oracle is trying to kill the Java market because I have to sign a contract with them to download the java that h2o.ai needs to operate, in this case with much more RAM.","Aug 1, 2019 at 18:34",,,,57304970
101905183,101905183,"If you look at 
hadoop.apache.org/docs/r2.9.0/hadoop-yarn/hadoop-yarn-site/…
 you see that the application is started as the user implying that all NMs need to have that user present.","Aug 30, 2019 at 20:00",,,,57699900
100929850,100929850,"THANK YOU! I have been trying to figure this out for hours yesterday. I had no idea the issue was with my computer having no Java. Using the 
java -version
 helped me realise I did not even have Java installed - after installing Java, H2O is finally working","Jul 26, 2019 at 1:26",,,,57210872
100929902,100929902,"Thank you, I wasn't sure which package to use or that the h2o-py and the h2o from anaconda was not official. I initially thought it had to do with the combination of packages but from TomKraljevic's answer, it turns out it I was just missing Java. I actually already tried 
conda install -c h2oai h2o
 but kept getting the CalledProcess Error. After getting Java instaled, I could run 
h2o.init()
 using the official h2o package from 
conda install -c h2oai h2o
 without any errors.","Jul 26, 2019 at 1:33",,,,57210018
100777388,100777388,Explain why this will solve the issue and also explain why the user is having an issue with existing implementation.,"Jul 21, 2019 at 5:23",,,,57130323
100795457,100795457,"Hi Harish, We have installed the suggested jar file but we are still getting the same error.","Jul 22, 2019 at 6:10",,,,57130323
100798784,100798784,Please type here: h2o version used in this run-time and the jar file version attached as well.,"Jul 22, 2019 at 8:16",,,,57130323
100799230,100799230,"Please modify 
sparkling_water_assembly_2_11_2_4_xx_all.jar
 as well.","Jul 22, 2019 at 8:33",,,,57130323
100518073,100518073,"The problem with that is that the algorithm then picks 'red, blue, green' as one string rather than 3 distinct colors. Meaning, if one cell is 'red, blue, green' and the other cell has 'blue, green, red' they will be looked at as they are not the same.","Jul 11, 2019 at 14:41",,,,56979048
100520403,100520403,"yes, they will not be same. If you want the model to treat them same then you can also sort these strings so that same color patterns will always look same, or use encoding to solve the issue.","Jul 11, 2019 at 15:47",,,,56979048
100520689,100520689,"I just need a model that differentiate between the different list items. Sorting the list won't make much sense in the case where list1=[blue,red,green], list2=[blue,black,green], since these 2 lists will be looked at as 2 different items rather than understanding that they share 2 similar colors. Using encoding will make the model not as accurate since the dimensionality will exponentially increase as there are many colors. Also, using one-hot-encoding is bad for decision trees from my understanding for other reasons.","Jul 11, 2019 at 15:56",,,,56979048
100451037,100451037,"What do you mean that the levels are decided by the depth? The model has 200 categorical variables so it looks pretty clear that there are 100 on each side of the first node, and 96 and 4 on the last one. And what does probability 1 at 
c
 or probability 1 at 
z>10.0325
 mean?","Jul 9, 2019 at 15:49",,,,56956107
100451224,100451224,"That is not how decision tree works... from the image provided, the right subtree from root ends at the first level","Jul 9, 2019 at 15:54",,,,56956107
100451911,100451911,You can see from the tree that the model checks z for a greater threshold and if that fails it checks it for smaller threshold and if it still fails than the prediction is 0.0 else it checks c and makes the final prediction.,"Jul 9, 2019 at 16:16",,,,56956107
100452105,100452105,"Almost got it, thanks! So if you look at the last level, where there is 96 on the left and 4 categoricals on the right, what does the 96 level means? Does the model check c, and if it has those 4 categoricals the probability is 1, and if its c with 96 other categoricals its 0?","Jul 9, 2019 at 16:22",,,,56956107
100452220,100452220,"is your problem binary classification and are you building one tree for every class. In that case the meaning of probability changes but rest will remain same. So verify that. If you are building multiple trees, then the leaf values will show the probability of the prediction to belong to that class.","Jul 9, 2019 at 16:26",,,,56956107
100421185,100421185,"Does that show the prediction (the final result / 
model.predict()
) or just a single tree?","Jul 8, 2019 at 18:17",,,,56940361
100423078,100423078,Just a single tree (hence the --tree parameter).,"Jul 8, 2019 at 19:35",,,,56940361
100423184,100423184,"So do I need to call 
predict
 somewhere to get the actual result and then graph it?","Jul 8, 2019 at 19:39",,,,56940361
100429407,100429407,"No, it's not visualizing predictions.  It's visualizing a tree of the model.","Jul 9, 2019 at 3:17",,,,56940361
100433846,100433846,"Hi, may I know how to set as factor in h2o Flow UI?","Jul 9, 2019 at 7:20",,,,56931994
100436221,100436221,"Following the example, the factor was type enum so I have set my response as enum when I parsed the data in Flow but still, no ROC curve plotted.","Jul 9, 2019 at 8:37",,,,56931994
100436714,100436714,"I have manually set my respond column as factor in command line, write back as csv in local and follow the example again, and I still can't get h2o to plot ROC curve. Please help.","Jul 9, 2019 at 8:53",,,,56931994
110471660,110471660,"@the775 Check in Flow to see what data type actually got imported. That is Python code? Should be 
df['target_cured'].asfactor()
 See 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/…","Jun 19, 2020 at 7:39",,,,56931994
110521294,110521294,"Hi Darren, I found the error. I was trying to cast my 
df['target_cured']
 to a category 
before
 casting to an H2OFrame. Needed to cast to H2OFrame, 
hf = h2o.H2OFrame(df)
 then run 
hf['target_cured'] = hf['target_cured'].asfactor()","Jun 21, 2020 at 5:22",,,,56931994
100360094,100360094,will my data stay on my local machine though or be sent to h2o server? couldn't figure out how does the API works (if it keeps my data or get access to it),"Jul 5, 2019 at 18:24",,,,56907485
100360284,100360284,"@welo121 When you run 
h2o.init()
 the H2O instance will be initialized wherever you run this command (like your local machine). Then when you move data into this H2O instance it will still be on your local machine.","Jul 5, 2019 at 18:34",,,,56907485
100360366,100360366,so the data will never leave my machine into a server or something? have to make sure because its confidential data,"Jul 5, 2019 at 18:39",,,,56907485
100373477,100373477,"@welo121 It is a server/client architecture, but by default both server and client are on localhost, so your data will not leave the machine.","Jul 6, 2019 at 15:21",,,,56907485
100378342,100378342,"if the h2o.init() ""ip"" parameter is localhost, then the data is not leaving your machine (the data is sent to localhost).  if the ""ip"" parameter is not localhost then the data will leave your machine (and be sent to the machine you named in the ""ip"" parameter).","Jul 6, 2019 at 21:35",,,,56907485
100335866,100335866,"Please give more detail on the first part. Also I think any answer should explain why 
valid=True
 and 
test_data=val
 are the same while their training counterparts are different.","Jul 4, 2019 at 22:46",,,,56894701
100341735,100341735,"See 
github.com/h2oai/h2o-3/blob/…
 for the actual code","Jul 5, 2019 at 7:06",,,,56894701
100341884,100341884,"@LoMaPh When using 
train=True
 or 
valid=True
 it is reporting the value on that data set from training. It is a helper function to extract just one bit of information. When you give a data set, it instead makes predictions using it. With the validation data set the results are obviously identical, as it was evaluated at the end of training. (From memory the training error is the error during training, not at the end, which would explain why it is worse.)","Jul 5, 2019 at 7:14",,,,56894701
100341970,100341970,"I can't (quickly) find a good reference on that, but did find 
0xdata.atlassian.net/browse/TN-9
  which shows how it is different when using balanced_classes, at least.","Jul 5, 2019 at 7:18",,,,56894701
100353855,100353855,"A possible reason why validation 
mae
 remains same is because during training, the model never learns from the validation data. It makes prediction on the validation set for tuning parameters both during training and testing, hence same result.","Jul 5, 2019 at 14:05",,,,56894701
100307304,100307304,"But let's say if I decided I want to use threshold = 0.5, how can I set this in the H2ORandomForestEstimator?   Is there some parameter that is similar to the threshold in the documentation -> 
docs.h2o.ai/h2o/latest-stable/h2o-py/docs/…
?","Jul 4, 2019 at 0:48",,,,56873438
100354322,100354322,"You cannot.  You need to take the trained model, make a prediction with it, take the resulting calculated probability, and then compare it with your custom threshold.","Jul 5, 2019 at 14:23",,,,56873438
100002876,100002876,"Thanks very much for pointing out the difference in training steps. Even though after changing to 
H2OAutoML(..., nfolds = 0)
, there are still minor performance differences. More importantly, however, is how to get the training steps of sklearn-xgboost be similar to H2O's, rather than 
downgrade
 H2O's to be like sklearn's. To achieve this, would calling 
xgb_clf.fit(train_df.drop('target', axis=1), train_df['target'])
 three times be sufficient?","Jun 23, 2019 at 4:36",,,,56683304
100030613,100030613,"Fitting three times wouldn't work since you divide your training set in three when you use k-fold operations. So you would have to get the exact same three folds that H2O made. You could try the option 
keep_cross_validation_fold_assignment = True
 to keep them.","Jun 24, 2019 at 11:51",,,,56683304
100031014,100031014,And did you try to transfer all the features of your H2O xgboost model @B.Sun ? You only transfered 10 in your example,"Jun 24, 2019 at 12:04",,,,56683304
100053565,100053565,"Would you mind to be more specific on ""transfer features""? Do you mean 'asfactor'?","Jun 25, 2019 at 6:07",,,,56683304
100063819,100063819,"Sorry I wasn't very clear, I meant fixing all the parameters in the XGBoost to be the same as in your h2o model. You did it for some parameters but not for all. For example your didn't fix the 
min_child_weight
 parameter in your XGBoost model to be the same as your h2o model","Jun 25, 2019 at 11:36",,,,56683304
99689373,99689373,"Honza, I'm sorry there was a problem with my SQL statement and I got misled by it (the example I gave was made up for illustration purposes as I cannot reveal my actual SQL which is very complex). I tried a simpler import and was able to confirm that the problem was not with H2O. NULL values are in fact recognized as NAs. It's just that when you preview a H2O Frame on the python console, there is no distinction between NAs and empty values for string columns. Whereas for numeric columns, NAs are explicitly printed as 'nan'. It makes sense for it to be that way though.","Jun 12, 2019 at 3:09",,,,56551971
99362352,99362352,"Thanks a lot. I get it. So firstly, gbm do the cross validation step on training set. Next, based on the finished cross validation, gbm will give the score on validaton frame.","May 30, 2019 at 15:18",,,,56358795
99055536,99055536,"I think I managed to get the CV predictions like this: 
model_ids <- as.data.frame(m@leaderboard$model_id)[,1];    se <- h2o.getModel(grep(model_ids[1], model_ids, value = TRUE)[1]);   metalearner <- h2o.getModel(se@model$metalearner$name)
, then I calculated the AUC manually","May 20, 2019 at 8:58",,,,56187032
99076627,99076627,"I see, so I am assuming then that the reason some of the 
enum
 fields do appear to be split by subset (rather than inequality operation) is because for those columns, there are less possible labels. I this correct or is there some other reason for some categorical columns splitting as expected and other not?","May 20, 2019 at 21:08",,,,56226089
98774550,98774550,"Thanks for your comment. However, it seems weird that H2O Flow does not handle merging dataset on string columns and would force you to convert to Enum. I end up merging the two datasets using Python Pandas library before feeding to H2O. That worked for me.","May 9, 2019 at 20:52",,,,56066992
98775145,98775145,"the reason that the conversion to enum is necessary is because h2o-3 performs a sort before doing the merge. You can convert back to string afterward if needed. Alternatively, if you feel like this feature would be a nice add, you can create a request for it via h2o.ai's jira system. 
jira.h2o.ai
. thanks!","May 9, 2019 at 21:19",,,,56066992
98743027,98743027,"Thanks Darren! I am trying it now. Actually, the dataset was prepared by the extraction of features from pre-trained deep learning pooling layers. It is the features from indoor image. I am trying it and let you know what happens. Thank you so much.","May 9, 2019 at 1:15",,,,56047978
98743345,98743345,"I tried to use h2o.prcomp(), but it gives an error: Gram matrices (one per thread) won't fit in the driver node's memory (4.060 TB > 18.85 GB) - try reducing the number of columns and/or the number of categorical factors.  I am now trying with experimental way. Add some layers and experiment. Let you know what happens.","May 9, 2019 at 1:41",,,,56047978
98747585,98747585,"Re 
h2o.prcomp
 wanting 4TB for a matrix that should only need 2GB (at 8 bytes per value): are all the columns numeric, or are some factors?","May 9, 2019 at 6:27",,,,56047978
98747879,98747879,Last column is factors which i remove for unsupervised training. The total size will be 5360*51200. All data are of float type. I also tried stacked autoencoder with fewer layers e.g 200 and trained with mse. It is giving less than 0.0108 loss for both validation and training set. I splited training set into train:val for 8:2 ratio. Is it a good direction?,"May 9, 2019 at 6:40",,,,56047978
98849681,98849681,"in the documentation, jdbc:redshift://xxxx.xxxxzubx6zm.us-west-2.redshift.amazonaws.com:5439/dev is a working jdbc url, infact i use same for my ide. but it fails to connect with this in h20 flow. its not about file formats but database connectivity with fetch data from tables","May 13, 2019 at 8:03",,,,56067119
99150618,99150618,Thank you - do you think it would make sense to be able to get these metrics in a 'more natural' or 'accessible' way in the future?,"May 23, 2019 at 2:45",,,,56137278
98593195,98593195,"tried the balance_classes but still , ROC AUC was 0.99 and the AUCPR was 0.03 .... so or the measurment is problematic or there is something not right with the balance classes, is there a limit to how much it can balance, if the data set is highly imbalance, does it still works ?","May 3, 2019 at 13:51",,,,55952771
98693409,98693409,"ROC AUC is not a good metric for highly imbalanced classes, so I would recommend not even looking at it. The low AUCPR suggests your model simply does not work well. What exactly is the proportion of the classes? If you have a very rare event/class to detect, you can also consider casting the problem as an anomaly detection. There's Isolation Forest model available in H2O that can do that.","May 7, 2019 at 14:28",,,,55952771
98560808,98560808,"Hi, Lauren. Thanks for your explanation for the weights. I guess I should have made my question clearer. What I am trying to understand is: why we need to include weights in the example from the document, and why we only included it in the training frame, not the calibration frame. Moreover, are weights necessary when we want to calibrate the probability? The comment didn't give any explanation on all these questions.","May 2, 2019 at 14:18",,,,55938118
98450180,98450180,"thank you for the answer, i've already installed h2o package but still encounter the problem. what i have to do next?","Apr 29, 2019 at 4:32",,,,55893702
98387465,98387465,"Ok. However it'd be useful to expose a 
grid_id
 parameter for the autoML function, so that you can train different models over different training sets in a loop, even if you don't parallelize them. Isn't it?","Apr 26, 2019 at 8:24",,,,55856332
98666057,98666057,The idea is to prevent people from comparing models trained on different training sets because in general that is probably a mistake (unless you're taking equal sample sizes of the whole training set).  The better way to do it is to train different AutoML objects (one for each training set).,"May 6, 2019 at 18:14",,,,55856332
98343416,98343416,Sure... accept and or upvote the answer and I'll get that much closer to the clouds... :),"Apr 24, 2019 at 23:36",,,,55776934
98128927,98128927,Thank you so much! i have seen this information and it didn't work out for me. anyhow i went all the way around by filtering database first. thank you again!,"Apr 17, 2019 at 10:07",,,,55713731
97939002,97939002,"We have tried MOJO option, but had difficulty in converting feature extraction logic from Python to Java. So we have kept the model as binary in H2O cluster and feature extraction logic in python. Any suggestions with the current deployment setup?","Apr 11, 2019 at 0:33",,,,55621782
97969107,97969107,"You can use MOJOs without using Java.  Keep all your same code in Python (including feature extraction logic), but save a MOJO model instead of a binary model and swap out the predict step with the 
h2o.mojo_predict_pandas()
 function.","Apr 11, 2019 at 18:36",,,,55621782
98002541,98002541,Thank you Erin. This is very helpful. Seems this feature is introduced in H2O 3.20.0.4 version.,"Apr 12, 2019 at 17:37",,,,55621782
99952892,99952892,"@Mohan I'm not sure what you mean by ""spawn a new JVM"".  Do you mean ""spawn a new H2O cluster""? One of the advantages of using MOJOs for scoring is that they don't require the H2O cluster to be running.","Jun 20, 2019 at 21:03",,,,55621782
99979077,99979077,"When the mojo_predict_pandas() method executed by H2O, we are seeing one JVM process per transaction in process monitor. It gets initiated per transaction and terminates after the transaction is complete. If you consider app server like JBOSS, it creates one JVM and all the requests go to the same running JVM. Agree that H2O cluster is not created but it is still initializing the H2OLocalServer to find JVM path. Any way to avoid H2OLocalServer initialization?","Jun 21, 2019 at 17:21",,,,55621782
115549818,115549818,"I am looking at this response right now and I think that the documentation was changed and does not mention what is the immediate result. The part: ""collinear columns will be dropped from the model and will have 0 coefficient in the returned model."", seems to be missing from the docs.","Dec 18, 2020 at 15:01",,,,55751434
97715818,97715818,"The docs don't seem to indicate that a specific column can be converted, only the entire frame. Is this true?","Apr 3, 2019 at 22:00",,,,55504435
97742376,97742376,"yes you can convert a column, please see our code examples in the user guide appendix, whenever there is a numeric column response column that needs to be converted to enum we apply .asfactor() to that single column. 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…
. hope this helps!","Apr 4, 2019 at 14:47",,,,55504435
100725446,100725446,"df['col_name'] = df['col_name'].asfactor()
. Similarly for the other two types.","Jul 18, 2019 at 20:35",,,,55504435
97713262,97713262,"Thanks for the debugging avenues. What worked was opening the browser to h2o connection url (could not do previously for still unknown reason) and check logs in the Admin>View Logs tab. Was able to connect to the url from VM developing in, but not from browser on the host. Any reason for this? Main problem ultimately due to a variable passing wrong value to the 
weights_column
 param in the 
model.train(.)
 call (embarrassingly, doubt my 
specific
 solution is useful to most people). Any reason why a 
weights_column
 must be specified at both model instantiation 
and
 in the 
.train()
 call?","Apr 3, 2019 at 20:10",,,,55498254
97714317,97714317,"@lampShadesDrifter According to the python example at 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…
 you only need to give it in the 
train()
 call.","Apr 3, 2019 at 20:50",,,,55498254
97756948,97756948,"Interesting. Running the example, it appears that having the 
receipt_key
 be an 
enum
 type is what makes the difference. Could you explain a bit what difference this makes in avoiding what would otherwise appear as something like left-join duplicates? How is the row from df2 selected? Are they just being dropped if df1 already maps to another similar-keyed row at a lower frame index (like a 
intersect
 operation)?","Apr 4, 2019 at 23:49",,,,55524714
97451661,97451661,"Thanks for your response but the algorithm is talking about the aggregation process which is not my question. I am looking for the prediction value which is a number between [0,1] interval and appears at the leaf node for just a sample tree.","Mar 26, 2019 at 18:23",,,,55359544
97451726,97451726,"in order to make in clear, I ran my h20 random forest by one tree to see if the prediction value in leaf nodes are basically the same as probabilities but they are not the same !\","Mar 26, 2019 at 18:25",,,,55359544
97451832,97451832,"a sample tree that I am talking about is plotted here  
h2o.ai/blog/finally-you-can-plot-h2o-decision-trees-in-r","Mar 26, 2019 at 18:29",,,,55359544
97460041,97460041,I updated the answer above.  Try single-stepping score0() in genmodel.,"Mar 27, 2019 at 1:01",,,,55359544
97461829,97461829,Thanks Tom. I still not quite get my answer. I am simply need to explain what are these numbers representing . that is it. those are my manager and they don't need details. my Also is there any way to give me R version of code as I don't use python,"Mar 27, 2019 at 3:34",,,,55359544
98011390,98011390,"But the example from 
github.com/h2oai/h2o-tutorials/blob/…
 is using two categorical features ""targetEncoder = TargetEncoder(x= [""addr_state"", ""purpose""], y = ""bad_loan"", fold_column = ""cv_fold_te"")""","Apr 13, 2019 at 3:32",,,,55637039
98011429,98011429,"what interesting is when I test your example use 2 features in TargetEncoder, it works without any issue but 3 features, it will have the error message I listed in the thread above","Apr 13, 2019 at 3:39",,,,55637039
98034953,98034953,"I followed the same demo and got the same error. Just trying with different features and number of features, I could solve it. Make sure you do not have missing data before to  encoding. I had a pandas dataframe and used the imputer shared by @sveitser in [
stackoverflow.com/questions/25239958/…
 because I had a small percentages of missing values. After that, I could encoding fourteen categorical variables with for loop. It should be noted that the target encoder in H2O.ai is still in alpha version.  PD: I am using h2o 3.22.1.2","Apr 14, 2019 at 11:43",,,,55637039
98855217,98855217,@joefaver Could you please share more details about the issue that you had been experiencing with missing values? It is supposed to work fine with missing data so lets see if it is a bug.,"May 13, 2019 at 10:50",,,,55637039
97296856,97296856,"thanks, 
df1 = data[data['L2Support'] == '0'].asfactor() df2 = data[data['L2Support'] == '1'].asfactor()  df1[""L2Support""].types df2[""L2Support""].types
 the type is enum now. But merging just leaves an empty dataframe. both df1 and df2 have the right data in them. 
This H2OFrame is empty. 
 when i print 
df3
 after 
df3 = df1.merge(df2)","Mar 21, 2019 at 15:07",,,,55273532
97277815,97277815,"If I'm running on a single node using data that's larger than my amount of memory, how is it handling this?  (I read the h2o doc you provided and I'm missing how it handles this situation).  Is it storing everything in memory just compressed?  Does it spill to disk?","Mar 21, 2019 at 3:43",,,,55251437
97314784,97314784,"It does store data compressed in-memory.  It does not spill to disk.  If the java heap really fills up with live objects and GC does not free any, then the job will die and you need to add more physical memory and make the java heap bigger.  Or add nodes and operate in cluster mode.  (Or reduce data.)","Mar 22, 2019 at 4:52",,,,55251437
97202840,97202840,Yes I have done that and I am able to use h2o using R and R studio. I just wanted to use h2o in Jupyter notebooks (with R backend) as well but that is not happening as it is not able to see the installed package.,"Mar 19, 2019 at 6:17",,,,55225070
97166319,97166319,"As the H2o cluster crashes in the middle of the grid search, this doesn't return any logs. So I was trying to find an intermediate location where H2o keeps track of these details. It shows the details in H2o flow UI. But after the crash, if I restart H2o, UI doesn't have any details about the models. Is it not stored in HDFS or somewhere?","Mar 18, 2019 at 6:26",,,,55215203
97167839,97167839,Logs will appear once the yarn job completes.,"Mar 18, 2019 at 7:26",,,,55215203
97168556,97168556,"As the H2o server crashes, yarn job is failing. Is there any place it temporarily logs the data?","Mar 18, 2019 at 7:52",,,,55215203
97168575,97168575,I am looking for a location where it logs details about various models it tried and param/scores of each model.,"Mar 18, 2019 at 7:53",,,,55215203
97178178,97178178,What you want are the stdout and stderr captured by “yarn logs” and available from yarn once the job ends.  That’s how we have been debugging hadoop yarn jobs since 2014.  I don’t know how to put it any other way.,"Mar 18, 2019 at 12:46",,,,55215203
101950044,101950044,"I am a bit confused here, I get the same error as OP, however in doc it clearly states s3 for 
save_models()
. Is it an error in the documentation? Thanks","Sep 2, 2019 at 12:19",,,,55227354
102859409,102859409,@Joesmaker please see my answer below,"Oct 4, 2019 at 22:06",,,,55227354
97246878,97246878,Thanks a lot marco :),"Mar 20, 2019 at 9:45",,,,55180071
97255237,97255237,You're welcome. Please consider approving my answer if it's been helpful :),"Mar 20, 2019 at 13:32",,,,55180071
96925424,96925424,Thanks a lot! When I do aml.leader.params['alphas']['actual'] I get 6 values. Are these the parameters for one model? I thought GLM was taking one alpha value per model...,"Mar 10, 2019 at 17:26",,,,55083154
97013131,97013131,"@GeorgiosKourogiorgas  Ah... This is an idiosyncrasy of the GLM code and how we pass the vector of alphas in the AutoML. GLM allows passing a vector for alpha and that's what we did (instead of using the traditional grid interface which would yield six GLMs instead of one final one) so therefore there doesn't seem to be a way to see what alpha was selected.  We have a JIRA open to fix this: 
0xdata.atlassian.net/browse/PUBDEV-5013","Mar 13, 2019 at 7:20",,,,55083154
97016944,97016944,Ok so for the time being I will pass all the alphas from the winning glm in automl,"Mar 13, 2019 at 9:23",,,,55083154
96834720,96834720,Thanks. I will try your suggestions.,"Mar 7, 2019 at 10:49",,,,55041253
96836839,96836839,"As suggested by you  I did sbt reload Then I tried with this in build.sbt. libraryDependencies += ""ai.h2o"" % ""h2o-core"" % ""3.22.1.3"" This 1 error was gone  not found: value water . The remaining 4 errors remained the same.","Mar 7, 2019 at 11:48",,,,55041253
96837057,96837057,"Then I tried with this in build.sbt libraryDependencies += ""ai.h2o"" % ""h2o-core"" % ""3.22.1.5"" I got the same errors.  Thanks for suggestions though.","Mar 7, 2019 at 11:54",,,,55041253
96837715,96837715,"Maybe you are missing more of those 
ai.h2o
 dependencies? So far you only have 
h2o-core
. See: 
search.maven.org/search?q=ai.h2o","Mar 7, 2019 at 12:11",,,,55041253
96840773,96840773,"Yes, I was trying now with libraryDependencies += ""ai.h2o"" %% ""sparkling-water-core"" % ""0.2.0"" and this is when i saw your post. I will add libraryDependencies += ""ai.h2o"" % ""h2o-automl"" % ""3.22.1.3"" also and see if it compiles. Thanks.","Mar 7, 2019 at 13:37",,,,55041253
96761269,96761269,"I have checked that if the standardize parameter is false, then the input data need to be scaled. For my own understanding, does that mean that I need to normalize both train and test data before using them as input?","Mar 5, 2019 at 12:38",,,,55000205
96767974,96767974,The normalisation happens by default so you do not need to do it. I switched it off just to demonstrate that the MSE is reported in the normalised space.,"Mar 5, 2019 at 15:37",,,,55000205
98310286,98310286,Thanks @Joe for the solution. I have been searching for the calculation but couldn't get it right.,"Apr 24, 2019 at 4:19",,,,55717738
96645316,96645316,"It can be hard to know what the ""current"" directory is, especially as it can be different for each of 
h2o.import_file()
 and `h2o.upload_file(), so I quickly found it was simpler to always give the full path to any data files.","Mar 1, 2019 at 9:03",,,,54927780
96588831,96588831,"Thanks a lot. Meanwhile I kept trying and figured this out by myself, since something finally worked, but I did not understand that the random forest can basically perform a sort of implicit PCA. This makes sense with the scope of the method actually.","Feb 27, 2019 at 17:15",,,,54907711
96650682,96650682,"Thanks, I didn't know fold_assignment parameter which can be quite useful.","Mar 1, 2019 at 11:49",,,,54896480
96514757,96514757,"To clarify, Sparking Water is just a Spark package that allows you to use the regular H2O-3 code yet H2O4GPU is a completely different codebase so it's not really a ""scaling up"" of H2O-3.","Feb 25, 2019 at 18:12",,,,54871324
96407507,96407507,"Thanks, @Michal. That's perfect. I should have figured that out myself via 
help(h2o.init)
. Duh.","Feb 21, 2019 at 20:20",,,,54813950
96416902,96416902,I got same exception. Is it a wrong version issue? Or maybe I missed something in my runtime java class path?,"Feb 22, 2019 at 6:02",,,,54814631
96447934,96447934,"thanks, the problem is still there. on pressing List All Frames it shows following:   Key_Frame__http___math_ucdenver_edu_RTutorial_titanic.hex  yet it does not appear into Split dropdown. I am running h2o using Rstudio.","Feb 22, 2019 at 23:36",,,,54812162
96417861,96417861,thanks Lauren! Just followed the link and the problem is solved.,"Feb 22, 2019 at 6:46",,,,54813046
96355121,96355121,"I can't add more data, so I try to deal with it ;) Moreover target variable isn't balanced (60 : 19). I tried to run GBM 100x and received mean AUC=0.56 (sd=0.07) and MSE=0.25. Data download link should be correct now.","Feb 20, 2019 at 14:15",,,,54777321
96508352,96508352,"Indeed, the folds without positives have AUC equal to NaN. I set also balance_classes=TRUE in GBM but the AUC metrics didn't get better.","Feb 25, 2019 at 14:59",,,,54777321
96164414,96164414,Thanks Lauren. One more thing: Can I retrain the exported model or is it only for prediction? What happens with stacked models?,"Feb 14, 2019 at 10:29",,,,54680393
96176324,96176324,"yes you can use checkpointing please see the user guide: Thanks! 
docs.h2o.ai/h2o/latest-stable/h2o-docs/…","Feb 14, 2019 at 15:58",,,,54680393
96070707,96070707,"conda list picks up two versions of colorama...0.3.9  and 0.4.1. No 0.3.7, funnily enough. So I uninstalled and reinstalled colorama, and now 
import h2o
 works. Strange.","Feb 11, 2019 at 21:27",,,,54581287
96069212,96069212,"Thanks for the insights about how 
h2o.H2OFrame()
 works. Wouldn't the I/O operations (i.e. writing and reading back from disk) will be slower?","Feb 11, 2019 at 20:30",,,,54568511
96070977,96070977,"@EngineeredBrain 
h2o.H2OFrame()
 will be joint-slowest in best case. I.e. it is a convenience function that does steps 1, 2 and 3. But when you notice it as a bottleneck, you can usually do better, i.e. if you are going to use the csv file 2+ times, doing step 1 yourself is free after the first time; if the server is running on localhost, step 2 can be skipped, and if you are running a multi-node cluster, 
import_file()
 can be multi-threaded.","Feb 11, 2019 at 21:37",,,,54568511
95927981,95927981,"Thanks @Lauren. I should have read the docs more carefully (see second bullet point in 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…
)","Feb 7, 2019 at 0:22",,,,54564379
95917972,95917972,"I may get this wrong, but this feature is already raised and resolved: 
0xdata.atlassian.net/browse/…","Feb 6, 2019 at 17:24",,,,54467473
95918033,95918033,"@Sixiang.Hu the issue was resolved for the python api but not for the r api, the original question is not that the functionality exists  - it does - the question was whether it was accessible for the R api - which it is not.","Feb 6, 2019 at 17:26",,,,54467473
95918148,95918148,"ah, thanks for clarifying this, and guess this is un-resolved one is the one we can keep an eye on: 
0xdata.atlassian.net/browse/…","Feb 6, 2019 at 17:28",,,,54467473
100524169,100524169,"For Python: 
h2o.export_file(df, 'C:\\PATH\\TO\\FILE')
.","Jul 11, 2019 at 18:02",,,,54421092
95575871,95575871,"That sounds reasonable, thank you. I didn't realise that 504 was an HTTP error code. I will ask the server admin to open the port and see if that fixes it. Will report back.","Jan 26, 2019 at 18:23",,,,54380895
95621607,95621607,It turns out iptables is not running and port 54321 is not blocked. I can start H2O using java -jar h2o.jar with no errors but I still get a gateway timeout error (i.e.: 504) and neither R nor the browser will connect to it. Any other idea?,"Jan 28, 2019 at 15:46",,,,54380895
95623125,95623125,"Try to disable SELinux.  Check whether there are proxy settings, and if there are, turn them off for localhost.  This is 100% something to do with the configuration of your environment.","Jan 28, 2019 at 16:24",,,,54380895
95626836,95626836,"Indeed, it was a proxy issue, though it might even be a bug in H2O. Posted resolution in another answer.","Jan 28, 2019 at 18:17",,,,54380895
95604703,95604703,"Thanks Lauren..Actually this error i ma getting when i am running through h20 GUI interface...I gave class_sampling_factors parameter value as 1., 0.5, 1.    but getting same error. Pls suggest what should be the corrrect value for this parameter.                                When I am tring to run auml code through  python spyder interface getting  error (H2OServerError: HTTP 500 Server Error:Server error java.lang.NullPointerException: None and H2OServerError: HTTP 500 Server Error: Server error water.util.DistributedException: Error: DistributedException from /127.0.0.1:54321: '","Jan 28, 2019 at 6:56",,,,54350149
95682277,95682277,@Lauren-  Please suggest,"Jan 30, 2019 at 8:48",,,,54350149
95708689,95708689,@SarvendraSingh are you no longer hitting an issue with your original question? can you post what version of H2O-3 you are using? For spyder since this is a separate question please post it as a new question - and provide enough information to reproduce the issue. Thanks!,"Jan 30, 2019 at 21:41",,,,54350149
97019236,97019236,I am using h20 version 3.22.1.2..I am using h20 GUI UI flow..So my query is what should be sample value we need to give for class_sampling_factors parameter.. Thanks.,"Mar 13, 2019 at 10:22",,,,54350149
95494187,95494187,"Lauren, Thanks for your reply (1) Our data has timestamp column with value like ""2018-05-27 00:00:00"". This column is detected as ""Time"" by H2O flow automatically when I load in our CSV file. Then, I run H2O (core) to parse the data. I saw the parse results in ""COLUMN SUMMARIES"" like ""1509494400000.0"" which looks right. Then, I run K-menas with those date columns; then in section “OUTPUT - CLUSTER MEANS” section and the timestamp filed is with the value like “1.4144556086883196e+22”. This looks a bug. Perhaps it's related to the one I reported before (see above)","Jan 24, 2019 at 2:53",,,,54336070
95494231,95494231,"For (2), I understand the Standardization process, but it's not my question. My question is how H2O reverse process from standardized cluster result back to original values ? I know I can see non standardized result in ""OUTPUT - CLUSTER MEANS”. But, I am wondering how H2O convert from standardized result back to non standardized using MOJO file? Hence, I posted the MOJO file as an example...","Jan 24, 2019 at 2:58",,,,54336070
95494687,95494687,"okay thanks so much for the clarification! (1) looks like a bug and as you mentioned could be related to your original post, (2) let me get back to you.","Jan 24, 2019 at 3:40",,,,54336070
95531477,95531477,"In addition, can you explain how H2O handles handle missing values during training for categorical features ? Say, I have a feature with True, False and missing value(NaN). thanks.","Jan 25, 2019 at 3:12",,,,54336070
95551179,95551179,"sure, the way kmeans handles missing values is described in the FAQ at the bottom of the algo page in the user guide (if you are interested in other algos you can go to their section in the user guide). 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…","Jan 25, 2019 at 15:47",,,,54336070
95339931,95339931,"I'll take a close look at those two parameters, maybe their differences explain the different model sizes. however I'm trying to understand why the three models can differ so much in their sizes. thank you Tom","Jan 18, 2019 at 16:27",,,,54256617
95410044,95410044,"after comparing the parameters of the three models, the most important difference seems to be the 
min_rows
 pmt. It is 16 for the first two models, and 1 for the last one. moreover, the last model has a much higher number of 
mean_leaves
, around 7 times the values of the other models (this should be a consequence of the 
min_row
 pmt, right?). the 
max_depth
 pmt is quite similar across the models, i.e. 19, 17, 17, whereas 
ntrees
 is 160, 270, 150. I'll check the grid searches' leaderboards to assess if this difference is due to noise because the three training sets have the same structure","Jan 21, 2019 at 17:11",,,,54266744
95410737,95410737,"@davide A small value for 
min_rows
 would definitely explain a much larger model. I'd be very wary using 
min_rows
 of 1, because of the risk of over-fitting, unless you have no noise in your data. See also 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…","Jan 21, 2019 at 17:36",,,,54266744
95184468,95184468,"Thanks for your reply.  Though I get that word2vec is unsupervised it doesn’t remove the need for it to be able to distinguish between different id’s – such as documents. Otherwise it will, in my case above, link the words ‘This’ and ‘first’ very close together, even though in the real world those two words are as far apart as possible, as they belong to two different id’s.  Or am I completely off here?","Jan 14, 2019 at 8:36",,,,54167366
95187555,95187555,"@EmilLykkeJensen For getting a deeper intuitive feel for what embeddings are doing, my own blog post might help: 
darrendev.blogspot.com/2017/12/…
   I've used that example at a few talks, at least a couple of which have been videoed and should be online.","Jan 14, 2019 at 10:24",,,,54167366
95189110,95189110,"Perfect - thanks @darren-cook. It was the NA sentences separator is was looking for - somehow I cound not see from the h2o doc, that NA is used to split sentences (or other ids).","Jan 14, 2019 at 11:14",,,,54167366
95144755,95144755,"Thanks, for reply. I have tested init and shutdown inside the loop. It still has problem. I have 64G of RAM and running H2O on python 2.7. I have attahhed the code in the question as well.","Jan 12, 2019 at 6:01",,,,54137124
95146361,95146361,"@Eli How does the cluster memory change over time? That is the key thing to watch, live, so that you know if low memory is causing the problem or something else.","Jan 12, 2019 at 9:00",,,,54137124
95160674,95160674,"I think, I found the problem. I am increasing the dimension of my dataset inside the loop, data size is (40000, 1000). I believe XGboost cannot handle that? do you have any suggestion?","Jan 13, 2019 at 2:07",,,,54137124
95211584,95211584,Pretty sad it didn't support in kaggle. Thank you for your help!,"Jan 15, 2019 at 2:26",,,,54188377
95038334,95038334,can you share me the link about where you find the example? I didn't find in H2O document,"Jan 9, 2019 at 3:25",,,,54102774
95039863,95039863,"Sure. It is ""hidden"", but I have found it some time ago: 
github.com/h2oai/h2o-tutorials/blob/…
 And the link to code itself: 
github.com/h2oai/h2o-3/blob/master/h2o-py/h2o/targetencoder.py","Jan 9, 2019 at 5:25",,,,54102774
97342144,97342144,"have you tested the Python code for target encoder? I some some error using the sample code 
stackoverflow.com/questions/55306686/…","Mar 22, 2019 at 19:54",,,,54102774
98855467,98855467,@Gavin issue is fixed and should be available in the next fix release 3.24.0.3,"May 13, 2019 at 10:57",,,,54102774
95959854,95959854,"I ended up using ARIMA, ETS, HoltWinters etc.","Feb 7, 2019 at 20:05",,,,54581250
94924055,94924055,h2o node is running for sure.. we get exception from it :) - but I am confused why it would not recognize our parquet file to be parquet,"Jan 4, 2019 at 18:27",,,,54040066
94885624,94885624,"This is the general answer you can find here on stack overflow. My problem was more that i am working on a remote linux server and i could not easily manage / access the java intallation / path. The key to solve my problem was to navigate the file structure with: list.dirs(), starting with list.dirs(""/usr/""), until I found java files. Then I tried multiple dirs until i found one that worked...","Jan 3, 2019 at 14:53",,,,54024327
94877757,94877757,"The problem is how to get the cross-validation data, and the model for each fold.","Jan 3, 2019 at 10:56",,,,54020876
94877868,94877868,"OK, I thought you had 2 problems","Jan 3, 2019 at 11:00",,,,54020876
94887772,94887772,"Your solution solved the issue as I put it, hence I mark it as solved. However, I think there is a subtle difference to what I was really aiming (which I only realised now). H2O performed a combined holdout predictions. With your solution I can end up computing it, by combining the predictions of all folds, but do you know of an integrated way to do it?","Jan 3, 2019 at 15:59",,,,54020876
94875875,94875875,"Thanks. I did that using caret to produced a Fold Id column and it works fine. The problem now is that, in my tests, using fold_column in h2o makes the grid search much slower.","Jan 3, 2019 at 9:58",,,,54007462
94888681,94888681,"file a bug report about slow grid search when using fold column here 
0xdata.atlassian.net/projects/PUBDEV/issues","Jan 3, 2019 at 16:27",,,,54007462
94811656,94811656,"@Dareen Cook , thank you for your suggestions.We have some pre-processing phase. we have huge data, is CSV will be able to handle huge data.","Dec 31, 2018 at 12:02",,,,53985262
94815472,94815472,"csv is the best format for H2O. csv compresses well, and H2O can read the compressed format. (However rapid minder cannot seem to write .csv.gz or .csv.zip directly, so that will need to be an extra manual step, maybe.) H2O can also read from a Hadoop cluster, if that is where your data currently is.","Dec 31, 2018 at 15:27",,,,53985262
94816533,94816533,"I think this is a good suggestions, after doing all your pre-processing steps in rapidminer  then put the data in hadoop cluster , from there use H2O to pull the data from hadoop cluster and build the model.","Dec 31, 2018 at 16:27",,,,53985262
95101676,95101676,I think I figured it out. I was using two different clusters which were using two different versions of h2o. Thanks for your help!,"Jan 10, 2019 at 18:49",,,,54027462
94419928,94419928,Hi @TomKraljevic my system has 20 GB ram. Can I allocate 64gb to that because two times it shut down and show me your pc ran out of memory,"Dec 14, 2018 at 17:19",,,,53783235
94424844,94424844,"@SanjayKumar When Tom says 90%... if you have 20GB, you could try 
max_mem_size=18g
, but any higher is likely to be unstable. 64gb is a definite no. :-) The best way to get 64GB would be to find another 3 machines of the same size, and have them each start a node with 16GB, and form a cluster.","Dec 14, 2018 at 20:45",,,,53783235
94425387,94425387,"Thanks, TomKraljevic and @DarrenCook for clear that confusion","Dec 14, 2018 at 21:08",,,,53783235
94412106,94412106,"I see. Maybe an alternative could be found here: 
stats.stackexchange.com/a/297546","Dec 14, 2018 at 13:14",,,,53777873
94385961,94385961,dl_model.max_hit_ratio_k[1] I tried this way but it shows this error                     TypeError: 'NoneType' object is not subscriptable,"Dec 13, 2018 at 17:21",,,,53766896
94386273,94386273,"hi @SanjayKumar,  I added an explicit example for you - it would be great if you could mark the reply as accepted -, currently h2o-3 returns a twodimtable (specific to H2O) and requires specific slicing techniques if you are not comfortable with that you can just convert it to a pandas dataframe (which I showed) and get the hit ratio that way.","Dec 13, 2018 at 17:32",,,,53766896
94386543,94386543,"Hi @Lauren thanks for the example. I am getting the hit ratio table but not getting the reply of max_hit_ratio_k command.  And, k=1  on train data, I  get this value   0.5385539 and on test data this 0.1001860. Is it good or bad?","Dec 13, 2018 at 17:42",,,,53766896
94387099,94387099,"unfortunately there is a bug for the max_hit_ratio_k parameter...it doesn't do anything at the moment, sorry about that (
0xdata.atlassian.net/browse/PUBDEV-5935
).","Dec 13, 2018 at 18:02",,,,53766896
94350315,94350315,"Thanks for the issue. We will look into it.  In the meantime, there is a workaround available (in R/Python), unfortunately, it doesn't apply to Flow.  In R/Python you can use parameter fetch_mode = ""SINGLE"" which will disable distributed import and enable compatibility mode. In compatibility mode, any JDBC drive should work just fine as we do not rely on database specific SQL constructs.   Please refer to our documentation: 
docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/…","Dec 12, 2018 at 18:05",,,,53731254
94232957,94232957,"Thanks, In any other platform  is available?","Dec 9, 2018 at 0:03",,,,53688186
100734532,100734532,"Would it be possible to map the combination probabilities back to separate probabilities per class? Regarding multilabel classification, it seems to me that this is getting pretty common and it surprises me a bit that h2o doesn't support it...","Jul 19, 2019 at 7:15",,,,53688186
94248574,94248574,ya that's an option but i want to try this one with a deep learning and I am using word2vec for embedding.,"Dec 9, 2018 at 20:55",,,,53696531
94226000,94226000,"Yes, the response variable is made up of arrays of those 700 unique numbers, but I want to predict the two or three numbers on one row, not the arrays. So if I want to predict the numbers so how my response variable looks like before passing to deep learning and what would be my categorical_encoding either it is eigen or a label_encoder","Dec 8, 2018 at 16:46",,,,53684511
94211187,94211187,"I can confirm that when RF is set to 
max_depth=5
 (this is default for GBM), the POJO sizes are very close and do not increase with N.  Under the default 
max_depth
 values, GBM has a max of 2^5 leaves per tree (plus proxy splits if there's missing data, I suppose) but RF has a max of 2^20 or 1 megaleaves.","Dec 7, 2018 at 20:50",,,,53674427
94232921,94232921,Best to switch to MOJO unless you need a POJO.,"Dec 9, 2018 at 0:00",,,,53674427
94392905,94392905,"K-LIME was an experimental feature that was removed from H2O.  You won't be able to find it in recent versions, sorry!  Instead, I'd recommend using the lime package: 
marcotcr.github.io/lime/tutorials/…","Dec 13, 2018 at 21:44",,,,53670856
101320956,101320956,Is there any function like load_model() to get the model from zip file? Thanks.,"Aug 8, 2019 at 21:28",,,,53656573
101351479,101351479,"if you want to use a saved binary model you can use 
docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/…
.","Aug 9, 2019 at 20:53",,,,53656573
101405478,101405478,"Yes, but this model was exported as mojo in past.","Aug 12, 2019 at 18:04",,,,53656573
94173455,94173455,"Yes, thanks, 
I surmised as much
 ;-)","Dec 6, 2018 at 18:26",,,,53657441
94145065,94145065,"Thanks! Then why does 
cross_validation_metrics_summary
 print 
No cross-validation metrics summary for this model
 even though the printed representation of the stacked ensemble includes 
** Reported on cross-validation data. **
?","Dec 6, 2018 at 0:35",,,,53621603
94175648,94175648,"@sds No reason other than the print statement is not implemented.  There's a ticket open here: 
0xdata.atlassian.net/browse/PUBDEV-3911
. You can print the 
cross_validation_metrics_summary
 for the metalearner model stored inside the Stacked Ensemble model, however.","Dec 6, 2018 at 19:53",,,,53621603
94175967,94175967,How do I extract those numbers for further processing?,"Dec 6, 2018 at 20:05",,,,53621603
94143098,94143098,"Thanks for the respond. I fixed the problem with importfile on 3.22.0.2 version.   Now by passing : importFiles [""s3a://ACCESS KEY:SECRET KEY@parvin-us-west1-data/Prod/154351418084_train/""] it can import the file. However it cannot parse the file after that. Can you please confirm that you are also able to parse the file with this format of filepath? The issue is that when i press (parse these files) in 3.22 flow, the  source_frames, does not include the credential part of the url. While in  3.18 the source file of setupParse was also including the credentials.","Dec 5, 2018 at 22:38",,,,53622558
94143443,94143443,@ParvinDadgar yes I was able to parse the file. Could you update your questions so that include the error message you are seeing? That might help see where our steps may have differed. thanks!,"Dec 5, 2018 at 22:56",,,,53622558
94143954,94143954,"Sure. After pressing, parse these files, i get the cell with following content: setupParse source_frames: [ ""s3a://parvin-us-west1-data/Prod/154351418084_train/data.csv"" ]. on the bottom of the page it says: Requesting /3/ParseSetup. It remained in this phase for 20 minutes. and in the logs it does not show anything after POST /3/ParseSetup, parms: {source_frames=[""s3a://parvin-us-west1-data/Prod/154351418084_train/data.csv"" ].   In 3.18 version i used to get: setupParse source_frames: [ ""s3a://ACCESS KEY:SECRET KEY@parvin-us-west1-data/Prod/154351418084_train/data.csv"" ] which worked well.","Dec 5, 2018 at 23:23",,,,53622558
94070260,94070260,"Ok ,  Thanks @Lauren","Dec 4, 2018 at 0:26",,,,53603945
94074117,94074117,"Thanks, Though will have to check if this will be suitable for my case, as the update required will be rather frequent.","Dec 4, 2018 at 5:14",,,,53599539
94524390,94524390,Thanks for the detailed breakdown Lauren :).,"Dec 18, 2018 at 17:22",,,,53788246
94122744,94122744,"Correct, F1 is then not defined. You need to use other metrics, such as e.g. logloss.","Dec 5, 2018 at 11:51",,,,53592475
93976532,93976532,"Thanks, which one should be used as the representative of the CV?","Nov 30, 2018 at 10:23",,,,53553974
93977321,93977321,"This is totally up to you, just be careful when you compare the models to always use the same one. I usually tend to use the mean of the hold out predictions (in this case the second one) since like this I also get some sense of variance in the performance. Then again I also tend to do repeated CV for most scenarios, in which case one can use a metric calculated on combined hold out predictions for each repeat and still get a sense of model performance variance in CV repetitions. There are no hard rules here.","Nov 30, 2018 at 10:49",,,,53553974
93977586,93977586,When I have a two class problem and want to plot the ROC curve I need to use the combined hold out predictions or I would end up with 10 ROC curves (for 10-fold CV) in that case I report/compare the AUC on the combined predictions.,"Nov 30, 2018 at 10:56",,,,53553974
94368683,94368683,"@Minyi Han Glad to help. If the answer was helpful and resolved your question, kindly accept it (
stackoverflow.com/help/someone-answers
).","Dec 13, 2018 at 9:04",,,,53553974
93970419,93970419,"Thanks, I would like to get the R2 for test","Nov 30, 2018 at 6:33",,,,53552404
93970889,93970889,Updated my answer.,"Nov 30, 2018 at 6:54",,,,53552404
93971380,93971380,"when I use h2o.performance(m, newdata = test), why the result is different from 
caret::R2(as.data.frame(predictions), as.data.frame(test[1]))","Nov 30, 2018 at 7:16",,,,53552404
93971613,93971613,"Did you 
set seed
? in both models? The same seed?","Nov 30, 2018 at 7:25",,,,53552404
93971754,93971754,"I would think a model built in 
caret
 would give different results fcompared to that in 
h2o","Nov 30, 2018 at 7:32",,,,53552404
94104081,94104081,"Thanks a lot, Lauren!","Dec 4, 2018 at 21:38",,,,53618422
94131593,94131593,"Hi Lauren, just following up the above question: am I right when I think that you mean the events are the outcomes 1 or 0?","Dec 5, 2018 at 15:47",,,,53618422
94141049,94141049,"@LanaKH, in this case you can think of the event as the outcome being one. For example if you are trying to see how well your model can predict people who are going to buy versus not buy, the event would be when someone buys. Hope that helps!","Dec 5, 2018 at 21:09",,,,53618422
100468055,100468055,"@Lauren Hi, may I ask a question about h2o here? Is transformation/preprocessing inside cross validation currently available? Related question 
here
. Thanks!","Jul 10, 2019 at 7:27",,,,53618422
93906230,93906230,"If you wish, nevertheless, to do a stratified sample, you can use the method 
stratified_split()
 in the Python module. If you wish to do stratified cross validation, you can set the model's parameter 
fold_assignment='Stratified'
 or construct a k-fold cross-validation column yourself using the Python module's method 
stratified_kfold_column()
.","Nov 28, 2018 at 11:52",,,,53510090
93889745,93889745,"See the files located at: 
1drv.ms/f/s!AsSlPHvlhJI1hIpB2M5X49J5L-h1qw
 Run the H2O server. Import the CSV file in H2O Flow. SetupParse and Parse the data. Run the test procedure. Thank you for your attention.","Nov 27, 2018 at 23:45",,,,53507955
93928744,93928744,"I am getting this error when trying to run the test:  java.lang.IllegalStateException: InjectionManagerFactory not found.  	at org.glassfish.jersey.internal.inject.Injections.lambda$lookupInjectionManagerFactory$0(Injections.java:98) 	at java.util.Optional.orElseThrow(Optional.java:290) 	at  Is there a reason why you don't use the REST client provided in h2o-bindings? Example: 
github.com/h2oai/h2o-3/blob/master/h2o-bindings/src/main/java/…
  I think you can avoid hitting issues if you use the h2o-binding.","Nov 29, 2018 at 0:30",,,,53507955
93964420,93964420,"I was not aware of those methods, and did not know how to use them. Thank you for pointing me to that example. Are there any other web pages that document how to use the h2o-binding library? All I can find are javadocs. I also found the documentation for h2o-genmodel, which promises to provide ""a step-by-step guide to creating and implementing POJOs or MOJOs in a Java application."" However, in the section that presents sample code for extracting generated models from H2O, there is a ""TODO"" for java. Thank you for your attention.","Nov 29, 2018 at 23:04",,,,53507955
94104646,94104646,Can you please point me to the TODO you found?   Regarding more documentation - I am not aware of it. I think the example is what we have + the endpoints are documented in Javadoc.,"Dec 4, 2018 at 22:02",,,,53507955
94165292,94165292,"See the following page: 
docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html
 There is no sample code for Java under the heading, ""Extracting generated models from H2O"".","Dec 6, 2018 at 14:22",,,,53507955
93829070,93829070,"In addition, the problem could be in the dataset itself. Are you sure the data is actually IID?","Nov 26, 2018 at 10:59",,,,53466650
93847724,93847724,I had had this on my mind for some time now. I had found the h2o.importFile() function and utilized it successfully. You are 100% correct. This was my first time working with something like h2o. Utilizing the h2o functions led to successful splitting and evaluation. Thank you for your response! I hope if someone else has this issue that they find this :) Have a good day sir!,"Nov 26, 2018 at 20:55",,,,53466650
93847783,93847783,"Regarding IID data, generally speaking I am. By that I mean that I don't have issues of singularity. But I don't expect the entire dataset to be IID. Unless I'm misunderstanding, I don't believe identical distribution of regressors is feasible with large datasets.","Nov 26, 2018 at 20:58",,,,53466650
93753274,93753274,With kerberos and Hadoop trusted proxy support (proxy user impersonation) an Apache Knox integration is just a matter of a service definition. 2 XML files: service.xml and rewrite.xml. Using Knox as a proxy will allow you to leverage any of the existing authentication and federation providers - including the use of KnoxSSO for enterprise SSO integrations.,"Nov 23, 2018 at 2:21",,,,53438299
93753401,93753401,Perhaps the trusted proxy support is for H20 talking to Hadoop components but not trusted proxies like Knox or Oozie talking to H20?,"Nov 23, 2018 at 2:36",,,,53438299
93758998,93758998,"I assure you that first thing I did was to check which ports were available, even before running ""java -jar h2o.jar""","Nov 23, 2018 at 8:32",,,,53438245
93789824,93789824,"Okay. Thanks for the answer. I have another question, can categorical variables be used in this type of a model?","Nov 24, 2018 at 14:24",,,,53438407
93792605,93792605,"Yes, h2o-3 can use categorical columns as inputs for a model.","Nov 24, 2018 at 17:16",,,,53438407
120710317,120710317,"So just to be totally clear, when assigning levels in lexicographical order, the highest value level (9 in the first example and 1 in the second example) will be the one considered the ""positive"" class, right?","Jul 8, 2021 at 10:53",,,,53384866
93580710,93580710,Thanks. I would like the algo to figure out the rest of the splits except for the first one. Are there any algorithms outside of H2O that can allow this?,"Nov 17, 2018 at 12:59",,,,53346309
93632639,93632639,You could split your data based on whatever feature and threshold yourself and then train trees for each split. You can then combine the two trees and the root split into the final model.,"Nov 19, 2018 at 16:06",,,,53346309
93635729,93635729,@vaclav could you share a Python example of this?,"Nov 19, 2018 at 17:46",,,,53346309
93658225,93658225,"@add787 I don't have an example readily available, but you can simply split the data by your feature and threshold manually. Then you have two data-frames, let's call them 
data_left
 and 
data_right
. Now you can train a tree on both left and right data and stitch them together into a final tree where the root branches into left and right branch based on the threshold and feature you chose, and then each branch corresponds to the models you obtained for 
data_left
 and 
data_right
.","Nov 20, 2018 at 10:55",,,,53346309
93680314,93680314,"@vaclav, that is great, but we use complex models such as xgboost for the remaining portion. How do I add my own tree on the top of the xgboost model?","Nov 20, 2018 at 22:25",,,,53346309
93567641,93567641,"Could you help me with this: Let's say I have a data frame with the meals I ate over each day of a week for the entire month. I wish I could group it per week day, and make a list of all the meals, e.g. Monday: [eggs, milk, pasta]. How could I do this in python with h2o or spark dataframe?","Nov 16, 2018 at 19:39",,,,53344170
93568640,93568640,"as a first quick attempt you could try using h2o's group_by method. please this link for a few examples of using group by in h2o python: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/…
.","Nov 16, 2018 at 20:17",,,,53344170
93680792,93680792,I ended up using only spark because for me the h2o group_by seems to be very limited to those built-in operations.,"Nov 20, 2018 at 22:48",,,,53344170
93465122,93465122,Did that change the values/results?,"Nov 14, 2018 at 1:14",,,,53291046
93492237,93492237,"@AndreasMueller It actually did...for whatever reason, the Scikit-Learn numbers are now much lower (precision ~0.6, recall ~0.6). H2O4GPU numbers are a touch higher.","Nov 14, 2018 at 17:27",,,,53291046
93503605,93503605,can you try using the same scoring function both times just to make sure? But I imagine the main difference is in hyperparameters.,"Nov 15, 2018 at 2:02",,,,53291046
93340152,93340152,"I thought about that, But I would like to avoid it because I am dealing with big data. I think if I do that I will bring the data to the machine running python instead of working with it on the machine running H2O on top of Spark.","Nov 9, 2018 at 13:33",,,,53213576
93592799,93592799,"Thank you.actually,this question was raised because once h2o.shutdown() is called, the ephemeral ip is lost.So doing h20.init() did not work.We found from one of the answers in h2o forums that restarting the individual vms from the google console helps get a new ip assigned again.","Nov 18, 2018 at 3:41",,,,53337160
93304965,93304965,I've since solved it thanks to your previous comments.,"Nov 8, 2018 at 13:16",,,,53205891
136584494,136584494,How is it solved ?,"Nov 13, 2023 at 15:48",,,,53205891
130587513,130587513,"As it’s currently written, your answer is unclear. Please 
edit
 to add additional details that will help others understand how this addresses the question asked. You can find more information on how to write good answers 
in the help center
.","Oct 5, 2022 at 10:25",,,,73899039
93283897,93283897,"Great, thank you for your help! May I also ask you about the interpretation of the GBM prediction  outcome, which looks like a matrix of LLLRL, LLLLL, RRLLL, etc.? Thank you in advance!","Nov 7, 2018 at 20:55",,,,53195861
93284481,93284481,"Hi Lana, glad to be of help! Could you  mark this question as correct if it was what you were looking for. For gbm predictions please checkout previously posted questions on this topic and checkout the user guide here: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…","Nov 7, 2018 at 21:16",,,,53195861
93293338,93293338,"I actually converted my target [1,0] to categorical and run xGboost - it still does regression and gives me prediction as continuous numbers with negatives. How to make H2O xgboost predict binary? Thank you!","Nov 8, 2018 at 6:34",,,,53195861
93313572,93313572,"hi lana, please set the distribution parameter to bernoulli. it would also be helpful if you could post a screen shot of what you are selecting in Flow and what Flow says the datas type of your target it. thanks!","Nov 8, 2018 at 17:17",,,,53195861
93421320,93421320,"Thanks, Lauren! I assume that the AUTO option should recognize the binary target..Unfortunately, I cannot check because H2o flow does not load the page today.  I will try that when H2O will allow me. May be you can give a tip how to load the page? I do the same I did  before, run java -jar h2o.jar. Shell give me the web link, but link does not work. I would appreciate your help. Thanks, Lana","Nov 12, 2018 at 19:21",,,,53195861
99077755,99077755,"I haven't tried it myself, but I believe you can set a username and password to access Flow to maintain security.","May 20, 2019 at 22:17",,,,53154823
93293361,93293361,"Thanks. but i have connected to gcloud from R earlier. The problem seemed to be that, once the cluster is shutdown after work, since the external Ip is ephemeral, it did not exists anymore.Is there a way to create a H2O cluster and get a static ip to it?","Nov 8, 2018 at 6:35",,,,53161919
139537663,139537663,"This is not true anymore. Even when setting the bind_to_localhost = false, it still gives out the same error. R version 4.4.1 (2024-06-14 ucrt) -- ""Race for Your Life"", H2O Version 3.44.0.3",Oct 28 at 15:37,,,,53161919
93041969,93041969,java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -i model.zip -o model.gv -f 20 -d 3 Error: Could not find or load main class hex.genmodel.tools.PrintMojo,"Oct 30, 2018 at 19:43",,,,53071472
93041990,93041990,"Sorry, my bad. But after I add it, it gives me another error as ""Could not find or load main class hex.genmodel.tools.PrintMojo""","Oct 30, 2018 at 19:43",,,,53071472
96436005,96436005,"I get the same error. I checked my H2o version and its ""3.22.0.1"". should I install graphviz in R as a separate package?","Feb 22, 2019 at 15:44",,,,53072659
113669839,113669839,I just got bit by this same problem.  Was a solution ever established?,"Oct 9, 2020 at 13:48",,,,53089051
113681301,113681301,"it should be, if you click on the link you can see that the ticket is resolved in version 3.24.0.1. what version of h2o are you using, if you are using an older version can you upgrade. If you are still seeing an issue, please post directly on the jira ticket. Thanks!","Oct 9, 2020 at 21:52",,,,53089051
113689677,113689677,"Thanks for confirming.  I was getting the same error and assumed I was having the same problem.  After a bit of testing on both my personal and work computers (same exact code, data, seed values, operating system, package versions, etc.), I’m not having any problems on my personal computer.  Long story short after more testing, I suspect my problem is attributable to IT security constraints on my work computer.  Sorry for the hassle!","Oct 10, 2020 at 11:41",,,,53089051
92921137,92921137,"ah, of course, thank you very much! I was missing something obvious","Oct 26, 2018 at 12:34",,,,53008673
92876048,92876048,Thanks. Yes it works but it is not allowed to expose all the ports for this container. Actually we want to run h2o cluster in Kubernetes and try to test in multiple docker containers. Do you know the exact ports which should be exposed?,"Oct 25, 2018 at 8:57",,,,52985267
92920664,92920664,When you start H2O with -port N then H2O uses port N and port N+1.,"Oct 26, 2018 at 12:20",,,,52985267
92859563,92859563,Thx for the quick clarification!,"Oct 24, 2018 at 19:23",,,,52976032
92793085,92793085,"Yes, correct. The result I posted works well on my local desktop. But when did the same testing in the container it is giving me an error when 
cpu = as.h2o(cpu)
     Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  :      ERROR MESSAGE:  Key not loaded: Key<Frame> /tmp/Rtmp0Wrlif/file7544e612dd.csv_sid_ade6_1  Calls: as.h2o ... h2o.parseSetup -> .h2o.__remoteSend -> .h2o.doSafeREST Execution halted","Oct 23, 2018 at 6:24",,,,52937782
92958805,92958805,This issue has been resolved. Problem here is: I am using R 3.1.1 version which is not compatible. So I upgraded it to R 3.5.1 after which I am not facing this issue,"Oct 28, 2018 at 6:22",,,,52937782
92600653,92600653,"does that mean if I have 10 variables, I need use a loop to go through them then stack into one data frame?","Oct 16, 2018 at 19:02",,,,52841382
92602796,92602796,i think it just depends on how you want to create you plot. you don't necessarily need to have one dataframe since you will be plotting a different line to represent the partial dependence of each feature against the target.,"Oct 16, 2018 at 20:18",,,,52841382
92432651,92432651,"Thank you for you answer. It is simple to calculate 'original' permutation importance, but way harder to make it conditional. Previous questions where about 'original'. Looking forward for updates.","Oct 11, 2018 at 7:35",,,,52746141
92448489,92448489,"okay great thanks for emphasizing that detail, since the jira ticket encompasses adding more importance metrics in general I've updated my comment on that ticket to specifically call out conditional permutation.","Oct 11, 2018 at 14:35",,,,52746141
92425765,92425765,"for question 1, if current AUC is 0.8, stopping_tolerance = 0.001 requires AUC increase to 0.8*(1+0.1%) instead of 0.8 + 0.001?","Oct 11, 2018 at 1:12",,,,52749348
92426278,92426278,"for question 3, I tested using random forest, I found a) if I specify score_each_iteration = True, it will run faster. b) the result of specify score_each_iteration is the same as specify both but different from specify only score_tree_interval = 5. c) When I run grid search I need to specify both score_each_iteration = True and set score_tree_interval = 5 to make it repeatable. I don't know why","Oct 11, 2018 at 1:50",,,,52749348
92311392,92311392,"I using 3.20.0.8 and maybe the reason why i don't get explicit error is somewhat related to version. But of course the standardization of the Poisson variable was the cause. Thanks for pointing this out, it should have been obvious for me from the start. So if I had some normal variables in the set and I want them to be standardized, and at the same time have some Poisson variables, than i know I should standardize the normal variables by my own before running glrm. Thanks very much!","Oct 7, 2018 at 19:48",,,,52655261
92135055,92135055,If I only use score_each_iteration = True without score_tree_interval. Does that mean score_tree_interval = 1?,"Oct 1, 2018 at 23:49",,,,52599801
92243898,92243898,"@Gavin No because the default for 
score_tree_interval
 is 0 which means a fixed interval is not used (we use a dynamic interval instead).","Oct 4, 2018 at 23:25",,,,52599801
92246800,92246800,"Erin, so what does each ""iteration"" mean in the H2O document of ""score_each_iteration"". Based on your explanation it is clearly not stands for each tree.","Oct 5, 2018 at 4:02",,,,52599801
92274472,92274472,"Lauren, thanks for your explanation. that is very helpful. I have added another 4 questions (4-7) that confused me in my original post regarding early stopping. Can you please help me to understand that as well in your posted answers?","Oct 5, 2018 at 19:43",,,,52656689
92348209,92348209,"Hi @Gavin glad the answers helped. For your new questions, I think it would be best if you could create a new post and post it to 
stats.stackexchange.com/questions/tagged/…
 since these are not really code based questions and are more specific to how the algorithm works.","Oct 8, 2018 at 22:47",,,,52656689
92316176,92316176,"How did u get this 50% and 80%? Is it the place where cumulative. capture rate touches at 1 or place starts converges? Can you please explain a bit more about ""you could capture about 80% of the events by targeting only 50% of the population""","Oct 8, 2018 at 2:57",,,,52669983
92382429,92382429,"When you take the point of 0.5 on the x-axis on the validation (right) plot and look at the cumulative capture rate (black) curve, you see the value is about 0.8. This information is useful if you for instance want to prioritise based on your model who you will target by e.g. marketing campaign. If you can predict who would buy if targeted, you can prioritise. In this example if you target the first 50% of people with the highest probability of buying, you would capture 80% of the people who will buy, so you safe some money while capturing majority of the buyers.","Oct 9, 2018 at 20:11",,,,52669983
92423145,92423145,"Can you explain if it is in a healthcare industry? For example, How can the graph give me an idea for predicting if the patient is having cancer or not?","Oct 10, 2018 at 22:02",,,,52669983
92423693,92423693,"Assume you have a new and very expensive cancer treatment method that works only for some patients. If you can predict in advance which patients it will work on, you can provite the treatment only to those patients where the likelihood they will respond to the treatment is the highest. In our example you could target the top 50% of the patients and in fact this way you would cure 80% out of all the patients the treatment would work for. Does it make sense?","Oct 10, 2018 at 22:34",,,,52669983
92461145,92461145,"Your explanation is very clear. But what if there is no additional thing like a cancer treatment and it is just the prediction of the event  'if the patient is having cancer or not'. In that case, how can we utilize this graph?","Oct 11, 2018 at 21:33",,,,52669983
92033883,92033883,Thanks! Do you know how to output the H2O XGBoost model to native XGBoost model?,"Sep 28, 2018 at 1:45",,,,52543019
91945569,91945569,"That's strange, it was already supposed to be a pandas dataframe in your question. :/","Sep 25, 2018 at 16:08",,,,52502277
91945727,91945727,"@IMCoins Hm yes I modified my question quite a bit. But I was doing this pandas conversion only when doing 
h2o.init()
 and not with the second way which I show above.","Sep 25, 2018 at 16:13",,,,52502277
91957691,91957691,"Wow! you're my savior! May I ask the definition of 
@
 and 
@model
 in h2o object? Seems like the h2o object is quite difference from basic R object and I couldn't find any reference regarding your solution.","Sep 26, 2018 at 1:35",,,,52505245
91988572,91988572,"The h2o models are S4 objects. For information on S4 objects please see: 
kasperdanielhansen.github.io/genbioconductor/html/…
 (this link includes helpful info like: ""Data inside an S4 class are organized into slots. You access slots by using either ‘@)""","Sep 26, 2018 at 19:02",,,,52505245
91997048,91997048,Noted. Thank you very much.,"Sep 27, 2018 at 3:11",,,,52505245
104376093,104376093,"A link to a solution is welcome, but please ensure your answer is useful without it: 
add context around the link
 so your fellow users will have some idea what it is and why it’s there, then quote the most relevant part of the page you're linking to in case the target page is unavailable. 
Answers that are little more than a link may be deleted
.","Nov 27, 2019 at 11:18",,,,59068609
106097054,106097054,I have tried this solution from the H2O.ai website but still receive the Error. I have found that uninstalling and reinstalling does Not clear the fact that H2O sees version Mismatches. Shouldn't there be an easier fix?,"Jan 30, 2020 at 18:07",,,,59068609
109409019,109409019,"Worked for me, thanks. This should be marked as right answer.","May 17, 2020 at 19:38",,,,59068609
121899912,121899912,"It gave me a download error so I downloaded 
h2o_3.32.1.6.tar.gz
 (up to date at the time of writing) manually using 
curl
 and installed it by 
install.packages(""~/Downloads/h2o_3.32.1.6.tar.gz"", repos=NULL)
. It shows no warnings now.","Aug 29, 2021 at 15:25",,,,59068609
133941153,133941153,If a user doesn't have access to a CRAN mirror (common in corporate/university networks) they will end up without any version of h2o at all.,"Apr 5, 2023 at 12:12",,,,59068609
106096920,106096920,If this is JUST a warning message and an alert THEN Do ppl feel that is incumbent on H2O.ai to provide a solution that solves this problem. I have tried their answer from their site and it Does Not Fix the error. I still get the error.,"Jan 30, 2020 at 18:02",,,,52504579
91832720,91832720,The problem is that I can't run models from h2o on r dataframes. h2o uses H2OFrame. So I can't use group_by from dplyr as I can't figure out how to make h2o.group_by work like dplyr group_by. I stucked with it.,"Sep 21, 2018 at 13:40",,,,52442128
92297428,92297428,"Lauren, thanks for your explanation. You mentioned train cannot have seed. But does the train in grid search can have seed? Is that the same as you put in estimator? I found the example from the following link: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html","Oct 7, 2018 at 2:11",,,,52486874
92348259,92348259,"hi @Gavin yes train for the estimator does not have a seed and if you pass a seed it should throw an error, but grid search is different and when you apply train because it accepts extra arguments it will allow you to pass in a seed parameter even if it doesn't use it. I realize this can be confusing so my recommendation is just use the seed parameter when you instantiate your estimator and in stopping_criteria for grid search.","Oct 8, 2018 at 22:50",,,,52486874
92202570,92202570,"Hi @Erin LeDell, I'm using version 3.21.0.4438 of h2o and I'm still running into the same problem. I set 
h2o_aml = H2OAutoML(max_runtime_secs = 300)
 and then execute 
h2o_aml.train(x = x_train_cn , y = y_train_cn, training_frame = df_train)
. However, half an hour later the code is still running. So, I'm not sure if the bug was actually fixed. I saw 
github.com/h2oai/h2o-3/commit/…
, but I wouldn't think it would take over 25 minutes to train the final model.","Oct 3, 2018 at 19:49",,,,52486986
92454439,92454439,"I'm working on a text classification problem. I have ~10,000 examples. I originally used a CountVectorizer because it performed slightly better than a TfidfVectorizer in testing with other automl libraries. However, a CountVectorizer results in a ~10,000x150,000 ndarray whereas a TfidfVectorizer results in a ~10,000x15,000. After switching to the TfidfVectorizer H2O completes the automl process; however, when training for 5 minutes it results in an empty leaderboard, 15 minutes results in one model on the lb. I'm using h2o version 3.21.0.4446, 80 threads, and 500 gb of RAM.","Oct 11, 2018 at 17:30",,,,52486986
93855586,93855586,"I am trying python version of 3.22.0.1, seems it still has problem of not respecting the max_runtime_secs, anybody has  update on python version ?","Nov 27, 2018 at 4:54",,,,52486986
94054614,94054614,"The 
max_runtime_secs
 does not currently include the Stacked Ensemble building at the end of the run, so it's possible that it can go over (we may change this in the future).  If you find that there are bigger issues, please file a reproducible bug report here and include your logs: 
0xdata.atlassian.net/projects/PUBDEV","Dec 3, 2018 at 14:46",,,,52486986
91797627,91797627,"Thanks! When I apply model_performance on test data set, from the output I do see the threshold. Is there a way to find the threshold using the test data set?","Sep 20, 2018 at 14:15",,,,52415457
91581648,91581648,"Ah yes! Thanks for the prompt answer @TomKraljevic! Indeed after your answer, I noticed that the threshold was set to 0.1 to maximize F1.","Sep 13, 2018 at 15:34",,,,52316007
91594673,91594673,what's the meaning of NA value?,"Sep 14, 2018 at 1:20",,,,52316214
91615318,91615318,"NA means not available, or a missing value.","Sep 14, 2018 at 14:35",,,,52316214
91663810,91663810,"Thanks a lot! By the way, if there any document of these param? params like leftward，naVsRest，inclusiveNa，inclusiveLevels， I still don't know.","Sep 17, 2018 at 1:18",,,,52316214
91580454,91580454,"based on the @SandipanDey response it seems the be the metric: 
max f1
 and not the 
max f0point5
 for this case. There is no so much documentation for 
h2o.predict()
. Can you provide some hint or link about to specify for prediction function a different performance metric? I have an imbalance class, so rather than 
max f1
 I guess it would be more convenient to use 
max f2
 that penalizes more the FN. I guess If have to specify some parameter using via 
...
 input argument.","Sep 13, 2018 at 15:01",,,,52308136
91586069,91586069,"@DavidLeal I updated my answer (re. F1) before your comment, but you probably already had it open and didn't see. Use 
h2o.confusionMatrix
 to specify your own threshold.","Sep 13, 2018 at 17:59",,,,52308136
91718207,91718207,This answer and the one provided by @DarrenCook are a valid response to my question. I will mark this solution as the best one because it gives also a numerical explanation based on the specific problem I posted. Both are really very valuable responses.,"Sep 18, 2018 at 12:45",,,,52309295
91582978,91582978,"After upgrading in another machine with more than 8GB ram, I am not able to start the application. Please refer to screenshot below [LINK] 
ibb.co/hLiQ4p","Sep 13, 2018 at 16:16",,,,52296927
91591023,91591023,Use journalctl to look at the more detailed logs.  'journalctl -u dai-dai'.  Hopefully that will give you better clues about why it didn't work.,"Sep 13, 2018 at 20:57",,,,52296927
91594698,91594698,"The log show exit as shown below [LINK] 
freetexthost.com/uej1ihln43","Sep 14, 2018 at 1:22",,,,52296927
91797262,91797262,Thanks Erin for your response. I will try it out with H2O 3.22 in python,"Sep 20, 2018 at 14:06",,,,52282483
96546630,96546630,Very interesting and useful information Ryan. Thank you so much.,"Feb 26, 2019 at 15:21",,,,52322770
38901520,38901520,"""The best way to avoid this type of exception is to always check for null when you did not create the object yourself."" If the caller passes null, but null is not a valid argument for the method, then it's correct to throw the exception back at the caller because it's the caller's fault. 
Silently ignoring invalid input and doing nothing in the method
 is extremely poor advice because it hides the problem.","Jul 29, 2014 at 13:32",,,,218510
40841139,40841139,"I would add a remark about this post explaining that even assignments to primitives can cause NPEs when using autoboxing: 
int a=b
 can throw an NPE if b is an 
Integer
. There are cases where this is confusing to debug.","Sep 26, 2014 at 19:45",,,,218510
47362287,47362287,Is it possible to capture NPE thrown by a webapp from the web browser?like will it show in the view page source from the web browser..,"Apr 13, 2015 at 14:51",,,,218510
55062487,55062487,"Yes check if the object equals null before you invoke a method on it or try to access a variable it might have. Some times structuring your code can help avoid null pointer exception. eg when checking an input string with a constant string you should start with the constant string like here: if (""SomeString"".equals(inputString)) {} //even if inputString is null no exception is thrown. So there are a bunch of things that you can do to try to be safe.","Nov 11, 2015 at 4:39",,,,218510
56904702,56904702,"An additional way of avoiding 
NullPointerException
 problems in your code is to use 
@Nullable
 and 
@NotNull
 annotations. The following 
answer
 has more information on this. Although this answer is specificially about the IntelliJ IDE, it is also applicable to other tools as is apparanet from teh comments. (BTW I am not allowed to edit this answer directly, perhaps the author can add it?)","Jan 3, 2016 at 18:17",,,,218510
379647,379647,"I understood everything you wrote there, but only because I've been coding for a while and know what a 'pointer' and a 'reference' are  (and what null is, for that matter).  When I try to dive right into explanations like that, my students look at me crosseyed, because there's not enough background.","Feb 20, 2009 at 4:06",,,,218390
31927855,31927855,"A more common way to get a NullPointerException in practice would be forgetting to explicitly initialize a member variable to something other than 
null
 before using it, 
like this
.  With local variables, the compiler would catch this error, but in this case it doesn't.  Maybe that would make a useful addition to your answer?","Jan 18, 2014 at 9:28",,,,218390
63891483,63891483,"@EJP I think your points are valid, so I've  updated the answer to be clearer and to avoid saying 'points to null' where it did.","Jul 6, 2016 at 22:42",,,,218390
63891982,63891982,@StevePowell I indicated a long time ago that I didn't want my answer to change. Please respect the intent of the original author.,"Jul 6, 2016 at 23:07",,,,218390
64156010,64156010,"Sorry, I was ""improving the answer"" as requested in the top of this stackoverflow item (
This question's answers are a collaborative effort: if you see something that can be improved, just edit the answer to improve it!
)  I disagree that your version is better, IMO @EJB has valid points; but you are quite welcome to keep your answer intact, confusing though it is.","Jul 14, 2016 at 11:19",,,,218390
56143652,56143652,"@RuchirBaronia A debugger allows you to step through a program line by line to see which methods are called and how variables are changed. IDEs should have some tools to do this. See 
vogella.com/tutorials/EclipseDebugging/article.html
 for example.","Dec 10, 2015 at 10:22",,,,24100776
56146343,56146343,"@RuchirBaronia You set breakpoints on the methods around any NullPointerExceptions as seen in the stacktrace, and check the values of variables against what you expect them to be. If you know a variable is null when it shouldn't be, then you can set breakpoints around any code that changes the value. There are also conditional breakpoints you can use which will tell you when a value changes.","Dec 10, 2015 at 11:33",,,,24100776
76673436,76673436,"i suggest also static analysis  tools, like FINDBUGS   
en.m.wikipedia.org/wiki/FindBugs","Jun 30, 2017 at 12:32",,,,24100776
95934455,95934455,"If we give System.out.println(a.length()); // NullPointerException will be thrown, to skip this we can handle with try catch block. thank you","Feb 7, 2019 at 7:25",,,,218394
59993193,59993193,"Keep it simple, I like this answer, add this if you consider correct - Access to uninitialized attribute of an object","Mar 23, 2016 at 13:06",,,,16050670
62151812,62151812,@Emiliano - simply accessing an initialized attribute does not cause an NPE.  It is what you >>do<< with the uninitialized attribute value that causes the NPE.,"May 19, 2016 at 6:57",,,,16050670
80720813,80720813,"If you want more cases: 1) using a 
null
 as the target of a 
synchronized
 block, 2) using a 
null
 as the target of a 
switch
, and unboxing 
null
.","Oct 23, 2017 at 10:16",,,,16050670
91428648,91428648,"""A NULL pointer is one that points to nowhere""
 I disagree. Null pointers don't point to nowhere, they point to null values.","Sep 8, 2018 at 22:46",,,,218408
47535610,47535610,"In j2ee projects,Nullpointer exception is very common.Some cases reference variables got null values.So You should check the variable initialization properly.And during conditional statement you should always check that flag or reference contains null or not like:-  if(flag!=0) { ur code that uses flag }","Apr 17, 2015 at 12:58",,,,24407197
59294053,59294053,"It is worth mentioning that some IDEs (e.g. Eclipse) offer automatic nullity analisys based on 
customizable
 annotations (e.g. 
@Nullable
 as listed above) and warn about potential errors. It is also possible to infer and generate such annotations (e.g. IntelliJ can do that) based on existing code structure.","Mar 5, 2016 at 10:34",,,,24407197
71738102,71738102,"First thing should do is before using a nullable object, you should check whether is it null, using 
if (obj==null)
.If it is null then you should write code to handle that also.","Feb 17, 2017 at 6:52",,,,24407197
72104364,72104364,"IMO, it is preferable to avoid returning null objects in methods when possible and use annotation when null input parameters are not allowed in order to, by contract, reduce the amount of ´if (obj==null)´ in the code and improve the code readability.","Feb 27, 2017 at 9:43",,,,24407197
75210081,75210081,"Read this ... before you accept these ""best practices"" as truth: 
satisfice.com/blog/archives/27","May 21, 2017 at 7:52",,,,24407197
28025857,28025857,"While this is a nice example, may I ask what it adds to the question that isn't already covered by all the other answers?","Sep 24, 2013 at 6:20",,,,18974045
28026152,28026152,"It is simply inappropriate to use the word ""uninitialized"" here.  The example you shown is in fact ""initialized"", and it is initialized with null.  For uninitialized variables, compiler will complain to you.","Sep 24, 2013 at 6:32",,,,18974045
77702573,77702573,"A NullPointerException often occurs when calling method of an instance.For example, if you declare a reference but does not make it point to any instance, NullPointerException will happen when you call its method. such as: YourClass ref = null; // or ref = anotherRef; // but anotherRef has not pointed any instance ref.someMethod(); // it will throw NullPointerException.  Generally fix it in this way: Before the method is called, determine whether the reference is null. such as: if (yourRef != null) { 	yourRef.someMethod(); }","Jul 28, 2017 at 10:25",,,,9043523
77702579,77702579,Or use exception capture: such as: try { 	yourRef.someMethod(); } catch (NullPointerException e) { 	// TODO },"Jul 28, 2017 at 10:25",,,,9043523
63959819,63959819,"operation on uninitialized object at instance level(not the class level) will lead to NullPointerException. operation need to be instance specific. if operation is at class level, saying calling a static method on uninitialized object then it will not throw NullPointerException exception. Even primitive wrapper class objects throws NullPointerException.","Jul 8, 2016 at 15:20",,,,23852556
82212148,82212148,"1. NullPointerException is a RuntimeException, that means will appear when your program is running, you will not at compilation time.! :(, but most of the IDE help you to discover this. 2. Minimize the use of the keyword 'null' in assignment statements. :)  
Reference url:","Dec 4, 2017 at 5:49",,,,23852556
82212250,82212250,"@tomj0101 I'm thoroughly unclear as to why you made that comment... But to your second point, a pattern before 
Optional
 was to return null.  The keyword is fine.  Knowing how to guard against it is critical. This offers one common occurrence of it and ways to mitigate it.","Dec 4, 2017 at 5:54",,,,23852556
88180304,88180304,@Shomu: At what point do I even suggest that it should be caught?,"May 29, 2018 at 13:25",,,,23852556
91409874,91409874,Thanks Lauren. Are custom evaluation functions used only for reporting or can they also affect early stopping (as stopping_metric)?,"Sep 7, 2018 at 22:04",,,,52228271
91410413,91410413,"great follow up question! you can find the answer here:  
stackoverflow.com/questions/51657527/…
. The short answer is not at the moment but there is a jira ticket for this feature request.","Sep 7, 2018 at 22:43",,,,52228271
121485541,121485541,"FYI this has been added in 
3.26.0.1
, released in July 2019","Aug 11, 2021 at 11:53",,,,52228271
91492455,91492455,"Thank you. Regarding your second bullet point ""multiplying ..."" - I guess that min_rows must be adjusted (like I wrote and tested in my OP) in order for the outcome to stay the same if the weights are multiplied by a constant.","Sep 11, 2018 at 9:20",,,,52261250
91544046,91544046,"@cryo111 yes you are correct, you would need to adjust the min_rows.","Sep 12, 2018 at 14:56",,,,52261250
111184533,111184533,@Lauren Should you provide some additional info about how the weight column interacts with the loss function?,"Jul 13, 2020 at 10:43",,,,52261250
91302416,91302416,So I always have to download mojo as a zip file using h2o.down_load(modelName) and read the zip file to get mojo model? why zip file is used as intermediate variable?,"Sep 5, 2018 at 1:35",,,,52161668
91309918,91309918,"That helps a lot. ps： my code is copied from h2o examples using R or Python, but I didn't find how to download mojo as zip in java. There is no method called h2o.download(**) or other similiar name.","Sep 5, 2018 at 7:57",,,,52161668
91196357,91196357,"hi @pixiesweet44 the easiest way to get help is to update your question with explicit steps of what you did and what errors you got as you try new things out. It's hard to know what went wrong if you simply post ""h2o.jar does not work"".  For example I don't know if you followed the instructions from the downloads page 
h2o-release.s3.amazonaws.com/h2o/rel-wright/6/index.html
 or did something else. I also don't know how you were able to run h2o.remove_all() before running h2o.init(). Poke around a bit more through the documentation, I think you'll be able to figure it out. best of luck!","Aug 31, 2018 at 20:56",,,,52121119
91197879,91197879,"thanks for posting this! ( you can also edit your original question if you want to include new information) Since I wasn't able to successfully run your code, I'm going to post a code snippet below. If you can try to reproduce your issue with the code I've posted, feel free to update your question with more details. It will also be a way for me to make sure I understand your question and whether we need to report a bug or not. Thanks again!","Aug 31, 2018 at 22:38",,,,52121646
91200849,91200849,"Hi, thanks for your advice, I've changed the question","Sep 1, 2018 at 4:46",,,,52121646
91257156,91257156,"Hi, @Lauren have u got a chance to look at this issue?  Sry for interrupting","Sep 3, 2018 at 16:29",,,,52121646
91300993,91300993,"@Kuba what is the size of the cluster you are using, and what version of H2O are you using? thanks for the reproducible code snippet!","Sep 4, 2018 at 23:15",,,,52121646
91303778,91303778,@Lauren The version of h2o: 3.20.0.2,"Sep 5, 2018 at 3:44",,,,52121646
91171695,91171695,"PS: as you said in 
github.com/h2oai/h2o-3/blob/…
 , I can't do this. Because hex.tree package cannot be found.  You can see my code below, I got a model ""DRFModelV3"", how can I use it to get a MOJO ?","Aug 31, 2018 at 7:36",,,,52105665
91241565,91241565,"Yes, Using ""SharedTreeGraph g = ((DrfMojoModel) genModel)._computeGraph(treeToPrint);"" can get a tree.","Sep 3, 2018 at 8:30",,,,52105665
94072287,94072287,"I am using java, I don't find the java version of these.","Dec 4, 2018 at 2:53",,,,53599442
90991695,90991695,Thank you very much... i updated the title (it adds one row and deltes several colums) and specified that data.table::fread() works as it should,"Aug 25, 2018 at 19:40",,,,52011836
90947586,90947586,"Thank you Lauren, that is precisely the method I was referring to. But it differs from the traditional method where the feature is recalculated for each step of the cross-validation (with one hold-out fold), and I was wondering about the possible consequences.","Aug 24, 2018 at 7:15",,,,51995882
91043185,91043185,"Hi @PierreC, this method is currently only intended to be used with a train and validation split. If you do the automatic cross-validation triggered by setting the 
nfolds
 parameter you could definitely have leakage issues. Your best bet is to do careful manual cross validation or try to insure you don't have levels with very low counts.","Aug 27, 2018 at 19:50",,,,51995882
91240150,91240150,Thank you Lauren for these clarifications,"Sep 3, 2018 at 7:44",,,,51995882
91075527,91075527,Thanks! This is sort of what I was looking for.,"Aug 28, 2018 at 16:34",,,,52062592
91126270,91126270,"Dear @Darren Cook I still have an issue in the prediction: this is the dimension of train_h2o [66816 rows x 19 columns] and the dimension of test_h2o [18524 rows x 19 columns]. I am using ""test_data_finialized"" which is the 'data.frame' set. and has same dimention as test_data_finialized. I am getting: Error in names(IND) <- deparse(substitute(INDICES))[1L]: 'names' attribute [1] must be the same length as the vector [0] Traceback: .... I will update my post.","Aug 30, 2018 at 1:20",,,,52071620
91126468,91126468,"It will be great if you can make the answer by showing the result with a reproducible example. Again, Thanks for your effort.","Aug 30, 2018 at 1:39",,,,52071620
91135431,91135431,"@KingJulien If you can modify your question to have a fully reproducible example, I could edit it/test against it.  (Remember a reproducible example is likely to start with 
library(h2o)
, define all data, etc. I.e. allow me to copy and paste into an R session and run it, and see the same error message you get, without having to do anything else.)","Aug 30, 2018 at 8:47",,,,52071620
91164140,91164140,I provided Boston data to be reproducible and much simpler than my dataset. Thanks.,"Aug 30, 2018 at 23:30",,,,52071620
91226101,91226101,"Dear @Dareen Cook here is my new question. I hope it is clear : 
stackoverflow.com/questions/52138212/…
 please feel free to edit anything. I just want to take each time 96 values -15 minute sampling- and make prediction for it.","Sep 2, 2018 at 15:04",,,,52071620
90902308,90902308,"If your prediction frame isn't too big, I'd suggest just converting your H2O predictions frame to an R frame and continuing using the R functions you used before.","Aug 22, 2018 at 22:22",,,,51957138
90812865,90812865,"Hi Lauren. Thanks for the explanation and the links. So from what I gather, the sample data I provided is already formatted correctly to be fed into DAI? It has the entire time-series sequence of length t of data for user 1 in the first t rows, followed by the t rows of data for user 2, etc.","Aug 20, 2018 at 13:11",,,,51903318
90823918,90823918,@KOB updated the answer to clarify the answer. The new example should help clarify why the sample data you provided is not yet formatted correctly for DAI.,"Aug 20, 2018 at 18:58",,,,51903318
90824065,90824065,"I still do not understand how this is different to my original example. In my example, I have t days of data for n users, hence the data set has txn (t times n) rows. Therefore, if I had t=10 days of data, and n=5 users, my data set would have 50 rows, just like you have suggested.","Aug 20, 2018 at 19:05",,,,51903318
90825815,90825815,"I see, I misunderstood your t units. Yes your sample is in the correct format then.","Aug 20, 2018 at 20:10",,,,51903318
90922640,90922640,Thanks Lauren. It does clarify my doubts.,"Aug 23, 2018 at 13:11",,,,51899909
90732657,90732657,"Yes. Thats why I did not post that as answer. Because with the training threshold, I was able to reach close but not exact same. I think you should post this on 
the H2O issues here
, so that you can get confirmed answers from developers.","Aug 17, 2018 at 8:00",,,,51884117
111419826,111419826,"Maybe there's a rounding happening here. Please print the model threshold by using 
print(model)
 and compare it with your threshold found by 
perf.find_threshold_by_max_metric","Jul 21, 2020 at 3:20",,,,62996718
111419842,111419842,"Also as you can see on the other answer discussion, even we are not able to get exact same results. So maybe posting it to 
H2O github issues
 may help","Jul 21, 2020 at 3:22",,,,62996718
90683963,90683963,Think you may be right about this. Have updated original question with more debugging info. Could you tell me whether the train of thought in the updated portion is a plausible theory of what's happening here?,"Aug 15, 2018 at 20:22",,,,51863436
90690644,90690644,"The error message says 3 of the 4 requested nodes could be started, but there were not enough resources to start the 4th node.","Aug 16, 2018 at 4:22",,,,51863436
90719643,90719643,"To others finding this post with similar problems, these articles (
mapr.com/blog/…
, 
mapr.com/blog/best-practices-yarn-resource-management
) may be useful in understanding the problem (they are for MapR hadoop, but the basics should be generally  applicable to other hadoop distributions)","Aug 16, 2018 at 19:20",,,,51863436
91162114,91162114,"@KingJulien Why are you commenting here for another issue? Your comment is not related to this question or my answer.  This is the second issue you've posted on, please do not do this.","Aug 30, 2018 at 21:23",,,,51775747
91162336,91162336,I wanted your help that's why I commented here. I will delete my comment. Thanks,"Aug 30, 2018 at 21:33",,,,51775747
97011542,97011542,"Hi @ErinLeDell, I am getting the same error but on a significantly smaller data set. My feature set is 10k rows x 20 columns. I'm trying to train a multi class classifier with 
balance_classes = TRUE
 with 
stopping_metric = TRUE
 and 
sort_metric = TRUE
. I have also tried your trick of setting 
max_runtime_secs
 to a large value and setting 
max_models
. My H2O version is 3.23.0.4532. I'm guessing balance_classes and multi class don't play nice? Or is there something else that might be going on? Thanks very much!","Mar 13, 2019 at 6:16",,,,51775747
97012458,97012458,"@elvikingo Both 
stopping_metric
 and 
sort_metric
 take a string as a value, they are not boolean. You are using a nightly version (can you re-try on the stable version 3.22?).  If you can post a reproducible example on Stack Overflow or even better, file a JIRA ticket with the example, 
0xdata.atlassian.net/projects/PUBDEV
, that would be super helpful.  Thanks!","Mar 13, 2019 at 6:55",,,,51775747
97045789,97045789,"@ErinLeDell thanks for your response, Erin. I'm sorry I made a mistake while writing that comment. I definitely had 
stopping_metric = ""AUC""
 and not TRUE. I changed to the stable version 3.22.1.6 and it seems to be working fine. Would you still like me to file a ticket for the nightly version?","Mar 13, 2019 at 23:34",,,,51775747
90536907,90536907,"so I should be running something like 
grid_search.get_grid(sort_by='logloss, decreasing = True)
?","Aug 10, 2018 at 15:33",,,,51789673
90537119,90537119,yes now that your target is categorical H2O should accept logloss as a sort_by metric.,"Aug 10, 2018 at 15:39",,,,51789673
90718892,90718892,Sorry for the delayed response. This worked and your answer has been marked correct. Thanks!,"Aug 16, 2018 at 18:51",,,,51789673
90463528,90463528,"thanks for pointing out that situation, I indeed had integers representing the targets for classification. I tried passing in the 
asfactor()
 code before training, but the same error persists. I have included more code in my question.","Aug 8, 2018 at 16:51",,,,51735807
90464874,90464874,"Can you add the output of: 
train.type(target)
 and 
train[target].table()
?","Aug 8, 2018 at 17:33",,,,51735807
90465024,90465024,"train.type(target)
 outputs 
enum
 and 
train[target].table()
 outputs a 
table with each factor level
 and its counts (BPA is my target).","Aug 8, 2018 at 17:38",,,,51735807
90467401,90467401,"Please confirm that you have only two factor levels in your response. If so, next try: 
grid_search[0].auc()
 and see if it outputs anything.  And then can you re-start your H2O cluster (or delete the grid) and try running your code again?","Aug 8, 2018 at 18:56",,,,51735807
90471010,90471010,"I have restarted the cluster and retrained the model and the error still persists. I ran 
grid_search[0].auc()
 and I got a 
KeyError: 'AUC'","Aug 8, 2018 at 21:10",,,,51735807
90440932,90440932,"Dont works. If i put the response as factor got the following error: 
ERRR on field: _response: Regression requires numeric response, got categorical","Aug 8, 2018 at 7:04",,,,51732173
90534898,90534898,"are you saying that the code snippet above doesn't work for you, or that your code didn't work. You need to specify that your 
family = binomial
 with 
H2OGeneralizedLinearEstimator(family = 'binomial')
 in addition to converting the target to a categorical. Note that your error is saying your algorithm still thinks you are doing a regression problem, but that you have successfully converted your target to type categorical.","Aug 10, 2018 at 14:37",,,,51732173
90302724,90302724,Check the link that i posted to understand more,"Aug 3, 2018 at 9:59",,,,51669529
90302794,90302794,Also i read somewhere that the leaf node values for binary classification in xgboost [scikit learn] gives the value of x for p[x=1]=sigmoid(x)..is it the same here for h2o as well,"Aug 3, 2018 at 10:01",,,,51669529
90593506,90593506,"How is this a user error? Sure, there's nothing for the model to learn, but the fact that the library throws exceptions like this makes it unnecessarily hard to embed in a large automated application. It would be much more user-friendly if it just built a model which predicted that same constant class. Instead we have to catch these exceptions and put in workarounds in our code for no good reason. Is this an edge case? Sure. But the problem is still not ill-defined, it's just super easy.","Aug 13, 2018 at 10:07",,,,51655970
90620104,90620104,I guess the best way I can respond to that is to say no data scientist I've talked to in the last five years would intentionally give a constant Y column.  It's a sign that the data was prepared incorrectly.  So the software treats it as an error.  And that's what this persona of user would expect and likes in my experience.,"Aug 14, 2018 at 2:57",,,,51655970
90247217,90247217,Thanks Erin.  Very nice.  I'll look forward to feature importance from a Stacked Ensemble model,"Aug 1, 2018 at 19:59",,,,51641210
125019333,125019333,"I need to update my answer above but note that you can now get variable importance for Stacked Ensemble models using the Permutation Variable Importance method (new since my original answer): 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…","Jan 15, 2022 at 4:40",,,,51641210
90293224,90293224,"Thank you for your method! I used a similar method before. The saved model can only be used when the R software is opening. If I close the R software and open it again, the saved model can't be used.","Aug 3, 2018 at 3:45",,,,51614443
90945723,90945723,"That is true, as the model is no more available in the environment.","Aug 24, 2018 at 6:00",,,,51614443
90217206,90217206,"Than you. Once I have run the script and unpacked the file, what do I do next? Can I install DAI from this directory, or do I just run it with the scripts? What do the 
dai-env.sh
, 
run-dai.sh
 and 
start-h2o.sh
 scripts do?","Aug 1, 2018 at 6:08",,,,51613796
90293866,90293866,use ./run-dai.sh.  that will start the needed processes.,"Aug 3, 2018 at 4:33",,,,51613796
90243146,90243146,"Thanks for the reply. I was aware of this fix on a case by case basis, but I was hoping to be able to set all the column types upfront on large datasets before I knew about any future issues that might pop up. I ended up just making a loop that goes through my_h2o1.types.items() and looking for any 'int' data types and converting them into .asnumeric(). I still think it would be nice if the column_types argument in H2OFrame worked, but this helps as a work around.","Aug 1, 2018 at 17:47",,,,51603198
90322112,90322112,"I included your issue in the comments of this jira ticket (
0xdata.atlassian.net/browse/PUBDEV-5166
) if you'd like to track it that will hopefully solve upfront specification of column types.","Aug 3, 2018 at 20:05",,,,51603198
90306616,90306616,"Thanks, the answer is both useful and surprising since the Gini importance has been shown to suffer from enormous bias in the presence of catgeorical variables","Aug 3, 2018 at 11:54",,,,51598742
90551308,90551308,"See this post (
blog.hwr-berlin.de/codeandstats/…
) for an example on the perils of Gini importance.","Aug 11, 2018 at 6:39",,,,51598742
90944807,90944807,May I ask if it is possible to obtain the oob indices for the individual trees in the h2o forests? That would enable me to write my own permutation importance function.,"Aug 24, 2018 at 5:11",,,,51598742
90167638,90167638,"This isn't an answer, I recommend you delete your question instead.","Jul 30, 2018 at 19:11",,,,51600441
90167700,90167700,Understood. But I'm going to keep it here for archival since these questions may more appropriately belong elsewhere based on h2o's guidelines. Providing a reference there under this context will keep others that go down a similar path from hitting the same issue.,"Jul 30, 2018 at 19:13",,,,51600441
90167747,90167747,"OK, I won't push you (but others might!)","Jul 30, 2018 at 19:14",,,,51600441
90157202,90157202,"Thanks for pointing to that link, Lauren. I actually saw that webpage from H2O but had no idea how to do it within R. The option ""-Dsys.ai.h2o.ext.core.toggle.XGBoost"" is not an argument in h2o.init(). The suggestions in that webpage seems to be for use in direct H2O or Hadoop H2O drivers which I don't have experiences yet. Maybe I should clarify my question to be how to disable xgboost in h2o initialization inside R running on Windows machine. Sorry for the imprecision in my original question. Thanks.","Jul 30, 2018 at 13:59",,,,51566533
90237941,90237941,"Thanks. Lauren. Yes, you are right. My problem was not due to XGBoost. The problem actually goes away after I restarted my machine (I previously only tried restarting R and the problem was still there. Out of frustration I gave up and restarted my machine this morning due to something else. But then h2o works too =). Thanks for your help Lauren. My lesson is that not just restarting R but also restarting the machine after updating h2o to avoid initialization error. Hope my question here is helpful for other people who encounter the same problem.","Aug 1, 2018 at 15:13",,,,51566533
90263969,90263969,thankyou - this will be really useful when wiring up a model into a production data flow,"Aug 2, 2018 at 9:38",,,,51640668
90087421,90087421,"Is there a reason for this that I can read about online? The main advantage of 
h2o
 for me was its use of categorical features...","Jul 27, 2018 at 14:40",,,,51547413
90164253,90164253,"The reason is that 
h2o4gpu
 was released only a few months ago.  It's alpha and many features are not complete yet.","Jul 30, 2018 at 17:15",,,,51547413
89928630,89928630,"This helps a lot.. can not thank you enough.. Just to connect the dots, So 
xgb.cross_validation_holdout_predictions()
 gives prediction from each 5(nfold) different models for their particular holdout is it?","Jul 23, 2018 at 13:32",,,,51460571
89934197,89934197,"Yep, exactly.  The predictions on each row are from when that row was part of the holdout set in the CV loop.","Jul 23, 2018 at 15:45",,,,51460571
89950034,89950034,"Awesome.. I think 
xgb.cross_validation_holdout_predictions()
 doesn't work when we have multiple classes because it shows None type when we use this method..","Jul 24, 2018 at 5:01",,,,51460571
89985628,89985628,"@AbhijeetArora Make sure that you set 
keep_cross_validation_predictions = True
 or it will not store the CV predictions.","Jul 24, 2018 at 22:20",,,,51460571
89890333,89890333,"This is almost correct, but not the right method -- this method will return a list of CV pred frames instead of the CV preds in a frame, like OP is asking for.","Jul 21, 2018 at 22:15",,,,51454985
90439620,90439620,"Thanks a lot Tom for your answer. I did a small poc on the same and found that if total underlying resources (CPU and RAM) are fixed, executing requests sequentially would perform better.","Aug 8, 2018 at 6:21",,,,51375839
89925939,89925939,How are you doing in H2o driverless ai. Are you running models in parallel or sequentially. I just ran few data sets using your 21 days evaluation version and that was fast considering it ran quite a few models.,"Jul 23, 2018 at 12:29",,,,51412235
90439723,90439723,"Thanks a lot Erin for your answer. I did a small poc on the same and found that if total underlying resources (CPU and RAM) are fixed, executing requests sequentially would perform better.","Aug 8, 2018 at 6:24",,,,51412235
89538493,89538493,"Yes it does seem like the case. I wanted to open a thread just in case anyone had another solution, but seems like this is it. I'm accepting your answer, thanks for the input! (Could you edit the link from 
h2o
 to 
h2oai
?  
h2o
 is another project on GitHub.)","Jul 11, 2018 at 8:23",,,,51267479
89621214,89621214,Thank You. Well I've already implemented this logic manually. Was looking for some attribute as you've rightly mentioned.,"Jul 13, 2018 at 10:28",,,,51313978
99951553,99951553,"@Erin , Can we get the predicted probability for the train data instead of test data. We can do pred = my_gbm.predict(test_data=train) but rather just from training the model. Thanks","Jun 20, 2019 at 20:06",,,,51313978
99952983,99952983,"@Neo We save the training metrics, but not the training predictions.  So you will have to re-generate them using 
my_gbm.predict(test_data=train)
.","Jun 20, 2019 at 21:07",,,,51313978
89322168,89322168,"correction:  version: '3' services:   server:     ...     depends_on:       - database   database:     ...     expose:       - 54321  and h2o.connect(ip='database', port='54321')","Jul 4, 2018 at 9:02",,,,51169475
89322466,89322466,"correct me if i am wrong, but i think that 
ports:
 declaration is sufficient when communicating between two linked docker images. You would want to 
expose:
 the port only when you want to open the container to external connections?","Jul 4, 2018 at 9:09",,,,51169475
89325563,89325563,"Thank you very much, it worked, I used depends_on: 
theThingItDependsOn
 and then in my python code I wrote ip=*theThingItDependsOn*","Jul 4, 2018 at 10:30",,,,51169475
89325772,89325772,"But it is programming and now I have a different problem. Now because the h2o server and python are running in the docker, the windows path C:/Desktop/Data/data.csv is not visible, because is somewhere in a container. How do I insert the csv file in the container and specify the path? Do I use volume or is there an easiear solution?","Jul 4, 2018 at 10:36",,,,51169475
89355477,89355477,"Simas, it's the opposite. ""ports"" will publish the port to the host - that's why the format is ""dest:source""","Jul 5, 2018 at 8:40",,,,51169475
89283806,89283806,"Now, I just redirect h2o.connect(ip='127.0.0.1', port='54321'?","Jul 3, 2018 at 8:40",,,,51149904
89283921,89283921,"Great! :) Please, as it works, upvote or accept my answer, please","Jul 3, 2018 at 8:43",,,,51149904
89284522,89284522,"I connect the python to 127.0.0.1:54321 where h2o server is running, but it can't find the data.csv file, can you help ?","Jul 3, 2018 at 9:00",,,,51149904
89284580,89284580,"I'll try, but first, can you tell me what's 
data.csv
 file?","Jul 3, 2018 at 9:01",,,,51149904
89284983,89284983,It is a file containing data to build the machine learning model off of,"Jul 3, 2018 at 9:13",,,,51149904
89282019,89282019,Awesome :) Thank you Lauren it works for me and quick reply,"Jul 3, 2018 at 7:45",,,,51142007
88973852,88973852,"thanks for your answer. I was just wondering, because my h2o deep learning model (one-hot-encoding) is generating dummy-features for bool-Features and there is also one Feature for the 'Missing'-Category added, although I do not have any missing values left in my data frame. My thought was that this comes from wrong interpreting bool as enum. Why does the DeepLearning Model add Features for the 'Missing'-Category?","Jun 22, 2018 at 14:00",,,,50989511
89028940,89028940,But there is a 'Missing(NA)'-Category added for a Boolean Feature that has not any missing Values. The Feature is not missing in training or test data. Why is this happening? I just want to understand and be clear what(and why) features are in my model in the end.,"Jun 25, 2018 at 7:26",,,,50989511
89030816,89030816,@dnks23 I added a couple of sections to my answer.,"Jun 25, 2018 at 8:28",,,,50989511
88935659,88935659,"That's unfortunate - why is this the case? I am very new to understanding how H2O works, so excuse my ignorance, but for H2O to run a model, couldn't the entire model essentially be a ""black box"" from H2O's point of view, where H2O just feeds the data into the model and retrieves the output? The majority of my work involves time-series problems, and I was excited with the idea of integrating H2O, but now it seems as though it is far too restricted with regards to time-series models.","Jun 21, 2018 at 13:24",,,,50969577
88941794,88941794,"The main reason is that H2O's models are built in-house and designed to run at scale and be distributed (note designing a model to be distributed is a feat in itself) - H2O isn't using someone else's model and viewing it as a ""black box"".","Jun 21, 2018 at 15:49",,,,50969577
88946018,88946018,"Makes perfect sense, I understand. Thank you","Jun 21, 2018 at 18:02",,,,50969577
88905333,88905333,Thanks for the both answers.,"Jun 20, 2018 at 17:21",,,,50952993
88982891,88982891,"Thank you, Erin!  For my case, i always got error as ""Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = urlSuffix, : Unexpected CURL error: Recv failure: Connection was reset"". I have asked a coworker to run this as well and he also got the same error as i did and he is using 3.18 version of h2o. I wonder what does this error may refer to and is there anything we may need to set up on edgenode?","Jun 22, 2018 at 19:02",,,,50994145
89131588,89131588,"Can you please try to reproduce without grid search? Can you build a 5-fold cross validated model? Can you build a simple model with XGBoost?  You can try limiting number of threads H2O can use, start h2o with -nthreads parameter. I would experiment with 10 and 20.","Jun 27, 2018 at 20:28",,,,50994145
89006603,89006603,"figured it out with the dir() function, but yes - thanks","Jun 24, 2018 at 3:14",,,,50890536
88650868,88650868,"I had tried 
h2o.shutdown
 to restart the cluster. It fixed the problem, forgot to update it here. Before running into this issue I ran 
automl
 for more than 12 hours. Do you think it could have something to do with making the cluster slow?","Jun 12, 2018 at 17:45",,,,50820886
88657879,88657879,"That might have something to do with it -- the H2O cluster might have run out of memory because it was storing so many models, so if you can, give it more memory.  If you download H2O 3.20.0.1 from h2o.ai/download, you can use the new 
keep_cross_validation_models
 option in AutoML which you can set to 
FALSE
.  This will throw away CV models, which should free up additional memory.","Jun 12, 2018 at 22:17",,,,50820886
88678602,88678602,"When I get this error it has usually meant I've used up too much memory (made too many models). At that point it is usually too late to recover gracefully, so I have to kill it and re-start. Be aware that you can pass an arg to h2o.init(), e.g. 
max_mem_size=""4G""
, to give it more memory. If the machine is not doing anything else, you should be able to safely allocate all but 1G of your system memory to H2O.","Jun 13, 2018 at 12:37",,,,50820886
88663416,88663416,"I have a very large dataset of about 10TB and also the data is not fixed and is always increasing (as it is a streaming data) .  So, how can CPU predict for such large dataset.?","Jun 13, 2018 at 5:25",,,,50825813
88757644,88757644,"as you said, it seems to be more suitable for weighting observations for time-varying data than for a particular feature. The documentation does not help too much. I was thinking like in a linear regression model, where the weights quantify the importance of each feature, but this is what we are looking when we build the model. 
h2o.varimp
 for GLM informs about coefficients and sign (a proxy of importance as it is in GBM/RF). I get slightly better results using GLM.","Jun 15, 2018 at 14:40",,,,50874444
88865590,88865590,The important point here is that you are extracting them from a fitted model not pre-specifying them. You might get better performance if you tune some parameters. In particular look at increasing the number of trees and adding early stopping for the gbm and rf models.,"Jun 19, 2018 at 17:02",,,,50874444
88622235,88622235,"Thanks a lot. But When I checked this option, it shows ""a large license is required to grant additional permissions to unsighed extensions. "" What is a large license?  I used the academic plan to get the license. So if I want to check this option, I have to buy a paid license?","Jun 12, 2018 at 1:58",,,,50792568
88622258,88622258,Or how can I make this extension which I developed a signed extension?,"Jun 12, 2018 at 2:01",,,,50792568
88855196,88855196,"At the moment, you need a commercial license to use the ""unsigned extension"" option. You can also try to apply for a trial license during your development phase.","Jun 19, 2018 at 12:15",,,,50792568
88875724,88875724,"There is no chance that I can use a free license to do my development with the unsighed extension? But we are not decided to use RM or not, I want to run the program and extension more locally . So I think RM is not so much friendly to the developer.","Jun 20, 2018 at 0:56",,,,50792568
88539162,88539162,"Could you try using one or both of these special characters:  ""–"" and ""‘’"" in your column names?","Jun 8, 2018 at 17:36",,,,50765012
88571605,88571605,how is your answer different then mine?,"Jun 10, 2018 at 9:59",,,,50766049
88578275,88578275,"@catta if you include 
<type>pom</type>
, then 
hex.genmodel
 packages will not be available. If you want to update your answer explaining why it's marked (perhaps incorrectly?) as a pom type dependency, I'll mark it as correct.","Jun 10, 2018 at 16:46",,,,50766049
90600898,90600898,"what about if i want to use 
categorical_encoding = 'enum'
 in my RandomForestEstimator? I do not know the final number of features that the model will use for prediction due to categorical encoding of H2O. How can I set mtries in this case, so that the Model will use all features as u suggested?","Aug 13, 2018 at 13:24",,,,50744752
90604010,90604010,"please see: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…","Aug 13, 2018 at 14:42",,,,50744752
90606660,90606660,"this does not answer my question. I asked: Due to 
categorical_encoding='enum'
 i do not know the number of features used for training. Therefore I can not set 
mtries
 - Parameter as you suggested. How to set 
mtries
 in this case?","Aug 13, 2018 at 15:52",,,,50744752
90640866,90640866,"set 
mtries
 to you number of original features in the dataset. Please read the linked description of 
categorical_encoding='enum'
 to understand why (i.e. the encoding leaves the dataset as is and provides a mapping from string to integers).","Aug 14, 2018 at 14:28",,,,50744752
91130870,91130870,"if I set mtries to the number of predictors (21) I get an Error saying that mtries can be in interval [1,16[ but not 21.","Aug 30, 2018 at 6:33",,,,50744752
88501445,88501445,What is the maximum data size that a panda dataframe can read ?,"Jun 7, 2018 at 17:23",,,,50739411
88501888,88501888,"@AnshulGupta That should be a new question, but don't do that, as it  is easy to google for. (The answer appears to be: as much as you have RAM for, assuming it is 64-bit python.)","Jun 7, 2018 at 17:38",,,,50739411
88504349,88504349,"That would be great, as is it's pretty confusing, especially since the documented way to get the h2o-genmodel.jar is in the model export along with the mojo.","Jun 7, 2018 at 18:59",,,,50740467
88506482,88506482,"While you're looking this direction, maybe you could check out this other H2O question? 
stackoverflow.com/questions/50749476/…","Jun 7, 2018 at 20:11",,,,50740467
88431213,88431213,"thanks a lot, this help me to fix the time type. But the chinese character still wrong. 
imgur.com/a/gOeXIGh","Jun 6, 2018 at 1:43",,,,50697824
88435009,88435009,Which H2O version you are using?  try using version 3.18.0.8,"Jun 6, 2018 at 5:56",,,,50697824
88436008,88436008,"My H2O version is 3.18.0.11. And I install the version 3.18.0.8, but it still show me this 
<0xA4EB>	<0xA9>P<0xA4BB>
. My python version is 3.6.5 does it impact for this problem?","Jun 6, 2018 at 6:36",,,,50697824
88442238,88442238,and which python version?,"Jun 6, 2018 at 9:30",,,,50697824
88471796,88471796,python version 3.6.5,"Jun 7, 2018 at 2:00",,,,50697824
88335494,88335494,That approach was working for me before. Thanks though. Looking to solve it through pickle if it's possible.,"Jun 3, 2018 at 2:03",,,,50645249
88269806,88269806,"+1 for 
cut
 (I am amazed I never knew about that command!). I guess the point of the question was ""20gb is too big to fit in memory"", so the other solutions won't be usable.","May 31, 2018 at 17:41",,,,50611180
88277927,88277927,"Thanks but no i have tried na.strings and the default if you look at h2o code is that it used ""NA_h2o"" as the na string in it's conversion - also, given as.h2o takes an R frame converts to csv and then calls importFile (or maybe uploadFile - they are similar)","May 31, 2018 at 22:55",,,,50608965
88314171,88314171,"@SimonR can you provide a few rows so i can test out your issue. in the following example, you'll see that as.h2o distinguishes between blank ' ' and NA : 
df <- data.frame(a = c(1:3,NA,4:6),b=c(letters[1:6],NA), c= c(1,NA,runif(5)))
 
df[1,1] <- ' '
 
dh <- as.h2o(df)","Jun 1, 2018 at 22:21",,,,50608965
88081172,88081172,"There is a problem with h2o.relevel; I tried to get the min or max using h2o.which_min(df$x) and h2o.which_max, but the output is NAN. This tells me that h2o.relevel does not set a decreasing order for instance. How can I achieve that? Thank you","May 25, 2018 at 17:57",,,,50476348
88082492,88082492,"The 
h2o.which_min()
 and 
h2o.which_max()
 functions don't work on factor columns.  I have updated my answer above to show an example so you can see that it's working.","May 25, 2018 at 18:50",,,,50476348
87948710,87948710,"thank you for the answer. I was looking for a solution for python not for R. i get this error when i run ""h2o.download_mojo..."" :  AttributeError: module 'h2o' has no attribute 'download_mojo' H2O session _sid_81cf closed.","May 22, 2018 at 12:33",,,,50416990
103530056,103530056,Is there any tutorial on how to deploy a distributed h2o model in azure rest api?,"Oct 29, 2019 at 14:44",,,,50401234
93708174,93708174,I have the exact same problem and can't resolve it . Even if i specified a new port,"Nov 21, 2018 at 16:49",,,,50274655
87559939,87559939,"thanks Lauren, I will try the boilerplate code with the test dataset and see if I can whittle down to the difference in my setup. I am currently restricted to using 3.10.x due to reasons outside my control but this is only temporary. Looking forward to trying the AutoML module...","May 10, 2018 at 11:04",,,,50261540
91488479,91488479,"I run a tomcat to check the port, and it haven't been taken. But I just can't run H2O successfully.","Sep 11, 2018 at 7:20",,,,50237057
68983017,68983017,I would give the spark-jobserver a chance. You can cache a model (a complete spark pipeline even) easily and quickly answer ml - relevant queries such as classifications or queries. It also gives you the opportunity to cache aggregated tables and quickly return json containing this data or parts of it for a visualisation or further processing in another application.,"Nov 30, 2016 at 9:23",,,,40536323
126051570,126051570,"MLeap's feature list looks like a missing puzzle in spark ML pipelines. However when I tried to serialize a simple pyspark ML pipeline containing an 
Imputer
 I failed to make it work. All examples show various transformers, which also work for me, but sadly Imputer does not seem to be supported :(","Mar 1, 2022 at 17:14",,,,49781272
87146456,87146456,"I got Rjava to work by installing the Java 8 on the website - JDK 1.8.0_171.   However, I'm not able to get h2o work.  when I use H2o I still get  java version ""10.0.1"" 2018-04-17 Java(TM) SE Runtime Environment 18.3 (build 10.0.1+10) Java HotSpot(TM) 64-Bit Server VM 18.3 (build 10.0.1+10, mixed mode).    I adjusted my .bash_profile to be --> export JAVA_HOME = ""/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk""   export LD_LIBRARY_PATH = ""/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/server"" export PATH=$PATH:$JAVA_HOME/bin","Apr 27, 2018 at 14:46",,,,50052695
87149254,87149254,"2 things: 1. how did you install/build h2o? (I suggest this one 
h2o-release.s3.amazonaws.com/h2o/rel-wolpert/8/index.html
); 2. R: are you in the terminal or in RStudio?","Apr 27, 2018 at 16:10",,,,50052695
87307594,87307594,"actually @Pasqui , I'm having a bit of trouble.  Somehow it broke and I'm not allowing it to work anymore..  I updated the post with a description.","May 2, 2018 at 22:59",,,,50052695
87098271,87098271,"Thanks. Weird that it's not saved in the 
params
 dictionary though, is this by design?","Apr 26, 2018 at 10:56",,,,50030391
86977542,86977542,"My two best performing models are indeed ensembles, but I'm gonna try this out for my other models.  Gonna check out lime for my ensembles, thanks!","Apr 23, 2018 at 12:10",,,,49980598
104443366,104443366,"Maybe this is new since the answer was posted, but with H2O AutoML in R I get a warning message ""In h2o.varimp(model) : No variable importances for H2OAutoML""","Nov 29, 2019 at 13:36",,,,49980598
104464001,104464001,Are you running that on the model object or the automl object? Needs to be on the model object.,"Nov 30, 2019 at 14:18",,,,49980598
86906452,86906452,"Hi, I used this technique it changes the beta after defining the beta constraints, but not giving me the desired results I'm looking for as per my question above.","Apr 20, 2018 at 15:31",,,,49926150
86906639,86906639,This is how I defined beta constraints,"Apr 20, 2018 at 15:36",,,,49926150
86906790,86906790,names  beta_given  lower_bounds  upper_bounds,"Apr 20, 2018 at 15:40",,,,49926150
86906801,86906801,Intercept      -4.455417     -4.455417     -4.455417,"Apr 20, 2018 at 15:40",,,,49926150
86906809,86906809,23_22_NA   -1.959672     -1.959672     -1.959672,"Apr 20, 2018 at 15:40",,,,49926150
86863252,86863252,"I have 2 Private IP:  54.x.x.x and 53.x.x.x  My flatfile is: 54.x.x.x:54321 53.x.x.x:54321  My dockerfile EXPOSES 54321 and 54322 and executes  java -jar h2o.jar -flatfile flatfile -port 54321   Since h2o is running in container (172.17.0.2:54321), my flatfile isn't picking up the 2 containers running the tar as it's looking for the h2o running on 54.x.x.x:54321 and my docker command is: sudo docker run -it -p 54321:54321 h2o What should I modify? Flatfile, java parameters?","Apr 19, 2018 at 14:34",,,,49911695
86905754,86905754,"you can attempt to force h2o to use public address, or you could make the flat file with all the ""172.17.x.x"" address, assuming that the containers and reach each other on the docker veth bridge","Apr 20, 2018 at 15:12",,,,49911695
86826416,86826416,"The make steps got further, but have prompted two more questions:  1. If I get ""Step 1/55 : FROM undefined"" is that because I am missing CUDA drivers?  2. Do I need the latest ""wget"", I am getting a SSL error on another machine when using wget (version 11.14) to sourceforge","Apr 18, 2018 at 17:06",,,,49898753
86828121,86828121,The FROM is nvidia/cuda:9.0-cudnn7-devel-centos7,"Apr 18, 2018 at 17:59",,,,49898753
87231847,87231847,"That is actually what I found out later, thank you for the answer!","Apr 30, 2018 at 19:51",,,,49988208
86863624,86863624,"My appologize, it is actually 80000+ and 2000+ fields, I will update my answer.","Apr 19, 2018 at 14:43",,,,49898554
131781832,131781832,"# Filter dictionary by keeping elements whose keys are divisible by 2 newDict = dict(filter(lambda elem: elem[0] % 2 == 0, dictOfNames.items())) print('Filtered Dictionary : ') print(newDict)","Dec 2, 2022 at 20:19",,,,74661061
86926862,86926862,"The line that caught my eye was 
spark.executor.memory=700m
.  I recommend making executors no smaller than 5gb each, and even that is small.","Apr 21, 2018 at 11:25",,,,49778031
91161942,91161942,@KingJulien Why are you commenting here for another issue?  Your comment is not related to this question or my answer.,"Aug 30, 2018 at 21:16",,,,51889351
137222562,137222562,The link is about GPU support. Is that a requirement for xgboost on h2o?,Jan 18 at 7:09,,,,49777984
86459189,86459189,Thanks a lot. I will just then need to make function more 'fail safe' inside shiny,"Apr 8, 2018 at 21:18",,,,49721669
86477514,86477514,Yes it worked perfectly! Thank you! Do you know if it does a similar thing with the output? I mean doing the inverse operations?,"Apr 9, 2018 at 11:35",,,,49729650
86414019,86414019,"I used H2O package. My R session did not crash (yet). Though I am unclear in terms of what optimizations can I perform to minimize R crashing, your answer helped. I am marking this as answered.","Apr 6, 2018 at 20:14",,,,49681471
86494172,86494172,The reason it works in H2O is because its far more memory efficient the GBM implementation from the party package.  It was crashing before because it was running out of memory (and now it's not).,"Apr 9, 2018 at 18:59",,,,49681471
86495368,86495368,"I do see some issues though. When I convert a R data frame to H2O frame (as.h2o(my_data_frame), the number of rows has reduced to 3.5 million rows from 7 million (approx). Investigating as to why is it happening. I stopped all the other programs so my server solely works for the model building task.","Apr 9, 2018 at 19:40",,,,49681471
86542964,86542964,"That's not good. If you can provide a reproducible example, please file a bug report here: 
0xdata.atlassian.net/issues
 If you don't need to do any data munging, load the data directly from disk into the H2O cluster using 
h2o.importFile()
 and skip 
as.h2o()
 altogether.  It's much more memory efficient.  If you have to use 
as.h2o()
, then install data.table and set 
options(h2o.use.data.table = TRUE)
 to speed it up.  See: 
stackoverflow.com/questions/49634547/…","Apr 10, 2018 at 22:19",,,,49681471
86393403,86393403,"I would suggest looking at the demo from the last H2O World conference available at: 
github.com/h2oai/h2o-tutorials/blob/master/h2o-world-2017/…
  It shows how the model can be trained off-line but the predictions are the on-line in the Streaming application.","Apr 6, 2018 at 10:37",,,,49671699
86312188,86312188,"@Darren_Cook - Imagine operating this data.table code ""df[, (paste0(""lag_"",rep(cols, each = length(my_lags)), ""_"", rep(my_lags, times = length(cols)))) :=            unlist(lapply(.SD, function(x) shift(x, my_lags, type = ""lag"")), recursive = F), .SDcols = cols]"" when ""my_lags"" has 140 elements and the initial df is about 20 columns if which 16 are used in ""cols"".  If I had to do it one at a time in h2o, it would take me in the neigborhood of 2280 lines of code.  I could make R write the code into a text file, then source it, but that is more of a headache than the 4 lines above.","Apr 4, 2018 at 13:14",,,,49644917
86315004,86315004,"It's 
not
 true that 
as.h2o
 uses 
data.table::fwrite
 if available. A bug in the package logic means you also have to set 
options(h2o.use.data.table = TRUE)
 as well.","Apr 4, 2018 at 14:11",,,,49644917
86319813,86319813,@Hugh Thanks: I just added that to the answer.,"Apr 4, 2018 at 15:54",,,,49644917
86319862,86319862,@EngrStudent Yes: it'd be lovely if H2O had built-in support for doing lags!,"Apr 4, 2018 at 15:55",,,,49644917
122440561,122440561,"how can one switch between a 
import ai.h2o.sparkling.ml.models.H2OMOJOModel
 to a 
hex.genmodel.MojoModel
?","Sep 21, 2021 at 19:01",,,,49521432
86025995,86025995,Thanks (Hvala) Tom :),"Mar 27, 2018 at 10:51",,,,49510720
86021140,86021140,"Yes 43 and 1 are the number of neurons on input and output layers given by default by h2o. [2] and [8] are my hidden neurons. I have tried [30,20] with rectifier and [8] with tanh. I am going to try more hidden neurons with Tanh","Mar 27, 2018 at 8:58",,,,49507985
86028365,86028365,"@T.RB Your 100-100-tanh chart looks like it is not learning anything. Personally, my next step would be to try a random forest and GBM on the same data (using all default settings), and see if they are bad too. If so, maybe the problem is a lack of signal in the data?","Mar 27, 2018 at 11:47",,,,49507985
86031166,86031166,"I tried random forest and GBM with defaults parameters, scoring history is smoother (see my post updated).","Mar 27, 2018 at 12:47",,,,49507985
86130927,86130927,This absolutely meets my needs! I had never explicitly used the call() function before. Thanks.,"Mar 29, 2018 at 16:56",,,,49547009
87748832,87748832,"It doesn't work for pysparkling 2.2: 
AttributeError: 'H2OFrame' object has no attribute 'add'
. Your sugestion of h2o solution works only on data, which (completely) fits into RAM memory, so it is not the case of Spark + H2O.","May 16, 2018 at 8:52",,,,49487038
87776898,87776898,"@wind Thanks. I think the OP wanted a Scala solution, but your info will be useful for people using pysparkling. (Actually that is just like the normal H2O python API, isn't it.)","May 16, 2018 at 21:45",,,,49487038
85992027,85992027,"Thank you Erin. A bug report has been created : 
0xdata.atlassian.net/browse/PUBDEV-5419
. The table in the bug report is messed up so I also attached the data as an excel file.","Mar 26, 2018 at 14:42",,,,49454846
85832333,85832333,"The above mentioned workaround does work. The code that I provided above is a simplified version of what I am actually trying to do. In my real application, I have to call h2o.cbind multiple times based on various conditions. Is there another workaround that can accomodate that constraint?","Mar 21, 2018 at 19:47",,,,49414799
85832363,85832363,"Also, I am curious why h2o.cbind is actually behaving that way.","Mar 21, 2018 at 19:48",,,,49414799
85840963,85840963,@Karthik Could you update the post with how you are using the function.,"Mar 22, 2018 at 2:55",,,,49414799
85852516,85852516,I just updated my original post to add some clarity on how I am using h2o.cbind.,"Mar 22, 2018 at 10:10",,,,49414799
85856833,85856833,"Glad that you  were able to resolve.  Sorry, I got busy and couldn't check your comment earlier","Mar 22, 2018 at 11:49",,,,49426732
85850245,85850245,"Thanks SO much Erin. We will give that a go, as it looks like this may be the way forward. We had been using binary models to date but as we are migrating from NTT to AWS the preference is for mojo so we can get around build vs deployment version issues. Thanks and ill update you as to our progress.","Mar 22, 2018 at 9:15",,,,49415285
85982975,85982975,"Hi Erin, we appear to have made some progress, Ie the json gets created fine, but we are seeing the following error message now....""Could not find or load main class water.util.H2OPredictor ""","Mar 26, 2018 at 11:13",,,,49415285
86023262,86023262,"Hi. We managed to get this error to disappear and have a prediction coming out, which is amazing thanks! The key was to bin toJSON and use your code from 
stackoverflow.com/a/47784930/5451344
. However, we now seem to not be able to include factors in the model where the values contain a space or ampersand. We have tried all ways to escpate them but to no avail...any ideas? thanks,","Mar 27, 2018 at 9:49",,,,49415285
86041734,86041734,"From the code      df<- data.frame    (a=0,b=0,c=0,d=1,e=0,f=0,g=""METAL"",h = ""LONDON & SE"") dfstr <- sapply(1:ncol(df), function(i) paste(paste0('\""', names(df)[i], '\""'), df[1,i], sep = ':')) json <- paste0('{', paste0(dfstr, collapse = ','), '}') dataPredict <- as.data.frame(h2o.predict_json(model = ""D:\\GBM_grid.zip"", json = json, genmodelpath = ""D:\\h2o-genmodel.jar"")) this is the error ""error: Factor w/ 1 level ""com.google.gson.JsonSyntaxException: Malformed JSON\r\n\tat water.util.H2OPredictor.jsonToRowData(H2OPredictor.""| 
truncated
: 1""","Mar 27, 2018 at 16:33",,,,49415285
86263772,86263772,"We seem to have fixed this issue by introducing '' around out strings with spaces in them so ""LONDON & SE"" becomes ""'LONDON & SE'"". SO far this has worked!","Apr 3, 2018 at 11:05",,,,49415285
85842038,85842038,Thank you Erin for your comment. But did not understand the point about non-US locales.,"Mar 22, 2018 at 4:16",,,,49394009
85843496,85843496,"If you're seeing NaNs on the leaderboard, this is caused by a bug triggered by system locale settings. See 
Sys.setlocale()
.","Mar 22, 2018 at 5:38",,,,49394009
85721126,85721126,"I'm getting the following error: 
value toDF is not a member of org.apache.spark.h2o.RDD[Int]","Mar 19, 2018 at 10:19",,,,49356186
85722965,85722965,"you would need 
import sqlContext.implicits._
 as well","Mar 19, 2018 at 11:08",,,,49356186
85735207,85735207,"why 
sqlContext.implicits
? also, I don't have the variable 
sqlContext","Mar 19, 2018 at 15:57",,,,49356186
85735366,85735366,.toDF() is available in sqlContext.implicits._ and you can create sqlContext as you created sparkContext,"Mar 19, 2018 at 16:01",,,,49356186
85735940,85735940,"Now it compiles, but when I run I get 
When using the Sparkling Water as Spark package via --packages option, the 'no.priv.garshol.duke:duke:1.2' dependency has to be specified explicitly due to a bug in Spark dependency resolution.","Mar 19, 2018 at 16:14",,,,49356186
85739304,85739304,"@DarreenCook, Now have installed the 3.18 h2o R-package and the result running R-script differs from h2o flow. I followed your suggestion, I ran the script with default parameters and I got different results (even using the same seed). I will post an update to my question for more details. My understanding is that we should be able to reproduce the same experiment (not just similar) when using the same seed in both cases.","Mar 19, 2018 at 17:41",,,,49334850
85742035,85742035,"@DavidLeal Your question shows a confusion matrix where it has always guessed ""yes"". If that is not what you are seeing when running the code you posted, then, yes, editing the question (or starting a new question) is a good idea!","Mar 19, 2018 at 19:02",,,,49334850
85746715,85746715,"I understand the question is valid so far because I am not able to reproduce the same result from h2o flow into R-package. I will try to verify this issue using another set of data if that is the case, then I will post another specific question","Mar 19, 2018 at 21:39",,,,49334850
132932207,132932207,"While this code snippet may be the solution, including a detailed explanation really helps to improve the quality of your post. Remember that you are answering the question for readers in the future, and those people might not know the reasons for your code suggestion.","Feb 3, 2023 at 12:56",,,,75334817
85549044,85549044,"Does the bug just affect Python? Or was this a bug introduced on the Java side, at some point? (The example in the book was done in R, and was done with H2O 3.10, IIRC.)","Mar 14, 2018 at 8:51",,,,49267726
85549045,85549045,"Thanks for the answer, but my issue concerned the Rate column in the confusion matrices, where even for balanced models I got an unbalanced number of Iris-virginica.  Anyhow I managed to output the proper CMs, using model.model_performance(train=True), now the question is what is the difference between the matrix I get from model.confusion_matrix(train) and the one I get from .model_performance(train=True) method?","Mar 14, 2018 at 8:51",,,,49267726
85549236,85549236,"@Daniele It sounds like that is worth asking as a new question. (If you think it is part of this same one, you could edit your question and show the additional code; but that can be confusing once a question has got an answer.)","Mar 14, 2018 at 8:56",,,,49267726
85619457,85619457,"@Daniele This is a known confusion matrix bug here: 
0xdata.atlassian.net/browse/PUBDEV-5243
 which is probably what you're running into, but this code does not work 
model.confusion_matrix(train)
 so i can't replicate what you're doing.  Check out the JIRA and please add your discrepancy as a comment. Thx!","Mar 15, 2018 at 20:29",,,,49267726
85619502,85619502,@DarrenCook It's not implemented in the backend in RF apparently... we just noticed this.,"Mar 15, 2018 at 20:30",,,,49267726
85581120,85581120,"Hi Erin and Michal, thanks for your answer. Do you think it were possible to implement it in forthcoming releases?","Mar 14, 2018 at 23:02",,,,49267663
85619135,85619135,"Yes, as long as XGBoost supports this, we will add it later, but not in the next release.","Mar 15, 2018 at 20:19",,,,49267663
85619373,85619373,"Thanks, I have opened an issue in Atlassian","Mar 15, 2018 at 20:26",,,,49267663
85428318,85428318,"Thanks, where do you find the older versions? Could you give an example of how to install version 3.14.0.7 and how you found the URL?","Mar 10, 2018 at 17:26",,,,49208353
85429313,85429313,"@Dan Google ""h2o 3.14.0.7"" :-)  Also see 
stackoverflow.com/q/40651735/841830","Mar 10, 2018 at 18:17",,,,49208353
85433837,85433837,"OK so if I google that exact version I get a page with a URL to the whl which I can install from (
h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/7/index.html
) however if I google other versions I get no such luck. Is there not some directory or list of the URLs where the older version whl files can be found?","Mar 10, 2018 at 22:41",,,,49208353
85433859,85433859,"btw even though this is the answer I guess I'm going to have to go with, I'm going to leave this as unresolved because it really seems like something h2o users will need to be able to do. Thanks for the help though!","Mar 10, 2018 at 22:42",,,,49208353
85464847,85464847,@Dan I've appended to my answer.,"Mar 12, 2018 at 8:22",,,,49208353
85413966,85413966,gradlew build will install h2o to the python path?,"Mar 10, 2018 at 1:04",,,,49202383
85424881,85424881,"Probably not, but in directory 
h2o-py
 there is 
setup.py
 and you know what to do with it.","Mar 10, 2018 at 14:33",,,,49202383
85428369,85428369,"I'm really not following how this works. Could you give step by step instructions of how to do this in Windows including what I would need to install (
zcat ... | ...
 doesn't seem like Windows to me), which directories I should go to and what to do with setup.py afterwards to make sure I'm installing to the conda virtual environment rather than global Python?","Mar 10, 2018 at 17:28",,,,49202383
85429562,85429562,"zcat ... |
 works on Windows in command line. But you can extract the archive any way you prefer — using WinRAR or WinZIP of how you usually extract archives.","Mar 10, 2018 at 18:29",,,,49202383
85458352,85458352,"yes, frames and models can be saved to disk，but not automatically,  each restart of the cluster will lost everything","Mar 12, 2018 at 2:26",,,,49191826
85459666,85459666,"This can be done in literally few lines of code, if we had such a feature in H2O you'd probably have to configure it and would take similar amount of work. Leaving this to the user indeed makes the user write more code but imho is a much more robust solution than anything we could come up with.  The only use case I could see where it would be better to have this as part of H2O is to implement it as a JVM shutdown hook, but you can implement it yourself if you're using Java/Scala version but need to remember it might not work 100% of the times depending on the type of shutdown.","Mar 12, 2018 at 4:15",,,,49191826
85458369,85458369,dose h2o have  Resource isolation or multi-tenant support?,"Mar 12, 2018 at 2:28",,,,49208250
85459593,85459593,"@寒江雪 no, the intended use case is to have an instance per user","Mar 12, 2018 at 4:11",,,,49208250
85577205,85577205,Hi Erin. Im currently using the Apache Spark KMEANS  however I am also using the Autoencoder its giving good results thanks.,"Mar 14, 2018 at 20:27",,,,49140456
85039123,85039123,"Where is the ""name"" or ""indices"" specification located in the 
h2o flow
 UI? When I trained the model through that interface, I do not recall ever seeing that parameter. Is it set a particular way by default? I ask because looking at the model's 
.get_params
 and 
.full_parameters
 fields in python, I could not find anything that would tell me what the model was expecting.","Feb 27, 2018 at 20:06",,,,49000468
85628899,85628899,"In my example, I accidentally pasted results of trying out on port 2341. But the results were the same when trying the default port 54321. Regarding giving permission to access localhost, Mac doesn't ask me. I assume it is enabled, by default.","Mar 16, 2018 at 5:25",,,,49025997
84988162,84988162,"Thanks for the reply. I had a look at the PR and it does look similar to what I need but I was hoping you could customize it since I need to perform other operations besides the average.  This might be slightly off topic, but I have been trying to find a workaround where I don't have to perform the cross validation myself. I have already run H2O's cross-validation; is there a way to use the cross-validated models to perform predictions as you normally would with a regular model? I couldn't find this in the documentation.","Feb 26, 2018 at 15:21",,,,48938657
84869360,84869360,"Thanks Lauren,  I have seen this before but I haven't seen any examples of how to pull from Parquet, ORC, or a TextFile stored in HDFS.  We currently either load into a Pandas DataFrame or create a temporary table with a comma delimiter,  But these create additional overhead in the job that I would like to remove.","Feb 22, 2018 at 15:37",,,,48916999
84911369,84911369,have you tried passing in the path to the parquet file or text file? you can use h2o.import_file(hdfs://path/to/myfile.parquet) in python for example or h2o.importFile(hdfs://path/to/myfile.csv) in R.,"Feb 23, 2018 at 16:33",,,,48916999
85029525,85029525,"Lauren I have tried the Python example you gave me and I keep getting an offset error  ~/.conda/envs/myJupyterKernel35/lib/python3.5/site-packages/h2o/h2o.py:522: UserWarning: ParseError at file (file path) at byte offset 61608; error = 'Unmatched quote char ""'   warnings.warn(w)  I have recreated the table with a very small subset of the data 5 rows x 3 columns and still get this error not sure where its finding this 61608 because the new table is no where near that big,","Feb 27, 2018 at 15:38",,,,48916999
85485746,85485746,is it possible for you to post an example of the data so I can see if I can reproduce the error. Parsing errors like that can happen if you have text columns with returns or newlines in them.,"Mar 12, 2018 at 17:21",,,,48916999
84853799,84853799,"In step 3, we get the prediction values for leaf nodes. I am not clear on how to get contribution  from non-leaf nodes. The nodes along the path that was traverse while making prediction.","Feb 22, 2018 at 9:28",,,,48918257
84868369,84868369,"yes that is true, for now you can only get the predicted values within the leaf nodes of each tree. I added a comment under your original post with other mli techniques to consider.","Feb 22, 2018 at 15:14",,,,48918257
84834874,84834874,"I might not have been clear, but the problem is with estimation in general. So I was able to train the xgboost on a given dataset using h2o 3.16. However, after removing this version and installing 3.18 the training produces the error. In other words, it fails to train the model in a given version, not training the model in one and testing in other. Hope that is clear now.","Feb 21, 2018 at 19:50",,,,48914199
84884597,84884597,I updated my answer with a reproducible example.  I don't have any errors when using XGBoost in H2O 3.18.,"Feb 22, 2018 at 23:18",,,,48914199
84895170,84895170,"When I add the fold column, the code produces an error. Please find an edited version of the question above.","Feb 23, 2018 at 8:59",,,,48914199
84966331,84966331,"New new code you posted above doesn't work because you're trying to use pipes on an H2OFrame which is not supported, and you didn't actually add the ""fold_assignment"" column to the frame.   The error will tell you that: 
Illegal argument(s) for XGBoost model: XGBoost_model_R_1519597007018_2.  Details: ERRR on field: _fold_column: Fold column 'fold_assignment' not found in the training frame ERRR on field: _fold_column: Fold column 'fold_assignment' not found in the training frame","Feb 26, 2018 at 2:26",,,,48914199
85014217,85014217,"Thanks for your help Erin. I used 
dplyr
 for the pipe operator.","Feb 27, 2018 at 9:08",,,,48914199
84850830,84850830,"Hello! Thanks for the response! Yep, we've figured it out yesterday, although formatting is far from being perfect. In H2O flow you can add descriptive cells with headers etc., so I was pretty sure, that it is report-generating friendly :) Again - thanks","Feb 22, 2018 at 7:59",,,,48915353
84747913,84747913,"While searching didn't work for me, I also arrived to a similar solution. I found the build page at 
github.com/h2oai/h2o-3/releases/tag/jenkins-3.14.0.1
 and based on that formulated the download URL as 
h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/1/…
  (which zip happens to contain a 
python
 subdirectory with a pip installable 
whl
 inside)","Feb 19, 2018 at 18:23",,,,48870126
99275773,99275773,"Hi David, May I know which name that is referred in the code please. name <- file.path(path.value, fileName), file, path, fileName","May 28, 2019 at 3:56",,,,48833654
101393745,101393745,"It simply renames the result file to a user-chosen name (here 
DRF_MO
)","Aug 12, 2019 at 11:21",,,,51837632
84670919,84670919,"I tried this also. The package gets installed, I can load it into the environment but then when I try h2o.init(), there is another error message (see below). I am fairly sure that java is the source of the problem because it states as such in the system requirements. (The only doubt is some other error message I get). I made some steps to try to load a different version of java but then this led to a layer of other problems...","Feb 16, 2018 at 19:04",,,,48833073
84670970,84670970,"´Starting H2O JVM and connecting: [1] ""localhost"" [1] 54321 [1] TRUE [1] -1","Feb 16, 2018 at 19:05",,,,48833073
84670977,84670977,"[1] ""Failed to connect to localhost port 54321: Connection refused""   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                  Dload  Upload   Total   Spent    Left  Speed   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 54321: Connection refused [1] 7 Error in h2o.init(nthreads = -1) :    H2O failed to start, stopping execution.´","Feb 16, 2018 at 19:05",,,,48833073
84671048,84671048,my version of java is 9,"Feb 16, 2018 at 19:08",,,,48833073
84672083,84672083,"ah okay, yes java 9 is not currently supported by h2o, you would need to use Java 7 or 8.","Feb 16, 2018 at 19:47",,,,48833073
84625506,84625506,"Great, that is why I asked the question. I wanted to be sure that the test-fold would not be resampled.","Feb 15, 2018 at 15:44",,,,48810493
84518140,84518140,"H2O doesn't support 
balance_classes = TRUE
 in GLM. I would remove that - this is what will help to resolve the NPE.","Feb 13, 2018 at 2:31",,,,48758239
84528457,84528457,"Removing 
balance_classes = TRUE
 seemed to solve the problem for me. Thanks!","Feb 13, 2018 at 9:59",,,,48758239
111404092,111404092,"Hi Erin, could you please have a look at 
the issue
 which I'm currently facing with when comparing the result of both confusion matrices? Thanks in advance.","Jul 20, 2020 at 14:45",,,,48712462
84438048,84438048,Thank you for your comment!,"Feb 10, 2018 at 10:10",,,,48697638
84376749,84376749,"Great. Thank you, Lauren!","Feb 8, 2018 at 15:43",,,,48676565
84339490,84339490,"Thank you so much @Lauren. Yap, in my case, I've got AUC about 99.99 % for the training data (cross-validated results with K = 5). Surprisingly, it's much more better than the other ML methods that I explored earlier. I understand that it's just the performance of the training data that will be different for the unseen data / test data.","Feb 7, 2018 at 18:24",,,,48670536
92906307,92906307,"Thank you very much @Lauren. If I'm correct ensemble.auc () shows the AUC value of the training data (not the cross-validated AUC).To get the cross-validation metrics i.e AUC,  I've to write  
ensemble.auc(xval = True) 
  and for cross-validated performance I've to write  
ensemble.model_performance(xval=True)
.  <br/> For base learners it works  however, for stacked ensemble it shows none. Please see code: (
imgur.com/D2lkaPu
).","Oct 26, 2018 at 3:28",,,,48670536
92907229,92907229,"It seems that we cannot evaluate the stacked ensemble on the cross-validation data. Any suggestions, as I need to compare the cross-validated results (i.e. AUC) from Base learners and stacked ensemble?","Oct 26, 2018 at 4:42",,,,48670536
84410437,84410437,Thanks a lot for your answer. In some of my models all rows of the first tree result to RRR - it's like the model didn't really try to do much in the first tree. Can you explain why this could happen?,"Feb 9, 2018 at 12:39",,,,48675837
84512857,84512857,are you applying the method to your training data or test data? If it is a new test dataset it could be (since your trees only have three levels) that all of your test data falls along the majority path (i.e. the most common path or majority node).,"Feb 12, 2018 at 21:38",,,,48675837
84550546,84550546,Indeed! I'm applying it to the test data in that case. Thanks!,"Feb 13, 2018 at 19:47",,,,48675837
84374831,84374831,"It's what I though but wanted to be sure. On the other hand, you possibly missed the last sentence. I'd be happy to know it :-)","Feb 8, 2018 at 15:00",,,,48688304
84452854,84452854,"Thanks to you, I've actually deployed the same environment in driver and executors and works fine :-) Thanks again","Feb 11, 2018 at 0:16",,,,48688304
84296849,84296849,"Here's a link to the Word2Vec user guide that provides additional info: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/…","Feb 6, 2018 at 18:26",,,,48647481
84292731,84292731,"Thanks for the clarification, Tom.","Feb 6, 2018 at 16:32",,,,48646234
98493402,98493402,"how do I extract these predictions ? I tried 
aml@leader@model$cross_validation_predictions
 but it's 
NULL
. I set 
keep_cross_validation_predictions = TRUE
 in my autoML model.","Apr 30, 2019 at 11:19",,,,48569670
84107881,84107881,"Thanks for the solution , importing through pandas dataframe also had the same issue if the new line characters are not removed, after removing these characters in pandas dataframe it could be  imported and parsed properly. This has helped me move ahead.","Feb 1, 2018 at 5:28",,,,48551351
84072406,84072406,"Thank's for your answer, Erin! The first option is exactly what I was doing without h2o, using models from skparklyr package. But I don't see so efficient the orchestration of the whole process from R in real time. That was my principal motivation to try h2o. Actually I saw the scheme on h2o webpage (
link
) pointing out data prep export to POJO in the same way as models. So I am feeling a bit disappointed about that.","Jan 31, 2018 at 9:30",,,,48529363
84100875,84100875,"You don't have to use R the whole time, just for the data munging and even though you are calling the prediction code from R, it's scoring in Java (so it's faster).      Do you know about rsparkling (H2O via sparklyr) would help?  That way you could do munging in Spark (instead of R) but you can still use to orchestrate. 
spark.rstudio.com/guides/h2o
 
github.com/h2oai/rsparkling","Jan 31, 2018 at 22:10",,,,48529363
84100952,84100952,@AndriyT. I added a third option.,"Jan 31, 2018 at 22:13",,,,48529363
84164392,84164392,"Based on your 3 option I gonna try to compare: 1. Load new data set to R, transform and write to disk, score it in Java using model stored as POJO. 2. Load new dataset and h2o model to R, transform and predict in the same session, write results to disk.","Feb 2, 2018 at 13:45",,,,48529363
103653237,103653237,@EmmaNej I just added a fourth option which may be of interest to you.,"Nov 2, 2019 at 23:07",,,,48529363
84070538,84070538,"I understand, so that's why I am looking for help to find the best way to do that.","Jan 31, 2018 at 8:39",,,,48526844
84038645,84038645,"Thanks, @Darren Cook. I suppose it was hidden inside unlike for classification it is open.","Jan 30, 2018 at 13:00",,,,48518342
84992262,84992262,It didn't help.  The problem has gotten worse as I can't seem to get it to work ever...,"Feb 26, 2018 at 17:04",,,,48479567
84994625,84994625,try killing it from shell and start using shell,"Feb 26, 2018 at 18:16",,,,48479567
83793425,83793425,"I was confusing 
fold_column
 with 
fold_assignment
.  Oops.  Thanks for the quick feedback!","Jan 23, 2018 at 13:16",,,,48392216
83918765,83918765,"I was wrong on my understanding of both 
fold_column
 and 
fold_assignment
: I was looking for a way to do the equivalent of 
scikit learn
 
GroupKFold
 by specifying the column to group on.  Looks like you manually need to make a kfold column in the dataset that does the grouping.","Jan 26, 2018 at 14:08",,,,48392216
83687588,83687588,I thought transforming the data will not help with ensemble models since they are nonlinear models and can capture these patterns. The performance does improve on the tail side although not as much as I would like. I will also play around with the weight feature to see if that helps. Maybe I did not use high enough weight.,"Jan 19, 2018 at 22:33",,,,48330650
83687927,83687927,"You are transforming the target response, not the features (very different things).  After logging the response, does the distribution look a bit more normal?","Jan 19, 2018 at 22:49",,,,48330650
83688195,83688195,"It is less skewed but still, it does not look like normal. I have updated my original post with the transformed distribution.","Jan 19, 2018 at 23:04",,,,48330650
83733984,83733984,"Yep, that's still relatively skewed.  You must have really big outliers in the original response.  I'd be interested in seeing the distribution of the original response...","Jan 22, 2018 at 1:08",,,,48330650
83758642,83758642,"Hi Erin, sorry for the delay. I just updated my post with the original response distribution.","Jan 22, 2018 at 16:02",,,,48330650
83605394,83605394,Does automl take interactions?,"Jan 17, 2018 at 20:56",,,,48309526
98356973,98356973,"Even though this comment is probably off-topic. Is ""k"" the parameter for the finite dimension and if so, why? When I perform a PCA, I want to get ALL Eigenvalues and decide for myself, how many I keep. How can I get this information from the PCA Estimator in H2O? Thanks for help","Apr 25, 2019 at 10:47",,,,48307885
83568058,83568058,"I originally thought that since 
h2o.deeplearning
 and 
h2o.deepwater
 are constructing 
similar
 networks (
similar
 in terms of no. of layers, nodes, activation function, etc), they will produce similar results.  I think my assumption is wrong.  Thanks for your suggestion and I will try increasing the epochs.","Jan 16, 2018 at 23:34",,,,48284872
83415603,83415603,"It is possible to use them, e.g., through clustering of features, but that is more of a statistics/machine learning question than a programming one.","Jan 11, 2018 at 22:27",,,,48216516
83416074,83416074,"That's good idea, which hides the individual level info behind new variable. We just need to be careful that some/a few clusters only exist in testing set.","Jan 11, 2018 at 22:49",,,,48216516
83416346,83416346,Ideally you would have some sort of clustering algorithm on the training set and be able to apply the same criteria to the testing set to map variables/groups of variables to those clusters.,"Jan 11, 2018 at 23:03",,,,48216516
83416403,83416403,"One common ""feature of a feature"" that you can cluster on is how frequently a specific class/level appears, as well as the average value of certain numeric variables that co-occur with it, or the incidence of other feature's missing variables with it. Possibly string length if the category is something like a URL, but then you might as well create a new variable just using the string length.","Jan 11, 2018 at 23:06",,,,48216516
83593018,83593018,"@user7792598, the purpose of put train and test together is to convert character variables to factors, hence all levels in train and test are involved.  Results column can be assigned with dummy value (e.g. 0).  Test data will not be used in training, it just levels useful into in the training data that factors including all levels (which may be used in test).","Jan 17, 2018 at 15:05",,,,48216516
83259704,83259704,"Keeping the h2o-3 instance running is difficult. I will post this as a feature request in github. It would be highly helpful for complex models.  Also why different seed is required. If different one is used, automl will start from another starting model ?  Also how do we know what models are added in subsequent runs - using the leaderboard slot right ?","Jan 7, 2018 at 19:53",,,,48140754
83267814,83267814,"If you use the same seed for each run then the sequence of hyperparameter vectors will be the same for each hyperparameter search in the subsequent runs, so you'll get duplicate models between runs.  The timestamp for the 
AutoML
 run will be part of the 
model_id
 of each model, so it'll be easy to tell which models came from which runs.","Jan 8, 2018 at 5:52",,,,48140754
83454504,83454504,"Yes, I know about checkpoints, but was hoping there was another way to extract the model parameters and train on a completely new data set. Essentially I'd just like to establish a model structure based on some data set and then apply it to different sets. So, for example, after running a GBM grid search I could get an object ""best_gbm_params"" and do something like h2o.gbm(x, y, train, valid, best_gbm_params, ...) later. Hope that makes sense.","Jan 13, 2018 at 0:51",,,,48216661
83461967,83461967,"@Edward, updated answer based on your given scenario.","Jan 13, 2018 at 12:26",,,,48216661
83489001,83489001,"This is what I've been doing in the past, training a grid, then getting the parameters from @allparameters and manually creating a call to h2o.gbm(). What I'd like to do is something like h2o.gbm(training_frame = new_train_data, best_model@allparameters), or have some other way of automatically extracting all parameters from the best model and generating a new call to one of the h2o train functions. I don't like the manual approach because it is tedious, but also because some parameters may be changed or added in the future, imposing a maintenance overhead.","Jan 14, 2018 at 19:18",,,,48216661
83508242,83508242,"@Edward, I see you point now.  This would need h2o to add a function to output and models to accept those best estimated parameters.  Another way is to write a function to: base on 
args
 output from 
h2o
 training model, then constructing character expression (by matching parameters).  Using 
do.call
 to run this expression.  This way you don't need to worry about change of parameters, but creating function is still needed.","Jan 15, 2018 at 12:09",,,,48216661
83571454,83571454,"Ok, thanks for your help, this sounds like a reasonable solution considering there is no native support in H2O for such functionality.","Jan 17, 2018 at 3:36",,,,48216661
83288365,83288365,Thank you. We will try this and get back to you with any errors. -Suhail,"Jan 8, 2018 at 16:54",,,,48142940
90979317,90979317,"support for Teradata is planned for 3.22.0 release: 
0xdata.atlassian.net/browse/…","Aug 25, 2018 at 6:05",,,,48142940
104518237,104518237,"I could not find the documentation of which operations are supported. For example, I would like to get the largest value from the prediction columns: test_h2o.apply((lambda x: x.max()), axis=1)","Dec 2, 2019 at 20:22",,,,48105119
91411257,91411257,I'm really not an expert in H2O. Sorry!,"Sep 8, 2018 at 0:01",,,,49061443
83275077,83275077,"Thanks Dmitry, but when I try to return a row I get compile errors: 
Error:(344, 53) Unable to find encoder for type stored in a Dataset.  Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._
          and                
Error:(344, 53) not enough arguments for method map: (implicit evidence$6: org.apache.spark.sql.Encoder[org.apache.spark.sql.Row])org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]. Unspecified value parameter evidence$6.]","Jan 8, 2018 at 10:32",,,,48126963
83283015,83283015,"Interesting... So the problem is not returning Row, your code should work just fine returning tuple. I've found some messy Spark ticket describing the same problem 
issues.apache.org/jira/browse/SPARK-18075
 related to different ways of submitting Spark application. Take a look, maybe it'll give you a clue about your problem.","Jan 8, 2018 at 14:28",,,,48126963
83363102,83363102,"Hi @Dmitry - actually, returning a tuple totally works for my purposes, since I can turn that directly into a DataFrame with a 
.toDF
 call! Thanks for this, if you edit tour original answer then I can accept it as a correct answer.","Jan 10, 2018 at 16:01",,,,48126963
83992711,83992711,"Thanks for the link. I did see your answer - but I needed something that did not involve pre-specifying the row names and types. And in this case you can call 
prediction.toInt
 since the prediction result in not a probability tuple, it is the label, or result of 
.predictBinomial(rData).label
).","Jan 29, 2018 at 11:01",,,,48464552
83128983,83128983,May be I will try to sample more to get the model working .,"Jan 3, 2018 at 12:43",,,,48076658
83167437,83167437,I am able to run your code for that data and get output...I'm just not sure what it's not liking about my dataset...,"Jan 4, 2018 at 13:30",,,,48069505
83177172,83177172,"The error message indicates an issue with the response column. Make sure that your response is a Factor with the same levels, meaning level 0 = No, level 1 = Yes, for all splits of your data. If the factor levels are inconsistent, that could cause this issue.","Jan 4, 2018 at 18:01",,,,48069505
83178892,83178892,"I am getting the same error at the explanation step: ""Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :    arguments imply differing number of rows: 5000, 0"" Any thoughts on why this is?","Jan 4, 2018 at 19:01",,,,48069505
83178981,83178981,"Yes, thank you, Matt! I changed the responses to a simple Yes/No like the dataset in your example, and it accepted that part.","Jan 4, 2018 at 19:04",,,,48069505
83220984,83220984,"I still haven't been able to solve variations of this error at the explanation step. Any insights?: ""Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :   arguments imply differing number of rows: 500, 0 ""","Jan 5, 2018 at 22:24",,,,48069505
83148507,83148507,thank you for the very detailed response! I have actually done a classification and had set the output column to be an enum. This makes sense given the context you provided as my output does in fact have multiple columns. I guess my problem is I don't know how to interpret the columns. I am only running the predict method on ONE row so i'm not sure how to interpret the 206 columns in the output of predict.,"Jan 3, 2018 at 23:50",,,,48074018
83158554,83158554,"@majorcoder Aha! Sorry, I'd missed ""1 row"" in your question. I've updated my answer.","Jan 4, 2018 at 9:23",,,,48074018
83247022,83247022,"The 6 outputs represent a particular dimension reduction mapping that I want to model.  As such, they should be very independent, so the 'Approach 1' looks like the best option.  Thanks for your help.","Jan 7, 2018 at 6:32",,,,47992227
83251716,83251716,"@PaulHannah If it is a 500 to 6 dimension reduction that you are after, have you tried simply using an autoencoder (which is designed to do exactly that)? h2o.automl might be the wrong tool for the job?","Jan 7, 2018 at 12:49",,,,47992227
83377525,83377525,"Thanks for the suggestion. Yes, I have given that a go, but ran into a couple of problems. First is the sheer amount of computation required to get there. The other is that we're looking for a particular mapping that emphasises particular features.","Jan 11, 2018 at 0:26",,,,47992227
99687144,99687144,Are over-fit base models good or bad when ensemble modelling?,"Jun 11, 2019 at 23:23",,,,47992561
99692209,99692209,"@Brad That is an interesting question. In my answer above I meant ""avoid over-fitting in the base models, it is bad"". But you could imagine a situation where the meta-learner could learn that a base model has (slightly) over-fitted and work with that to give a slightly better ensemble.","Jun 12, 2019 at 6:24",,,,47992561
99723272,99723272,"Thanks. I fit my base learners using carets selectionFunction = tolerance. Then combine the models using only the probability columns by penalized logistic regression with all interactive terms. Using 1 training set, and 1 meta-training set and 1 holdout set. The bias that concerns me is my human brain as I see what happens in the holdout set, then I go back and change feature section and fit selection criteria (one SE, tolerance, etc). The bias is not present in the code. I really need 2-holdout sets to mitigate this bias. The 2nd holdout set allowing only 1 single attempt.","Jun 13, 2019 at 1:57",,,,47992561
99723317,99723317,Another thing I learnt by ensemble modelling is sometimes more base learners can be good even if returns are diminishing they can offer something. For example if the meta-training set is only 100 rows. 2 base learners would give 200 data points - But 5 base learners gives 500 data points. Thereby stabilizing logistic regression even in data limited situations.,"Jun 13, 2019 at 2:01",,,,47992561
82856436,82856436,"I get:    from pysparkling import * [WARNING] H2O requires colorama module of version 0.3.8 or newer. You have version 0.3.7. You can upgrade to the newest version of the module running from the command line     $ pip2 install --upgrade colorama  h2oContext = H2OContext.getOrCreate(spark)  py4j.Py4JException: Method getOrCreate([class org.apache.spark.sql.SparkSession, class org.apache.spark.h2o.H2OConf]) does not exist ...","Dec 22, 2017 at 14:57",,,,47943291
82857050,82857050,"I updated the code example. Please first detach all previous libraries, restart the cluster to flush out the dependencies, attach the h2o_pysparkling_2.1, run the code above. I just verified this myself on a Spark 2.1 cluster.","Dec 22, 2017 at 15:21",,,,47943291
82842701,82842701,"Hi @Lauren, thanks for writing. But I think I couldn't explain the problem well. What I am expecting is the comparison operation should return a TRUE or 1 value in R format. But it's returning 1 [1 row x 1 column].","Dec 22, 2017 at 6:18",,,,47927763
83100888,83100888,"Hi @Dmitry, thanks for this - I just got back from holidays and am trying this out. My code is: 
df.rdd.map { r => val rData = rowToRowData(df, r); val prediction = easyModel.predictBinomial(rData).classProbabilities; println(""prediction = ""+prediction.mkString("","")) }
, but I am not seeing any predictions being printed. I have been able to output them using 
.collect()
 instead of 
.rdd
, but this is not practical for large datasets . . How do I append the prediction as an additional column of the distributed df, or alternatively as a new df in parallel?","Jan 2, 2018 at 15:55",,,,47856079
83230459,83230459,"I think the problem is that you trying to print from rdd.map method. This code executes on Spark executors, so output is printed to executor's stdout.  If you want to see output in console (= driver's stdout), your options are 1) collect(), as you suggested 2) in map code return Row with predictions, convert resulting RDD back to DataFrame, and then use show() method to see results. The second option also allows you to write results to HDFS without collecting everything on driver.","Jan 6, 2018 at 11:35",,,,47856079
82602015,82602015,"Does this mean that if you wanted to created a new model using a checkpoint of another model solely to train on more data (to further refine the older model's weightings), you would just do something like 
gbm_continued = H2OGradientBoostingEstimator(checkpoint= gbm_orig.model_id, ...)
 then 
gbm_continued.train(x=extra_data, ...)
? Asking because that is ultimately what I'm trying to do with checkpoints and 
other
 posts seems to indicate that it is not possible.","Dec 14, 2017 at 18:31",,,,47809126
82602763,82602763,"Yes, that should work. The linked-to answer is about restrictions with cross-validation. (Seems a bit strict, but I've never tried CV and checkpoints together, so I am not going to argue!)","Dec 14, 2017 at 18:53",,,,47809126
82547462,82547462,"I have tried to do it analogically to 
this
, but it is not working.","Dec 13, 2017 at 12:43",,,,47785053
82569974,82569974,"If you found my answer to be correct, can you please accept it? Thx.","Dec 14, 2017 at 0:39",,,,47785053
82542487,82542487,Cool! Thank you!,"Dec 13, 2017 at 10:29",,,,47785027
82555341,82555341,"But don't I just get a string with the ID's then? What I want is the model it self. Example:  grid_search_rf.model_ids[:3]   [u'Grid_DRF_py_53_sid_a1ca_model_python_1513162115962_79468_model_11',  u'Grid_DRF_py_53_sid_a1ca_model_python_1513162115962_79468_model_4',  u'Grid_DRF_py_53_sid_a1ca_model_python_1513162115962_79468_model_7']  I want to predict using the first model, like so somehow, but below is just the string and not the model itself   Grid_DRF_py_53_sid_a1ca_model_python_1513162115962_79468_model_11.predict(test_frame)","Dec 13, 2017 at 15:58",,,,47775111
82560892,82560892,"I thought you wanted to replace your variable 
all_model_ids
 with a subset of ids. You can use 
h2o.get_model('a_model_id')
 to get the model from the id. But since you used model ids here: 
base_models = all_model_ids
 I assumed you just want to extract specific model ids to pass to the stack?","Dec 13, 2017 at 18:32",,,,47775111
82553433,82553433,"Many thanks Erin. I'm actually using h2o.deepfeatures rather than making a prediction, so will h2o.predict_json still be applicable?","Dec 13, 2017 at 15:09",,,,47784930
82690519,82690519,"It can't be used directly, no.  You may be able to create a function similar to 
h2o.predict_json()
 that could pass data to a DL MOJO/POJO and return the deep features but that would require custom code.","Dec 18, 2017 at 5:52",,,,47784930
82737578,82737578,"Many thanks Erin, thanks for confirming, I'll give that a go.","Dec 19, 2017 at 11:30",,,,47784930
82484592,82484592,"Thanks. I am using Window 7, I tried the command conda install -c h2oai h2o, and it still didn't fix it.","Dec 11, 2017 at 21:21",,,,47760502
82485054,82485054,I also verified that both python.exe and pip.exe were in anaconda folder using 'where' command.,"Dec 11, 2017 at 21:36",,,,47760502
82488000,82488000,"try checking the h2o installation 
conda list h2o
. If the correct version is installed and spyder still can't see the library, you need to check that spyder's python interpreter is set to anaconda python (in preferences menu). You can also add the correct path to 
PYTHONPATH
 manager in spyder.","Dec 11, 2017 at 23:49",,,,47760502
82511309,82511309,"Thanks, last night, I uninstalled everything, Then I installed anaconda latest stable version. I tried conda install -c h2oai h2o, but that didn't work. then I tried pip install h2o and that seems to work now. My guess was same as yours that the path was not getting recognized. Thanks for all your help.","Dec 12, 2017 at 14:38",,,,47760502
82452495,82452495,"Thanks Darren, h2o.H2OFrame() worked awesome. I'll probably put in a feature request for uploading binary files directly still.","Dec 11, 2017 at 3:54",,,,47741326
82483092,82483092,"Not exactly on topic, but related: How would capturing this output be done in python? H2o is a blocking process who's output prints as a stream of text lines rather than in bulk, this made it hard for me to get the output line needed using basic python Popen logic (I don't use those object very often). Thanks.","Dec 11, 2017 at 20:33",,,,47723124
101876904,101876904,"As a response to my previous comment, here is a way that I have used to start h2o and grab the IP output in python scripts in the past: 
gist.github.com/reedv/…
 (where 
startup_parse_line_regex
 is regex pattern to get the IP from the ""Open H2O Flow in your ..."" output line).","Aug 29, 2019 at 20:52",,,,47723124
82392164,82392164,This is not answer to my question. I already provided log of HTTP requests and responses from all sides. Question is: why does H2O fail importing and does not report anything about why is this happened without any calls to my local server.,"Dec 8, 2017 at 14:09",,,,47715642
82393267,82393267,I tried your R code and got the same log as posted before.,"Dec 8, 2017 at 14:41",,,,47715642
82425319,82425319,"If you think you got the same log as before, you're looking at the wrong thing.  I suggest trying again.  The new log is on the client side, not the server side.","Dec 9, 2017 at 19:38",,,,47715642
127557135,127557135,"Your answer could be improved with additional supporting information. Please 
edit
 to add further details, such as citations or documentation, so that others can confirm that your answer is correct. You can find more information on how to write good answers 
in the help center
.","May 11, 2022 at 5:45",,,,72113388
82372124,82372124,Excellent looking forward to it,"Dec 8, 2017 at 0:29",,,,47685623
92067778,92067778,"Need some 
examples
 /documentation to make this useful:","Sep 29, 2018 at 3:44",,,,47685623
82284933,82284933,Sorry - I meant if I remove the validation_frame but keep the nfolds.   Still same deal?,"Dec 5, 2017 at 21:24",,,,47647429
82285934,82285934,"@runningbirds We may be talking at cross-purposes, but you do not currently use validation_frame in the code (you showed).  Generally you should use nfolds or validation_frame, avoid not specifying other... and in general using both nfolds and validation_frame is redundant.","Dec 5, 2017 at 21:58",,,,47647429
82531129,82531129,Darren Cook - I will edit my code as I'm not sure I'm getting my point across - give me 3min,"Dec 13, 2017 at 3:03",,,,47647429
89349193,89349193,This has been fixed in H2O 3.18.0.1.,"Jul 5, 2018 at 5:08",,,,47563989
82009409,82009409,Thank you @Darren. Appreciate your help and precise answer.,"Nov 28, 2017 at 8:11",,,,47523107
81961861,81961861,"Would auto-balancing at <10% be sufficient for your purposes, or do you need direct access to the 
balance_classes
 (and related) arguments?","Nov 27, 2017 at 2:06",,,,47503014
82006367,82006367,"Ideally I would like the latter, is there a timeline on when that option could be exposed? Thanks for your response.","Nov 28, 2017 at 6:21",,,,47503014
85152612,85152612,"I've added a ticket to fully expose the balance classes args, which should be done very soon: 
0xdata.atlassian.net/browse/PUBDEV-5377","Mar 2, 2018 at 16:37",,,,47503014
85294759,85294759,"Thank you, looking forward to the release of this","Mar 7, 2018 at 5:42",,,,47503014
81849020,81849020,"Is there a way to do continual training in h2o with python? Ie. save the trained state of an algorithm and continue training it later? I have only ever used 
flow UI
 and 
MOJOs
 up to this point and can't find documentation on how to set up continual training with the h2o programming APIs. Thanks","Nov 23, 2017 at 3:02",,,,47445683
81874398,81874398,You really have to look at the python API to built it from scratch. There are APIs available to perform everything needed however you will have to put them together for your task.,"Nov 23, 2017 at 16:31",,,,47445683
81697379,81697379,"switching to 'hadoop jar'  did the trick.  I never saw the cluster come up (the ""requesting flatfiles portion"" ) With that switch, server is up, and I can connect.  Wasn't able to get to Flow as the address is firewall blocked (I suspect), but WAS able to connect through python and confirm I can import through hdfs.  --edit once I figured out the 'name' to the server for flow, I was able to connect through I firewall (address doesn't work--but again firewall, not h2o).","Nov 18, 2017 at 23:56",,,,47371447
81743044,81743044,"Thanks for the suggestions @lev. Since I thought this IP issue may be related to our firewall, I have switched my driver's network switch. My spark connection still terminates before starting an h2o context, but now the only non-INFO log message is:    
Jar check fails; my hash=[...]  |  Jar check fails; received hash=[...]
   Any ideas what might be going on here?","Nov 20, 2017 at 15:05",,,,47352790
81770527,81770527,"OK, figured out the Jar issue (trying to run multiple versions of sparkling water on the same cluster). But now am back to my original 
IP address not found on this machine
 issue. Changing switches has not resolved the problem, and I am not sure how to problem solve it further . . .","Nov 21, 2017 at 8:41",,,,47352790
81788042,81788042,"what is the result of running 
calcPrioritizedInetAddressList
 on the driver?","Nov 21, 2017 at 15:47",,,,47352790
81816328,81816328,"I couldn't run it because of missing class 
calcPrioritizedInterfaceList","Nov 22, 2017 at 9:25",,,,47352790
81892692,81892692,It seems like it could be a communication issue the between the spark master / executors / driver when starting the h2o context. But this is strange as I can run regular spark jobs on this cluster without any communication issues.,"Nov 24, 2017 at 8:32",,,,47352790
81430403,81430403,"I get a proper prediction while running the model in Rstudio, but when I run the same model after building h2o POJO  and run on gradle builder I get this error of having the same class output of 1 for all my test data","Nov 11, 2017 at 16:19",,,,47238373
81432086,81432086,@VenkataKrishnan and why exactly you didn't include this info in your post?,"Nov 11, 2017 at 17:39",,,,47238373
81653679,81653679,"Thank you @Darren, you are absolutely right. I found that the information on the website for Deep Water installation was not up to date.","Nov 17, 2017 at 12:38",,,,47248102
81653620,81653620,"Thank you, it is useful answer","Nov 17, 2017 at 12:36",,,,47293646
81353654,81353654,Thanks for the quick and detailed answer!,"Nov 9, 2017 at 13:09",,,,47201623
81282156,81282156,"I am trying to connect with web app and jquery just followed by this tutorial        
github.com/h2oai/app-consumer-loan
 , but rest api connection and h2o everything is running, but all the time the curl command return the same result as json, so how do i fix that ?? but the prediction is working well using h2o in R studio, but not in curl command..please help","Nov 7, 2017 at 19:43",,,,47163450
81350633,81350633,"Since the app-consumer-loan example works properly, one thing you can do is use 'git diff' to examine all the differences between the original version and your modified version.  One of the changes you made is causing it not to work.  Try making the smallest possible change, one at a time, from the original to see where you are getting off track.","Nov 9, 2017 at 11:52",,,,47163450
81236635,81236635,Thank you for that. It seems like I have to retrain it.,"Nov 6, 2017 at 18:23",,,,47142383
81255622,81255622,"Lauren, you wrote ""3.14.*"". Does that mean a model built in any 3.14.x.x can now be loaded in any other 3.14.x.x ? I thought it had to be an exact match, right down to the minor version. E.g. a model built in 3.14.0.6 or 3.14.0.8 won't run in 3.14.0.7?  If this has changed it is a small step in the right direction!","Nov 7, 2017 at 8:26",,,,47142383
81276760,81276760,yes it has to be an exact match let me update that thanks!,"Nov 7, 2017 at 17:05",,,,47142383
81357046,81357046,Perfect. Works... Exactly what I needed! I just need to replace the random generated data for the Row with real values...,"Nov 9, 2017 at 14:23",,,,47168929
124261890,124261890,"In the latest version of the genmodel package, they provide mse value. But is there a way to get the threshold value from the Java class itself? or any calculation would be useful.","Dec 9, 2021 at 18:15",,,,47168929
82805523,82805523,"Hi Thnaks for your response, I have fixed the dependencies I never get Joda exception anymore but I am getting kyro excpetion when I use kyro serilizer in my Spark application.._transform (hex.aggregator.AggregatorModel$AggregatorParameters) aggregatorParameters (au.com.vroc.mdm.H2oModel)         at com.cloudera.livy.shaded.kryo.kryo.serializers.ObjectField.read(ObjectField.java:125)         at com.cloudera.livy.shaded.kryo.kryo.serializers.FieldSerializer.read(FieldSerializer.java:507)    ..do u have any opinion how to resolve the kyro exception as well?","Dec 21, 2017 at 6:12",,,,47179567
81184157,81184157,Thank you. Yes it works when I set reproducible=TRUE and seed=1.,"Nov 5, 2017 at 0:38",,,,47106939
81184592,81184592,"Can anyone suggest how can I let the results not biased to a certain class, although the 2 classes are balanced in training phase?","Nov 5, 2017 at 1:22",,,,47106939
81221040,81221040,Thanks for answering.,"Nov 6, 2017 at 11:29",,,,47101832
81221548,81221548,Thanks a lot. My training data is skewed and has more negative examples. Actually I am new to H2O. I have some further questions.  1). Is there any documentation in h2o regarding selecting threshold and prediction and use calibration?  2). How can I use the threshold for automl build?,"Nov 6, 2017 at 11:42",,,,47101832
92959379,92959379,Is there a way of identifying which version of H2O was used to build the model? I am getting the same error. But without loading them (or even after loading them in R environment) I don't know which version of H2o model was used to build this model.,"Oct 28, 2018 at 7:24",,,,47086496
93252465,93252465,"Yes, this information is available in the binary export file. It is in the header of the file in plain text. If you are on Mac/Linux you can type this command to get the version: 
strings model.hex | head -1
 (where model.hex is the binary export)","Nov 6, 2018 at 22:41",,,,47086496
97332216,97332216,"@ErinLeDell I am having the same issue but using the same versions, any ideas?","Mar 22, 2019 at 14:31",,,,47086496
99285062,99285062,@Lucif3r - as mentioned above. just use h2o.shutdown() and then run h2o.init() again. Post that load the model. It should work!,"May 28, 2019 at 10:12",,,,47086496
81228014,81228014,"Hi Erin, thank you so much for answering my question. As I was googling for this question, I saw you answering many similar questions elsewhere and I did looked into your code. Very impressive I have to say. However, my forecast are not binary, so I cannot use your package in my situation.","Nov 6, 2017 at 14:35",,,,47086394
81080087,81080087,"Thank you for your advice. And I could not explain in detail, sorry.","Nov 2, 2017 at 0:54",,,,47059392
81080156,81080156,"I did installing thrift, and I can run run_tcp_server.sh which used thrift. So, I think python can't done the code ""from thrift.transport import TSocket"" .","Nov 2, 2017 at 0:59",,,,47059392
81082646,81082646,@H.Doi sorry I'm not following - what is the exact error you're getting after running the example now?,"Nov 2, 2017 at 3:55",,,,47059392
81085789,81085789,"@ Mateusz Dymczyk Error message is ｢File ""example_client.py"", line 5, in from thrift import Thrift ModuleNotFoundError: No module named 'thrift'｣  I explain what I did below.  1. prepared an EC2-instance on AWS (ubunts 16.0.4)  2. install python3.6 (with command shown in ""6.1 Prerequisites"" in document)  3. Install Thrift (with command shown in ""6.1 Prerequisites"" in document)  4. run run_tcp_server.sh  5. run run_tcp_client.sh and the above error occured.  Sorry to understand ""thrift"" or ""Driverless AI"".","Nov 2, 2017 at 6:34",,,,47059392
81256362,81256362,"@ Mateusz Dymczyk Sorry and Thank you for your advice. I ran after @EDIT, and I noticed that the cause of the error was the failure to install pip. 　　　 After installed pip with command 'curl ""
bootstrap.pypa.io/get-pip.py
"" -o ""get-pip.py"" ' and 'pip install -r client_requirements.txt' , I can do it.  Thank you very mach !!","Nov 7, 2017 at 8:46",,,,47059392
81493205,81493205,"Just for extra clarification, when you say 
""So if you are changing the threshold for rows with unknown values, it's relative to max-F1 (not 0.5).""
 Do you mean that if I were to use the model's MOJO in java code and set a custom threshold (for say, max_mean_perclass_accuracy) of t0 with a line like 
return (p.classProbabilities[1] >= t0) ? 1: 0;
, then the model would actually be using a threshold of maxF1+t0 or just that the default threshold is maxF1? Thanks.","Nov 13, 2017 at 18:34",,,,47239891
81533362,81533362,"I changed the word ""default"" to ""built-in"".  The MOJO only knows max-F1 baked in.  The predicted class from the MOJO is based on max-F1.  So you have to write your own piece of code comparing p.classProbabilities[1], as you show above, to use a different threshold for deciding the predicted class.","Nov 14, 2017 at 17:06",,,,47239891
81062838,81062838,"When the cluster is running, I have no problem using the model. However, the problem is, when I setup the h2o cluster from R and run the model during the night, the cluster is disconnected when I check the cluster status in the morning. I am sure the training process is finished because I can see the summary result of the model when I type the model name in R console. However, I just can not use it for prediction because the h2o cluster is disconnected. Do the cluster have any default setting like, if we do not use it for a period of time, then it will shut down itself automatically ?","Nov 1, 2017 at 15:03",,,,47023930
81065617,81065617,"No, H2O will never shut itself down.  Only the user can do that, or possibly some other process on the machine kills the Java process (unrelated to H2O).  If you're running this on a remote machine, then you need to use 
screen
 or 
nohup
 otherwise all processes will be killed when you lose the ssh connection to the machine.","Nov 1, 2017 at 16:12",,,,47023930
81065637,81065637,"Have you double-checked that the H2O Java process is no longer running? I am still confused as to whether the cluster is simply disconnected from you R session or if the cluster Java job is no longer running. You said ""I can reconnect back to the cluster.""  Do you mean you can create a new cluster or you can reconnect to former cluster that contains your models? If it's not running, then unless you saved the models in your script using 
h2o.saveModel()
, your models are gone (they exist only in memory until you save them).","Nov 1, 2017 at 16:13",,,,47023930
81068126,81068126,"I mean I can create a new cluster by typing 
h2o.init()
, not reconnecting to the previous cluster. How can I check the h2o java process and see if it's running ? Thank you","Nov 1, 2017 at 17:18",,,,47023930
81079561,81079561,"Well, if you are connecting to a remote machine, then you really need to investigate using 
screen
 or 
nohup
, otherwise when you local console loses the connection, your remote jobs will die.  Is the R process still running when you log in in the morning, or is that killed too?  I updated the answer with info on how to check if the H2O Java cluster is running.","Nov 2, 2017 at 0:21",,,,47023930
80891911,80891911,@ Anand CU. I was exactly doing the same Thing but i am thinking that because of the large size of the dataframe the type conversion is not efficient,"Oct 27, 2017 at 9:54",,,,46972127
80892045,80892045,@ayaan Do you have too many NANs in your dataset? What percentage of the values are NANs in the dataset?,"Oct 27, 2017 at 9:57",,,,46972127
80892070,80892070,yeah around 40% percent of my dataframe is NAN,"Oct 27, 2017 at 9:57",,,,46972127
80892201,80892201,"@ayaan One option would be to replace 
nan
 with a single, obviously out-of-range value. Ex . If a feature varies between 
0-1
 replace all 
nan
 with 
-1
 for that feature. Then You can possibly use sklearn's algorithms as well","Oct 27, 2017 at 10:00",,,,46972127
80892343,80892343,"@ayaan Or you could also use the class 
Imputer
 to handle 
NAN
 values","Oct 27, 2017 at 10:04",,,,46972127
80995288,80995288,Thanks i will try this and let you know,"Oct 30, 2017 at 21:02",,,,47023695
94619684,94619684,"If a pandas dataframe already has types specified, why would H2O need need the types explicitly passed in?","Dec 21, 2018 at 14:40",,,,47023695
80869094,80869094,"Tom, can you update your answer with how to tell H2O to redirect this output to devnull so the files are not created in the first place?","Oct 26, 2017 at 17:57",,,,46959079
80870407,80870407,"Erin, this would be the preferred option in my use case. I am not sure what I am doing differently, but the .OUT file (which is the real source of the storage issues) is not removed when my session exits.","Oct 26, 2017 at 18:36",,,,46959079
80875777,80875777,@jhearn I have updated the post to include instructions on how to do this.,"Oct 26, 2017 at 21:20",,,,46959079
80907328,80907328,"Thanks guys. I am not sure that the additional dev/null statement is necessary, however, as the files in question are not created when started from cmd. That said, Tom's original solution works just fine, and serves as a nice BandAid until I address the underlying RStudio-linked problem.","Oct 27, 2017 at 16:52",,,,46959079
80887356,80887356,"Thanks for your input, I tried configuring as above in H2O without Spark and Hadoop but am still getting the same above error without any more detail. Please note that the same LDAP configuration is working absolutely fine in few other tools.","Oct 27, 2017 at 7:53",,,,46960523
80892668,80892668,"I'm not sure what the *'s are for.  Try removing those.  The next thing I would try would be to turn off Ldaps and inspect the actual network level packets with tcpdump.  After that, I would go inspect the source code.  After that, I would run standalone H2O in a good java debugger like IntelliJ IDEA and single-step it.  (And finally, if you just want hand-held help debugging the security issue, you can contact the company h2o.ai for enterprise support...  i still think a config issue is the most likely problem...)","Oct 27, 2017 at 10:13",,,,46960523
85994759,85994759,"Also, please have a look on our brand new documentation. LDAP has been fully tested and documented recently 
docs.h2o.ai/sparkling-water/2.2/latest-stable/doc/tutorials/…","Mar 26, 2018 at 15:43",,,,46960523
80741111,80741111,"I did not correctly copy the code, in the first example, it does not look like that. It looks like you specified. But i have empty train. But I went to 
127.0.0.1:54321/flow/index.html
, and it shows me that the dataframe has been loaded into the cluster. But in Python, I get empty train. I use Spyder with IPython console, can it somehow influence the result?","Oct 23, 2017 at 19:24",,,,46896837
80779623,80779623,"What happens when you do: 
train.nrow
?  It might be an issue with the console not printing rather than the fact that the dataset is not there.  You can confirm by checking the number of rows.","Oct 24, 2017 at 17:03",,,,46896837
80786036,80786036,"In [3]:train Out[3]:    In [4]:train.nrow Out[4]: 150; Yes, This issue with the console. Could the encoding be the cause? I use the Russian language Spyder, with the encoding utf-8.","Oct 24, 2017 at 20:18",,,,46896837
80786370,80786370,"It seems to be an issue with your specific IDE. It works fine in a regular IPython shell. If you see the data frame when you use 
print(train)
 or 
head(train)
 then I'd recommend using that instead.","Oct 24, 2017 at 20:29",,,,46896837
80787217,80787217,"Thank you, its problem with my IDE. I started the ipython without the IDE. Variables are displayed. But the error remains, I removed the string 
x=range(0,2)
, and the program worked, both in IDE and in the simple ipython console. But since I took an example in DeepLearningBooklet from 
link
. I want to ask, what am I doing wrong?","Oct 24, 2017 at 20:55",,,,46896837
80660552,80660552,"Thx, effectively I am looking for renaming it after parsing the file.","Oct 20, 2017 at 20:02",,,,46853942
83510230,83510230,"This is awesome!! Thank you so much, it is exactly what I was looking for. Appreciate the help.","Jan 15, 2018 at 13:12",,,,47898040
80719430,80719430,"Hi @AvkashChauhan . Thanks so much for your detailed response and providing me with links to examples. This really helps, but I'm still uncertain about one thing however.  Where you mention I can "" read the parquet from HDFS and then pass each row as RowData to above example"", how exactly do I pass the read in parquet files as Row Data? Say for example I built a model on the Titanic Data Set, and I'd like to score 
raw.githubusercontent.com/agconti/kaggle-titanic/master/data/…
 , how would I pass the read in data as Row Data and score row by row?","Oct 23, 2017 at 9:35",,,,46853122
80719594,80719594,How would the code you provided above have to change if i were to read in the data linked above? I'm new to scala so apologies if this is a silly question.,"Oct 23, 2017 at 9:39",,,,46853122
80747663,80747663,"This article shows how you can read parquet file in scala and save to csv. If you dont have nested parquet file, then you just need to use the basic code to read parquet and then save to CSV or feed directly to H2O 
dzone.com/articles/…","Oct 24, 2017 at 0:16",,,,46853122
80756208,80756208,"I'm able to read in parquet files with scala, I'm just not sure how to pass each row iteratively into RowData. In the example code you provided above, you create new data. My data set has about 10 million rows, and I'd like to know how to pass each row into the Mojo scoring function. This example, 
github.com/h2oai/h2o-droplets/blob/master/…
, reads in a csv file and scores it using a Pojo. I'd like to read in 10 millions rows (parquet) and score them using mojo. Thanks for your help!","Oct 24, 2017 at 7:39",,,,46853122
80776607,80776607,I will write a sample and share soon.,"Oct 24, 2017 at 15:43",,,,46853122
95106890,95106890,"the only issue is that this wouldn't work for very large datasets unless you're running on a massive instance type...that seems counter to the reasons I would be doing distributed computing in the first place. If I just run everything on a massive single instance, I would probably just use 
doSNOW
 or 
parallel
 libraries in R and forgo Spark altogether.","Jan 10, 2019 at 22:15",,,,54135983
80409483,80409483,"Hi Erin, thanks for the initial insights... I will try to replicate the issue on a open db and then update comments.","Oct 13, 2017 at 14:00",,,,46714119
80374466,80374466,"Thank you for your answer. Yes I tried that but it's the same thing, just with more trees. The training error eventually stop decreasing and I don't know why.","Oct 12, 2017 at 15:59",,,,46713654
80399261,80399261,"Hey I updated my post with additional information. Looking in the YARN resource manager shows that the job never did run or succeed, so I do think there is another problem. I think maybe the hosts for the data nodes can't read the .jar files, but I don't know how to fix that.","Oct 13, 2017 at 9:24",,,,46716635
80181470,80181470,It Worked.Thanks,"Oct 6, 2017 at 22:23",,,,46614149
99251488,99251488,@AvkashChauhan I want to set it permaments ...i.e. which would be intact in next login window ... which bash file i need to set it ?,"May 27, 2019 at 7:39",,,,46614149
80094320,80094320,"The docker image has an unreleased version of H2O (assuming this is a Deep Water docker image), so it will not be possible to find a matching R package.  So when you start up h2o, make sure to set 
scrict_version_check = FALSE
 since the Java H2O version and R h2o version will not match.","Oct 4, 2017 at 17:01",,,,46570029
80102745,80102745,Unfortunately with STABLE and latest bleeding I'm getting exactly the same error.,"Oct 4, 2017 at 21:39",,,,46570029
80104572,80104572,Would u please confirm the latest version which gives you error?  Also please do not use Docker images as we are not updating them frequently. Also I have just edited above the 3.14.0.3 file import without a problem.,"Oct 4, 2017 at 23:17",,,,46570029
80114301,80114301,"There is no problem with import, if I run cluster from R. There is a problem when I connect to the cluster which is started from docker image. I'm using docker image because I want to use well build deepwater with tensorflow and mxnet. I cannot achieve such speed when I'm building it by myself from github.","Oct 5, 2017 at 8:06",,,,46570029
80074643,80074643,"Thanks! Google word2vec pretrained model are provided as a binary file, do you also have plan for handling such files?","Oct 4, 2017 at 8:41",,,,46555914
80094332,80094332,This is certainly possible but we don't have any timeline for this feature. It would be great if you could log a feature request in our jira: jira.h2o.ai,"Oct 4, 2017 at 17:01",,,,46555914
80046807,80046807,"Running a container (created with the h2o Dockerfile: (
github.com/h2oai/h2o-3/tree/master/docker
) ) on centos. h2o is running ok, except H20XGBoost running using 1 cpu.","Oct 3, 2017 at 13:56",,,,46529944
80049637,80049637,"log: ""INFO: No GPU (gpu_id: 0) found. Using CPU backend.""","Oct 3, 2017 at 15:04",,,,46529944
80049887,80049887,"10-03 14:55:09.368 172.17.0.3:54321      200    main      INFO: Found XGBoost backend with library: xgboost4j 10-03 14:55:09.379 172.17.0.3:54321      200    main      INFO: Your system supports only minimal version of XGBoost (no GPUs, no multithreading)! 10-03 14:55:09.379 172.17.0.3:54321      200    main      INFO: ----- H2O started  -----","Oct 3, 2017 at 15:11",,,,46529944
80052830,80052830,"The docker environment is does not have full library support thats why there is a message about ""minimal version of XGBoost"". You would have to look your docker environment to resolve this limitation.","Oct 3, 2017 at 16:30",,,,46529944
80074025,80074025,"yes. To be more precise it is the openmp support. I have gcc installed, so it should have solved this problem.","Oct 4, 2017 at 8:22",,,,46529944
79942508,79942508,"I showed that the 
default
 java I have is ""1.8.0_121"". Not sure where R is getting that version 9 (and, note, it seems to read version 9, not 1.9, so I'm wondering if there's an issue there).","Sep 29, 2017 at 17:29",,,,46492688
79949528,79949528,"Ok, sorry I missed that the first time around.  I see from your latest edit that you have multiple Javas installed.  Can you 
uninstall Java 9
 or update your path to prefer Java 8?","Sep 29, 2017 at 21:51",,,,46492688
79960194,79960194,"I changed $JAVA_HOME to point to 
/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home
 but the problem persists. I don't know how to change the java that 
h2o
 wants to call!","Sep 30, 2017 at 13:07",,,,46492688
79972185,79972185,"Are you using RStudio instead of command line R?  I've noticed that RStudio doesn't pick up environment variables on occasion.  You can see if R knows about 
JAVA_HOME
 by checking 
Sys.getenv(""JAVA_HOME"")
.  If it's blank, try setting it using 
Sys.setenv(""JAVA_HOME"")
?  It's a shot in the dark, but might do the trick...","Oct 1, 2017 at 3:33",,,,46492688
79979154,79979154,"Yes, that was the key! RStudio, by design, doesn't read the environmental variables from 
.bashrc
 (no idea what's the reason).  Please edit your answer to include the following info and I'll accept it :). First, get the location of 1.8 java with 
/usr/libexec/java_home -v 1.8
. Second, with that location edit 
~/.Renviron
 and add 
JAVA_HOME=your_java_1.8_location
. Restart 
RStudio
 and it works!","Oct 1, 2017 at 12:48",,,,46492688
87495518,87495518,I'm getting stuck on something simple here regarding the command line?  What directory do I need to run this from?  My current working directory?  Or a specific h2o folder?   I get the following message:     Error: Could not find or load main class hex.genmodel.tools.PrintMojo,"May 8, 2018 at 17:21",,,,46430246
87498128,87498128,"""java -cp /path/to/your/h2o.jar"".  You need to know where your h2o.jar is.  It will either be in the R or Python directory where the h2o package gets installed, or you can download it from h2oai.download -> H2O latest stable release -> Download H2O.","May 8, 2018 at 18:47",,,,46430246
79789130,79789130,"I don't think that the model is being imported as a MOJO in this case, since I am not experiencing the same kinds of problems that I was having as in this post (
stackoverflow.com/q/46353578/8236733
) when it was more likely that the model was being imported as a MOJO. The model I am using now is much smaller (200MB as opposed to 800MB).","Sep 25, 2017 at 23:39",,,,46414097
79789323,79789323,"I believe Steam always sends DRF models as MOJOs. You can try and export it as a POJO and build a prediction service from that, and see if you get the same result.","Sep 25, 2017 at 23:50",,,,46414097
79790000,79790000,"Useful note for others: From the prediction service url (eg. localhost:16563), you can navigate to ""/info""  subdomain (eg. localhost:16563/info) to see a json map of some of the info about the model being used.","Sep 26, 2017 at 0:32",,,,46414097
79790962,79790962,"I have posted my own solution, but it is very hacky. You seem to know way more than me and if you could add any insights based my posted answer, it would be appreciated. By the way, if you don't mind, are you a contributor to the 
h2o steam
 project or affiliated with 
h2o
 in some other direct way?","Sep 26, 2017 at 1:49",,,,46414097
91237858,91237858,Can I just use mojo model in code rather than download it and read it to project again? Can I use fake code like this: Mojo mojo = h2o.getMojo(**);,"Sep 3, 2018 at 6:17",,,,46394550
79751580,79751580,Finally...................  It worked. Thanks Hack and Erin...  I uninstalled my java 9 and am now running java 8 to run the h2o library directly from r.,"Sep 25, 2017 at 3:38",,,,46392517
79787708,79787708,@Mayur You are very welcome. If you don't mind terribly could you click the green check mark by my answer so that I can get credit? :),"Sep 25, 2017 at 22:08",,,,46392517
84994511,84994511,"downgrading to 8.0.161 worked for me too, just uninstall JDK9 and install JDK8, thanks","Feb 26, 2018 at 18:11",,,,46392517
85114251,85114251,"Gotta get this information more available. Spent way too much time messing with R settings trying to figure out why I was only predicting one class in a neural net. h2o group needs to acknowledge which version of Java we need to be on, and either bundle it or link it with the h2o package. Thanks for the solution.","Mar 1, 2018 at 16:56",,,,46397353
86627792,86627792,"@Erin LeDell - User feedback. Please pass it along to your documentation team. :) H2o is great, btw.","Apr 12, 2018 at 21:58",,,,46397353
79709358,79709358,"Since the models in 
steam
 project seem like they can only come from running 
h2o flow
 cluster I guess there is no way to change the hard-coding. But all (binomial) POJOS from 
flow
 seem to have a score0() function that takes some arguments and returns a prediction value. In this function there seems to be the threshold value used to get the max f1 threshold prediction (near the bottom of this function in my experience). From here I think I can modify the threshold value manually, but is there then a way to use this new .java POJO in the 
steam
 server?","Sep 23, 2017 at 1:06",,,,46374948
79709375,79709375,"Also, is there a way to access the predict.js file shown in the post screenshot so that it can be used instead in the 
steam
 instance?","Sep 23, 2017 at 1:08",,,,46374948
79709412,79709412,"No I don't think you can change it. I think it's possible that you can change the threshold in the POJO Java file and then build a prediction service from that. Can't say if you can get that into Steam, but you can use it with the stand-alone Prediction Service Builder. As for 
predict.js
 you can find that here 
github.com/h2oai/steam/tree/master/prediction-service-builder/…
 Note that in there you can't change any thresholds anyway.","Sep 23, 2017 at 1:12",,,,46374948
79709509,79709509,"For the 
predict.js
 file, I know where it is within the raw source of the github steam repo. (
github.com/h2oai/steam
) file structure, but I am running 
steam
 from the the official download page (
h2o.ai/download
) (for linux) using these instructions (
docs.h2o.ai/steam/latest-stable/steam-docs/…
) not from a git clone of the source repo. And from within this unzipped directory there is no 
predict.js
 file that I can find.","Sep 23, 2017 at 1:21",,,,46374948
79783385,79783385,"The prediction service builder is a stand-alone web application that is distributed with Steam. If you unpack the Steam download, you'll find it in a file called 
ROOT.war
. Steam starts this web application. Now if you look inside 
ROOT.war
 you'll find 
predict.js
 in 
extra/predict.js
. It is indeed a jar file, in this case called a war file because it's a web application.","Sep 25, 2017 at 19:30",,,,46374948
79707308,79707308,"Could you point me towards any resources, tutorials, examples, or official docs of how to do this? This post (
stackoverflow.com/q/43766401/8236733
), lead me here (
github.com/h2oai/steam/blob/master/prediction-service-builder/…
), but I'm not fully sure what to make of it. Thanks for all your help.","Sep 22, 2017 at 22:15",,,,46373619
79707501,79707501,"StackOverflow has the answer: 
stackoverflow.com/questions/21711030/…
 Use DateFormat.parse()","Sep 22, 2017 at 22:27",,,,46373619
79707568,79707568,"Thank you for helping me. I know how to convert between POIX time-stamps and date-strings (from working with MOJOs in local CLI java programs). I was more lost in terms of what a 
preprocessing script
 looks like for deploying a model from 
steam
, since it's not clear to me how the .py gets used or called by steam (or the model?).","Sep 22, 2017 at 22:33",,,,46373619
79707681,79707681,"I may be confused about what you are suggesting. I am wondering if there is a way to convert data input from the user the in prediction service using a preprocessing .py script after the ""predict"" button is pressed but before the model attempts to predict on the entered inputs.","Sep 22, 2017 at 22:42",,,,46373619
79708535,79708535,"OK, I see. Yes there are 2 possibilities for preprocessing, either using Java or Python. There's one example for each of them. Java: 
github.com/h2oai/steam/tree/master/prediction-service-builder/…
 and Python: 
github.com/h2oai/steam/tree/master/prediction-service-builder/…
 Check out the readme for the Python example for a longer explanation of how it works.","Sep 22, 2017 at 23:47",,,,46373619
79704662,79704662,"Does this mean that, under the hood, 
steam
 passes all models to the prediction service as 
mojos
?","Sep 22, 2017 at 20:17",,,,46372556
79704737,79704737,"If I remember right it passes some models as MOJOs (tree-based models), but other ones are passed as POJOs.","Sep 22, 2017 at 20:19",,,,46372556
79705091,79705091,"This is open source, and you are welcome to submit changes: 
github.com/h2oai/steam/blob/master/CONTRIBUTING.md","Sep 22, 2017 at 20:31",,,,46372556
79670960,79670960,"I started the service builder following the instructions here 
docs.h2o.ai/steam/latest-stable/…
, if that's what you mean (never used gradle before). Where do I add the 
GRADLE_OPTS=-Xmx4g
 command? Is is all a single line? (eg. 
$ GRADLE_OPTS=Xmx4g ./gradlew jettyRunWar
)?","Sep 22, 2017 at 1:35",,,,46355344
79695414,79695414,Yes all in a single line,"Sep 22, 2017 at 15:12",,,,46355344
79702383,79702383,"Trying this did not produce any errors in the cli, but when trying to compile the pojo into a .war in the service builder, the the browser (chrome) gives the error screen ""localhost didn’t send any data. ERR_EMPTY_RESPONSE."" Nothing else seems to happen after this.","Sep 22, 2017 at 18:53",,,,46355344
79703447,79703447,"Nothing else seems to happen after this for a long time, then cil gives same 
java.lang.OutOfMemoryError: Java heap space
 error.","Sep 22, 2017 at 19:31",,,,46355344
79704181,79704181,"Thanks, now I understand the problem better. The service builder runs java internally to compile and build the services. It has an internal setting of 4 GB which is normally fine. In your case it looks like you need more. You can change that on this line 
github.com/h2oai/steam/blob/master/prediction-service-builder/…
 Then just restart the prediction service builder with 
./gradlew jettyrunwar
. I hope this helps.","Sep 22, 2017 at 19:59",,,,46355344
79668464,79668464,"Thanks. The cli example from the github page works for me, but this command does not. I have updated my original post to add what happened when trying to run your provided command.","Sep 21, 2017 at 22:45",,,,46353786
79668523,79668523,"Looks like you ran out of memory. Try with 
-Xmx4g
 or something like that. Command then is 
java -Xmx4g -jar jetty-runner-9.3.9.M1.jar --port 55001 ~/Documents/h2o_production/mojos/drf_denials_v4/drf_denials_v4.war","Sep 21, 2017 at 22:49",,,,46353786
79668769,79668769,"Thanks, that helped. I can now click predict and get a label as in the update screenshot without any error messages in the cli. But like in the updated screenshot, there are still no input fields (the model takes 20 inputs and I have successfully predicted on them when using the mojo zip in a java file as in the mojo quickstart example (
github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/howto/…
)). What could be causing this? Inspecting the page html, it's not as if the input fields are hidden.","Sep 21, 2017 at 23:04",,,,46353786
79668979,79668979,"Great to hear that it worked. I suspect the answer again is that the UI has not been updated to handle mojos. It should work fine to predict using the command line. Then you'd do something like 
curl -X POST --data '{Var1:  Val1}' localhost:55001/predict
 etc.","Sep 21, 2017 at 23:18",,,,46353786
79669431,79669431,"Thank you. That seems to be that case. Unfortunately it also nullifies a big portion of the reason the service builder would have been useful in my case, since not having a UI interface means I can't take advantage of the input selection drop downs for categorical inputs. Anyways, thank you for your knowledge.","Sep 21, 2017 at 23:46",,,,46353786
79568744,79568744,"That's very helpful, thanks. I wish there was a more general way to do it, regardless of whether cross-validation was chosen (I.e.: something that could be specified in 
h2o.splitFrame()
, which would cover the simplest case with one training and one validation set).","Sep 19, 2017 at 14:34",,,,46303042
79541220,79541220,"Thanks, Erin, once again! I missed it. Somehow I thought that these two options were not there in a grid search. I think they were not there because I didn't select cross-validation option. My bad. Thank you again!","Sep 18, 2017 at 22:30",,,,46259618
79542193,79542193,"No problem!  You can pass any algorithm argument (including 
keep_cross_validation_predictions
) through to 
H2OGrid
 -- that's how you can modify the algorithm to use non-default settings (same is true for model hyperparameters).  Examples here: 
github.com/h2oai/h2o-tutorials/blob/master/h2o-open-tour-2016/…","Sep 18, 2017 at 23:33",,,,46259618
79517061,79517061,Thank you! Error messages should be more descriptive though.,"Sep 18, 2017 at 10:36",,,,46244232
79377293,79377293,Thanks -- I have zero experience in web programming -- trying to work my way through this and will provide feedback when I can,"Sep 13, 2017 at 21:16",,,,46206613
79662681,79662681,"Thanks Erin for the guidance. I would suggest to incorporate this into the h2oai documents, at least in a synthetic format","Sep 21, 2017 at 18:52",,,,46351059
79379390,79379390,"Thank you for the pointer regarding the use of ExpRectifier. In the Flow UI, I do not see an option for ExpRectifier. I only see Linear, Tanh and MaxOut, alongwith their dropout counterparts.  I am using version 3.14.0.2 installed via R.","Sep 13, 2017 at 22:59",,,,46204997
79576397,79576397,"Thanks Avkash. Will the mojo.getDomainValues() function also work in case the predictor is of any other data type? eg. time, string, UUID? I believe these are actually the datatypes of the hex dataframe (h2o internal dataframe generated after data parsing).   Second part of my question is, what are the different datatypes the different columns in the hex dataframe can take-  time, string, UUID..I believe numeric = real..? Is this documented anywhere in the H2o documentation?","Sep 19, 2017 at 18:19",,,,46125082
79577287,79577287,"Because the models is built by H2O, the getDomainValues understands all the supported data type used while building model. H2O supports integer & real numbers and enums, strings, UUID and time data type.","Sep 19, 2017 at 18:47",,,,46125082
79833151,79833151,@kivk02 Glad it worked for you. Its always good to accept the answer.,"Sep 27, 2017 at 1:46",,,,46125082
80544947,80544947,"Does the wrapper have a function to directly print out the datatypes? Right now, I am able to print the domain value and that says whether if it is numeric (it prints out null), but in other cases it prints out the actual domain values for the columns. So, the question is- Is there a function to directly print out the datatypes in other cases too like string, enum, time, uuid etc..?","Oct 17, 2017 at 20:52",,,,46125082
79289468,79289468,"This is exactly what I was looking for, Erin; I apologize for the poor word choice. Thanks!","Sep 11, 2017 at 20:06",,,,46125952
79292438,79292438,"If you found my answer useful, can you please give it an upvote?","Sep 11, 2017 at 22:06",,,,46125952
79410016,79410016,"I have. But due to my newness to StackOverflow (rep. < 15), it is not displayed.","Sep 14, 2017 at 15:55",,,,46125952
79421732,79421732,No worries.  Welcome to Stack Overflow! :-),"Sep 14, 2017 at 22:08",,,,46125952
79198196,79198196,"Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  :","Sep 8, 2017 at 13:45",,,,46117435
79198839,79198839,@penguin - Never worked on H2O. My answer might not be valid for your query in that case. I can take it off so others can still assist you.,"Sep 8, 2017 at 13:59",,,,46117435
79199017,79199017,Thanks. I am not sure whether you should remove it. This works for default  R dataframe object. I was hoping that it will work for r h2o frame object also as most of R operations work.,"Sep 8, 2017 at 14:04",,,,46117435
79199042,79199042,"This is a similar issue but still unresolved 
stackoverflow.com/questions/27181616/…","Sep 8, 2017 at 14:04",,,,46117435
79199171,79199171,"Can you show how to create that 
H2O frame
? I have downloaded the required package.","Sep 8, 2017 at 14:07",,,,46117435
79193365,79193365,"setting :  
Sys.setlocale(""LC_MESSAGES"", 'en_GB.UTF-8') Sys.setenv(LANG = ""en_US.UTF-8"")
 worked!","Sep 8, 2017 at 11:43",,,,46113255
85539267,85539267,"I added a ticket to fix this here: 
0xdata.atlassian.net/browse/PUBDEV-5402","Mar 14, 2018 at 0:21",,,,46113255
78914345,78914345,Are there any solution for fitting a model with generator method like keras framework ?,"Aug 31, 2017 at 9:22",,,,45977094
78916090,78916090,"@khant Not that I am aware of. The H2O philosophy is in-memory machine learning, that works efficiently over a cluster: keep adding machines until the total cluster memory is big enough for your dataset. (I just added a couple more ideas to my answer, hope it helps.)","Aug 31, 2017 at 10:02",,,,45977094
79024791,79024791,"Please comment when you downvote, especially if there is some technical inaccuracy that needs correcting. (I thought I had correctly answered the question, in the first sentence.)","Sep 4, 2017 at 7:45",,,,46002429
78867218,78867218,"Thanks Tomas, that is interesting. In the linked to question, the best lambda of the 3 cv folds were 0.011, 0.018, 0.016, but the model's best lambda was 0.106 (i.e. 10 times larger). It doesn't look like it has been picked based on cross-validation, but is that still possible with some unusual data?  (Or is that also a symptom of the #4858 early stopping bug?)","Aug 30, 2017 at 7:44",,,,45949460
78826892,78826892,"Erin, is the only bug that 
early_stopping = F
 is being ignored? If you want early stopping, is the current behaviour correct? It seemed to be stopping a bit early here, especially on the OP's unseen real data; but is that part of guarding against over-fitting, when using CV?","Aug 29, 2017 at 8:37",,,,45928270
78854509,78854509,"@DarrenCook Yes, that's the bug.  When 
early_stopping = F
, it computes all lambdas in the CV models, but the bug is that in the main model, it will still do early stopping (by computing up-to the best lambda instead of all lambdas).","Aug 29, 2017 at 20:41",,,,45928270
78855972,78855972,"Erin, my comment got a bit long, so I made it into a full question: 
stackoverflow.com/q/45948642/841830","Aug 29, 2017 at 21:34",,,,45928270
78769868,78769868,Thank you very much for your detailed response. This makes sense now. :),"Aug 27, 2017 at 14:00",,,,45903390
78780240,78780240,Could you please clarify what booklet you are referencing?,"Aug 28, 2017 at 1:30",,,,45903390
78783338,78783338,"@Darren, I am now still actually seeing differently on my actual dataset. I have edited my post to show the results of my actual model.  The cross-validated models have selected smaller lambda's, yet the main model stops at a very large lambda. Please let me know if you have any further thoughts.","Aug 28, 2017 at 5:46",,,,45903390
78787847,78787847,"@C8H10N4O2 Sorry, added the link to the download page, where you can find a booklet on GLM, describing the h2o implementation.","Aug 28, 2017 at 8:25",,,,45903390
78788006,78788006,"@jav My first two thoughts on your real results were: 1. the cv models tried down to 1e-5, but chose a lambda 3 orders of magnitude higher, so it wants to regularize a lot, suggesting a lot of noise; 2. nfolds of 3 is low - try 10, and see if you get better parameter estimates? Though, I do agree it is strange that the main model didn't try a few more lower lambdas, given that it chose the last lambda it tried.","Aug 28, 2017 at 8:31",,,,45903390
78692143,78692143,h2o should be able to read yyyy/mm/dd this format but glad to see you found a work around.,"Aug 24, 2017 at 16:34",,,,45851303
78633074,78633074,"Partly solves it but brought me on the right track! (I left out part of the requirement though, which is that model.aic needs to be called with some keyword argments as well). Instead of just passing getParam, I need to also pass **kwargs. Then return getParam(**kwargs).  Finally call tryParam(model.aic, ""valid=True"").","Aug 23, 2017 at 11:08",,,,45837544
78600172,78600172,"Yes, I agree. Just did this as quick workaround to get it running. Though, local repository is also no real option if you want to share your project (e.g. on Github), right?","Aug 22, 2017 at 15:06",,,,45817058
78610602,78610602,You share your project on github with a maven configuration file which lets other people download their own dependency jars.,"Aug 22, 2017 at 20:16",,,,45817058
78734620,78734620,Please note that in this case you can't use a maven version since you need to use one with deepwater built in. See my answer to this question.,"Aug 25, 2017 at 18:39",,,,45817058
78631869,78631869,"Okay, this explains why mine is not working. The model download method only creates two files: DeepWater_model_python_1503483286537_1.zip and h2o-genmodel.jar.  However, deepwater-all.jar is not created. How do I create / generate this file? I also unzipped the created zip and jar to check the content. The h2o-genmodel contains some classes about the backend. But as you said, I still need the deepwater-all.jar. Thus, right now still the same exception as before, of course.","Aug 23, 2017 at 10:41",,,,45829433
78650946,78650946,"Yes, this part is not well documented. You can download it the same way you can download h2o-genmodel.jar from the running H2O app. 
curl localhost:54321/3/deepwater-all.jar > deepwater-all.jar
.  You can also do 
jar xvf /opt/h2o.jar www/3/deepwater-all.jar
 to get it out into a 
www/3
 directory.","Aug 23, 2017 at 17:56",,,,45829433
78677213,78677213,"Yeah, the inconsistency and incompleteness of H2O docs / booklets / github examples is really a big problem for beginners like me, unfortunately. Anyway, I still have the same problem after using the correct JARs: ""Cannot find TensorFlow native library for OS: darwin, architecture: x86_64."" Is there a need for a local TensorFlow installation or any additional dependency? Can you maybe share with me a working Java example / project and the corresponding H2O Deep Water JARs which you created? (the issue is with Deep Water - a standard GBM model works well the same way)","Aug 24, 2017 at 10:54",,,,45829433
78702523,78702523,"Since Deepwater is built for Ubuntu Linux only we don't have a version for Macintosh (i.e., darwin). You can run the CPU-only docker image on the Mac, and what I talked about above has to be run within the docker image. You also have to run the resulting Java code within the docker image. It will not run on your Mac since it contains code that is compiled for and can only be run in Ubuntu 16.04 Linux. Unfortunately there are quite a few moving parts here. This is why we provide the docker images where everything has been installed for you.","Aug 24, 2017 at 22:28",,,,45829433
78713470,78713470,Thanks for clarification (again) :-) I will try it out within the Docker instance. I assume it will work then...,"Aug 25, 2017 at 8:42",,,,45829433
78591052,78591052,"I have also observed that nfolds with xgboost fails and when I train multiple models in a row (with different validation set seeds in lieu of cross-validation), the models gives weird results (all metrics will be equal to 0.5). Is this also a known XGBoost issue?","Aug 22, 2017 at 11:53",,,,45808793
78591116,78591116,Is the above issue with saving and loading models fixed in the nightly bleeding edge?,"Aug 22, 2017 at 11:55",,,,45808793
78614073,78614073,"For the first issue, can you provide a reproducible example and file a JIRA ticket?  That sounds like a bug.  The save/load issue has been worked on yet, but it's a high priority item, so it should be fixed soon.","Aug 22, 2017 at 22:43",,,,45808793
91819664,91819664,"I am using h2o3.20.0.5， so I changed the command as ""pip install 
h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/2/Python/…
"". But the link can't be reach. Only ""h2o-3.14.0.2"" can success, why?","Sep 21, 2018 at 7:09",,,,45828610
91836850,91836850,"This is the URL for 3.20.0.5.  
h2o-release.s3.amazonaws.com/h2o/rel-wright/5/index.html
 -- and this is the pip for it:  pip install 
h2o-release.s3.amazonaws.com/h2o/rel-wright/5/Python/…","Sep 21, 2018 at 15:36",,,,45828610
78540119,78540119,"And how can I do to use set(matrix1,i,1L,3) if I want to fill all the column instead a simple row [i]??","Aug 21, 2017 at 7:14",,,,45784139
78548356,78548356,"Double loop? Well, actually if you want to fill your table you're better to fill it at the creation not after the creation in a loop. This is  not the R way.","Aug 21, 2017 at 11:00",,,,45784139
78551600,78551600,"Imagin I want to assign to a column of a matrix a value of another df, which is the best way to do it?","Aug 21, 2017 at 12:23",,,,45784139
78559888,78559888,"matrix[,i] = df$mycol
 to copy the entiere column 
mycol
 in the matrix column 
i
 or 
matrix[,i] = 3
 for a single number.","Aug 21, 2017 at 15:37",,,,45784139
78567257,78567257,And this is not inefficient way? I thought that it was a bad way to do it... It is not possible to do like := or using h2o? Thanks!,"Aug 21, 2017 at 20:00",,,,45784139
78444845,78444845,"Thanks, I filed a bug report here: 
0xdata.atlassian.net/browse/PUBDEV-4818","Aug 17, 2017 at 19:43",,,,45737424
78553615,78553615,"Comment Part I: Thanks for the answer.  First I checked the Ubuntu version and it is „Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-generic x86_64)“. I doubt that a plain Ubuntu VM from Azure use some sort of non-standard Linux version, because I never experienced any problems. But on the other side I can’t clear out that this might be some issue.","Aug 21, 2017 at 13:10",,,,45747057
78553660,78553660,"Comment Part II: Then I made progress with the mxnet backend – it works now without changing anything. The only steps between the errors mentioned at top and the successful computation now:  I stopped the virtual VM and started it again. Maybe Azure uses some restart mechanism on the VM and this was all that was needed. I don’t know, just guessing. So, mxnet now works. But tensorflow just has the same error then before. I attached a log file to my question. I added the log files from H2O at the beginning of my question.","Aug 21, 2017 at 13:11",,,,45747057
78616229,78616229,"Hi, given that MXNet suddenly is working without changes, makes me thinks it's not a standard Ubuntu environment. I looked at the log files and can't say why tensorflow is not loaded. Perhaps there are some version differences on some libraries. To solve that you may need to build it yourself on that platform. Again, I would recommend you to use the docker image as we know that it works on Azure and elsewhere. 
github.com/h2oai/deepwater#pre-release-docker-image","Aug 23, 2017 at 1:33",,,,45747057
78328600,78328600,"Thanks Erin, that was my guess otherwise the coefficients wouldn't be as interpretable. I guess I just have to keep an eye on each feature so they don't change too much overtime. Also do you know if there is function that will extract these mappings for me? i.e. the mean and standard deviation used to standardise each feature or do i just write a function that does it on the raw data ... mean(x) and sd(x). Basically I am wanting to move the model closer to my data in a database and write the function for the model manually using sql.","Aug 15, 2017 at 1:45",,,,45684659
78329674,78329674,"No, these methods are not exposed via the H2O client APIs (that I'm aware of).  You can turn this off and do the operations by hand (see the 
standardize
 arg in GLM & DL; the other algs don't warp the features), but if you're going to use H2O for modeling, it's easiest to let H2O handle this automatically.","Aug 15, 2017 at 3:17",,,,45684659
80760736,80760736,I have since discovered that h2o produces both standardized and non-standardized coefficients. the non-standardized ones can be used on non-standardized data!,"Oct 24, 2017 at 9:37",,,,45684659
78334849,78334849,"Getting the best model as described above gives an object that has actual_params (<property at 0x7fa349f62050>) but when trying to use the commands as you mention, I get the following error: 
'property' object has no attribute '__getitem__'","Aug 15, 2017 at 7:55",,,,45684784
78363035,78363035,updated answer think this should solve your problem now,"Aug 15, 2017 at 22:12",,,,45684784
78390519,78390519,"Still getting the same error. 
type(best)
 yields 
h2o.estimators.glm.H2OGeneralizedLinearEstimator
 and 
type(best.actual_params)
 is 
property","Aug 16, 2017 at 14:26",,,,45684784
78395325,78395325,"The first is the correct type: 
best
 should be an H2OGeneralizedLinearEstimator, but type(best.actual_params) should be a dict. Can you try the fully reproducible example I added to see if/when your code deviates? also instead of 
best = h2o.get_model(grid.sort_by('r2', increasing=False)['Model Id'][0])
 can you use 
best = grid.get_grid(sort_by = 'auc', decreasing = True).models[0]
.","Aug 16, 2017 at 16:21",,,,45684784
78406728,78406728,"When I try to run your example using alpha hyper-parameters and 
lambda_search=True
, the 
actual_params['lambda']
 returns the full set of lambda values.","Aug 16, 2017 at 23:35",,,,45684784
78390130,78390130,"thanks for thorough reply! wonder if there's a way to access not just the top1 leader model but the next few too. on a second thought difference between validate and test seems reasonable, maybe 5-6 point difference in accuracy, yet to use it more to have more results","Aug 16, 2017 at 14:18",,,,45681480
78402560,78402560,"All the models are stored on the H2O cluster, so in order to access them, you just need to grab the model by ID.  This will grab the sorted model IDs and convert into a character vector:  
model_ids <- as.data.frame(aml@leaderboard$model_id)[,1]
  Then 2nd best model would be 
m <- h2o.getModel(model_ids[2])
 for example.","Aug 16, 2017 at 20:15",,,,45681480
78354931,78354931,90	23:22:21.552	Info	ModelTraining	Built: 34 models for search: GBM hyperparameter search 91	23:24:34.304	Info	ModelTraining	GBM hyperparameter search complete 92	23:24:34.304	Info	ModelTraining	AutoML: out of time; skipping DL hyperparameter search 93	23:24:34.304	Info	ModelTraining	AutoML: out of time; skipping DL hyperparameter search,"Aug 15, 2017 at 17:33",,,,45667577
78354949,78354949,It looks like it does GBM hyperparameter search takes up the entire time and finishes before it gets to deep learning,"Aug 15, 2017 at 17:33",,,,45667577
78360845,78360845,It looks like it only ran for ~23.5 hours and not the full 100.  Did you stop it early or did it stop on it's own?,"Aug 15, 2017 at 20:45",,,,45667577
78362172,78362172,"It stopped on its own, I will try to rerun it.","Aug 15, 2017 at 21:35",,,,45667577
78362239,78362239,"Please give it more memory if you can, it might have run out of RAM.","Aug 15, 2017 at 21:37",,,,45667577
78408456,78408456,"Thank you for your reply, I just upgraded to 3.14.01. Will rerun the experiment and try to reproduce the results.","Aug 17, 2017 at 1:50",,,,45722534
78408602,78408602,I am using auto stopping metric.    Thank you so much for your help.,"Aug 17, 2017 at 2:01",,,,45722534
78489919,78489919,Great!  I look forward to getting to the bottom of this!,"Aug 18, 2017 at 22:15",,,,45722534
78425726,78425726,"When we use H2OXGBoostEstimator instead of GBM, it seems to have better performance but the implementation suffers from finishing the grid search. (
stackoverflow.com/q/45726324/1928229
)","Aug 17, 2017 at 11:36",,,,45680831
78420302,78420302,"I think you meant model.algo, but yes, this is exactly what I am looking for","Aug 17, 2017 at 9:30",,,,45640350
78283826,78283826,"It is not working with ""h2o.init()"" on my Mac. Error as shown above... There is either something missing or the Docker Image is not configured correctly. FYI: I use Docker Community Edition Version 17.06.0-ce-mac19 (18663) on My Mac OS X 10.12.6...","Aug 13, 2017 at 17:38",,,,45640149
78322611,78322611,"I just tried this on my Mac and it was fine. You need to run 
docker run -it --rm -p 54321:54321 -p 8080:8080 -v $PWD:/host opsh2oai/h2o-deepwater-cpu
, then go to 
http://localhost:54321/flow/index.html
 . This shows that H2O is running on the Mac. Then start python, do 
import h2o
, 
h2o.init(strict_version_check=False)
, which stops it from complaining that you may have the wrong version installed in your Python. Note that your h2o package has to be compatible.","Aug 14, 2017 at 20:15",,,,45640149
78334592,78334592,"I have a fresh installation of Anaconda and Python 2.7. H2O version is h2o 3.10.0.9 (shown in 'pip list'). I do exactly the steps you wrote down. I can access the Flow UI. But 'h2o.init(strict_version_check=False)' still shows the errors above. Strange... Which versions are you using? I can do fresh installs and try again... Really need to get this running :-) (I also tried the Github build locally, but too many build exceptions like missing R packages so I stopped trying that after 30min) ... Just need ""any kind"" of Deep Water running locally.","Aug 15, 2017 at 7:45",,,,45640149
78361372,78361372,"I've never seen your error. Your docker image may be old. Run 
docker pull opsh2oai/h2o-deepwater-cpu
 to get the latest one. Also, I would also recommend you to run Python within the docker image, since then you have the correct python package installed. You do that by putting the h2o in the background: 
java -jar /opt/h2o.jar &
 . Then do 
python
 normally and 
import h2o
. You should then be good to go. I've tested this and it works fine on a Mac with the latest docker image.","Aug 15, 2017 at 21:06",,,,45640149
78448285,78448285,I looked up the exact version of the Python wheel used in the docker image. You can get it here: s3://h2o-deepwater/public/nightly/deepwater-h2o-356/h2o-3.13.0.356-py2.py3-none-any.whl,"Aug 17, 2017 at 21:45",,,,45640149
78156870,78156870,"Thank you, it makes complete sense, just wondering if I had to do it manually or not.","Aug 9, 2017 at 19:00",,,,45598669
78124565,78124565,"Thanks, did not know that. But how does it relate to a prediction of a single row? Allow me to clarify: My code is designed to be run with thousands of API calls per second for prediction, where every prediction request is made of a single row. Sounds like what you are describing would, in this case, affect only training time and not the prediction time.","Aug 9, 2017 at 6:05",,,,45551286
78268791,78268791,"For that use case, you should export a MOJO or POJO from H2O and use that to make predictions.  They are meant for real-time one-row-at-a-time use cases.  I would not use the full H2O, it's going to have a lot of overhead for one-row-at-a-time use cases.  See 
docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html","Aug 12, 2017 at 22:00",,,,45551286
78124625,78124625,"Thank you, tested what you've written, but H2O still lags behind significantly on a one-row prediction task.  My data has categorical features as well, I'm trying to avoid the misuse of sklearn on categoricals, that is why I've been searching for an alternative in the first place.","Aug 9, 2017 at 6:07",,,,45558364
78234665,78234665,"Thanks! but my need is to be able to reply to multiple single value prediction requests, and process them fast. There is no overhead, since I tested both models locally without any calls.  But I'll definitely give Mojo/Pojo a try and report back with findings.","Aug 11, 2017 at 14:29",,,,45611394
78239851,78239851,"There is no ""local"" for H2O. When you run the Python API command it makes a REST API call and sends it to the H2O server (which is written in Java). When your H2O server is running on localhost 20ms of overhead sounds about right, doesn't it?","Aug 11, 2017 at 16:52",,,,45611394
78274760,78274760,"Yes, I see what you mean. So, in that case, sounds like I won't be able to go below this threshold.","Aug 13, 2017 at 8:13",,,,45611394
78275147,78275147,"As I said, if the 23ms overhead of a REST API call is significant overhead, you should be using the MOJO. See 
docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html
 for the various ways it can be used. I'd be very interested to see the results if you do try it.","Aug 13, 2017 at 8:40",,,,45611394
78345304,78345304,"OK, so I just discovered 
CatBoost
, which runs GBM and not Random Forest (which is what I was looking for).  It gives me better results and does predictions in less than 1 millisecond per call. So far, recommended!","Aug 15, 2017 at 13:21",,,,45611394
78015361,78015361,"So, in my example, the predicted value was 1 (from the table) with a probability of 0.1150.  Why was the predicted value computed to be 1 with such a low probability?","Aug 6, 2017 at 0:33",,,,45525905
78015747,78015747,"By the way, if I run ""model.display()"", I get a lot of printout.  There is a table called ""metrics"" that contains: ""max f1  10.0741772  0.571429"".  So... how can I apply this information?  I need a formula that I can use to evaluate streaming data to see if I have a valid classification.  Any help will be greatly appreciated.","Aug 6, 2017 at 1:14",,,,45525905
78033605,78033605,"From that, I guess that ""1"" is class 0. So the p0 was 0.885, which is greater than the 0.571 of Max F1, which is why 
predict
 is ""1"".   (If that is still not making sense you might want to post the first few rows of your training data.)","Aug 6, 2017 at 21:27",,,,45525905
78061022,78061022,"Darren, it's the value of p1 which is compared, not p0.  And the '1' is class 1.  See here for the code that's used to calculate this for the POJO/MOJO.  The function is getPrediction().  
github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/…","Aug 7, 2017 at 15:35",,,,45525905
78070400,78070400,"Forgive me for belaboring the point.  I still have my training wheels on. I'm still not getting an answer to my question: If the probability of getting class 1 (p1) is less than 0.5, how can h2o predict 1, regardless of the threshold number? Applying the threshold to the prediction seems to imply that there is a weak or strong prediction.  Is this how we should think about it?","Aug 7, 2017 at 20:28",,,,45525905
111180911,111180911,"Should be an idea to insert weights using the 
weights_column
? For example, the positive examples should have an higher weight w.r.t the negative ones, in order to put the focus on the true positive.","Jul 13, 2020 at 8:32",,,,45610982
77964227,77964227,"Thanks for your help. I assume that other machine learning techniques (such as GBM, where the model size is generally smaller) do not run into this problem. It's a pity that DRF cannot be sped up, because depending on the problem size and DRF hyper parameters, single-node model training can take up to 45mins in my case. That makes sequential hyperparameter optimization tricky... Anyhow, I will try to run my code on a x1.32xlarge machine and see how it performs. From what I have seen, memory bandwidth seems to be the DRF bottleneck and these instance provide high mem bandwidth (supposedly).","Aug 4, 2017 at 8:27",,,,45496049
77984615,77984615,"GBMs will require a similar amount of memory -- usually you train fewer trees in an RF than GBM, but the trees are deeper in an RF.  Often GBM gets better performance than RF, so you might want to try out both to see what works best for your data.","Aug 4, 2017 at 16:43",,,,45496049
78189143,78189143,"Erin, one more question: Shouldn't it be possible to grow the individual trees of a forest independently from each other? Given that one turns off early stopping, there should be no intermediate communication overhead then. Very much like the proposed RF training algo #1 in Michal Malohlava's rf-brighttalk slides I have linked in my question. My guess is that for ""big data"" reasons h2o went for another implementation (that depends on intermediate exchange of histograms). Is there a plan at h2o to also implement algo #1 in addition to #2 (see slides)?","Aug 10, 2017 at 13:34",,,,45496049
78207774,78207774,"Yes, it's possible, but it requires each of those independent processes to hold the entire training set in memory, so that's the big drawback.  We used to have both versions (""DRF"" and ""SpeeDRF"") in H2O-2 but the latter is not scalable to big data.  It's possible that we could put a fast/smalldata version back in, but it's not on the roadmap at this time.","Aug 10, 2017 at 21:59",,,,45496049
78305803,78305803,"Thanks for confirming this. BTW: Now with large memory cloud instances being available (2TB for AWS x1.32xlarge) and with Bayesian hyperparameter optimization becoming more popular, I would guess that user demand for the ""small data"" version will pick up.","Aug 14, 2017 at 12:10",,,,45496049
78180982,78180982,"Darren, thanks a lot for your input. What you describe (having a separate h2o cluster on each node) works very well for random search and grid search. Actually, I already use such a solution for grid/random search. However, if one wants to do Bayesian hyperparameter optimization (which, basically, works sequentially), it would be better to have several nodes work on one parameter configuration. BTW: I have your book ;)","Aug 10, 2017 at 10:39",,,,45611203
78181378,78181378,"Is your multinode grid/random search working for a set of H2O clusters? I'd love to see a blog post, or something, showing the scripts you use.  (Thanks for buying the book!)","Aug 10, 2017 at 10:49",,,,45611203
78181945,78181945,"I do everything from within R (on a master node that does not do any h2o calculations). The cluster setup is described in my answer to 
stackoverflow.com/questions/43515062/increase-h2o-init-timeout
. But I am using 
clusterCall
 instead of 
foreach
 now for the cluster setup. The distribution of tasks is done via 
foreach
. I do also split the tasks by CV-fold (not only by hyper param conf). The results are collected via 
data.table::rbindList
 (important if you have larger data sets).","Aug 10, 2017 at 11:03",,,,45611203
79367862,79367862,"Hi Darren, if you are still interested in running 
R
 ML tasks on a cluster, I can highly recommend the new 
future
 
R
 package. I can now use my own load balancing methods, dynamically create/delete tasks and analyze incoming results sequentially. It does not solve the issue of getting Bayesian Optimization parallelized (as described in my original question) - but it's a much more flexible approach than using 
foreach
 or 
clusterCall
.","Sep 13, 2017 at 16:23",,,,45611203
77963554,77963554,"I did start H2O. As described in the docs. Also, please note that I use the CPU-only Docker Image as I want to run it on my Mac. What logs do I need to check / share?","Aug 4, 2017 at 8:08",,,,45491655
77994881,77994881,"For logs I mean what's printed on the screen when you run the commands. When you do 
java ... &
 it outputs its log on the screen. If you could post that we can figure out what went wrong. It's hard to tell with this little information about what you do. Note that to access h2o you go to 
localhost:54321
 on the machine where you run docker from.","Aug 4, 2017 at 23:37",,,,45491655
78040543,78040543,Added the logs to the post... I think there is no issue with starting H2O. Looks all good to me? I also do not use localhost for accessing the Flow UI in the browser. Maybe there is some wrong (security) configuration in the H2O Docker template so that I cannot access it?,"Aug 7, 2017 at 6:09",,,,45491655
78071879,78071879,"From the outside of the docker image, the url will be 
localhost:54321
 The IP address 172.... is only inside the docker. The -p flag makes the port available on the machine outside of docker.","Aug 7, 2017 at 21:24",,,,45491655
78077736,78077736,Wow. That simple solution for my problem... :-) Thanks a lot.,"Aug 8, 2017 at 4:11",,,,45491655
77944967,77944967,Thanks for your response.  Would h2o.xgboost with GPU=TRUE not work either on this arch.  That is part of code h2o lib and not the deepwater bits.,"Aug 3, 2017 at 18:19",,,,45491572
77951695,77951695,"No that does not work since TensorFlow and MXNet have been compiled for x86-64 and is included inside. For CPU-only, you have to use the version that is built for cpu only. There are downloads for this and we also have a cpu only docker image available, that's the easiest thing to use.","Aug 3, 2017 at 21:49",,,,45491572
78197824,78197824,"Thank you for reporting it. I think this is the point of sparse arrays, to save memory by using only index:value combinations. This is a valid svmlight format, you can try to parse it on scikit-learn for example. It should not matter if the index is 1, 100 or 1,000,000.Thanks for the prompt reply again!","Aug 10, 2017 at 16:42",,,,45610449
78266757,78266757,Thanks for this immediate answer. Worked like a charm in our project.,"Aug 12, 2017 at 19:41",,,,45466609
77887179,77887179,Thank you. But how to use h2o.confusionMatrix ?? ? ?,"Aug 2, 2017 at 14:12",,,,45451086
77892803,77892803,"Please see the R documentation for the function:  
h2o.confusionMatrix(deep_model, newdata = deep_test)","Aug 2, 2017 at 16:14",,,,45451086
77859325,77859325,Thanks for the clarification. This makes sense now. I realize I could also do a shut down from H2OFLOW in a browser.,"Aug 1, 2017 at 23:22",,,,45448227
77816856,77816856,"Then, You mean that it has no problem, right??? Is it just a as.h2o function error? As a result, is there a no problem to use h2o.deeplearning function as this data???","Aug 1, 2017 at 1:59",,,,45427759
77817287,77817287,"That's right.  The print-out is wrong (it always says 10 rows even if there are more than 10 rows, which is why we filed a bug to fix that).  You can verify the data size yourself by running 
nrow(deep_credit)
 or 
dim(deep_credit)
.","Aug 1, 2017 at 2:31",,,,45427759
84091006,84091006,Thanks for this. Can't believe such simple functionality still doesn't exist in H2O.,"Jan 31, 2018 at 17:02",,,,45641157
87583245,87583245,"I think that using formulas in h2o.glm would make implementing the deta_constraints very complicated, because the constraints refer explicitly to the variables that are constrained. You can create a formula as @C8H10N4O2 suggests, and then create the design matrix X in R using X = model.matrix( ~ formula , data=mydata). Use X in the h2o.glm call.","May 11, 2018 at 0:46",,,,45641157
77745210,77745210,"I think the memory issue is with the java server, which keeps as many copies of the dataset as CV iterations. So 
gc()
 won't help. What I ended up doing is call h2o.removeAll() in the outer loop.","Jul 29, 2017 at 17:48",,,,45388619
77755751,77755751,"@horaceT Yes, it is h2o (the java server) holding the memory. But it won't release it while it thinks a client is using it, apparently even when re-using a model id, which is why you do the explicit 
gc()
 on the R client.   
h2o.removeAll()
 is even better when you have that option; I will edit my answer to mention that.","Jul 30, 2017 at 7:50",,,,45388619
77768124,77768124,"My experience has been 
gc()
 doesn't do much to help R's memory issue. It's a pity that while R has gained so much popularity in recent yrs, its core weaknesses have never been addressed. Or maybe it's just me grumbling....","Jul 30, 2017 at 19:41",,,,45388619
77677880,77677880,"Thank you Patrik!. My bad, it's an obvious one.","Jul 27, 2017 at 18:15",,,,45358061
77682662,77682662,"happy to help, fyi, if it solved the problem you should accept the answer so the question is marked as completed","Jul 27, 2017 at 20:45",,,,45358061
77699346,77699346,"Yes, I did all. But I have not seen the cluster start with multi node :(","Jul 28, 2017 at 9:09",,,,45340194
77699397,77699397,Do not vote -1 my question. I tried all your step before but multi node cluster still not started.,"Jul 28, 2017 at 9:11",,,,45340194
77752629,77752629,"is it possible, that you have firewall, which is blocking TCP connection on ports 54321 and 54322? regarding -1 vote - i think this is good question, no point to down vote it.","Jul 30, 2017 at 2:54",,,,45340194
77774721,77774721,"I test it in private network, so fire wall was disabled. (I'm sure because when I install HDP, disabled fire wall is required)","Jul 31, 2017 at 3:41",,,,45340194
77873281,77873281,do you have any suggestion?,"Aug 2, 2017 at 9:11",,,,45340194
77680062,77680062,"Can you provide a little more detail on the (dis)advantages of each method? I've been using the binary model, save/load back work just fine. But as part of a production pipeline which I'd run daily, which approach is better? Thanks for the response. Quite helpful.","Jul 27, 2017 at 19:19",,,,45341697
77683828,77683828,"If the binary method is working fine for you, then you could stick with that method.  The disadvantage is that you have to always be running an H2O cluster and that the binary models are tied to specific versions of H2O.  The 
h2o.predict_json()
 method is more of a convenience wrapper for the standard pure Java MOJO/POJO method.  In that case, you don't need to be running an H2O cluster and you can compile the models into your bigger Java project.","Jul 27, 2017 at 21:25",,,,45341697
77683834,77683834,"The speed is faster for MOJO/POJO because you don't have to convert your test frame (usually a 1-row data.frame) into an H2OFrame before you can make predictions; you can pass the values directly as JSON.  Unless you are dealing with sub-millisecond speeds (and that speed-up matters to you), then there's no need to switch over to MOJO/POJO if you are already happy with binary models.","Jul 27, 2017 at 21:25",,,,45341697
77644659,77644659,One more question : how about the POJO model ?,"Jul 27, 2017 at 4:44",,,,45337642
83256705,83256705,"@horaceT yes, the 
download_mojo
 function saves a 
java
 file, which doesn't depend at all on 
R
. To run this file, the compilation then must be done in 
java","Jan 7, 2018 at 17:10",,,,45337642
77638921,77638921,Thanks for your excellent comments Darren.  I will up the leave the memory size off and see what happens.,"Jul 26, 2017 at 22:25",,,,45338148
77685731,77685731,"This is a bug in the print-out only.  Look at 
nrow(h2o_train)
 to validate the size.  I filed a bug report here: 
0xdata.atlassian.net/browse/PUBDEV-4742","Jul 27, 2017 at 22:54",,,,45323560
77408554,77408554,"Thanks Tom.Yes, I have been through these docs. And saw that there is so much similarity between h2o's python APIs and scikit learn. Also there is similarity between h2o data munging and pandas data wrangling. So I was looking for a side-by-side comparison of syntax, or a h2o data munging and ML cheatsheet.","Jul 20, 2017 at 17:10",,,,45220499
3151554,3151554,"Would it be correct to summarise your answer as follows:  ""It's just like an 'Out of Java Heap space' error.  Give it more memory with -Xmx.""  ?","Jun 19, 2010 at 13:28",,,,1393503
3156128,3156128,"@Tim: No, that wouldn't be correct. While giving it more memory 
could
 reduce the problem, you should also look at your code and see why it produces that amount of garbage and why your code skims just below the ""out of memory"" mark. It's often a sign of broken code.","Jun 20, 2010 at 15:48",,,,1393503
4676701,4676701,"Thanks, it seems Oracle isn't actually that good in data migration, they broke the link.","Nov 29, 2010 at 19:30",,,,1393503
12051521,12051521,"@Guus: if multiple applications run in the same JVM, then yes, they can easily influence each other. It'll be hard to tell which one is misbehaving. Separating the applications into distinct JVMs might be the easiest solution.","Mar 1, 2012 at 11:48",,,,1393503
58703454,58703454,"I'd just had this happen to me with Java 7 and a web application containing 2001670 lines of Java code, of which I wrote about 5. ""You should also look at your code"" is not so easy in such cases.","Feb 19, 2016 at 13:18",,,,1393503
1234625,1234625,"""You can turn this off..."" but the OP most likely should not do this.","Sep 8, 2009 at 12:57",,,,1393522
2875372,2875372,"Can you tell me the difference between ""-XX"" and ""-Xmx""?  I was able to turn it off using the ""-Xmx"" option too.","May 14, 2010 at 12:37",,,,1393522
5639590,5639590,"Replying to a very old comment here, but... @Bart The 
-XX:
 at the start of several command line options is a flag of sorts indicating that this option is highly VM-specific and unstable (subject to change without notice in future versions).  In any case, the 
-XX:-UseGCOverheadLimit
 flag tells the VM to disable GC overhead limit checking (actually ""turns it off""), whereas your 
-Xmx
 command merely increased the heap.  In the latter case the GC overhead checking was still 
running
, it just sounds like a bigger heap solved the GC thrashing issues 
in your case
 (this will not always help).","Feb 18, 2011 at 10:51",,,,1393522
59440299,59440299,In my application (reading a large Excel file in Talend) this did not work and from other users explanation I understand why.  This just disables the error but the problem persists and your application will just spend most of its time handling GC.  Our server had plenty of RAM so I used the suggestions by Vitalii to increase the heap size.,"Mar 9, 2016 at 10:59",,,,1393522
132403639,132403639,"My jenkins slave is using :  
java -Xmx50G -jar slave.jar
   still facing the issue. Any help here?","Jan 6, 2023 at 9:54",,,,1393522
77292041,77292041,"I disagree with the third advice. Reuse existing objects do not save memory (do not leak old objects save memory :-) Moreover ""reuse existing object"" was a practice to relieve GC pressure. But it's NOT ALWAYS a good idea: with modern GC, we should avoid situations where old objects hold new ones because it can break some locality assumptions...","Jul 18, 2017 at 8:52",,,,8498644
104033792,104033792,"@mcoolive:  For a somewhat contrived example, see the comments to answer 
stackoverflow.com/a/5640498/4178262
 below; creating the 
List
 object inside the loop caused GC to be called 39 times instead of 22 times.","Nov 15, 2019 at 19:12",,,,8498644
136562800,136562800,It's funny to call 1GB heap limit as a increase. Requirement was quite different previous decade.,"Nov 10, 2023 at 20:27",,,,8498644
12830193,12830193,"Please clarify: When you say ""Triggered n times"", does that mean that a regular GC happened n times, or that the ""GC overhead limit exceeded"" error reported by the OP happened n times?","Apr 5, 2012 at 15:15",,,,5640498
103962574,103962574,"I tested just now using java 1.8.0_91 and never got an error/exception, and the ""Triggered n times"" was from counting up the number of lines in the 
gc.log
 file.  My tests show much fewer times overall, but fewest ""Triggers"" times  for BETTER, and now, BAD is ""badder"" than WORST now. My counts:  BAD: 26, WORSE: 22, BETTER 21.","Nov 13, 2019 at 19:41",,,,5640498
103962812,103962812,"I just added a ""WORST_YET"" modification where I define the 
List<Double> list
 in the 
outer loop
 instead of 
before
 the outer loop, and Triggered 39 garbage collections.","Nov 13, 2019 at 19:50",,,,5640498
42824886,42824886,"The android apps dont have 
arguments
 tab...what should we do to achieve this?","Nov 27, 2014 at 8:50",,,,23628984
65623049,65623049,What tool is that answer for? That was not an Eclipse question.,"Aug 25, 2016 at 7:38",,,,23628984
70668170,70668170,"There is no ""minimum limit"". -Xms is the initial size.","Jan 19, 2017 at 8:51",,,,23628984
75979481,75979481,What is the max of maximum limit that could be set??,"Jun 12, 2017 at 6:50",,,,23628984
115075136,115075136,"@JPerk the max is as much as the physical memory of your machine. However, other applications will compete over memory use if you try that.","Dec 1, 2020 at 13:16",,,,23628984
72085012,72085012,Works great for the simulator. Any idea how this affects real devices? i.e. is this a good idea or is it just masking the issue? Thanks.,"Feb 26, 2017 at 18:16",,,,40771497
46839458,46839458,the most simple way to fix this problem. Thanks :),"Mar 29, 2015 at 0:40",,,,27716421
47905609,47905609,eclipse.ini file in jdev?,"Apr 27, 2015 at 8:48",,,,27716421
61003430,61003430,problems  unsolved even when the configuration has been changed to this.,"Apr 19, 2016 at 3:20",,,,27716421
65623067,65623067,The OP did not ask an Eclipse question.,"Aug 25, 2016 at 7:39",,,,27716421
76988159,76988159,"This ""answer"" does not answer the question above.","Jul 10, 2017 at 8:39",,,,27716421
72814902,72814902,"Yes, when using Gradle :)","Mar 17, 2017 at 9:52",,,,41344611
93563576,93563576,"How could you even think this is a solution to his question 
in general
? You set your heap size to 4g which is totally arbitrary in a gradle configuration for Android 
facepalm
.","Nov 16, 2018 at 17:02",,,,41344611
61796913,61796913,These settings are only specific to your local IDE. This will no work for Prod environment.,"May 10, 2016 at 2:24",,,,36594743
77380811,77380811,"This link for ""fold_assignment"" is slightly better (it never goes stale): 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…","Jul 20, 2017 at 6:55",,,,45206165
128519436,128519436,"Is anyone here able able to demonstrate how i can generate the XNew. I am having the same challenge, and not smart enough to get the product of Anew * Inverse(Y). I'm trying to cluster new datasets on the arch features from trained GLRM. 
stackoverflow.com/questions/72753783/…","Jun 26, 2022 at 11:42",,,,45258659
77354559,77354559,"Note this benchmark is about four years old and out of date, even though the date on the post strangely says 2017.  (Look at the 2015 date on the comment at the bottom.)  Also note the author, Erin, is now at H2O (full disclosure: I am too).","Jul 19, 2017 at 14:31",,,,45192532
77354759,77354759,"Well, at least this article can be a beginning. And I agree, that H2O could be better.","Jul 19, 2017 at 14:35",,,,45192532
77357305,77357305,"As the author of the wise.io benchmarking article, yes, it's very out of date.  The 
randomForest
 R code has changed very little since then, but both the H2O and sklearn RF implementations have improved a great deal in the past 4 years.","Jul 19, 2017 at 15:27",,,,45192532
77357482,77357482,"@AndreyLukyanenko If you have specific suggestions on how the H2O RF implementation can be better, please send your ideas to our mailing list (or even better, make a pull request): 
groups.google.com/forum/#!forum/h2ostream","Jul 19, 2017 at 15:31",,,,45192532
77357616,77357616,"@Erin LeDell I meant that I think that H2O is better that RF implementation (could in this case = not sure, but think so). Sorry for misunderstanding.","Jul 19, 2017 at 15:34",,,,45192532
77282243,77282243,col_used.col_names  is the final step I was looking for.  Thanks! h2o.init doesn't tell me the version the model was built with.  That's what I was looking for.,"Jul 18, 2017 at 3:01",,,,45154577
103364098,103364098,"After loading my trained model and using the code above, I'm getting ""TypeError: 'property' object has no attribute '
getitem
'""","Oct 23, 2019 at 8:59",,,,45154577
103412079,103412079,"hi @Ege can you create a separate stackoverflow question with reproducible code, that will make it easier for folks to debug your issue. thanks!","Oct 24, 2019 at 16:23",,,,45154577
120188912,120188912,"Accessing 
training_frame
 won't work if it was removed after training, if the h2o instance was restarted, or the model has been archived and re-imported (stored on disk, in a code repo, data lake connected to MLflow, etc).","Jun 16, 2021 at 9:28",,,,45154577
77323358,77323358,"Ok Erin, thanks beat me to this by a few seconds.  I updated the above with an example using the cover type dataset.  Thanks!","Jul 18, 2017 at 21:27",,,,45177389
77269954,77269954,"I tried that to no avail...  Error: Found version 3.13.0.337, but running version 3.13.0.341","Jul 17, 2017 at 17:40",,,,45147752
77271896,77271896,"Please post the code you used to start up the H2O cluster.  
strict_version_check = False
 should work.","Jul 17, 2017 at 18:42",,,,45147752
77303161,77303161,Thanks a lot. It helps.,"Jul 18, 2017 at 13:05",,,,45143490
79450962,79450962,"This is the same link, but release agnostic:  
docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html","Sep 15, 2017 at 16:00",,,,45143490
77162848,77162848,"In h2o Flow, I'm assuming that the MOJO the the thing that is referred to as the ""Model Deployment Package."" Is this correct?","Jul 14, 2017 at 5:27",,,,45094438
77814457,77814457,"@reedv Yes, and we will update the text on the button to make that more clear.","Jul 31, 2017 at 23:06",,,,45094438
77163086,77163086,"I am currently using the 
.setConvertUnknownCategoricalLevelsToNa(true)
 configuration in my EasyPredictionWrapper to simply ignore the unknown catagories as you suggested, but I would like to further know how to get the model to recognize the two different sample features p1 and p2 as being the conceptually the same (eg. so that I don't need to train the model with a sample that has (p1=a, p2=b) if it has already trained on a sample that has (p1=b, p2=a)).","Jul 14, 2017 at 5:38",,,,45094060
77187743,77187743,"You should probably break this up into two Questions (they are not really related).  Most of the algos are capable of ignoring redundant features, so it shouldn't matter (if you are using a GLM, make sure to use some regularization).  If you want to do something more complicated, that will require you to write custom code to filter ""conceptually duplicate"" samples out of your training set.","Jul 14, 2017 at 17:02",,,,45094060
77149661,77149661,"Passing in ""numeric"" instead of ""real"" will not fix the problem.  If you pass in ""numeric"" in a column that can be converted to integers like [9,3,99.0], then 
frame.types
 will still show ""int"" as the type.","Jul 13, 2017 at 18:38",,,,45088244
77108966,77108966,I will give it a try. Thanks!,"Jul 12, 2017 at 21:30",,,,45065438
80907226,80907226,"Note that the 
lime
 package has since been updated to integrate 
h2o
. You may need to download the GitHub version here: 
github.com/thomasp85/lime","Oct 27, 2017 at 16:50",,,,46264371
77062906,77062906,"Thanks! This works, however only for non parallelized estimation. Do you happend to know a way to use a seed when using multiple threads?","Jul 11, 2017 at 20:52",,,,45040052
77066714,77066714,Not sure what you mean. Does h2o have a separate seed for parallel estimates?,"Jul 12, 2017 at 0:04",,,,45040052
77075673,77075673,"I don't know, but I was hoping it would. Since I couldn't fine one I thought I just ask.","Jul 12, 2017 at 7:28",,,,45040052
77101682,77101682,AFAIK the seed should work in all cases. Otherwise it's probably an h2o bug?,"Jul 12, 2017 at 17:37",,,,45040052
77104033,77104033,"Well, in the example I've tested it worked with h2o.init(nthreads=1), but not with h2o.init(nthreads=2). I also read that there is a seed (set.seed(123, ""L'Ecuyer"")) that works with parallelization in mlr (when there is no h2o involved), but not for windows systems. Maybe the same underlying problem applies here? (found it here: 
github.com/mlr-org/mlr/issues/938
)","Jul 12, 2017 at 18:45",,,,45040052
77042804,77042804,"Thanks for your update. I was able to use the GPU-enabled version about two weeks, so I am assuming it was removed? Also, any estimate when the GPU enabled version will be available on Nimbix?","Jul 11, 2017 at 12:30",,,,45024919
77043327,77043327,"H2O.ai and Nimbix Bring Next-Gen GPU-Powered AI to Cloud: 
h2o.ai/h2o-ai-and-nimbix-bring-next-gen-gpu-powered-ai-to-cloud","Jul 11, 2017 at 12:40",,,,45024919
77060890,77060890,"You can use the Deep Water version for now which has GPU support. We will release a new GPU-enabled version right after next stable release of h2o-3 (~July 22, 2017).","Jul 11, 2017 at 19:47",,,,45024919
77029301,77029301,Is it possible to also use the temp object to make a prediction using only one of the learners from the stack or do I have to  train the single learners again separately?,"Jul 11, 2017 at 7:08",,,,45024759
77030510,77030510,"If I use the same method twice (base = c(""regr.rpart"", ""regr.rpart"")) it throws an error:  Error in makeBaseEnsemble(id = ""stack"", base.learners = base.learners,  :    Base learners must all have unique ids! How can I do that?","Jul 11, 2017 at 7:38",,,,45024759
77042856,77042856,"If you want to use the same method more than once you can use a bagging method.  
mlr-org.github.io/mlr-tutorial/release/html/bagging/index.html","Jul 11, 2017 at 12:31",,,,45024759
77048702,77048702,Solved the id problem: I have to set the id in the learners manually. So if I don't want do use a subset of the data for each identical learner is it still better to use bagging?,"Jul 11, 2017 at 14:28",,,,45024759
77049657,77049657,If you want to use the same learner multiple times I would look at bagging. If you then want to also use other learners you can use the bagged learner within the stacked learner,"Jul 11, 2017 at 14:47",,,,45024759
77032079,77032079,Unfortunately this gives me an error (Installation failed: Timeout was reached). Is there another way to install the Github version?,"Jul 11, 2017 at 8:23",,,,45021207
77054179,77054179,"You can also clone the repository and do 
R CMD INSTALL .
 in it.","Jul 11, 2017 at 16:31",,,,45021207
76947124,76947124,"I can confirm this bug also exists in R (both h2o 3.10.3.3 and 3.12.0.1) and that it does not seem to be GLM specific, but rather something to do with explicit one hot encoding - see the question I linked to in the comments.","Jul 8, 2017 at 13:04",,,,44977136
80389062,80389062,"When I run 
flow
 on my local machine, exporting models and .hex files results in those things being downloaded into the directory I launched the h2o.jar file from. But the same does not happen when running 
flow
 from the hadoop node I am remoting into. From you answer, it seems like it should be downloaded to 
h2o-3.14.0.6-mapr5.2
 on the node I am ssh-ed into (I'm not very familiar with hadoop terms, as I only want to use it for running 
flow
 in my case), but I am not seeing this.","Oct 13, 2017 at 1:30",,,,44972691
80699444,80699444,"If you use an hdfs path (which is recommended) then the model will be saved to hdfs and can be retrieved from anywhere that can see hdfs.  If you don't use an hdfs path, then the path is local to the host where Flow is connected to (the IP address in your browser).  You may or may not be able to login to that host.  This is probably not the same host where you ssh'd to start h2o.","Oct 22, 2017 at 16:11",,,,44972691
82292266,82292266,"Adding note to self and others that may also be in similar situation as I was when posted this question (ie. no experience with 
h2o
 or 
hadoop
): Access to the hdfs would be done with something like 
$hadoop fs <command to retrive files>
 or by mounting a nsf gateway for hadoop on local file system.","Dec 6, 2017 at 4:02",,,,44972691
76986032,76986032,"Hi, thank you very much. I also get the correct result on all but on one machine I ran the code on. The error seems to be hardware or version specific. I thought, that maybe somebody has a suspicion regarding the cause of that issue.","Jul 10, 2017 at 7:38",,,,44972989
76979951,76979951,"I'm still getting ""tuple index out of range"" error.  (This error message is also unhelpful...)","Jul 10, 2017 at 2:27",,,,45002118
77007471,77007471,"It looks like it's working in Python 2.7 and 3.5 but not 3.6.  I have filed a bug report here: 
0xdata.atlassian.net/browse/PUBDEV-4672","Jul 10, 2017 at 16:07",,,,45002118
76745370,76745370,So you are suggesting I do it manually ? there is no way to specify an argument is the python command itself ?,"Jul 3, 2017 at 10:49",,,,44883603
76745447,76745447,I think you can open current file in python and do simple replace,"Jul 3, 2017 at 10:52",,,,44883603
76745675,76745675,"You can open 
.java
 file in any text editor, so you can try it.","Jul 3, 2017 at 10:58",,,,44883603
76747952,76747952,"Interestingly, I do not notice error increase with an increase in epochs.","Jul 3, 2017 at 11:57",,,,44878270
76749333,76749333,@Borealis This is not necessarily the case. But usually.,"Jul 3, 2017 at 12:33",,,,44878270
103419616,103419616,"I get the same error today - on Window 10 Desktop: 
github.com/dmlc/xgboost/issues/4983","Oct 24, 2019 at 21:25",,,,45718739
76746962,76746962,Yes but I have 120 trees and 40 features.... impossible I need something more industrial,"Jul 3, 2017 at 11:31",,,,44852474
76641653,76641653,"Hi Dr. LeDell. Thanks so much. I am on H2O 3.10. The error message is thrown for any custom learner, even just a single GLM or randomForest. I can show some reproducible code. Shall I close this as answered (as to which versions are compatible) and continue troubleshooting the problem in a separate question, or handle both here?","Jun 29, 2017 at 16:35",,,,44830368
76730994,76730994,"An update: I tried upgrading to 3.12 and 3.13, but encountered the same error.","Jul 3, 2017 at 0:17",,,,44830368
76829412,76829412,"I see that you've updated your question to include that you were using 3.10.0.2, which is actually compatible with h2oEnsemble 0.1.8, not 0.1.9.  For now, you can use 3.10.5.2 or the latest stable, 3.10.5.3.  I have verified above that that version 3.10.5.2 is compatible (and .3 also works). 
h2o-release.s3.amazonaws.com/h2o/rel-vajda/3/index.html","Jul 5, 2017 at 12:58",,,,44830368
76840814,76840814,"Great, thank you, I will try that presently. Yea, I left a comment above about my version then came back later and made a corresponding edit. Got your update. I will try those versions today and report back. Thanks again for your help; much appreciated.","Jul 5, 2017 at 17:25",,,,44830368
77286250,77286250,"h2oEnsemble
 0.1.9 is now released, this should fix all your issues.  It's not merged into master yet: 
github.com/h2oai/h2o-3/pull/1376
  but the source is here: 
s3.amazonaws.com/h2o-release/h2o-ensemble/R/…","Jul 18, 2017 at 6:22",,,,44830368
76854961,76854961,"Sorry, I'm not trying to change the column name, but the actual values within the columns.   If they value in row 1 of the column used to be 23 then I would want it to be 'please-help-me----23'   where I provide that text in front.","Jul 6, 2017 at 3:39",,,,44791593
76855579,76855579,"It looks like this is somewhat related?  
0xdata.atlassian.net/browse/PUBDEV-3729
   When I use   df[ 'mpg'] = df['mpg'].ascharacter()   I receive an error.","Jul 6, 2017 at 4:20",,,,44791593
76882411,76882411,"@jack updated the answer, hope this is what you are looking for","Jul 6, 2017 at 15:49",,,,44791593
76727206,76727206,check out sparsio package for fast svmlight reader and writer. I put it on cran last week.,"Jul 2, 2017 at 19:24",,,,44754423
76770008,76770008,thanks @Dmitriy Selivanov. I have been trying to install laura2/sparsity package to no avail. I'll try using sparsio.,"Jul 4, 2017 at 2:26",,,,44754423
76770081,76770081,"sparsio doesn't convert dgCMatrix type, does it?","Jul 4, 2017 at 2:32",,,,44754423
76770490,76770490,"So, i used the sparsio package to convert my dgCMatrix type sparse matrix to SVMlight but i get error importing it to h2o. I get this error: ""error = 'Columns come in non-increasing sequence. Got 0 after 1. Rest of the line is skipped.'","Jul 4, 2017 at 3:04",,,,44754423
76770736,76770736,I think h2o by default accepts one_based SVMlight files. So i changed the file to one based and it worked. Thanks again for your time and help! all good.,"Jul 4, 2017 at 3:25",,,,44754423
76579941,76579941,If you load a UTF-8 file in any editor or viewer capable of UTF-8 you will just see the text you expect. What you have shown is the way you could encode unicode in an html page if you cannot type the characters.,"Jun 28, 2017 at 10:32",,,,44770720
76562661,76562661,"Also found out that when I passed four values (c(0,0.05,0.1,0.2) to the 'input_dropout_ratio' during grid search, that caused the ensemble function to fail. But when I passed c(0,0.05) and c(0.1,0.2) on two separate runs, then the ensemble function worked on both occasions.","Jun 27, 2017 at 22:28",,,,44771881
110141844,110141844,"@Erin  Your answer here is really helpful.  I was using Pythron and had passed something like df_all[idx_train, :] to each level_0 learner as well as the ensemble.  And I was getting exactly the same error.  Just defining df_train = df_all[idx_train, :] upfront, fixed it.  Thanks!!","Jun 9, 2020 at 7:15",,,,44771881
76563772,76563772,Thank you for answering. Running locally slashed run time by 5 times. Is there any h2o guidelines for using hadoop vs local machine.,"Jun 27, 2017 at 23:32",,,,44772507
76602508,76602508,"If you can run it on a single machine, it will be faster, so use a single machine.  Rule of thumb is that you need 3x amount of RAM as the size of your data.","Jun 28, 2017 at 19:29",,,,44772507
76465135,76465135,"thank you for responding. I looked at water meter, most of CPUs are idle with an occasional spike in work load. I understand from your comments that speed of h2o purely depends on infrastructure. Is it a fair statement? Is there any way to decide best number nodes for a given problem? Please let me know.","Jun 24, 2017 at 23:56",,,,44740478
76479448,76479448,"I would say the speed of H2O depends on infrastructure, but certainly not purely.  To determine the best number of nodes for a given problem, you have to experiment with the problem.  What I would say in general is, when you are first experimenting with a new problem, start with a smaller number of bigger memory nodes; fewer things can go wrong that way.","Jun 25, 2017 at 18:14",,,,44740478
76479485,76479485,"I would also say that if the CPUs aren't busy, then you need to tweak a parameter in your experiment.  Start by reducing the number of nodes.  CPUs not being busy for RF is a red flag.","Jun 25, 2017 at 18:16",,,,44740478
76595340,76595340,"I replied to your questions in the body of my original question, under the section 
UPDATE 2: 28Jun2017 in response to comments by @Michal Kurka.
  Thank you for looking into this.  We are unable to continue with this project until we can get this problem resolved.","Jun 28, 2017 at 16:08",,,,44781879
76645811,76645811,Thank you for adding this information. We didn't observe similar behavior with other users. Would you be able to share an anonymized version of the dataset with H2O so that we can reproduce it?,"Jun 29, 2017 at 18:35",,,,44781879
76688616,76688616,Thanks for your reply @Michal Kurka.  Would you mind speaking to Josephine Wang?  She and I have spoken in the past.  It would probably be more informative to speak with her vs what I could type.  Please feel free to contact me via voice if you prefer.  Thanks.,"Jun 30, 2017 at 19:48",,,,44781879
76836145,76836145,"Sure, no problem","Jul 5, 2017 at 15:21",,,,44781879
77313191,77313191,A thought: perhaps the large increase in model size (169M vs 37G) is related to the number of distinct values in categorical data?,"Jul 18, 2017 at 16:39",,,,44781879
76530707,76530707,"Thanks for you comment, did not know that was possible. Will look into it.","Jun 27, 2017 at 8:03",,,,44737237
76465311,76465311,"If I start h2o on the command line, will the output in tempdir() remain after exiting/shutdown?","Jun 25, 2017 at 0:16",,,,44729936
76479342,76479342,"If you start h2o on the command line the output isn't stored in tempdir() at all.  Yes, it will remain after exiting/shutdown.","Jun 25, 2017 at 18:08",,,,44729936
76501493,76501493,Thank you for the clarification.,"Jun 26, 2017 at 13:04",,,,44729936
76434597,76434597,"I runned the command on the jar and found those files: 
com/hw/h20try$.class
,  
com/hw/h20try.class
,  
src/main/scala/com/hw/h20try.scala
  but still got the 
ClassNotFoundException","Jun 23, 2017 at 16:29",,,,44725654
79060767,79060767,Is there a Windows solution for this?,"Sep 5, 2017 at 8:47",,,,44727088
79082429,79082429,"We have only built Deep Water for Ubuntu Linux. We do provide Docker images that run in Windows. That would be the easy solution unless you want to built it yourself for Windows. See here: 
github.com/h2oai/deepwater#pre-release-docker-image","Sep 5, 2017 at 18:15",,,,44727088
76423723,76423723,"hi, I still get the same error ` Error in is.H2OFrame(x) : object 'Speed' not found` .  . It is not taking the H2Oframe and its values.","Jun 23, 2017 at 11:55",,,,44720354
76435077,76435077,"The 
y
 argument takes a column name, so you must use 
y = ""Speed""
 instead.  Also, you may find an H2O R tutorial useful if you are just starting out with H2O: 
github.com/h2oai/h2o-tutorials/blob/master/h2o-open-tour-2016/…","Jun 23, 2017 at 16:45",,,,44720354
77472663,77472663,"I tried to run Grid Search for XGBoostEstimator in python but it does not seem to work even though the same code works for GBM and RFs. 
h2o.exceptions.H2OResponseError: Server error water.exceptions.H2ONotFoundArgumentException:   Error: POST /99/Grid/None not found   Request: POST /99/Grid/None     data: {u'response_column': 'xxx', 'nfolds': '2', u'hyper_parameters': ""{'ntrees': [50, 100], 'max_depth': [3, 10]}"", u'training_frame': 'py_yyy'}","Jul 22, 2017 at 12:06",,,,44726226
77485602,77485602,"@user90772 Thanks for the report.  This is a known bug, documented here: 
0xdata.atlassian.net/browse/PUBDEV-4704?filter=21100","Jul 23, 2017 at 2:50",,,,44726226
77494430,77494430,"Thank you, is this a bug only for Python or it is not supported in any language?","Jul 23, 2017 at 13:46",,,,44726226
77533912,77533912,"@user90772 Yes, it is working in R.  I made a demo here: 
gist.github.com/ledell/71e0b8861d4fa35b59dde2af282815a5","Jul 24, 2017 at 16:41",,,,44726226
77549478,77549478,"@user90772 XGBoost grid search in Python is now fixed on master: 
0xdata.atlassian.net/browse/PUBDEV-4704
  To get the changes, git clone the h2o-3 repo and build from master; or wait a day for it to be in the nightly release: 
h2o-release.s3.amazonaws.com/h2o/master/latest.html","Jul 25, 2017 at 4:24",,,,44726226
76306666,76306666,"Yep, you can use 
%in%
 or 
h2o.match()
: 
rdocumentation.org/packages/h2o/versions/3.10.4.6/topics/…","Jun 20, 2017 at 18:36",,,,44660576
76307522,76307522,"It's probably cleaner to use 
==
 instead of the 
%in%
 since that is more common in base R, so I updated the answer.","Jun 20, 2017 at 18:59",,,,44660576
97407521,97407521,"@ErinLeDell - is it possible to pass the tissue name into 
model_id
 ? I'm trying to find a way to make sense of all the model names.","Mar 25, 2019 at 15:29",,,,44660576
97448945,97448945,"@RyanJohn Yes, you would have to set the 
model_id
 parameter in the 
h2o.glm()
 function, which means in the code above you would have to reformulate the 
sapply()
 function and the anonymous function it applies to.  The 
h2o.saveModel()
 function will use the name of the model id (you can't change it here, it must be set at train time).","Mar 26, 2019 at 16:57",,,,44660576
100333295,100333295,type object 'H2ORegressionModelMetrics' has no attribute '_get_metrics',"Jul 4, 2019 at 19:34",,,,44669089
104922585,104922585,"try this 
_metric_json","Dec 16, 2019 at 21:18",,,,44669089
76322187,76322187,I dont want to fire another API request to the JVM runner just to get the detail data for the model performance that i already make. I found the answer anyway,"Jun 21, 2017 at 6:52",,,,44641075
76237460,76237460,"rds is probably compressed, so your csv file might be 10GB. However H2O will read *.csv.gz files, so you can then recompress your file. I recommend going this route, rather than using 
as.h2o()
 with large data.  (E.g. if you ""only"" have 16GB, then running R and H2O at the same time, and giving them both enough memory for a 10GB data set isn't going to work.)","Jun 19, 2017 at 8:44",,,,44620211
83554319,83554319,I think this only works for Python 2.7 and not Python 3.6,"Jan 16, 2018 at 15:51",,,,44589032
101545174,101545174,"Please note that 
h2o-py
 is not an official h2o.ai package and is not recommended. Use 
conda install -c h2oai h2o
 to get the official python package. Source: 
h2o-release.s3.amazonaws.com/h2o/latest_stable.html","Aug 17, 2019 at 22:56",,,,44589032
82918830,82918830,"Yes it did work fine on my machine (Windows 10) , Anaconda3-5.0.1, h2o cluster version: 3.16.0.2 . But this did not work:  conda install -c anaconda h2o .","Dec 26, 2017 at 6:37",,,,47178181
76113994,76113994,"Gee, i didn't realise! That makes sense now. Thanks for the clarification.","Jun 15, 2017 at 8:31",,,,44559442
76112977,76112977,"Or (if you really need a 20,000 class output) give up on GBM and switch to deep learning: I think in this case it will be both quicker and better.  (But, I would first spend a lot of effort on seeing if those 20,000 can be reduced, using domain knowledge, e.g. to nearer 50 or 100.)","Jun 15, 2017 at 8:05",,,,44558607
76114141,76114141,"I agree that it's never a good idea to train a classifier with 20,000. I had even already reduced it from 50,000 levels. :-o I'm using clusters as well. I'll try to change the way data is organised before I dive into the deep learning business. Thanks all for your help.","Jun 15, 2017 at 8:35",,,,44558607
76150800,76150800,But where did you find something about word2vec in question? Text2vec != Word2vec. Question is about how to export sparse matrix to h2o! And the way to do it - convert matrix to svmlight format.,"Jun 16, 2017 at 5:18",,,,44560092
76226103,76226103,"The task Noobie asked about was the H2O-only equivalent of training a model on text -- I mean you can perform the same task (using Word2Vec) in H2O.  The solution above allows you to keep using text2vec, but it also requires performing the text-processing computation in R memory (rather than distributed H2O w2v), so I suggested H2O w2v as a work-around.","Jun 18, 2017 at 22:31",,,,44560092
76241061,76241061,"@erin-ledell still it is different. h2o allows to obtains vectors for words or for sentences (averaged word vectors). But example here was about bag-of-words model and large sparse matrix. BTW I took a look on how h2o coerces sparse matrix to the internal format (
github.com/h2oai/h2o-3/blob/master/h2o-r/h2o-package/R/…
) - it is nightmare. I will send PR.","Jun 19, 2017 at 10:12",,,,44560092
76258941,76258941,1) it is just wrong - silently and implicitly considers first column as target variable 2) will work very (very) long even for small data sets,"Jun 19, 2017 at 17:28",,,,44560092
76427282,76427282,"@noobie, for example use 
github.com/dselivanov/sparsio
 to write matrix as svmlight. Then you can read it with 
h2o.uploadFile
.","Jun 23, 2017 at 13:23",,,,44560092
76092859,76092859,"I was also plotting in the same chunk, so I just moved the plots to a new chunk and so this works perfectly!","Jun 14, 2017 at 17:30",,,,44551073
76100825,76100825,This is also great! I didn't know about this before.,"Jun 14, 2017 at 21:43",,,,44552300
100681539,100681539,"How  would you get rid of the remaining information printed? I.e., of ``` java version ""1.8.0_45"" Java(TM) SE Runtime Environment (build 1.8.0_45-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)  ```","Jul 17, 2019 at 15:19",,,,44552300
113815965,113815965,"I use this in an Rnw file and nothing were                                                                printed <<warning=FALSE, message=FALSE, echo=FALSE, results='hide',eval=TRUE>>= invisible(library(h2o)) suppressMessages(invisible(h2o.init())) @","Oct 15, 2020 at 4:43",,,,44552300
89752009,89752009,How to impute missing values(I dont see 'nan' in my DF) for only one column? Thanks.,"Jul 17, 2018 at 20:48",,,,44533746
76055051,76055051,"Hi, thanks for your response, based on the documentation, ""The alpha parameter controls the distribution between the ℓ1ℓ1 (LASSO) and ℓ2ℓ2 (ridge regression) penalties. A value of 1.0 for alpha represents LASSO, and an alpha value of 0.0 produces ridge regression."", I think I should  make alpha as 1? I also don't want to use cross validation and need to apply attribute selection once on whole training set. Can I specify the number of most important attributes which the lasso should return?How to get the selected attributes from GLM then?","Jun 13, 2017 at 21:17",,,,44530143
76058360,76058360,"You're right.  I meant 
alpha = 1.0
 is Lasso and I will update my answer.  You will have to play around with the 
lambda
 parameter to increase or decrease the amount of regularization applied (which will lead to a larger or smaller number of coefficients being set to 0 in the model).  You can also use 
max_active_predictors
 to put a limit on the number of ""active"" (non-zero-weighted) features in the model.","Jun 14, 2017 at 0:13",,,,44530143
76271039,76271039,Thank you for the recommendation. I am thinking about to go with a solution to hash the table in sqlite format and zip it in lambda package to reduce the latency as those tables is lookup table and it is pretty small.,"Jun 20, 2017 at 2:09",,,,44550936
76015518,76015518,Could you please brief it for the binomial one? I need R2 RMSE etc from the 'pred'   ((Frame pred = drf.score(testDataFrame); //Score the test)) Also I need to find the deviation of test frame from the model. Would you mind giving a code example as well?,"Jun 13, 2017 at 2:15",,,,44495063
76032343,76032343,"@RejoyMathew see edit, should work but didn't run it myself.","Jun 13, 2017 at 11:33",,,,44495063
76316561,76316561,Thanks a lot for providing the speedy response.,"Jun 21, 2017 at 1:58",,,,44495063
76316585,76316585,I have one more question: After the training and scoring of model how do i find the feature important variables (in JAVA)?,"Jun 21, 2017 at 2:00",,,,44495063
75869911,75869911,This clarifies things... I was not aware that DeepWater is NOT running on Spark!,"Jun 8, 2017 at 12:55",,,,44434557
75870335,75870335,"@KaiWähner to clarify - the tutorial above doesn't use DeepWater. Also deepwater can also run on Spark via SparklingWater but only if there's 1 worker, which is a pretty rare Spark usecase. We'd love to hear from the community if making a distributed version of DeepWater would be useful (we'd need actual use-cases and not only ""sure"" :-)).","Jun 8, 2017 at 13:04",,,,44434557
75824803,75824803,"Thanks for information about new version of image, but I still cannot use functions which don't exist in R package version (XGB training).","Jun 7, 2017 at 12:42",,,,44404138
75759222,75759222,My apologies.  Would those bits work for RHEL6 x64 or is it specific for Ubuntu only?,"Jun 5, 2017 at 23:29",,,,44379149
75759365,75759365,"We haven't tested it on RHEL6 but I'd say yes, it should work out of the box.","Jun 5, 2017 at 23:39",,,,44379149
75759409,75759409,"I am about to give it a spin.  I think need to install the parts which are 
above
 the example in the original post.   Do I need to do the 
install_tensorflow()
?","Jun 5, 2017 at 23:43",,,,44379149
75760537,75760537,"@ironv you don't need 
rstudio/tensorflow
 to run DeepWater, unless you want to create custom TF graphs first. We provide several networks out of the box (MLP, lenet, alexnet, restnet, vgg etc.).","Jun 6, 2017 at 1:13",,,,44379149
75784737,75784737,Thank you. I have spent more time on H2O documentation and figured out that both Python and R versions are available.,"Jun 6, 2017 at 14:19",,,,44379883
75807003,75807003,"If you found the answer to be correct, can you ""accept"" my answer? thx","Jun 7, 2017 at 5:04",,,,44379883
75765593,75765593,"Thanks for the intel, that does help. However, h2o tends to parse time incorrectly. For example, a CSV that has dates in the format dd-mm-yyyy hh:mm, the complier not only adds milliseconds, with the extra 1000 like you showed, it also gives an NaN for good chunk of the values.","Jun 6, 2017 at 6:23",,,,44371791
75760110,75760110,"Note: If your response column is encoded as 0/1 or any other two-valued numeric representaion, but you intended to do binary classification, then you need to convert the response column to a ""factor"" by using the 
as.factor()
 function.  Otherwise, H2O will perform regression and AUC won't be accessible as a performance metric.","Jun 6, 2017 at 0:32",,,,44379108
75760849,75760849,"It's interesting that I used this exact script about two months ago, and it work o.k.","Jun 6, 2017 at 1:38",,,,44379108
75794865,75794865,"What I object to is that you guys change the API, but you do not change the hundreds of web pages that still show a use of the old API. Even your own documentation is in error.","Jun 6, 2017 at 18:43",,,,44379108
75807158,75807158,@CBrauer could you link to the pages/docs that have incorrect examples?,"Jun 7, 2017 at 5:12",,,,44379108
75836142,75836142,You are asking me to do your work for you.  My fee is $100.00/web-page that is in error. Are you willing to hire me for this job?,"Jun 7, 2017 at 17:02",,,,44379108
75726657,75726657,"Thanks! I tested that and it works. I was looking for a .egg file in the directories which no longer exists in more recent versions i guess. The --package works also, my problem was I had installed pysparkling on that cluster which isn't associated with h2o is some random other package. A bootstrap with pip install h2o_pysparkling_2.1 works as well with the --package arg.","Jun 5, 2017 at 6:00",,,,44361167
97499422,97499422,I don't see h2o_pysparkling file in the download link. How do I get this file,"Mar 28, 2019 at 1:27",,,,44361167
100187828,100187828,@Naveenan It's inside the main download. If you open it you can find it inside py/build/dist/,"Jun 29, 2019 at 11:40",,,,44361167
75695593,75695593,"Assuming 
model.dl
 is a pointer to your deep learning model, you can do 
model.dl@model$weights
 and 
model.dl@model$biases
 to extract a list containing information about the weights and biases respectively. Then, loop through the list to extract the 
name
 attribute of the list (which returns the frame id)  and use 
h2o.getFrame()
 to return the frame itself.","Jun 3, 2017 at 17:02",,,,44345073
75696298,75696298,"Thank you Mauna +1. Your solution works if I set export_weights_and_biases=TRUE which I did not do in my original model. Hence my attempt to checkpoint my model so I can set it = TRUE. However b/c I did not use Modulo CV, I'm unable to checkpoint.","Jun 3, 2017 at 17:40",,,,44345073
75696329,75696329,Any suggestion to extract weights and biases from a model in which the model's export_weights_and_biases argument was not set to TRUE?,"Jun 3, 2017 at 17:41",,,,44345073
75696935,75696935,"I can't think of any way other than re-training the model. Here's the idea: Use 
h2o.loadModel()
 to load the model into 
model.dl
. Then you can use 
model.dl@parameters
 to get a list of the current parameters set and add set export_weights_and_biases to TRUE. Finally, use 
do.call()
 on 
h2o.deeplearning()
 and the updated list of parameters to retrain the model.","Jun 3, 2017 at 18:15",,,,44345073
75699701,75699701,"Thank you. I will give this a shot. While I have not tried do.call, I have tried to retrain new models with all the parameters, seed, and the dataset exactly as in the original model - but I'm unable to get h2o to reproduce a model with the same generalizability of the original model. In fact, all the retrained models have 100% failed miserably to generalize well - yet all models train, validate and test well. I think I was just lucky with my original model - and I really need to extract the weights and biases somehow. I've read it might be possible to do with POJO but I'm not certain.","Jun 3, 2017 at 21:17",,,,44345073
75642323,75642323,"How does the aggregate function work? I tried replacing 
nrow(""class"")
 with 
h2o.nrow(""class"")
 but gives an error (Name lookup of 
h2o.nrow
 failed). Does this mean that the aggregate function being used is the one in base R?","Jun 1, 2017 at 23:03",,,,44317516
75681697,75681697,"the aggregate functions do not use base R. H2O's groupby uses a different naming convention. I created a jira ticket (
0xdata.atlassian.net/browse/PUBDEV-4549
) so that our documentation lists the aggregate functions you can use. Thanks for the feedback!","Jun 3, 2017 at 0:12",,,,44317516
75580992,75580992,"So i should put the 
init
 inside something like 
while(h2o.clusterIsUp())
 ?","May 31, 2017 at 14:12",,,,44286883
75581344,75581344,"you should first runt 
while(h2o.clusterIsUp())
 (preferably with a 
sleep
 inside the loop) and run 
h2o.init
 after that loop. But as I mentioned all of that is wasteful, you don't need to start/stop the nodes every time.","May 31, 2017 at 14:20",,,,44286883
75584468,75584468,"@quant 
removeAll
 will remove also all the data that you uploaded to H2O yet you're using 
td.train.h2o
 etc. in your random forest modeling. Either upload that data again or instead of 
removeAll
 just remove the things you don't need anymore (previous models etc).","May 31, 2017 at 15:29",,,,44286883
75884713,75884713,"Thanks a lot Mateusz ! You are right, I need to get the model performance to get the respective thresholds of metrics:  Here is the model performance, so the metrics showing are the ones I can get from h2o.find_threshold_by_max_metric() function.","Jun 8, 2017 at 18:56",,,,44279924
75885230,75885230,Maximum Metrics: Maximum metrics at their respective thresholds                         metric threshold    value idx 1                       max f1  0.463273 0.904095 250 2                       max f2  0.000980 0.952198 398 3                 max f0point5  0.990303 0.901456  14 4                 max accuracy  0.556570 0.839004 214 5                max precision  0.999478 0.962611   2 6                   max recall  0.000025 1.000000 399 7              max specificity  0.999981 0.918722   0,"Jun 8, 2017 at 19:13",,,,44443797
75552922,75552922,One additional thing to point out is the h2o.init() output won't mention GPUs today even if they're going to be used.  But the nvidia-smi tool above is reliable.,"May 30, 2017 at 21:50",,,,44271812
79060921,79060921,"""build it yourself according to the instructions here for deepwater ..."" The word ""windows"" is never mentioned there :-(","Sep 5, 2017 at 8:51",,,,44253818
79061322,79061322,"@Dan yes, unfortunately we haven't tested it on Windows machines. Would be good to test it and eventually add necessary fixes (as well as add new features) but unfortunately the team is pretty spread out now across other projects.","Sep 5, 2017 at 9:02",,,,44253818
79069910,79069910,"I see. Just to mention it: I'm fine with Linux, but we're at a huge company here with Windows laptops and no admin rights. Somebody around here would possible even pay for Windows functionality before they let us play with different OSs.","Sep 5, 2017 at 12:42",,,,44253818
75537964,75537964,"thanks. But there is another question. mtcars_h2o <- as_h2o_frame(sc, mtcars_tbl) Error in h2o.init(ip = ip, port = port, strict_version_check = strict_version_check,  :    Version mismatch! H2O is running version 3.10.4.8 but h2o-R package is version 3.10.3.2.          Install the matching h2o-R version from - 
h2o-release.s3.amazonaws.com/h2o/rel-ueno/8/index.html","May 30, 2017 at 14:26",,,,44243431
75547195,75547195,"You need to clear 
h2o
 installation and choose the one corresponding to your 
rsparkling
 installation. The table of correspondence is here: 
github.com/h2oai/rsparkling/blob/master/README.md","May 30, 2017 at 18:39",,,,44243431
84754257,84754257,"I had this error on 
h2o_3.17.0.4198
 today when re-running saved data and code to reproduce a model object. I still have the error after setting 
project_name
. Is it a version issue? H2O had been completely shut down for days in between sessions but the error is nearly identical to the OP. Is this a separate question or the same?","Feb 19, 2018 at 22:32",,,,44250887
84755101,84755101,"Null pointer exceptions can be caused by all sorts of things.  I'd recommend posting a reproducible example as a separate question so we can take a look.  I'd also recommend upgrading to the latest version of H2O, 3.18.0.1: 
h2o-release.s3.amazonaws.com/h2o/rel-wolpert/1/index.html","Feb 19, 2018 at 23:13",,,,44250887
84755818,84755818,Thank you! I tried the update. It didn't work so I'll fall back on your old ensemble package until there's time for a deeper dive on the bug.,"Feb 19, 2018 at 23:55",,,,44250887
75496752,75496752,"would python be an option? something like this (found on stackoverflow as well):  from 
future
 import print_function import psutil print(psutil.cpu_percent()) print(psutil.virtual_memory()) #  physical memory usage","May 29, 2017 at 13:39",,,,44237753
75500863,75500863,"No, it would have to be part of out core platform which is written in Java","May 29, 2017 at 15:37",,,,44237753
75501632,75501632,"The major reason this was never done for any platform but Linux is H2O has always shipped as pure Java (for simplicity of distribution), and getting these numbers (kernel CPU tick info) out for any platform besides Linux requires C code.  A second minor reason is most people that run H2O distributed (in a cloud or a Hadoop environment, for example) use Linux, and remote distributed environments really benefit from having the built-in Water Meter.  If you can run top or htop locally, the need is less acute.  This may be worth revisiting in the future as other C/C++ components are added to H2O.","May 29, 2017 at 16:04",,,,44237753
75455330,75455330,"Your suggestion works. Not sure why mine didn't but problem is solved, thks.","May 27, 2017 at 23:24",,,,44221382
75536431,75536431,"I'm using a GBM model and using the 
Enum
 categorical handling so the model knows to accept strings for those variables, not numeric values.","May 30, 2017 at 13:53",,,,44209609
75756541,75756541,"Hi Matt, I modified the code to fall back to using the string if it can't parse it as a float. The code has been pushed so this should work for you now.","Jun 5, 2017 at 21:16",,,,44209609
75921845,75921845,"I've submitted a PR (
github.com/h2oai/steam/pull/375
) to add this change to the strMapToRowData function as well. The GBM model I am using seems to default to strMapToRowData not the sparseToRowData function","Jun 9, 2017 at 16:29",,,,44209609
76937422,76937422,"We use Scala, should just submit through different threads and it should work?","Jul 7, 2017 at 23:38",,,,44233251
120885411,120885411,"I have a level that contains spaces and H2O throws error that ""Did not find level `spaced%20level` in the column"" even though I can see that level in 
df.categories()
 (w/out the %20 representing the space character). Is there a way to solve this?","Jul 15, 2021 at 20:56",,,,44092010
120891736,120891736,"@lampShadesDrifter  You can replace the spaces with underscores or some other character of your choice.  
h2o_frame['A'] = h2o_frame['A'].set_levels([x.replace(' ', '_') for x in h2o_frame['A'].categories()])","Jul 16, 2021 at 6:31",,,,44092010
83406187,83406187,as a note: in python you would do model.model_performance(valid = True) model.plot(),"Jan 11, 2018 at 17:08",,,,47821853
87476740,87476740,"I might be using an old version of H2O, but for me 
h2o.plot
 isn't a function. That being said, base R 
plot
 worked sufficiently well.","May 8, 2018 at 9:00",,,,47821853
75102350,75102350,"Hi, I removed the questions from your answer. This kind of doubts must be solved using comments below the question. You must wait to have 50 points of reputation to be able to comment on any question. Now that you wrote somewhat of an answer, you can probably comment on the question.","May 18, 2017 at 3:16",,,,44030769
75171096,75171096,"But generally how should I test out my python code part? My python code works fine with local I/0, but wrap it as preprocess python code in the .war file, it shows errors  that the python call not read in the test txt correctly. thanks","May 19, 2017 at 15:14",,,,44030769
75079049,75079049,"Thanks! Yes it seems that I hadn't killed the h2o cluster on the port I was using. Killing the existing cluster first then initializing the cluster again with the max_mem_size worked! Thanks for your help! I thought that since it said ""h2o is not running yet, starting it now..."" meant that I was starting a new cluster but I should have known by looking at the cluster uptime that it was connecting to an existing cluster.","May 17, 2017 at 13:32",,,,44014143
75085254,75085254,"Yeah the fact that it said ""h2o is not running yet, starting it now..."" seems weird to me too.  It shouldn't do that, but it should also print out a bunch of start-up messages, so that's a bit weird.  Glad it fixed it though!","May 17, 2017 at 15:43",,,,44014143
129794853,129794853,Do you know how that might be done in sparkling water? I'm starting a spark session with 8 cores and 1gb per executor but it only says 1.6 available free memory,"Aug 26, 2022 at 10:43",,,,51024734
75130102,75130102,thanks for your answer. Is it possible to adjust the input values (e.g. add a certain value to all values) and do the calculations with these numbers.,"May 18, 2017 at 15:49",,,,44014154
75145920,75145920,"Do you mean adjust the 
feature
 input values or the 
response
 input values?  If response, then check out the 
offset_column
 parameter: 
docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/…","May 19, 2017 at 2:32",,,,44014154
75300389,75300389,"what if also some feature input values are 0 or close to 0? is this 
offset_column
 or sth similar also available for that?","May 23, 2017 at 17:12",,,,44014154
75304184,75304184,"The features are automatically scaled and normalized inside the 
h2o.deeplearning()
 function, so the scale of the original values doesn't matter.","May 23, 2017 at 19:10",,,,44014154
75158716,75158716,"rite! We should remove proxy before Run h2o:  Sys.unsetenv(""http_proxy"")","May 19, 2017 at 10:16",,,,43960433
75421339,75421339,"Hi Tuong, does it make sense to accept this answer then?","May 26, 2017 at 14:44",,,,43960433
84430683,84430683,"I am getting errors even after shurring down and restarting. Is there a way to run h2o from R to protect against this problem? I mean, some way to isolate H2O to have only one totally separate H2O instances per script? Would I need totally separate jar files?","Feb 9, 2018 at 23:50",,,,43932717
84441644,84441644,"@Hack-R That deserves to be its own question. (You can run multiple instances, by putting each on a different ip/port combination, but usually it is not a good idea, and without knowing more about the errors you see, my guess is that it wouldn't help.)","Feb 10, 2018 at 13:40",,,,43932717
74864813,74864813,"the data frame I used for training is definitely the one I used to build the GBM; After I didn't see it the first time I did what you did, just start an h2o server with only the training frame and the two models. I'm using Steam on a local machine, and also an AWS server and neither have been able to see the model.","May 11, 2017 at 12:47",,,,43896748
74815933,74815933,But the code needs fundamental algorithms that could already be in h2o. One could combine a few and get the result ??,"May 10, 2017 at 11:23",,,,43883405
74842783,74842783,"@MohanRadhakrishnan Yes, that's true, H2O could be extended to include a reinforcement learning framework.  No one is working on that actively at the moment though, that I'm aware of.","May 11, 2017 at 0:05",,,,43883405
74752055,74752055,"Thanks Darren! The chart above showed ""with weight"" and ""without weight"" scenarios on the same development and validation data. Wondering why there is a log loss difference on the left chart, but not on the right chart?","May 8, 2017 at 22:24",,,,43842351
74761563,74761563,@Eric_IL I suspect it is just an artefact of that particular data split - the point of my answer was to investigate if this is the case or not.,"May 9, 2017 at 7:01",,,,43842351
74657927,74657927,"Yeah, I knew about it. I wanted to flush the whole thing to drive and then load it again. With all cross validation models, metrics, grid searches etc. I think at the moment my script kind of solves this problem. Thanks!","May 5, 2017 at 16:08",,,,43795912
131739159,131739159,"""It doesn't really make sense to save the data frames since you already have a copy of the data (that you loaded into H2O)."" I disagree with this. h2o has a rich set of data manipulation functions--what is the point of these if they cannot be saved for coming back later? The inability to save and restore the full environment is one of my biggest frustrations with h2o.","Nov 30, 2022 at 22:21",,,,43795912
132811901,132811901,"In Flow, there's not much available in terms of data manipulations, but you can also save individual frames by clicking on the name of the frame and hitting the Export button (similar to the screenshot for models above).  You can more easily save all objects using the R or Python API since there's a function to list all objects, but that's not possible in Flow, sorry...","Jan 28, 2023 at 0:40",,,,43795912
74622189,74622189,"If I only have one desktop, does that mean it only run on my desktop? Then will it be faster than not using H2O since it is only using my desktop?","May 4, 2017 at 19:01",,,,43787106
74624190,74624190,"@Gavin Could you rephrase that? What is the ""it"" that would be faster than not using H2O?","May 4, 2017 at 19:58",,,,43787106
74624784,74624784,I think it make sense if I use H2O connect to some serve or EC2 to leverage the computation power. That can speed up the calculation. But if I only have one local machine without connect to another machine or server. Will running calculation be faster if I use H2O vs do not use H2O? Why? I don't understand what makes H2O faster?,"May 4, 2017 at 20:15",,,,43787106
74633964,74633964,"thanks. I think I understands your answers. The link 
docs.h2o.ai/h2o/latest-stable/h2o-docs/architecture.html
 also help me to better understand why H2O is faster.","May 5, 2017 at 5:01",,,,43787106
100762793,100762793,"@MustardTiger Thanks, I just added a paragraph to my answer on that.","Jul 20, 2019 at 7:07",,,,43787106
74672599,74672599,"Follow-up note: Someone pointed out to me that it's very easy to find the download page just by googling ""h2o 3.10.4.2""","May 6, 2017 at 4:50",,,,43795304
74485864,74485864,"Thanks, in my case the threshold is very different for specificity and recall, so I don't have a good threshold that maximizes both. I am using the default value for 
stopping_metric
 (=
logloss
 for classification), but I don't know how to interpret the value: 
0.46
. The range of this metric can be even greater than one. I guess it is not a good result due to my 
sens
, 
spec
 values, but according to this metric, I don't know exactly how to understand it.","May 1, 2017 at 14:56",,,,43700476
95985563,95985563,"Any idea how one would use the 
idx
 value in that table? What's it an index of?","Feb 8, 2019 at 14:43",,,,43700476
95989085,95989085,"@Hack-R It appears to be a 0..399 index into the bins used; i.e. it represents where on the x-axis of an AUC chart that optimal point is. See 
github.com/h2oai/h2o-3/blob/…
 and the definition of NBINS in that same file.","Feb 8, 2019 at 16:24",,,,43700476
74441581,74441581,"I tried both ways, but I get the same output: a confusion matrix, with same values, error, and threshold. Why you prefer the second way(
h2o.confusionMatrix(p)
)","Apr 29, 2017 at 17:08",,,,43693485
74443826,74443826,"@DavidLeal Because if I print 
p
 it tells me not just the confusion matrix, but also MSE, RMSE, Logloss, hit ratios, etc. It is also the parameter you give to the individual functions, such as 
h2o.mse(p)
.","Apr 29, 2017 at 19:03",,,,43693485
74419570,74419570,"Say I were to use each of K prediction probabilities as columns in my fit (sum to 100%, obviously one of them would be unnecessary). Am I correct that it doesn't matter if they are class probabilities or class logodds (relative to a reference class) because that is a monotonic transformation?","Apr 28, 2017 at 18:32",,,,43674594
74422945,74422945,"Also, are you suggesting that I could probably edit the code for my personal use pretty easily once I changed semantics regarding ""offset_column""? Or do you think altering those semantics would be to big a hurdle?","Apr 28, 2017 at 20:26",,,,43674594
74440942,74440942,"Tom, Thank you for your response. After using h2o for a bit I realize that it doesn't have a streamer. My architecture is what you call a one-pass streaming - exactly because I have 100s of millions to billions of records in one epoch. Tried spark's local iterator function but it doesn't work on spark 2.01 - and I didn't have the time to upgrade. So I was hoping to find a quick solution to the problem and that's when I tried using h2o (which I already had a cluster installed). I could have looked into Kafka / other big data technologies but didn't want to open yet another can of worms.","Apr 29, 2017 at 16:38",,,,43688522
74385396,74385396,"I don't think this has to do with memory.  I have tried with ""12g"" and that does not help.  The code is self contained...try with smaller 
tot_obs
 and 
tot_var
.  Still same issue:  
ERROR: Unexpected HTTP Status code: 500 Server Error (url = http://localhost:54321/3/ParseSetup)  water.util.DistributedException  [1] ""DistributedException from localhost/127.0.0.1:54321, caused by java.lang.ClassCastException: water.fvec.Vec cannot be cast to water.fvec.ByteVec""","Apr 27, 2017 at 23:05",,,,43668955
74385437,74385437,"I tried your other suggestion 
options(""h2o.use.data.table""=TRUE)
 and then 
tmp <- as.h2o(mat.agg.dt)
.  I now get the error 
Error in h2o.parseSetup(data, pattern = """", destination_frame, header,  :    length of col.names must equal to the number of columns in dataset","Apr 27, 2017 at 23:07",,,,43668955
74388124,74388124,You don't need the last line (I've updated my answer above to clarify that).,"Apr 28, 2017 at 1:59",,,,43668955
74388161,74388161,I get the 'h2o.parseSetup' error when I run as.h2o.  Just that line.  Not the next line.,"Apr 28, 2017 at 2:01",,,,43668955
74388216,74388216,Is it a h2o version issue?  Does it need a later version?,"Apr 28, 2017 at 2:07",,,,43668955
74237639,74237639,Thanks!  My mistake was not realizing the numbering was 0-based.,"Apr 24, 2017 at 17:07",,,,43593039
74237618,74237618,"Thank you for reply! That was my thought aswell, unfortunately I didn't find any good source to confirm this. But it's most probable.","Apr 24, 2017 at 17:06",,,,43593206
74259215,74259215,"No, I couldn't find a source either :( hope you find an answer","Apr 25, 2017 at 8:06",,,,43593206
74233485,74233485,"Thanks. I am curious, is that command also how you would permanently store a model object for scoring new data (in H2O format) in the future?","Apr 24, 2017 at 15:20",,,,43582163
74246273,74246273,"@dj_ski_mask Check out 
h2o.saveModel()
 and 
h2o.loadModel()
 for binary models.  Those are the easiest to use, however for productionizing models, check out 
h2o.download_pojo()
 or 
h2o.download_mojo()
. 
docs.h2o.ai/h2o/latest-stable/h2o-docs/pojo-quick-start.html","Apr 24, 2017 at 21:30",,,,43582163
74184621,74184621,Thank you Erin for your quick comment. May i also know if i can purely go by the mean_per_class_error or should i also keep an eye on the AIC for the individual models to choose the best model.,"Apr 23, 2017 at 3:42",,,,43563619
74201303,74201303,"I'd recommend just using 
mean_per_class_error
 to choose the best model.","Apr 23, 2017 at 19:33",,,,43563619
74207555,74207555,"Thanks again Erin, let me complete the models and their comparison and post it here for your review :)","Apr 24, 2017 at 2:33",,,,43563619
76042123,76042123,Fantastic. Thank you for this explanation and the support.,"Jun 13, 2017 at 15:01",,,,44503483
74234302,74234302,"Please provide your OS, GPU and environment details,","Apr 24, 2017 at 15:38",,,,43545980
74691259,74691259,Any suggestions?,"May 7, 2017 at 0:43",,,,43545980
74738981,74738981,Build the latest Deep Water code and disable GPU flag works now with Tensorflow so u can using TF backend without CUDA.,"May 8, 2017 at 15:31",,,,43545980
74163911,74163911,"For non-numeric (in other words, categorical) data, yes, H2O algos only allow factor columns, but not string/character columns.","Apr 22, 2017 at 6:40",,,,43526712
83654229,83654229,"@ErinLeDell this manual transformation seems only needed for the target column? 'auto' only fixes input variables? documentation isn't clear 
h2o-release.s3.amazonaws.com/h2o/rel-ueno/2/docs-website/…","Jan 19, 2018 at 5:18",,,,43526712
83686842,83686842,"All categorical columns must be factors (includes features and response).  The 
categorical_encoding
 option encodes factors into another representation under the hood, but it must be a factor to start with.","Jan 19, 2018 at 21:59",,,,43526712
74222932,74222932,"I did not see this exposed via the 
R
 interface.","Apr 24, 2017 at 11:34",,,,43546870
74197687,74197687,Thank! this is very helpful,"Apr 23, 2017 at 16:49",,,,43560940
74009562,74009562,"+1 thank you Erin for your easy-to-understand answers. 1) Yes I see that I'm using data leakage incorrectly. Thank you for the clarification. I am splitting by rows, and I do not have any columns that can leak to the target variable. 2) I only manually remove the test data set myself, do not randomize, and the test set consists of the most recent 3 yrs of data from the original data set; then I use the appropriate partitioning function to split the remaining data into the train and validation sets. It is here and only here when I manually create the test set myself that I get poor results.","Apr 18, 2017 at 16:05",,,,43466852
74009863,74009863,3) Yes I use h2o.performance and the results are very acceptable when using partitioning functions; I even plot the histogram of the residuals which turn out to be normally distributed. 4) But it still doesn't make sense to me b/c it seems that the model should predict equally well whether I use the randomizing data partitioning functions or a manually created holdout used as the test set (and not randomized).,"Apr 18, 2017 at 16:13",,,,43466852
74010654,74010654,"One final issue: the reason why I decided to manually create a holdout, test data set myself instead of just relying on a partitioning function is b/c I wanted to rule out some kind of ""sham"" that may be occurring.  With both h2o and caret's xgb, the results are simply TOO good to believe! R-squared >0.9 on test data set and in all 10-fold CV along with minimal SD b/t  iterations and low RMSE and normally distributed residuals ...all of it just makes me doubt that machine learning can really be this good. I need to know what to believe: is my model good or bad?","Apr 18, 2017 at 16:35",,,,43466852
74018391,74018391,"It sounds like you have time-series data, which would explain why your manual partitioning (without randomization) would produce poor results.  If the data generating distribution shifts over time, then training a model on ""old"" data and predicting on ""new"" data may not work well if you don't have any features that capture recent event data.  When you randomize, you get a mix of new and old data in your training set and your test set, which is why you get a model that generalizes better to the test set.","Apr 18, 2017 at 20:08",,,,43466852
74018434,74018434,"Also, don't worry about R^2 when dealing with tree models.  Just look at RMSE.","Apr 18, 2017 at 20:09",,,,43466852
73962595,73962595,"Since each worker in doParallel is a separate process, wouldn't that code create 12 separate h2o instances and each process can only connect to the h2o instance that is created within that process?","Apr 17, 2017 at 14:41",,,,43444826
73971976,73971976,"I'd do a benchmark between 1 & 2 on a small number of groups to try to estimate which will work best on the full set.  I'm afraid that you may run out of RAM since GBM models can be large, so I would also recommend saving each GBM to disk and removing the model and the associated training set from the H2O cluster, within the loop.","Apr 17, 2017 at 19:22",,,,43444826
73972747,73972747,"@mauna You have raised a good point. I have tried it out and it does seem to work, so I will update my #3 option to be this option (instead of auto-generating a bunch of R scripts using a bash script and then launching them all separately).","Apr 17, 2017 at 19:46",,,,43444826
73979614,73979614,"Also, I think option #3 will work as intended on a Windows platform only since UNIX-like systems use fork() so will share resources with the parent process. What do you think?","Apr 18, 2017 at 0:54",,,,43444826
73982419,73982419,"@mauna In theory, every solution will be helpful. But in practice, it's very hardware and problem dependency. I highly agree @Erin, 
#1 is probably the most scalable/stable solution
.","Apr 18, 2017 at 4:07",,,,43444826
73886081,73886081,"Armo. Thanks for the reply, very helpful! When I apply weight on the observation when building model in h2o such as GBM, I found the default gains table output from h2o is not in decile but in some value such as 22%, 25% .....                                   Do you know how to code in R to output the gains chart in exact decile or twentile format. Sorry I am new to R....","Apr 14, 2017 at 14:37",,,,43405169
73904489,73904489,"You can't change the quantiles without touching Java code, but deciles and twentiles are contained in the current table - basically there's more information than what you seem to ask for. Look at the cumulative data fractions.","Apr 15, 2017 at 6:22",,,,43405169
73805641,73805641,This path exactly was what I was trying to avoid. It costs time to dwld data from oracle to R.,"Apr 12, 2017 at 14:06",,,,43369383
73904512,73904512,"Tom said above that you would run Java, not R code. 
github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/howto/…","Apr 15, 2017 at 6:24",,,,43369383
73930886,73930886,Thanks Erin. This gave me an identical result to lm. I'll now work to get the same result as glmnet.,"Apr 16, 2017 at 11:56",,,,43330288
73942986,73942986,"@fifthace Set 
alpha = 1.0
 in H2O if you are using glmnet defaults.  Note that glmnet will probably find a different 
lambda
 than H2O, so you could run that first, take the best 
lambda
 value and then use it in 
h2o.glm()
.","Apr 16, 2017 at 23:10",,,,43330288
110017795,110017795,"@ErinLeDell I was able to follow your example and produce the identical coefficients listed above; however, when I tried performing a logistic regression on CAPSULE ~ AGE + RACE + PSA + DCAPS I got different coefficients via the 
h20.glm
 method compared to the 
glm
 method; I changed family from 'gaussian' to 'binomail', but is there any other arguments I have to specify in order to obtain identical coefficients?","Jun 5, 2020 at 0:39",,,,43330288
73915516,73915516,"@ Tom K, glmnet gives me almost identical results to glm, when choosing alpha using a 10-fold cross-validation to minimise the MSE. Basically, elastic net is not well suited to my example, and your explaination is not correct (in my case).","Apr 15, 2017 at 17:06",,,,43327110
73658953,73658953,"Both answers are very useful & correct, but this is much easier to use.","Apr 8, 2017 at 15:53",,,,43295444
73650871,73650871,"I haven't customized my R installation. Its just a direct 
apt
 install with a few packages added that were needed. How can I confirm if it is a pdflatex issue?","Apr 8, 2017 at 8:23",,,,43291787
73652089,73652089,"I'm afraid, I don't know. Maybe install rstudio? It brings a whole lot of software with it in order to render Rmarkdown as PDF. In Rstudio,  generate a simple Rmarkdown file and ""knit"" as PDF. If this works, you probably have a working PDFlatex infrastructure.","Apr 8, 2017 at 9:40",,,,43291787
73652309,73652309,"I was able to successfully knit the pdf. Although a few R packages were needed, they didn't help make the h2o problem go away :(. Atleast pdflatex isn't the problem.","Apr 8, 2017 at 9:53",,,,43291787
73652460,73652460,"I'll try to build h2o.ai from source myself, first time. I also have a Ubuntu 16.04. May take a while.","Apr 8, 2017 at 10:03",,,,43291787
73653207,73653207,Thanks a lot for the help :),"Apr 8, 2017 at 10:50",,,,43291787
73722334,73722334,"Thanks Arno! But then I'm wondering what does autoencoder do? As the first figure above, if that's what I got from autoencoder hidden layer (2 nodes), doesn't it mean my data actually has some obvious clusters (as shown in the first figure, it shows 6-8 clusters)?","Apr 10, 2017 at 17:07",,,,43290852
73785245,73785245,"Yes, it seemed that clustering was useful in getting a good dimensionality reduction. However, the cluster assignments only exist in you head. There's no automatic way to get a cluster ID from an autoencoder AFAIK, you have to run a clustering algo in addition.","Apr 12, 2017 at 6:16",,,,43290852
73833540,73833540,"So after applying AE and getting the 2D features (like the first plot), then, can I apply clustering techniques (e.g. k-means) to the 2D features to get their clusters/labels, and use these labels directly for the original data? Thanks!","Apr 13, 2017 at 7:28",,,,43290852
73587775,73587775,"I get memory error: Not enough free memory to allocate the distance matrix (404279 rows and 404279 cols.   See, you seem to be making an all-pairs distance matrix. But it's a bad assumption -- I did not want an all-pairs computation.  I just want distance between the two points as defined by the x frame and the y frame.  The implementation is making bad assumption about all-pairs.  Perhaps you had nearest neighbors in mind, but NN is definitely not the only thing distance computation is good for.  I just have 2 points per frame row to compute the distance on.","Apr 6, 2017 at 15:32",,,,43213877
73588319,73588319,"I got a memory error.  (see comment to Erin).  Why is h2o.distance making an all-pairs computation?  I do not want that in the general case of computing a distance.  Of course h2o cannot allocate a square matrix in dense format of 404279 x 404279. I just want distance between 2 points (100-d in my case) in each row.  No all-pairs stuff here.  An exhaustive nearest neighbors search is not necessarily why users want to make distance computations. Bad idea to attempt exhaustive NN search on huge number of point-pairs -- approximate methods are suitable at this scale, like balltree and LSH.","Apr 6, 2017 at 15:43",,,,43214213
73786868,73786868,"Or: 
sqrt(h2o.sum((hex[,cols1] - hex[,cols2])^2, axis = 1, return_frame = TRUE))","Apr 12, 2017 at 7:04",,,,43362315
73452689,73452689,Thanks! It's certainly a better solution than the other two.,"Apr 3, 2017 at 16:32",,,,43189705
107237287,107237287,"thanks it helped me, the second line did the thing for me","Mar 10, 2020 at 9:05",,,,54487673
73504235,73504235,"Thanks Erin. I will surely do that and I agree that my question sounds generic. Moreover I am strongly believing for stock exchange problems, invariably we need to do feature engineering by deriving the typical traders indicators like average training index and others. Thanks for spending some time on it. I am keeping this question open to see if we can get any other insights for few days, then will close. Hope it is in the spirit of stackoverflow. Thanks again.","Apr 4, 2017 at 19:51",,,,43214809
73538919,73538919,It turned out to be a great decision to follow your comment. Did Cartesian search rather than Random search and got good results. Thanks Erin!,"Apr 5, 2017 at 14:41",,,,43214809
73848556,73848556,"thank you for your reply.  I agree, ""chasing that route [changing 
max_mem_size
] is not useful"".  Our Linux machine has 1.5 Tera of memory.  At one point I allocated 
max_mem_size = 500G
 and I still got an OOM error.  Nothing has changed on our Linux machine except upgrades to R (from v3.2.3 to v3.3.2) and H2O (from v3.6.0.8 to v3.10.4.2).","Apr 13, 2017 at 13:34",,,,43381738
73848592,73848592,"The R code has not changed.  The calls to H2O had not changed.  The GBM model training successfully completed (ie, 
h2o.saveModel
 was written to disk) with the old version of R/H2O.  The GBM model training throws an OOM at 
h2o.saveModel
 with the new environment.  After working through 10 different versions of H2O (always using the new version of R v3.3.2), I found that all H2O versions 3.10.3.x and 3.10.4.x throw an OOM error.  I found that H2O v3.10.2.1 works; I am now using this version.  H2O version 3.11.0.3839 also works but I am not using this version as it seems to be bleeding edge.","Apr 13, 2017 at 13:35",,,,43381738
73848602,73848602,"I hope this OOM error can be fixed otherwise we are stuck with v3.10.2.1 or will have to migrate to, say, python's scikit-learn.","Apr 13, 2017 at 13:36",,,,43381738
73849651,73849651,"Please send an email to 
[email protected]
 so we can troubleshoot your problem on your machine, I will help you there.","Apr 13, 2017 at 14:01",,,,43381738
73965444,73965444,"thank you for offering to help.  I just sent an email to 
[email protected]
.  Thanks!","Apr 17, 2017 at 16:03",,,,43381738
73384743,73384743,"Thanks Avkash - so do you mean something like use h2o.ifelse(pred$p1 > f1,1,0) ? Is it the max f1 threshold?","Apr 1, 2017 at 7:54",,,,43151950
73393608,73393608,Exactly.  I did a quick test and max f1 and the number of almost match.,"Apr 1, 2017 at 16:32",,,,43151950
109556205,109556205,How do you do this?  Can you provide steps?,"May 21, 2020 at 19:31",,,,43149744
73434295,73434295,"Hey Nick, though this works and can be used. I wanted to achieve the same using the h2o Flow alone.","Apr 3, 2017 at 9:16",,,,43143946
73433880,73433880,"hey Arno, Other than your step 1 have followed, same steps as you have. Can you check the ""missing"" under ""column summaries"" in ""seeds_dataset1.hex"".  I am not able to import in h20 flow from web, hence i saved the file. I get same result as before. h20 is able to identify 8 columns. But check out row 8 and 36.","Apr 3, 2017 at 9:06",,,,43144488
73501924,73501924,"I am not sure what exactly was wrong with my code but when I executed the same piece on cluster and not local, it worked fine. I think the issue was mostly with my local network settings. Sorry for the late response.","Apr 4, 2017 at 18:41",,,,43150288
73291623,73291623,I have already default encoding equal to 'utf-8'. What else can be there?,"Mar 29, 2017 at 22:12",,,,43103759
73291942,73291942,"Just checking, your
type('César Chávez Day')
 is ""str""?","Mar 29, 2017 at 22:27",,,,43103759
73292066,73292066,"Maybe try this (might be redundant though): 
df = pd.DataFrame({'col1': [1,1,2], 'col2': [str('César Chávez Day'), str('César Chávez Day'), str('César Chávez Day')]})","Mar 29, 2017 at 22:33",,,,43103759
73304268,73304268,"I understand that is strange, but 
type('César Chávez Day') = str
 and your second advice also causes the same 
unicode erorr","Mar 30, 2017 at 8:15",,,,43103759
73211644,73211644,"The H2O frame is generated by converting from a Spark dataframe with various transforms applied (which was itself originally generated from a Hive query). It doesn't directly correspond to a file on disk, as far as I am aware.","Mar 28, 2017 at 8:03",,,,43051434
73214154,73214154,"Thanks for the suggestion and for adding the JIRA ticket! It would be a great addition I think. I tried pulling the ""subject"" column into a data.frame, but the problem is, even this dataframe becomes smaller than the original H2O frame, for some reason.  > h2o.nrow(data) [1] 43594  > nrow(sub) [1] 32367  And when I try to copy it back to H2O, I get an error message: ""Requires same count of rows in the number-list (43594) as in the source (43823)"" (I don't really understand what is 43823 there) Maybe there is something I'm missing, some parameters of H2O has not been set perhaps?","Mar 28, 2017 at 9:07",,,,43058254
73245498,73245498,"That sounds like a bug with 
as.data.frame()
.  Do you have the data.table package installed?  If you do, you should try using and then not using data.table on the backend.  Try again first using 
options(""h2o.use.data.table""=TRUE)
 and then 
options(""h2o.use.data.table""=FALSE)
 and let me know if one of those two gives the correct number of rows.","Mar 28, 2017 at 22:41",,,,43058254
73311157,73311157,"Great, it finally worked with options(""h2o.use.data.table""=TRUE) (I tested it with FALSE as well, and the problem of less rows in the dataframe reappeared). I knew about this package, but I didn't know that h2o had such an option. Thank you so much!","Mar 30, 2017 at 11:02",,,,43058254
73334704,73334704,"@Hadron It's a new option meant to speed up the 
as.h2o()
 and 
as.data.frame()
 functions.  I'm glad to hear that data.table is doing the right thing.  It sounds like the bug appears when using the default 
as.data.frame()
 backend.  If there is any way that you can upload your dataset to JIRA, it would be great to look into this bug further. 
0xdata.atlassian.net/projects/PUBDEV","Mar 30, 2017 at 20:42",,,,43058254
73059554,73059554,Thank you for these helpful answers!,"Mar 23, 2017 at 18:08",,,,42983585
84421455,84421455,I have the same problem (I think) but the working directory is set normally to a reasonable path. It's like this some buggy code appending to some internal H2O path variable.,"Feb 9, 2018 at 17:36",,,,42979142
115272373,115272373,"How to set options(""datatable.verbose""=TRUE) in python???","Dec 8, 2020 at 16:42",,,,42965786
72967227,72967227,Thank you for the very fast response. Hope this will be solved this fast too. :),"Mar 21, 2017 at 18:17",,,,42932790
72832927,72832927,"Hi Lauren, could you provide an example with Bernoulli please? That's where my confusion is. Your example is with Gaussian.","Mar 17, 2017 at 17:10",,,,42862431
72834626,72834626,"According to 
en.wikipedia.org/wiki/Generalized_linear_model
, link function which I need to use to get to the linear space for Bernoulli is logistic ln(mu / (1-mu)), which is what I used for my example.... But H2O complains that the offset has to be less than 1. What did I do wrong? Or more importantly, what H2O is expecting me to do?","Mar 17, 2017 at 17:58",,,,42862431
72835182,72835182,"I added this Boston example to my 
notebook on GitHub
. I adapted it to what I'm trying to do, not just some arbitrary offset, but a prediction from glm. And it works fine. So, I have no problem with Gaussian. But Bernoulli is still a problem","Mar 17, 2017 at 18:14",,,,42862431
72838267,72838267,"updated it for you, you just need to provide a offset column that contains values less than 1, hope that helps","Mar 17, 2017 at 19:48",,,,42862431
72910928,72910928,"Unfortunately, that's not helpful at all. In your example you just added some arbitrary offset of 0.5. I don't want an arbitrary offset. I want to use offset that corresponds to the prediction from a glm model. And I want to know how to construct it. I updated the 
Github
. Look at cells 16, 17 and 18. There I added ""something"" that is less than 1, right? Namely I added Probability from GLM. However, LogLoss even after the first tree is 0.6. The GLM model has a LogLoss of 0.48. It cannot increase!","Mar 20, 2017 at 14:04",,,,42862431
72841501,72841501,"To clarify -- 
h2o.importFile()
 doesn't have a 
pattern
 argument, only 
h2o.importFolder()
 does.","Mar 17, 2017 at 21:51",,,,42860507
72709926,72709926,"Thanks, Frank.  I've updated the JIRA.  Also see my updated answer above.","Mar 14, 2017 at 22:21",,,,42796822
72730500,72730500,I specifically mention that I am using R package version 3.6 which does not have the h2o.arrange function that 3.10 has.,"Mar 15, 2017 at 12:00",,,,42796822
72758188,72758188,"Ok, I did not recall off the top of my head which version of H2O that 
h2o.arrange()
 function was first introduced, but it sounds like you are out of luck until you upgrade.  The work-around is to do the sorting in an R data.frame or data.table and use the 
as.h2o(df)
 function to send the sorted frame to H2O.  The other alternative is to use Spark / sparklyr to do the sorting if your data is too big for a single machine's memory in R.","Mar 16, 2017 at 0:48",,,,42796822
72779322,72779322,"Thanks. That's what I was afraid would be the case. If you update your answer, then I will accept it.","Mar 16, 2017 at 13:11",,,,42796822
72626626,72626626,Sorry that was a typing mistake. I was asking Can I use only some of the columns from the entire set of columns that I used to train data using GBM Model - The reason is we are creating a look alike model in which some of the datasets that we have doesn't have all the columns used to create the model.,"Mar 13, 2017 at 1:16",,,,42742517
72654625,72654625,"Yes, you can create a new frame based on selecting only interesting columns (let's say you pick top 10 the most important input features) or you can specify option 
ignore_columns
 option (depends on API you are using)","Mar 13, 2017 at 17:14",,,,42742517
72360846,72360846,"I actually tried doing this for some time, but my challenge was figuring out which predictor to use when.  The model I had was not a binomial predictor so I couldn't use it.  I was getting an error.  Is there an easy way to figure out which predictor to use based on the type of model used?","Mar 6, 2017 at 0:46",,,,42611520
73644382,73644382,"This piece of code has an example which may be helpful.  
github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/…","Apr 7, 2017 at 22:46",,,,42611520
72338920,72338920,"FYI, I figured this out by deploying steam and having it automatically deploy a web service based on my model.  Once I put the inputs into the service I saw that the output (which was labeled) matched my numbers","Mar 5, 2017 at 4:00",,,,42604363
92665325,92665325,"By open the url... do you mean paste  ""
localhost:54321
"" in a browser?  How does one open the url?","Oct 18, 2018 at 14:09",,,,44609899
71842645,71842645,That solves my first question.  Any solid links for complete example to get start with Sparkling water end to end?,"Feb 20, 2017 at 13:23",,,,42312567
71866932,71866932,@mvg I know our documentation is a bit behind - we're working on updating it to 2.x but I think it still should be doable to get a full working example by following our Github README and standard spark practices. Which parts do you find challenging?,"Feb 21, 2017 at 3:27",,,,42312567
71868740,71868740,"I took this code 
github.com/h2oai/sparkling-water/blob/master/examples/src/main/…
 and created jar file out of it and submitted it to Spark-Submit and it starts H2o flow.  I opened it in browser and stuck there, because it more looks like a config tool.","Feb 21, 2017 at 5:13",,,,42312567
71868897,71868897,"@mvg could you post a new question with a bit more details (how you created the jar, what's your spark submit command etc).","Feb 21, 2017 at 5:20",,,,42312567
71869340,71869340,sure will close this question and open a new one.  Thanks !!,"Feb 21, 2017 at 5:38",,,,42312567
104415912,104415912,How do you restart the server without losing the previous objects? I'm using RStudio as well (library h2o),"Nov 28, 2019 at 14:07",,,,45463442
110574646,110574646,Were you able to get around this issue?,"Jun 23, 2020 at 0:38",,,,45463442
71355540,71355540,"It works!! Thanks so much. I also had to include libraryDependencies += ""ai.h2o"" %% ""sparkling-water-repl"" % ""2.0.4"" to run the app.","Feb 7, 2017 at 14:43",,,,42071341
71356093,71356093,"Great. I've disabled repl in my project with 
spark.ext.h2o.repl.enabled=false
 in h2oConf","Feb 7, 2017 at 14:54",,,,42071341
71192032,71192032,"Thank you for this response. This is probably the only way, I guess. I explored options over the last 2 days but couldn't find one. I have been trying to not convert a h2o frame to R data frame for data processing. But after realizing that h2o has limited support functions, I have to decided to do all necessary processing with data tables and then convert necessary data to h2o prior to model execution.","Feb 2, 2017 at 17:05",,,,41992992
70870932,70870932,ughh god... I hate when a silly misreading happens. Thanks for the quick spot.,"Jan 25, 2017 at 3:49",,,,41841166
70867709,70867709,"The ""key"" in is just a unique identifier that the H2O cluster uses to keep track of H2OFrames.  This can be a different name than the R object that represents the H2OFrame in R.","Jan 25, 2017 at 0:16",,,,41837966
70870149,70870149,Ok.  What is the h2o key in case of df? That's also a h2oframe. Right? Also where it is used?,"Jan 25, 2017 at 2:56",,,,41837966
115101858,115101858,Are there any developments on this issue?,"Dec 2, 2020 at 10:19",,,,41645916
115502383,115502383,@wake_wake This has been fixed (see update above).,"Dec 17, 2020 at 0:04",,,,41645916
115505301,115505301,"Interesting! It still doesn't work on my Windows machine. Even if I set 
Sys.setlocale(""LC_ALL"",""Chinese"")
 I get weird characters when I transform my correct characters from a 
as.character
 to a 
as.h2o
. I end up with text like this:  ""氓鈥犈撁︼拷鈥<98>""","Dec 17, 2020 at 4:00",,,,41645916
115775583,115775583,@wake_wake What version of H2O are you using and which version of Windows?,"Dec 28, 2020 at 23:24",,,,41645916
116073886,116073886,"Thanks @wake_wake, we re-opened the ticket to investigate the issue.","Jan 10, 2021 at 8:13",,,,41645916
70469295,70469295,"Hi @ab90hi, thanks for your advice. Actually, I had no problem in reading the original dataset into R and show them as appropriate Chinese characters by using read_csv from dplyr. The challenge is to import or transform the original data set into an H2OFrame and show them appropriately.","Jan 13, 2017 at 12:40",,,,41629289
70240857,70240857,"Thanks @Mateusz for the helpful answer. I think I get a clearer understanding now, thanks!","Jan 7, 2017 at 2:42",,,,41501645
70376033,70376033,"could you please take a look at questions in the section of 
Questions-2017-01-11
 thanks","Jan 11, 2017 at 8:37",,,,41501645
70383552,70383552,"@Tom done, next time please make a new question - some of H2O devs (me included) have SO filters for that and we get emails when such questions appear.","Jan 11, 2017 at 11:46",,,,41501645
70408911,70408911,Thanks @Mateusz for the great answer! And I will do what you suggested in the above comment.,"Jan 12, 2017 at 0:30",,,,41501645
70089267,70089267,Thanks a lot for you detailed answer @Darren Cook.,"Jan 3, 2017 at 10:43",,,,41441578
70164647,70164647,"Thanks; for future reference if others come across, this, I've now forked the suggested GitHub repo (which did not work at scale) and made a function that writes libsvm format with large simple_triplet_matrix objects at 
github.com/ellisp/r-libsvm-format-read-write/blob/master/R/…
 .","Jan 5, 2017 at 7:46",,,,41454135
77898924,77898924,Is there any example of model building with svmlight formatted files in Python?,"Aug 2, 2017 at 19:03",,,,41454135
77899107,77899107,"Just use 
df = h2o.import_file(""mydata.svmlight"", method = ""SVMLight"")
, and then set 
training_frame = df
 in any H2O Python algorithm.","Aug 2, 2017 at 19:08",,,,41454135
122600143,122600143,"Unfortunately, 
the JIRA ticket
 has not been worked on it seems...","Sep 28, 2021 at 15:08",,,,41454135
122632213,122632213,"@AntonAntonov I've added the ""nice_feature"" label so we keep track of this as something that we should do, but sorry to see that we have not had time to do it yet.","Sep 29, 2021 at 18:39",,,,41454135
69749119,69749119,"I'd like to run two or more R scripts concurrently and independently, each using some functionality of h2o, e.g. reading/writing a dataset to and from server, training two separate, unrelated models. I'm aware of 
startH2O=FALSE
 but it seems odd to have to check failure to know whether an instance is running.  But thks.","Dec 21, 2016 at 23:58",,,,41273481
69758786,69758786,"@horaceT For 
that
 use case I'd just do 
h2o.init()
: the first script that runs will start H2O for you, and the second will automatically use the running instance.  (To be precise 
h2o.init(nthreads=-1, max_mem_size = ""4g"")
, and make sure your scripts all use the same command; alternatively start it from the commandline in advance.)","Dec 22, 2016 at 8:23",,,,41273481
69480318,69480318,"(I've not used this approach with Spark, so I'm just checking with one of the developers if there is any reason it cannot be used...)","Dec 14, 2016 at 9:08",,,,41138415
69468441,69468441,"Peter - Thank you for the response. Aren't both x1 and x2 in your example categorical variables? Interactions() works well when both are categorical variables, but not when one of them is a continuous variables (e.g. price).","Dec 13, 2016 at 23:05",,,,41029376
68896539,68896539,"Just setting 
seed
 will not work. With deep learning you must also set 
reproducible=TRUE
. This latter argument is what forces it to run on a single core.","Nov 28, 2016 at 8:18",,,,40829547
68897251,68897251,"@DarrenCook, Forgot about that part. adjusted answer.","Nov 28, 2016 at 8:40",,,,40829547
68887365,68887365,"Thank you, Darren, for this explanation this. If I use more than two hidden layers, how can I plot the results? Thank you","Nov 27, 2016 at 23:02",,,,40802277
68896444,68896444,"@forever You might use 
hidden = c(32,2,32)
, meaning 32 neurons, then 2, then back out to 32. You  then extract the middle layer, with 
f <- h2o.deepfeatures(m, tfidf, layer = 2)","Nov 28, 2016 at 8:14",,,,40802277
68923482,68923482,How can I know if I use the right parameters?. How can I plot the error vs epochs?,"Nov 28, 2016 at 21:00",,,,40802277
68923735,68923735,"@forever Re: ""right parameters"". Neural net tuning feels like more art than science :-)  Just keep experimenting (h2o's grids can help). Re: ""plot error vs. epochs"". Look at the score history (there is a ready-made chart in the Flow UI, or you can fetch the data with 
h2o.scoreHistory(m)
.)","Nov 28, 2016 at 21:09",,,,40802277
68924955,68924955,Do we have an example of using Denoising Autoencoder and Stacked Autoencoder?,"Nov 28, 2016 at 21:53",,,,40802277
90093371,90093371,""" what I prefer to do is to take the encoded vectors and pass them to a standard back-error propagation neural network"" - Hi, can you pls elaborate this or provide an example to do that?","Jul 27, 2018 at 17:59",,,,48517280
90173961,90173961,"Take the hypothetical problem where you want to classify a set of images as porn/not porn. Assume input images of size [500x500] (250,000 dimension vectors). Our output will be a 2 dimension vector: [0,1] = porn, [1, 0] not porn. As you can imagine a 250,000 dimension vector is quite huge and contains a lot of information. A logical first step could be to FIRST train an autoencoder on the image data to ""compress"" the image data into smaller vectors, often called feature factors,  (e.g. 250 dimensions), and THEN train the image feature vectors using a standard back-propagation numeral network.","Jul 31, 2018 at 0:57",,,,48517280
90174003,90174003,"The autoencoder trained feature vectors ideally contain less noise, and more ""important"" information about the original images. And being of smaller size, it makes them more ideal/practical to train in a smaller neural network via something like back-error propagation, as it has less information it has to filter/learn.","Jul 31, 2018 at 1:01",,,,48517280
68780976,68780976,I am new to SPRAK and AKKA. I have downloaded the project and successfully executed it in my local machine. Can I run the same application in Yarn? Can I use it in production?,"Nov 24, 2016 at 5:43",,,,40778389
68781373,68781373,It is not a production level code ! You can change it according to your use case !,"Nov 24, 2016 at 6:02",,,,40778389
68781574,68781574,"If I want run the code in yarn mode, What are all the changes I should do? Can I not use AKKA rest in yarn mode?","Nov 24, 2016 at 6:11",,,,40778389
68781886,68781886,That I have to check ! Please go ahead and see for yourself and let me know here too ! If you can document it how to run it in cluster mode successfully and make a PR on this Repository . I would be glad to accept it !,"Nov 24, 2016 at 6:23",,,,40778389
93856622,93856622,"also, you can download other versions by changing the numbers 4301 to upward or downwards,  
h2o-release.s3.amazonaws.com/h2o/master/4301/index.html","Nov 27, 2018 at 5:53",,,,40652307
68403774,68403774,"Thank you! I used '--data-urlencode' and ""nfs://"" prefix. It worked.","Nov 14, 2016 at 8:11",,,,40545929
68408948,68408948,@user3117619 Great - that is useful to know. Thanks!,"Nov 14, 2016 at 10:43",,,,40545929
68081151,68081151,Everything works after installation in a new folder. Thank you,"Nov 4, 2016 at 5:27",,,,40399241
68012115,68012115,"Ah rats, ok. Thanks!","Nov 2, 2016 at 12:39",,,,40370180
68172260,68172260,"When this is the cause you get an error message explicitly saying ""version mismatch"".  This sounds more like a change in the behaviour of h2o.load_model() between 3.6 and 3.10?","Nov 7, 2016 at 11:19",,,,40370180
67983593,67983593,"FYI: I reported the issue here: 
0xdata.atlassian.net/browse/SW-248","Nov 1, 2016 at 17:21",,,,40365216
67986485,67986485,Help me out a bit. where do I find the python2 specific code to modify? I am not able to figure out looking at the notebook UI.,"Nov 1, 2016 at 18:46",,,,40365216
68009394,68009394,"In the notebook that should be enough, but unfortunately we are also missing some changes in pysparkling, I should commit them today though","Nov 2, 2016 at 11:26",,,,40376640
68241214,68241214,"The version in master was updated to support Python3: 
github.com/h2oai/sparkling-water/blob/master/py/examples/…
  The change will be propagated into release branches soon.","Nov 9, 2016 at 0:23",,,,40376640
67723460,67723460,"This is exactly what I thought.  I dug deeply into the 
ScoringInfo
 code and found that the scoring results are indeed sorted, however, I see no way to correlate the 
ScoringInfo
s with either the 
Model
 or the params which is the key element I'm missing.  Your post looks like it's the answer in R, but I was hoping to find it in Java.","Oct 25, 2016 at 1:59",,,,40227836
67757228,67757228,"The Model exposes ScoringInfo as a public property: 
github.com/h2oai/h2o-3/blob/master/h2o-core/src/main/java/hex/…
.","Oct 25, 2016 at 18:48",,,,40227836
67762023,67762023,"This is correct, but I don't want to have to traverse through each Model using 
grid.getModels()
 and compare the best 
ScoringInfo
 to each Model's scoring info, that seems hacky.  It just seems strange that the 
Grid
 object doesn't expose a method called something like 
getBestParams
 which is what I was initially looking for.  I've updated my question with some more info.","Oct 25, 2016 at 21:09",,,,40227836
78102187,78102187,"This no longer works in H2O-3.  The new version is: g.get_grid(sort_by='auc',decreasing=True)","Aug 8, 2017 at 14:44",,,,40213575
67690670,67690670,"Re: ""PostFile is not in documentation"". Is it just ""not documented yet"", or is it not officially part of the public interface (e.g. so it might change in future).","Oct 24, 2016 at 7:56",,,,40208004
67718844,67718844,"@DarrenCook It 
is
 part of the public interface, so it's not going to change in the future. It is not in the official documentation yet because it doesn't follow the standard scheme of all other endpoints, so it may require some hacking to it properly documented.","Oct 24, 2016 at 21:26",,,,40208004
91312410,91312410,"Hey, I am using h2o-bindings api to train model. I used ""h2o.train_gbm(gbmParams);"" and got ""ModelKeyV3 modelKey = (ModelKeyV3)job.dest; ModelsV3 models = h2o.model(modelKey); GBMModelV3 model = (GBMModelV3)models.models[0];""  . But I don't know how to transform the GBMModelV3 to MOJO model. I didn't find any method that can do this kind of things. So how can I got mojo model in h2o-bindings api? ps： I am using java.","Sep 5, 2018 at 9:06",,,,48465047
67655023,67655023,"So 
auc
 is apparently not supported anymore so had to do 
mse
 or 
r2
. Thanks for the advise though!","Oct 22, 2016 at 16:43",,,,40186343
77447596,77447596,Can we export these results somehow in a file?,"Jul 21, 2017 at 14:57",,,,40186343
77457478,77457478,"auc should be supported as long as you are doing a binary classification problem, please make sure your target variable is an enum with 
.asfactor()
  (you can find examples in the h2o user guid).","Jul 21, 2017 at 19:54",,,,40186343
77457605,77457605,"I don't think you can export the grid search object as a table, but you can get an individual model's information from the grid search table (h2o.get_model('<your model id>') and then export parts of those results to a file (anything that is type H2OFrame)","Jul 21, 2017 at 19:58",,,,40186343
67589792,67589792,"I have also added my workaround as a separate answer.  h2o.glm can handle factors automatically, but I have to do a workaround so that essentially 0*0 = 1*0 = 0*1 = 0.  My workaround collapses 3 levels 0*0, 1*0, 0*1 into a single level.","Oct 20, 2016 at 17:08",,,,40159426
67595346,67595346,"@jmuhlenkamp I think you'll find the above code more efficient (and giving the same values?),  as I've only used H2O built-in functions. If I've understood your solution correctly it is ""Have H2O make the wrong data, then fix it in R code""?","Oct 20, 2016 at 19:45",,,,40159426
67597306,67597306,My solution actually only uses R code to make the level1 character vector and then applies h2o.ifelse to fix the data (I've updated my ifelse to be h2o.ifelse to make this more clear).  It by no means passes the full data from h2o back to R.  It's also preferable for me as my real data (not posted here) has some factors with lots of categories.  In my workaround I only need to specify the factor and rather than the specific levels.,"Oct 20, 2016 at 20:47",,,,40159426
67028114,67028114,Thanks! It would be great if you could also point me to some documentation related to the ml pipelines support for sparkling water.,"Oct 5, 2016 at 9:48",,,,39843657
67104086,67104086,"@void unfortunately we don't have much in terms of documentation as we're still implementing this and consider it an experimental feature. For now we only support H2O's GBM and DeepLearning as part of the pipelines (here's some example code 
github.com/h2oai/sparkling-water/blob/master/examples/pipelines/…
). We are very open to contributions :-)","Oct 7, 2016 at 4:55",,,,39843657
67146379,67146379,Thanks a lot for the reply! Please point me to any issues (jira) related to adding more algorithm support to pipelines? I would like to keep track.,"Oct 8, 2016 at 12:06",,,,39843657
66817961,66817961,Thank you! It worked. I missed 'export_weights_and_biases' in the documentation.,"Sep 29, 2016 at 4:11",,,,39718877
66535167,66535167,Thanks for this workaround. I'd be also grateful for confirming if it's a bug or not and when it is possible to get this issue resolved.,"Sep 21, 2016 at 10:38",,,,39611616
66571565,66571565,@user2280549 I added the link to the bug report.,"Sep 22, 2016 at 8:04",,,,39611616
66453654,66453654,"I know about the POJO, I just wanted to get back to old model, but cluster is already running new version. Thanks for the ticket. Will keep an eye on it.","Sep 19, 2016 at 11:27",,,,39568760
66454274,66454274,"@JaKu I'd keep expectations low - I got the impression it was not going to happen unless lots of people (H2O's paying customers in particular) start asking for it.  (I.e. developers, whatever the project, love the flexibility to change binary formats, and not have to worry about backwards compatibility.)","Sep 19, 2016 at 11:44",,,,39568760
66705448,66705448,"@JaKu (and anyone else interested) I got frustrated by this again, so tried to hack my way round it, but failed. I added a comment to the ticket. If you vote and/or comment there I think it is more likely to get addressed.","Sep 26, 2016 at 13:06",,,,39568760
80088973,80088973,"I have version 3.15.0.4050 on my AWS and 3.15.4052 on my mac, and I cant make  the mac read the AWS generated model and cannot find the right version of h2o to install on the mac. frustrating.","Oct 4, 2017 at 14:37",,,,39568760
80089852,80089852,"@WoodyPride It seems in the past year that ticket has got exactly zero votes. Personally this is my biggest complaint about H2O, but obviously not the case for other people.    BTW, I think all releases are to be found on S3... can't seem to find the URL at the moment, though.","Oct 4, 2017 at 14:58",,,,39568760
66465804,66465804,"Thanks for the explanation. So the only difference betwn your codes and mine is 
h2o.init(ip=""localhost"", port = 54321 + (i*2),...)
. By assigning a different port, h2o creates a separate cluster for each thread.","Sep 19, 2016 at 16:34",,,,39549658
66466273,66466273,"@horaceT Also the 
as.h2o()
 data upload has to go inside the for loop. (I also put the 
library(h2o)
 inside the foreach loop, though I'm not sure if that was required.)  (As noted the code won't work until the port bug is fixed, anyway.)","Sep 19, 2016 at 16:47",,,,39549658
66466886,66466886,"I have not tested it but I just want to understand the concept. The call 
h2o.init(...)
 creates a cluster and each cluster is attached to one and only one thread. I can't have multiple threads running inside the same cluster. Is that how it's supposed to work?","Sep 19, 2016 at 17:05",,,,39549658
66467694,66467694,"I find it helps to always think of the H2O cluster as being on a separate machine (or set of machines) to your R client.  The H2O cluster will use as many threads as you assign to it. Your R client is just sending instructions to that cluster, on the remote machine. There is no calculation happening on the client machine, so whether your R client is using a single thread or multiple threads does not make anything happen more quickly..  You can have multiple clients connected to an H2O cluster, each uploading, downloading, launching models, etc.","Sep 19, 2016 at 17:31",,,,39549658
65765913,65765913,"It seems I'd already reported the grid output bug a month ago: 
0xdata.atlassian.net/browse/PUBDEV-3153","Aug 29, 2016 at 19:20",,,,39213568
65772580,65772580,Why do you think that my intention was to set input_dropout_ratio to zero? My intention was to learn both the input and hidden dropout ratio and including the zero in the lists in order to consider not using dropout as well. Do you spot a fallacy in my intention?,"Aug 30, 2016 at 0:25",,,,39213568
65780423,65780423,"@abvaekvnl Sorry, bad assumption by me. I'll edit my answer to put it back in!","Aug 30, 2016 at 7:28",,,,39213568
66619138,66619138,"How do we calculate the 
class_sampling_factors
? For example if I have dataste which contains 1000 datapoints from positive class and 50000 datapoints from negative class, what will be the sampling factors here and how will I compute it?","Sep 23, 2016 at 10:36",,,,39315859
66620049,66620049,"@Newbie They are just how much you want to over-sample (or under-sample if less than 1.0) each class. So, in your case, I guess you want to over-sample each ""positive"" sample 50 times? So you give 
class_sampling_factors = c(50, 1)
  (assuming ""positive"" is the first class). BUT NOTE: that is the default behaviour of just setting 
balance_classes
! Only bother setting 
class_sampling_factors
 if you need a different ratio.","Sep 23, 2016 at 11:01",,,,39315859
65718923,65718923,"Thank you very much! If I use this commands 
h2o.clusterInfo()
 and 
dath2o <- as.h2o(dat, destination_frame = ""dat"")
  it works!","Aug 28, 2016 at 7:53",,,,39176039
65547283,65547283,"Thank you @Avkash Chauhan, I vl go through this link","Aug 23, 2016 at 11:50",,,,39090678
65443734,65443734,"Awesome! Someone else pointed me to 
groups.google.com/forum/#!topic/h2ostream/TkNkMFprzf0
, which is a bit old but I was able to verify that 
h2o.find_threshold_by_max_metric(h2o.performance(dlmodel), ""f1"")
 was indeed the threshold that seems to be used","Aug 19, 2016 at 20:06",,,,39046859
65336027,65336027,"Thank you sir, I forgot about this option altogether.","Aug 17, 2016 at 8:51",,,,38980384
65311459,65311459,"That's correct, but it's not a 
quanteda
 behaviour, but the fact that any data.frame is dense. This is a nice solution to avoid the coercion to a dense object.","Aug 16, 2016 at 15:53",,,,38974836
65312526,65312526,"I agree with you, it makes no sense to convert sparse matrix to dense data.frame. Just pointed. We can convert sparse matrix in triplet form to data.frame, but this is another story.","Aug 16, 2016 at 16:23",,,,38974836
65276882,65276882,"Thank you for your suggestion, please go through the above edited query.  CRAN h2o, is producing error in the key argument in the foll code,         prostate.hex <- h2o.assign(data = prostate.hex, key = ""myNewName""),     
no key argument is found","Aug 15, 2016 at 18:53",,,,38951905
65277889,65277889,"@varun I'm confused: if you are on to using 
h2o.assign()
, does that mean running the simple 
install.packages(""h2o"")
 worked? If you have successfully installed H2O, and have a question about 
h2o.assign()
 that should be a new question. (See 
meta.stackexchange.com/questions/39223/…
 )","Aug 15, 2016 at 19:25",,,,38951905
65633774,65633774,Let me give you a shout out. Awesome explanation!,"Aug 25, 2016 at 12:11",,,,39135080
65268867,65268867,"This points in the right direction. However, side-by-side tables - at least as shown in the linked posts, are not necessarily matching the corresponding coefficients. They just simply put two tables beside each other, right?","Aug 15, 2016 at 14:48",,,,38904233
65205918,65205918,This doesn't seem like an answer (yet).,"Aug 12, 2016 at 18:42",,,,38924517
65163864,65163864,"yes the second example should have said h2o.importFile, thanks for catching that. I'll edit it.","Aug 11, 2016 at 17:26",,,,38879746
65262015,65262015,"Thanks for the ticket Lauren, seeing as you are a member of 0xdata, any idea when the feature will be implemented ?","Aug 15, 2016 at 11:21",,,,38860691
130419436,130419436,@Lauren Do you mean RMSLE added from version 3.10.0.5?,"Sep 26, 2022 at 22:02",,,,38860691
64837255,64837255,"Is 
.logloss()
 really returning the accuracy or precision of a model ? because when I look ip on the documentation, I get only the logloss it self. Do I have to do something more than printing printing the value?","Aug 2, 2016 at 21:08",,,,38724825
91718601,91718601,"@sedioben No, it's not returning accuracy.  Hopefully Lauren can fix the answer.","Sep 18, 2018 at 12:55",,,,38724825
91884958,91884958,@sedioben I have updated my answer sorry for the confusion.,"Sep 24, 2018 at 0:53",,,,38724825
93708329,93708329,Hi I have the same exact problem. Can't resolve it even if I specified a new port.,"Nov 21, 2018 at 16:53",,,,42823389
93847498,93847498,"@MarcoFumagalli Are all your ports blocked?  Otherwise, setting to a different random port should work.","Nov 26, 2018 at 20:47",,,,42823389
64792283,64792283,are you just looking for a way to sort your data?,"Aug 1, 2016 at 20:15",,,,38689601
64796895,64796895,yes. I just want to organize my data based on year. same as the one i have attahed,"Aug 1, 2016 at 23:42",,,,38689601
64447795,64447795,"ok thanks! but this means that i have to re-run the model to save it? or i can load tho old model and then save it using 
h2o.loadModel()
? (last time the model training took 17h)","Jul 22, 2016 at 12:46",,,,38515114
64451010,64451010,"@FrancescoDalPont If you didn't use h2o.saveModel() you cannot load it, and will need to re-make it. Sorry! If the model is taking that long to train, take a look at checkpoints: you can make, say, the first 50 trees, then save that model, but also carry on learning. And repeat this every 50 trees (or every hour - however many trees you make in one hour). Also, once the model is good enough for you, you just stop.","Jul 22, 2016 at 14:07",,,,38515114
64311249,64311249,"Hi Darren, thanks for the quick answer. The good news is that I can now start a cluster from within R. The bad news is that R freezes as soon as I execute  ""system(command = launchH2O, intern =TRUE, wait=FALSE)"". In fact, R does not freeze but it tells me that it is busy. Only after shutting down the cluster via my browser (ip:54321), R stopps being busy again...   do you have an idea?  PS: I used another path for the working directory but this obviously works fine since the cluster starts...","Jul 19, 2016 at 8:40",,,,38446001
64311837,64311837,"I got it - you have to set intern = FALSE since the interpreter waits in case you've set intern = TRUE, even if wait is set to FALSE. So system(command = launchCluster1, intern = FALSE, wait=FALSE) works. Would you mind to explain how to shutdown the clusters again via cmd?","Jul 19, 2016 at 8:55",,,,38446001
64317009,64317009,"@Constantin It should just be 
h2o.shutdown()
 from within R, when connected to the cluster.","Jul 19, 2016 at 10:55",,,,38446001
64318413,64318413,"By executing h2o.shutdown(), I cannot explicitly indicate which cluster I want to shutdown, right?","Jul 19, 2016 at 11:27",,,,38446001
64319308,64319308,"Your R script can only connect to one cluster at a time. So it would shutdown whichever one you are connected to (whichever one you did 
h2o.init()
 for).","Jul 19, 2016 at 11:47",,,,38446001
64202106,64202106,"Thank you, I will apply your approach over the weekend!","Jul 15, 2016 at 13:07",,,,38361213
64115639,64115639,Hadn't even crossed my mind to slice it like a numpy array. Thanks!,"Jul 13, 2016 at 12:25",,,,38341393
82657227,82657227,"Using 
axis
 argument also works: 
df = df.drop([0,1,2], axis=0)
. But 
inplace
 does not","Dec 16, 2017 at 14:22",,,,38341393
64205091,64205091,For my case I figured out the problem and the solution. Your troubleshoot mechanism also helped to to find out what is going on.,"Jul 15, 2016 at 14:17",,,,38278020
63657766,63657766,"Hi Darren, awesome, the problem is solved by setting ip and the port by 54321. As you said, the problem should be related to the ipv6 addresses. Thanks a lot.","Jun 30, 2016 at 0:23",,,,38109759
75305016,75305016,"But one of the error reads - ""On /127.0.0.1 some of the required ports 54321, 54322 are not available, change -port PORT and try again"". I wonder why this worked for you despite the error","May 23, 2017 at 19:38",,,,38109759
64129201,64129201,There are 2 ML packages in Spark currently as one is the old one and the second one (aimed at DataFrame) is the new on - the old one is there for backwards compatibility,"Jul 13, 2016 at 17:46",,,,38358325
134798425,134798425,"This answer puts more light on the differences: 
stackoverflow.com/q/38835829/2650427","Jun 10, 2023 at 21:00",,,,38358325
64129017,64129017,"Thanks for the help, these steps in the code are running on spark and spark supports vector as column type. In future steps H2O it self transforms  that like the way you already mentioned above.","Jul 13, 2016 at 17:40",,,,38131534
63564023,63564023,"Thx. How do I write this into my CSV? I tried to separate the hobbies with commas (e.g. ""singing,painting"") but that didn't work. I don't have to use a CSV file if there is a better format.","Jun 27, 2016 at 20:16",,,,38042926
63577052,63577052,"Sorry, @MarkusKramer, I'd missed the point of your question. Just updated my answer.","Jun 28, 2016 at 7:25",,,,38042926
63604557,63604557,"thanks for the explanation. so the ""one hot encoding"" method suggested by Thomas is the answer for H2O as well","Jun 28, 2016 at 18:53",,,,38042926
66058133,66058133,"Works like a charm! Enough to do 
import org.apache.spark.h2o._
 and 
val h2oContext = new H2OContext(sc).start()
 in the start of the notebook.","Sep 7, 2016 at 8:20",,,,39314845
63072404,63072404,"Thanks for the help, apparently the problem was that I forgot to close the terminal...","Jun 14, 2016 at 5:44",,,,37781534
63182282,63182282,That save my life!,"Jun 16, 2016 at 14:49",,,,37781534
63030398,63030398,"As an follow-up -- if you are only planning on starting H2O from Python (or R), then it's easier to just use the Python (or R) module, rather than dealing with the stand-alone H2O jar.","Jun 13, 2016 at 3:49",,,,37780288
74006528,74006528,"The data is not big enough for Spark/Hadoop setup. It generally varies between 50 to 1GB (having few hundred rows). Right now, I am using [H2o,ai] ( 
h2o.ai
) as it's java based, so it's going well with my Java-based product. But it has limited ML algorithms (no SVM etc.). Eventually, I would like to call a python (or R) from my java based application to utilize rich set of ML algorithms.","Apr 18, 2017 at 15:00",,,,42717648
74008340,74008340,I mean to say- data size is between 50 MB to 1 GB (max),"Apr 18, 2017 at 15:38",,,,42717648
74012056,74012056,"Given those data sizes, it should be trivial to implement the ML in Python or R. I would suggest that rather than trying to call R or Python from Java, serialise the data into an ingestable format (e.g. CSV) and make a system call (batch/bash) to run the processing in Python or R. This ties in with your need to support cross-platform compilation.","Apr 18, 2017 at 17:14",,,,42717648
74012282,74012282,"In addition, as you are shuttling the data between different frameworks, I would suggest that you spend some time developing a set of schemas for the models that you would like to develop. Then develop software that matches these interfaces as defined by the requirements - this will naturally create a framework for your model and a testing framework for robust development.","Apr 18, 2017 at 17:20",,,,42717648
8399311,8399311,"Thanks for developing this package.  I have a feeling I'm going to be revising a 
lot
 of my code to use this package.","Aug 11, 2011 at 17:48",,,,7030140
8408411,8408411,"On chat I was asked to self ask/answer (which apparently is 
encouraged
) - that question is 
here","Aug 12, 2011 at 7:29",,,,7030140
15358264,15358264,@MatthewDowle Want to include an explanation of when not to use := and to use set() instead?,"Jul 22, 2012 at 17:42",,,,7030140
15955941,15955941,@MatthewDowle I'd +1 again if I could.,"Aug 15, 2012 at 14:11",,,,7030140
36441091,36441091,"@jabberwocky No problem. 
set(DT, i, ""V1"", i)
 sets the 
""V1""
 column whilst 
set(DT, i, colVar, i)
 sets the column name contained in the 
colVar
 variable (e.g. if 
colVar = ""V1""
 was done earlier). The quotes indicate to take the column name literally rather than lookup the variable.","May 17, 2014 at 13:55",,,,7030140
62376728,62376728,"It's a start, but: (1) The ""Use Cases"" section states ""The following use cases are demonstrated with code examples"". Which code examples? (2) Is there a more detailed tutorial on that? For example, I'd like to use it as dependency in a Scala code built with Maven, how do I plug it in?","May 25, 2016 at 12:24",,,,37436584
62391290,62391290,"One more example (again, a web app, with a JS front-end): 
github.com/h2oai/app-consumer-loan","May 25, 2016 at 18:02",,,,37436584
62417536,62417536,@MateuszDymczyk : The R tutorial is great. Any chance there are Scala tutorials too?,"May 26, 2016 at 11:13",,,,37436584
62425349,62425349,"@shakedzy we don't really have that much Scala API, you can check some classes here 
github.com/h2oai/h2o-3/tree/master/h2o-scala
 but apart from that it's just the same as using the JavaAPI. We have quite a few Scala tutorials in SparklingWater 
github.com/h2oai/sparkling-water
 they are using RDDs as input but the models built are H2O so you can just swap the way you create the Frame (i.e. not from RDD but CSV for example) and use those examples","May 26, 2016 at 14:09",,,,37436584
72354903,72354903,"Here is a better link:   
docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html","Mar 5, 2017 at 19:31",,,,37459718
62341441,62341441,"What do you mean by turning off the proxy? Do you mean uncheck the box for proxy server in IE? If this is the case, the error persists.","May 24, 2016 at 15:25",,,,37402402
61935259,61935259,Its not clear at all which adjustments to make.  I have already adjusted all of those xml values and there is no difference.,"May 13, 2016 at 5:07",,,,37121763
62135243,62135243,"It seems ok, and is it still failing?","May 18, 2016 at 17:56",,,,37305263
61781988,61781988,"Thanks. Good tip with the 
.remove()
!","May 9, 2016 at 16:09",,,,37086248
86435813,86435813,"Source code: 
github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/…","Apr 7, 2018 at 19:25",,,,42885061
93564907,93564907,How would you draw this with colors / shapes indicating the classifications of the end nodes?,"Nov 16, 2018 at 17:53",,,,42885061
61513418,61513418,Great! Is there any added benefit of running more than one instance of h20 on a machine?,"May 2, 2016 at 9:31",,,,36972317
61513730,61513730,"That is on my list of questions, too! I suspect if you have a 4GB machine and a 16GB machine, you could run 4x4GB instances on the big machine to have a 5-node cluster, but you'd be better just running a single instance on the 16GB machine, and not use a cluster (because of communication overhead). But if you have 10 of the 4GB machines, and two of the 16GB machines, setting up an 18-node 72GB cluster might be better than a 12-node 48GB cluster, or a 2-node 32GB cluster.  If you try any exotic combinations I'd be interested to hear the results.","May 2, 2016 at 9:41",,,,36972317
61735664,61735664,"Thanks, this worked perfectly! Wasn't aware of getDeclaredField","May 8, 2016 at 4:14",,,,36926234
61394671,61394671,"Hi, thanks for your answer, the version is 3.8.1.4. It works well as you suggested. My original idea was to implement a k-fold function, I'm new to this stuff, I'm wondering if you know how to do it efficiently. Thanks.","Apr 28, 2016 at 13:35",,,,36897399
61404199,61404199,"You don't need to implement your own k-fold function, H2O does cross-validation already using the 
nfolds
 argument.  Check out this notebook for an example: 
github.com/h2oai/h2o-3/blob/master/h2o-py/demos/…","Apr 28, 2016 at 17:15",,,,36897399
61409686,61409686,"I understand the nfolds argument. What I am trying to do is to set the lambda_search=True and nfolds=3 at the same time in a GLM model. It seems won't let me do that. To avoid a manual grid search on lambda, I decided to implement a k-fold function. Does it sound like a proper way? Thanks a lot.","Apr 28, 2016 at 19:50",,,,36897399
61201694,61201694,thanks a lot for your time and detailed explanation.,"Apr 23, 2016 at 18:04",,,,36813707
64866289,64866289,"This is really a comment, not an answer. With a bit more rep, 
you will be able to post comments
.","Aug 3, 2016 at 14:22",,,,38745829
61025945,61025945,This exporting package only supports categorical variables. Are you aware of a package that supports continuous variables as well?,"Apr 19, 2016 at 13:54",,,,36712107
61035527,61035527,"There is this related question: 
stackoverflow.com/q/9301191/841830
  Does that help?","Apr 19, 2016 at 17:47",,,,36712107
65759824,65759824,"Good point - the point of both my question and my answer was wanting to know how many epochs were done before early stopping stopped it.  I find your stat - the number of epochs to reach the minimum of some metric - also interesting. Though, all of them should be used cautiously: you can easily vary +/-50% epochs to reach the same result from run to run.","Aug 29, 2016 at 16:04",,,,39209897
102015969,102015969,It's really surprising how little is documented about the java api. Thanks for posting. This would have been really painful to work out.,"Sep 4, 2019 at 15:16",,,,50958877
60721618,60721618,"And if I go with bundling, can I just use smth as simple as H20Frame df = CreateFrame(arrayiist double[], list colnames)  and then 'save' this object somehow to pass to h2o instance?","Apr 11, 2016 at 22:47",,,,36556356
62055453,62055453,"MASTER is just set to 
spark://myhost:7077
 - standard fare.","May 16, 2016 at 22:40",,,,36741952
75125281,75125281,"This is not a typo --  what is wrong with 20g per worker?  I had seen the problem 
starting
 at 2g .. but that is different from the amount of ram we actually need.","May 18, 2017 at 14:05",,,,44039480
75869244,75869244,"This is not an Sparkling Water issue, but matter of configuring your spark jobs with correct memory configuration.  You can set and override any spark configuration as part of 
sparkling-shell
 by passing it extra arguments you would normally pass to 
spark-submit","Jun 8, 2017 at 12:41",,,,44039480
60502081,60502081,"Per my question, I have already ensured that the response is encoded as a ""factor"".","Apr 6, 2016 at 7:27",,,,36439405
60580562,60580562,"Are you sure that column 322 is the response column?  Please paste the output of 
h2o.describe(sdcs_data[,322])
 or 
h2o.getTypes(data)[[322]]
.  It should say ""enum"".","Apr 7, 2016 at 19:36",,,,36439405
60580600,60580600,"Additionally, you can explictly set 
distribution = ""bernoulli""
 and if you have mistakenly not converted your response to a factor, then you will see a message that includes the following: 
""bernoulli distribution is not allowed for regression.""","Apr 7, 2016 at 19:37",,,,36439405
60580670,60580670,"Lastly, if you are seeing the error, 
""For CrossEntropy loss, the response must be categorical.""
, then that means that you have not converted the response to a factor.","Apr 7, 2016 at 19:39",,,,36439405
60131624,60131624,Thank you so much.,"Mar 27, 2016 at 18:27",,,,36243490
60154413,60154413,It does not work for h2o flow on hortonworks. How should I do to start flow in hortonworks sandbox 2.4?,"Mar 28, 2016 at 13:19",,,,36243490
60168495,60168495,"Here is the command to start H2O on Hadoop:  
hadoop jar h2odriver.jar -nodes 1 -mapperXmx 6g -output hdfsOutputDirName
  More info here: 
h2o-release.s3.amazonaws.com/h2o/rel-turan/4/index.html#Hadoop","Mar 28, 2016 at 20:37",,,,36243490
60065605,60065605,I can't ping to10.0.2.15 from my computer,"Mar 25, 2016 at 8:57",,,,36212869
60066090,60066090,"I tried port forwarding using NAT, but it does not work. How can I access from my computer to 10.0.2.15 @Erin","Mar 25, 2016 at 9:17",,,,36212869
60117330,60117330,"This is more of a networking question, sorry I can't be of more help.  This shows how to reach localhost if it's not accessible, perhaps you can try the same for your 10.0.2.15: 
community.hortonworks.com/articles/6227/…","Mar 27, 2016 at 3:33",,,,36212869
60125737,60125737,Thanks for your helps. This problem was because of incompatibility of my sandbox and h2o version. @Erin,"Mar 27, 2016 at 13:50",,,,36212869
59702178,59702178,"I think you are pointing to where it says ""
Variable importance is determined by calculating the relative influence of each variable: whether that variable was selected during splitting in the tree building process and how much the squared error (over all trees) improved as a result.
""  This isn't ""Gini"" or ""Decrease in Accuracy"".  Is there an equation, a paper reference, or pseudocode?  I'm finding very different behavior than the output of the R 'Boruta' library for RF.","Mar 16, 2016 at 2:21",,,,36024146
59791740,59791740,"We use the same tree code in our GBM and RF, so the underlying equation used is the same in both (although the algos work differently so the final GBM and RF importance values will be different).  The reference is equation 45 in this paper: 
statweb.stanford.edu/~jhf/ftp/trebst.pdf","Mar 17, 2016 at 22:30",,,,36024146
59794681,59794681,I love greedy approximations.  The importance is going to be as fundamentally different as the GBM is from the RF.  Thank you.,"Mar 18, 2016 at 1:06",,,,36024146
82469185,82469185,"@EngrStudent Am I missing something here? Because I don't see your question being answered. The SO answer is referring to ""squared error"" and the same for the relevant section of the linked paper. But your question was regarding a classification problem.","Dec 11, 2017 at 13:45",,,,36024146
82478032,82478032,"Erin pointed to it in the comment.  I was able to get where I needed from there, I think.  It was almost 2 years ago, so I don't have it off the top of my head.","Dec 11, 2017 at 17:42",,,,36024146
59640897,59640897,Additional note: i pushed upgrade of droplet to be in sync with the latest release of Sparkling Water,"Mar 14, 2016 at 17:30",,,,35982650
64507609,64507609,"I did the showJar step. The complaint is not about the water/fvec/Frame classes, but about missing org/apache/spark/repl/h2o/H2OInterpreter  I checked, the class sits in a SparklingWater jar sparkling-water-repl_2.10-1.6.4.jar  which is declared as a dependency, but ./gradlew shadowJar did not include it in the fat jar.  Anyone knows why not?","Jul 25, 2016 at 0:50",,,,35982650
69217717,69217717,@bhomass I have the same issue as your. Did you have solved it?,"Dec 6, 2016 at 20:44",,,,35982650
59520947,59520947,Thanks the new jar worked. I was just testing it out. I'll definitely allocate more memory when I do some performance evaluation.,"Mar 11, 2016 at 3:29",,,,35905442
59374320,59374320,"One more way: you can download Model as code, compile it, deploy it and then call directly from Python via Py4J.","Mar 7, 2016 at 21:24",,,,35854316
59375839,59375839,"Thank you Michal, solution 2 looks simple enough (I have compiled model in jar). But I cant reference spark context within map operation. How to deal with that?","Mar 7, 2016 at 22:13",,,,35854316
59555393,59555393,"@USER you are right - i forgot that 
sc
 is not accessible in rdd operations (this is good post with possible alternatives: 
stackoverflow.com/questions/31684842/…
)  For now, i do not have good answer. We need to somehow figure out this limitations.","Mar 11, 2016 at 20:43",,,,35854316
59243880,59243880,Surprised too. This is amazing. Any idea how well it compares in terms of speed to the other methods?,"Mar 4, 2016 at 1:15",,,,35786076
59243902,59243902,"I just edited the answer. Wondering as well, as the OP has an excellent test environment...","Mar 4, 2016 at 1:16",,,,35786076
59271548,59271548,"Great answer! Using this method, I was able to read and aggregate my data much much faster. Using 8 cores, I was able to read in and process 696,000 files in 1.5 minutes, where before it took 12 minutes. I will next need to scale this to millions of files, so this is a huge help! Can I ask what the 
grep -v ""^Day""
 part of the code is doing?","Mar 4, 2016 at 16:24",,,,35786076
59273563,59273563,"@Mike it's removing line 1 (the headers) in each of the files. It's a bit of a kludge, but I haven't found a cleaner way to do it, and is probably fine in general if you have a numeric first column. The '^' is an anchor. So it's saying ""remove all lines where the first three characters of the line are Day""","Mar 4, 2016 at 17:13",,,,35786076
59203777,59203777,"You can simplify this to 
rbindlist(lapply(dat.files, read.delim))
, by the way. +1. This seems faster than 
read_tsv
 too.","Mar 3, 2016 at 7:36",,,,35764724
59220242,59220242,"This did help quite a bit. I am now able to read in 232,000 files in 12 minutes instead of 18. I need this to be quite a bit faster still, but this is a great start","Mar 3, 2016 at 14:11",,,,35764724
59145746,59145746,"After I do h2o.saveModel and h2o.loadModel, I'm running into another issue which I have reported 
here","Mar 1, 2016 at 23:30",,,,35714569
59044879,59044879,"This is great, Erin. In the reproducible example I didn't pass a validation set, but in my actual code I did. Thank you!","Feb 28, 2016 at 14:30",,,,35679932
71355095,71355095,"H2O.grid() does not use validation_frame, actually. It uses training_frame only.  It ignores the validation_frame which you pass in for scoring purposes. The resulting model is overfitted, naturally, and therefore it is useless. Has this problem been fixed yet?  You can look at your winning model from the search and directly see its scoring progression to compare for example the training_auc and the validation_auc. You will see the problem if you look there.","Feb 7, 2017 at 14:33",,,,35679932
71994446,71994446,"@GeoffreyAnderson We have a ticket open to track your observations/issues with the 
validation_frame
 and 
h2o.grid
 and hope to resolve that shortly. You can follow the progress here: 
0xdata.atlassian.net/browse/PUBDEV-4035","Feb 23, 2017 at 19:29",,,,35679932
71999406,71999406,"@Erin L. Thank you for looking into.   FYI the model training functions (e.g. h2o.gbm(), h2o.randomForest()) and not the grid per se is the actual source of the problem as I perceive it according to continuing research I have done on it.  I look keenly toward fixing my user error if any or fixing with some workaround any software error if any.","Feb 23, 2017 at 21:57",,,,35679932
72042803,72042803,"Iris is a multiclass problem, which is why AUC is not supported in your example above.  The error message prints exactly the metrics that are supported for multiclass: 
Invalid argument for sort_by specified. Must be one of: [r2, mean_per_class_accuracy, max_per_class_error, err, total_rows, rmse, accuracy, err_count, logloss, mse, mean_per_class_error]","Feb 24, 2017 at 22:40",,,,38857065
71355673,71355673,"H2O does not tell you the version when you run library(h2o), but it would be helpful in cases like this.  H2O does not have a function like h2o.version either, but that would also be helpful in cases like this.","Feb 7, 2017 at 14:45",,,,42092632
71355807,71355807,H2O cluster version:        3.10.1.1 from h2o.init(),"Feb 7, 2017 at 14:48",,,,42092632
71512572,71512572,"I don't think this is answering the question (about how to retrieve an ordering of the models). If you are seeing a problem with validation_frame being ignored, I'd suggest deleting this answer and starting a new question, with a fully reproducible example.","Feb 11, 2017 at 9:47",,,,42092632
71995006,71995006,"@GeoffreyAnderson We don't need a special function in H2O to get the package version; that's what 
packageVersion()
 in R is for.  Just type: 
packageVersion(""h2o"")
 or 
h2o.init()
 to see the version number.","Feb 23, 2017 at 19:46",,,,42092632
71998587,71998587,"@GeoffreyAnderson H2O's algos do use the validation frame for early stopping. The model stops after the early stopping criteria are met, but doesn't provide an additional pruning step to find the highest AUC for the trees built so far. In other words the model saw that after the a specified # consecutive 
stopping_rounds
 the AUC didn't improve by a specified 
stopping_tolerance
. At that point it had built X trees with a certain score so that is the score it returns. It doesn't return the highest score, because the highest score in your example corresponds to a different number of trees.","Feb 23, 2017 at 21:31",,,,42092632
58276809,58276809,"Thanks Erin, I just wonder how could I still use my old code. It did not work (under the same platform) when i rerun it recently so that i rewrite my code. But I would love to reproduce my old results.","Feb 9, 2016 at 2:10",,,,35279111
58319683,58319683,"here is my old function:          h2oann <-h2o.deeplearning(x = 2:ncol(data),                     y = 1,                      data = h2otrain, # data in H2O format                    activation = ""TanhWithDropout"", # or 'Tanh'                    input_dropout_ratio = 0.2, # % of inputs dropout                    hidden_dropout_ratios = c(0.5,0.5,0.5),                     balance_classes = TRUE,                     hidden = c(50,50,50), # three layers of 50 nodes                    epochs = 100)","Feb 10, 2016 at 0:07",,,,35279111
58321898,58321898,"All you need is a copy of H2O Classic (2.0), which you can download here: 
s3.amazonaws.com/h2o-release/h2o-classic/master/latest.html
  Let me know if you have any trouble getting that installed.  It will be easiest if you uninstall your current h2o R package first.","Feb 10, 2016 at 2:29",,,,35279111
58408934,58408934,"Yes, H2O adds an NA class for all categoricals -- this is because if the test set contains a new category (not present in the training set), then that value will have somewhere to go.  Although this is not strictly needed for training, it is helpful if you want to productionize the models.","Feb 11, 2016 at 21:55",,,,35016975
57530359,57530359,"Thanks very much! Is it not the case that it is more effective to scale binary inputs as (-1,1) - centred near the origin, and likewise for categorical by using e.g.: urban = (0 1), suburban = (1 0), and rural = (-1 -1)? Or does having a bias unit mean that the effects coding (-1 for the omitted) is equivalent to standard 1-of-(C-1) coding? Further, since the the continuous features are only standardized then does that not mean we have one input with a range of 0 to 1 and another with range of 0 to 1,000,000 which results in it 'contribution' over-powering the tiny (0,1)?","Jan 20, 2016 at 10:01",,,,34888535
57530543,57530543,"I was just getting at this bit ""If you know that some inputs are more important than others, it may help to scale the inputs such that the more important ones have larger variances and/or ranges"" from the neural-nets/part2/ FAQ As it appears that normalising the continuous inputs will give them a range of e.g. (-10,10) compared to the categorical (0,1) and thus more importance in the neural network? Whereas if they are normalised to (0,1) also, so all our inputs are (0,1) then this seems to contradict that using (-1,1) is more effective. Thanks! Confused.","Jan 20, 2016 at 10:06",,,,34888535
57531493,57531493,sorry one last thing: is it the case that the normalisation method used depends on the activation functions in the hidden layer? To minimise the bias we want to use a range that falls within the input to the activation function that produces a non-flat gradient? So tanh has a wider range than sigmoid and ReLU has a wider range than tanh? So for ReLU we want to have input > 0? Thanks!,"Jan 20, 2016 at 10:30",,,,34888535
57558778,57558778,Thank you. Exactly what I needed,"Jan 20, 2016 at 22:08",,,,34833057
98209923,98209923,"There's an example that shows how to normalize here: 
stackoverflow.com/a/55717738/10913732","Apr 19, 2019 at 21:02",,,,55604352
57247155,57247155,"Thanks, @Cliff. To confirm: there is no 
data.table
 esque way of mutating the original table but reads are fine.  Right now, I am returning vectors back to the caller which gets assigned to h2o where the Frame is in scope to avoid the local copy. Another thing that I am unsure about is what happens when you do (in the main scope): 
dx = dx[dx$col > 5,]
.  Are both Frames in memory on H2O side?","Jan 12, 2016 at 17:59",,,,34748249
57514708,57514708,"H2O does the update-in-place optimization on the H2O side in some cases, and generally will rapidly recycle Big Temps in any case.  For the row-selector case, yes both Frames are in memory briefly.  At the next R GC the old copy of 'dx' will be reclaimed.","Jan 19, 2016 at 22:27",,,,34748249
57041071,57041071,"great, that will teach me for having a space in my user name!  Just because Windows allows it doesn't make it a good idea.  I wonder how many other applications this might cause problems with too.","Jan 7, 2016 at 5:12",,,,34644678
56794935,56794935,Thx for the fast answer.,"Dec 30, 2015 at 9:41",,,,34517366
62493806,62493806,Using the nightly release does not solve this bug for me. Running on Mac OSX.,"May 28, 2016 at 13:13",,,,34517366
62547659,62547659,"@timothyjgraham Please provide more info, and/or follow the bug report instructions on the h2ostream Google Group: 
groups.google.com/forum/#!forum/h2ostream","May 30, 2016 at 14:41",,,,34517366
62564072,62564072,@ErinL. Thanks - have posted a bug report on the Google Group.,"May 31, 2016 at 4:50",,,,34517366
56634337,56634337,"To add to Michal's second point, make sure you have the scala plugin installed for intellij.  Then do this:      
git clone https://github.com/h2oai/sparkling-water.git
;      
cd sparkling-water
;     
./gradlew idea
;     
open sparkling-water.ipr","Dec 24, 2015 at 1:30",,,,34445995
56634365,56634365,Thanks Michal.Can u tell me if this error is generated due to conversion of RDD to h2oRDD? or is this only due to configuration of dependency....,"Dec 24, 2015 at 1:32",,,,34445995
56682289,56682289,Can you please provide little bit information? Which Sparkling Water and Spark version are you using? From my user experience is better to use DataFrame instead of using strong-typed RDD.,"Dec 26, 2015 at 10:16",,,,34445995
56697471,56697471,"i m using ""spark-core_2.10"" % ""1.5.1"" and ""sparkling-water-core_2.10"" % ""1.5.6""","Dec 27, 2015 at 5:48",,,,34445995
56632224,56632224,Thanks  for the help.I tried with code(updated in question ) and got error(check log in question).Please let me know where it goes wrong.,"Dec 23, 2015 at 23:16",,,,34440562
59421890,59421890,This is not the answer i guess it should have been on comment section.,"Mar 8, 2016 at 22:27",,,,35878975
59422786,59422786,"I think the original question has diverged So I wrote answer according to Log 
java.lang.IllegalArgumentException: argument type mismatch","Mar 8, 2016 at 23:02",,,,35878975
79833592,79833592,"POJOs are great, and that's what I turned to, but they don't automate the H2O flow, and it's not an out-of-the-box solution, since you still have to write a main class and jar up the model. So, while this solves the problem, it doesn't really address the question in the way I was hoping","Sep 27, 2017 at 2:21",,,,44966386
56453656,56453656,"Thanks cliff. I was trying to test the 
swap-to-disk
 feature purposefully restricting the RAM usage of H2O. I will do that bleeding edge release and more RAM.","Dec 18, 2015 at 12:54",,,,34341959
67089513,67089513,"@Cliff, has any one you know of, tried using swap-to-disk on a much faster (order of magnitude faster) PCIE3-NMVe-M.2-connected solid state disk device like a Samsung 960 Pro?  My luck has been that I keep finding datasets that are just a wee bit too big for my system.... I might build a data mining rig specifically for use with H2O and one of those, and as much RAM as I can afford too.","Oct 6, 2016 at 17:19",,,,34341959
55878365,55878365,Thanks phiver. That was the problem. It's not really clear in the documentation that the SDK is needed.,"Dec 3, 2015 at 9:46",,,,34061741
55556257,55556257,I'm afraid this method will tell me which Java was launched by my Python client. What I'd like to know is which Java was used to launch H2O. I'm accessing this H2O instance thanks to the Python client talking to the REST API.,"Nov 24, 2015 at 14:58",,,,33881972
55556316,55556316,"BTW, if it solves my problem, it's OK to directly query the REST API from Python, without using the official Python client.","Nov 24, 2015 at 14:59",,,,33881972
55374416,55374416,"I want a matrix with 1 and 0 (1 if the client buy a product and 0 if not) and then use this matrix ( package recommenderlab.) in this code binary_matrix <- as(test, ""binaryRatingMatrix"")","Nov 19, 2015 at 12:56",,,,33804502
55374723,55374723,"@Kardu Your question is still not sufficiently specific. We still don't know what exactly you are trying to do, but you probably need to get more low-level than just using the package (if it doesn't offer facilities for data the size of yours). A dense binary matrix will be huge if you have many users and many codes. Even if you can fit it in your RAM you won't be able to work with it.","Nov 19, 2015 at 13:03",,,,33804502
55374821,55374821,"However, after looking into the documentation, a 
binaryRatingMatrix
 seems to be a sparse matrix object. Your question actually seems to be how to create that from your data.","Nov 19, 2015 at 13:05",,,,33804502
55374961,55374961,I have 200k users and more that 100k products.. its a huge matrix... this is the point.. I don't know How can I solve this problem?parallelize the code?,"Nov 19, 2015 at 13:08",,,,33804502
55375719,55375719,"No, simply study the documentation of the recommenderlab and arules packages. They use sparse matrices internally and should be able to deal with this. However, don't attempt to create a dense matrix-like object with tidyr since that will be too big for your RAM.","Nov 19, 2015 at 13:26",,,,33804502
54910953,54910953,"Thank you, Michael! The beauty of an in-memory application like h2o is that when you close the program everything is gone. ;) The problem still persists, though. FYI: I was using the latest stable release from October.","Nov 6, 2015 at 12:13",,,,33529451
54794919,54794919,"Hi Michal, Thanks for your response. i have this error after modify my code.java.lang.RuntimeException: ReplaceNA.Ljava/lang/Object;: Serialization not implemented","Nov 3, 2015 at 17:46",,,,33445842
54667921,54667921,"Thanks for response. Can you explain a little more to me? test is the class name, what about T? I can't understand how you parametrized the class? Really appreciate that","Oct 30, 2015 at 15:51",,,,33439867
54667970,54667970,"Just read documentations about generics: 
docs.scala-lang.org/tutorials/tour/generic-classes.html","Oct 30, 2015 at 15:52",,,,33439867
54668882,54668882,Thanks! Sorry for keep asking...in the documentation I can not understand how it T is bound to a real type?,"Oct 30, 2015 at 16:15",,,,33439867
54668888,54668888,Thanks for your patience,"Oct 30, 2015 at 16:16",,,,33439867
54669110,54669110,"Can I do class test[T <: String, T <: Double](a: T, b: T) extends MRTask {}","Oct 30, 2015 at 16:21",,,,33439867
54664415,54664415,Thanks for your help!,"Oct 30, 2015 at 14:22",,,,33427366
54596461,54596461,"Thanks, what does case_ mean? I post My result the max row is still 1","Oct 28, 2015 at 22:14",,,,33402425
54596640,54596640,"case _ means default, if the value was not matched to any of the previous cases, so it is neither 0 nor NaN.","Oct 28, 2015 at 22:22",,,,33402425
54596853,54596853,why not add a print statement? default => println(default); nc.addNum(1);,"Oct 28, 2015 at 22:31",,,,33402425
54597259,54597259,Can you tell me whats wrong with my original code? Thanks,"Oct 28, 2015 at 22:47",,,,33402425
54677338,54677338,"Thanks! I have solved this one! Can you help me take a look at this? 
stackoverflow.com/questions/33442536/…","Oct 30, 2015 at 20:40",,,,33444516
54537950,54537950,"I did. same problem. if I run the same dataset multiple times, I will get different results. I am not changing my code at all, but sometimes it will work, sometimes it will not. Am I missing a parameter that can control this?","Oct 27, 2015 at 15:16",,,,33340000
54599862,54599862,"H2O Deep Learning is not reproducible unless you set reproducible=TRUE and seed=1234 (or any integer).  In that case, it runs in single-threaded mode, and a lot slower, but will result in the same model every time.  The fact that your model isn't giving consistent results means that the parameters aren't good. If you need a deep network, you can try a stacked autoencoder: 
github.com/h2oai/h2o-3/blob/master/h2o-r/tests/testdir_algos/…
 or look at the MSE on the training data to confirm that it actually gets better over time.","Oct 29, 2015 at 0:55",,,,33340000
54627575,54627575,"is it different than the autoencoder parameter in the deeplearning function? technically that's also stacked if you have multiple hidden layers.  I also tried the same data set on a different machine and it worked properly. So I am almost certain it's an issue with the other machine. I tried removing R and deleting everything associated with it then re-install it, but that didn't solve the problem.","Oct 29, 2015 at 15:57",,,,33340000
54125993,54125993,"Welcome to SO, Erin L :)","Oct 15, 2015 at 21:08",,,,33158479
54126365,54126365,"Please do 
not use answers to ask
 for reply from the questioner, use comments instead;","Oct 15, 2015 at 21:21",,,,33158479
54126441,54126441,"Thanks, I will update my answer so it does not ask for a reply.  This solution should fix the problem.","Oct 15, 2015 at 21:24",,,,33158479
53859143,53859143,I tried that with no positive result. After that I tried opening everything for my IP and still nothing.,"Oct 8, 2015 at 14:05",,,,33005568
53883957,53883957,I'm not sure about your EC2/SG setup. We run RStudio and H2O on our EC2 cluster all the time - nothing special to be done there other than opening up the ports. Which AMI are you using?,"Oct 9, 2015 at 6:05",,,,33005568
73290363,73290363,"Please provide additional context such as version number, excerpt from change log, etc.","Mar 29, 2017 at 21:21",,,,43104008
53621645,53621645,"But that's the warning message. The actual error message is  Error in system2(command, ""-version"", stdout = TRUE, stderr = TRUE) : '""""' not found How do I solve that?","Oct 1, 2015 at 20:20",,,,32896116
53621692,53621692,"So, you're saying that you have a JDK installed and it is properly configured? What do you see if you type 
javac -version
 in the CMD?","Oct 1, 2015 at 20:21",,,,32896116
53623182,53623182,"Thanks! I updated my JDK version as you suggested, and it works now.","Oct 1, 2015 at 21:12",,,,32896116
69752588,69752588,This is very helpful but it begs the question of how to save a Matrix object n svmlight format. Unless I'm mistaken this is non-trivial; is there a neat solution?,"Dec 22, 2016 at 4:01",,,,32877906
79930251,79930251,"There is the discontinued RSofia Package that has a built in function 
write.svmlight
. I haven't used it for this specific case, but you can install the old source via 
devtools::install_github(""cran/RSofia"")","Sep 29, 2017 at 11:33",,,,32877906
138060553,138060553,What if you have multiple variables you want to predict the category for? Should you format it in one column with different options or n columns with 0/1 options for each category?,Apr 11 at 15:02,,,,32877883
55687422,55687422,you should paste the content which answers the question.,"Nov 27, 2015 at 21:32",,,,32259829
95444620,95444620,What is the similar function to h2o.weights for Python?,"Jan 22, 2019 at 16:12",,,,32322132
118821183,118821183,"Similar approach: I installed openjdk and the H2O Python module from 
H2O docs
 
pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o","Apr 23, 2021 at 0:38",,,,65101496
118821431,118821431,Isn't that only installing H2O? So you installed java separately?,"Apr 23, 2021 at 0:59",,,,65101496
118849489,118849489,"Yes, but I said I installed openjdk 
and
 H2O Python module from H2O docs - as opposed to h2o-py.","Apr 24, 2021 at 1:46",,,,65101496
51818709,51818709,"Thanks for that suggestion. I changed the JAVA_HOME environmental variable and also tried setting in the PATH, and I'm still getting an error. However, a clue: When I go to C:\Anaconda\h2o_jar and click on h2o.jar and then run h2o.init() from within python, I see the report that the cluster is healthy. I tried reconfiguring my JAVA_HOME and PATH to C:\Anaconda\h2o_jar, but that didn't work. Can I direct h2o.init() to run this file in any way?","Aug 12, 2015 at 2:01",,,,31953158
51818788,51818788,Did you try this command in MS-DOS while being inside java directory of h2o  java -jar h2o.jar  and then ran h2o.init() in R?,"Aug 12, 2015 at 2:07",,,,31953158
51214427,51214427,"This solution will work on a base R 
data.frame
 too, so not sure what's your problem with the linked dupe.","Jul 26, 2015 at 4:58",,,,31624645
51106313,51106313,"I have some issues with R interface before. I can of course give it another try ... I can save a flow, it is not a problem. But I'd like to be able to save a model. Otherwise something that has been fitting for hour is lost should anything happen to the app, or java, or computer .... The worst thing is that manual has an instruction how to do it, but I can not find these options. Probably the documentation is for a previous version, and something happened in the newer one ... I hoped maybe someone from H2O would comment ...","Jul 22, 2015 at 23:36",,,,31572847
56603034,56603034,What about loading in the flow?,"Dec 23, 2015 at 7:55",,,,32749374
56618758,56618758,Do you mean loading a saved '.flow' file?,"Dec 23, 2015 at 15:35",,,,32749374
59154825,59154825,The pojo of the model is not sufficient to re-import back in to H2O later.,"Mar 2, 2016 at 7:06",,,,33102005
94539750,94539750,In that case you have to save the model in binary format. So that in future you can load it again. But the down side of the binary format is that it is version dependent.,"Dec 19, 2018 at 7:01",,,,33102005
55684336,55684336,"Is this stille the ""current"" solution?","Nov 27, 2015 at 19:05",,,,31525994
59195843,59195843,"testing on h2o v3.8, you don't need to specify destination_frame in h2o.importFile()","Mar 3, 2016 at 1:17",,,,31525994
67371810,67371810,"They need to fix this. I am on version  3.10.0.2 and 
as.h2o
 is still broken for ordered factors.","Oct 14, 2016 at 16:26",,,,31525994
51458948,51458948,"Yes, I figured it out later. Thanks tho!","Aug 1, 2015 at 15:45",,,,31368028
50560037,50560037,"Thanks. that worked using this syntax 
h2o.saveModel(model, filename=""file:///C:/temp/model"")","Jul 8, 2015 at 4:50",,,,31270146
49861518,49861518,"i have checked memory usage during forest growing. The memory goes down rapidly and at the last I get the connection error. i'll kill other process, and run RF algo only.","Jun 18, 2015 at 9:53",,,,30883384
49861683,49861683,"Let us know if it helped. Alternatively, you can try less resource-demanding ML approach like deep neural networks, which also exist in H2O base edition.","Jun 18, 2015 at 9:57",,,,30883384
49878956,49878956,It was my mistake. Previously I was running H2O instance with default memory option (That is was too less for my data). Now I'm running the H2O instance with -Xmx14g option and algo is running successfully. Cheers...:). I'll consider your suggestion of deep learning if I'll get accuracy less than a threshold in my case.,"Jun 18, 2015 at 16:37",,,,30883384
53016203,53016203,"What does relative importance tell you? Does a higher value mean that that variable is the most contributing in predicting the target variable with respect to other variables? or is it the vice-versa? So, in your example, relative importance id higher for petal_len, does it mean it is the most important?","Sep 15, 2015 at 8:21",,,,31999499
47921862,47921862,"thank you for your help. But I want to use 
h2o.gbm
. It works only with h2o parsed data. And I get there the same error.","Apr 27, 2015 at 15:16",,,,29889006
77526451,77526451,What about Python?,"Jul 24, 2017 at 13:34",,,,34319119
98579233,98579233,"Is this only a problem for h20 temporary objects in loops? If I call a function and it creates temporary h20 objects, will R retain dead variables outside of the function scope?","May 3, 2019 at 6:17",,,,34319119
111361045,111361045,"Yes, this is the approach I developed a few years ago for h2o-3.  The java GC log output can then be sent to gceasy.io to visualize it.","Jul 18, 2020 at 20:17",,,,56173937
45202523,45202523,"That does seem to work, but is extremely slow when copying more than a toy example.","Feb 10, 2015 at 16:06",,,,28347846
45206165,45206165,R is fundamentally slow.  Have you looked at loading compressed csv into h2o?,"Feb 10, 2015 at 17:38",,,,28347846
98398776,98398776,"as.h2o still goes to file though, so this is not actually any faster than first writing to csv and then doing h2o.importFile - that's in fact exactly what as.h2o does...","Apr 26, 2019 at 14:08",,,,28347846
98400325,98400325,"The problem here definitely isn't R being slow, but just that passing data by going to file as h2o does is really slow... They should really fix this and provide an in-memory solution as the whole performance advantage of H2O is lost in this way...","Apr 26, 2019 at 14:55",,,,28347846
44771719,44771719,"This trims the last 2 elements from the string, which in this case, happens leave the first 6.","Jan 28, 2015 at 21:34",,,,28202714
44771903,44771903,"gsub('(.{6}).*','\\1', df1$var1)
 is a more literal translation of 
substr(x,1,6)
 .","Jan 28, 2015 at 21:40",,,,28202714
94099620,94099620,Why do we append a .hex?,"Dec 4, 2018 at 18:53",,,,35243251
65121838,65121838,"This is now quite out of date (since h2o version 3). See also: 
Unable to convert data frame to h2o object","Aug 10, 2016 at 17:55",,,,27579400
85150933,85150933,The answer by @Ram is the easier/simpler one.,"Mar 2, 2018 at 15:52",,,,27579400
43078407,43078407,"sub1<-h2o.exec(trans[trans$Type==1,rownames(trans)])
 surprisingly it improves the speed.","Dec 5, 2014 at 3:20",,,,27296668
43149584,43149584,"Do you mean 
trans[trans$Type == 1, colnames(trans)]
?","Dec 7, 2014 at 20:28",,,,27296668
43195155,43195155,yeah. a quick typo right there. thanks for correcting me,"Dec 9, 2014 at 5:26",,,,27296668
43237596,43237596,"Do you have a non-trivial, benchmarked example for the speed differences?","Dec 10, 2014 at 7:41",,,,27296668
54125628,54125628,"revolutionanalytics is a supplier of ""r"".  (
quora.com/What-is-Revolution-Analytics-equivalent-for-Python
)","Oct 15, 2015 at 20:57",,,,31953261
